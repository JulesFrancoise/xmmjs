{"version":3,"file":"index.es.js","sources":["../src/training_set/phrase.js","../src/training_set/index.js","../src/core/model_base_mixin.js","../src/common/euclidean.js","../src/kmeans/kmeans_training_mixin.js","../src/kmeans/index.js","../src/common/matrix.js","../src/common/gaussian_distribution.js","../src/core/em_training_mixin.js","../src/gmm/gmm_base_mixin.js","../src/gmm/gmm_training_mixin.js","../src/core/multiclass_mixin.js","../src/core/multiclass_training_mixin.js","../src/common/circular_buffer.js","../src/core/prediction_mixin.js","../src/common/validation.js","../src/gmm/gmm_prediction_mixin.js","../src/core/multiclass_prediction_mixin.js","../src/gmm/index.js","../src/hmm/hmm_base_mixin.js","../src/hmm/hmm_training_mixin.js","../src/hmm/hmm_prediction_mixin.js","../src/hmm/hierarchical_hmm_prediction_mixin.js","../src/hmm/index.js"],"sourcesContent":["/**\n * Data Phrase Prototype\n * @ignore\n */\nconst phrasePrototype = /** @lends Phrase */ {\n  /**\n   * Get the value at a given index and dimension\n   * @param  {Number} index index\n   * @param  {Number} dim   dimension\n   * @return {Number}\n   */\n  get(index, dim) {\n    if (typeof index !== 'number' || Math.floor(index) !== index) {\n      throw new Error('The index must be an integer');\n    }\n    if (dim >= this.dimension) {\n      throw new Error('Phrase: dimension out of bounds');\n    }\n    if (this.bimodal) {\n      if (dim < this.inputDimension) {\n        if (index >= this.inputData.length) {\n          throw new Error('Phrase: index out of bounds');\n        }\n        return this.inputData[index][dim];\n      }\n      if (index >= this.outputData.length) {\n        throw new Error('Phrase: index out of bounds');\n      }\n      return this.outputData[index][dim - this.inputDimension];\n    }\n    if (index >= this.length) {\n      throw new Error('Phrase: index out of bounds');\n    }\n    if (!this.inputData[index]) {\n      throw new Error('WTF?');\n    }\n    return this.inputData[index][dim];\n  },\n\n  /**\n   * Get the data frame at a given index\n   * @param  {Number} index index\n   * @return {Array<number>}\n   * @throws {Error} if the index is out of bounds\n   */\n  getFrame(index) {\n    if (index >= this.length) {\n      throw new Error('Phrase: index out of bounds');\n    }\n    if (this.bimodal) {\n      return this.inputData[index].concat(this.outputData[index]);\n    }\n    return this.inputData[index];\n  },\n\n  /**\n   * Push an observation vector to the phrase\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the observation's dimension does not match the\n   * dimension of the training set\n   */\n  push(observation) {\n    // console.log('push:', observation);\n    if (observation.length !== this.dimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    if (this.bimodal) {\n      this.inputData.push(observation.slice(0, this.inputDimension));\n      this.outputData.push(observation.slice(this.inputDimension, this.dimension));\n    } else {\n      this.inputData.push(observation);\n    }\n\n    this.length += 1;\n  },\n\n  /**\n   * Push an observation to the input modality only\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the phrase is not bimodal\n   * @throws {Error} if the observation's dimension does not match the\n   * input dimension of the training set\n   */\n  pushInput(observation) {\n    if (!this.bimodal) {\n      throw new Error('this phrase is unimodal, use `push`');\n    }\n    if (observation.length !== this.inputDimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    this.inputData.push(observation);\n    this.trim();\n  },\n\n  /**\n   * Push an observation to the output modality only\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the phrase is not bimodal\n   * @throws {Error} if the observation's dimension does not match the\n   * output dimension of the training set\n   */\n  pushOutput(observation) {\n    if (!this.bimodal) {\n      throw new Error('this phrase is unimodal, use `push`');\n    }\n    if (observation.length !== this.outputDimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    this.outputData.push(observation);\n    this.trim();\n  },\n\n  /**\n   * Clear the phrase's data\n   */\n  clear() {\n    this.length = 0;\n    this.inputData = [];\n    this.outputData = [];\n  },\n\n  /**\n   * Clear the phrase's input data\n   */\n  clearInput() {\n    this.inputData = [];\n    this.trim();\n  },\n\n  /**\n   * Clear the phrase's output data\n   */\n  clearOutput() {\n    this.outputData = [];\n    this.trim();\n  },\n\n  /**\n   * Compute the mean of the phrase (across time)\n   * @return {Array<number>} The mean vector (same dimension as the\n   * training set)\n   */\n  mean() {\n    const mean = Array(this.dimension).fill(0);\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        mean[d] += this.get(t, d);\n      }\n      mean[d] /= this.length;\n    }\n    return mean;\n  },\n\n  /**\n   * Compute the standard deviation of the phrase (across time)\n   * @return {Array<number>} The standard deviation vector (same dimension as\n   * the training set)\n   */\n  standardDeviation() {\n    const stddev = Array(this.dimension).fill(0);\n    const mean = this.mean();\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        stddev[d] += (this.get(t, d) - mean[d]) * (this.get(t, d) - mean[d]);\n      }\n      stddev[d] /= this.length;\n      stddev[d] = Math.sqrt(stddev[d]);\n    }\n    return stddev;\n  },\n\n  /**\n   * Compute the minimum and maximum of the phrase (across time)\n   * @return {Array<{ min: number, max: number }>} The min/max vector (same\n   * dimension as the training set)\n   */\n  minmax() {\n    const minmax = Array.from(\n      Array(this.dimension),\n      () => ({ min: +Infinity, max: -Infinity }),\n    );\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        minmax[d].min = Math.min(this.get(t, d), minmax[d].min);\n        minmax[d].max = Math.max(this.get(t, d), minmax[d].max);\n      }\n    }\n    return minmax;\n  },\n\n  /**\n   * Trim the phrase length to the minimum of the input and output lengths\n   * @private\n   */\n  trim() {\n    if (this.bimodal) {\n      this.length = Math.min(this.inputData.length, this.outputData.length);\n    }\n  },\n};\n\n/**\n * Create a data phrase, potentially bimodal. Phrases are data structures for\n * temporal data (e.g. gestures), used to constitute training sets.\n *\n * @param {Object} [params]                   Phrase parameters\n * @param {Number} [params.inputDimension=1]  Dimension of the input modality\n * @param {Number} [params.outputDimension=0] Dimension of the output modality\n * (optional)\n * @param {Array<String>} [params.columnNames=null] Data column names, e.g.\n * \\['accX', 'accY', 'accZ'\\] (optional)\n * @param {String} [params.label='']          Phrase label\n * @return {Phrase}\n * @function\n *\n * @property {Boolean} bimodal Specifies if the phrase is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} length Phrase length (number of frames)\n * @property {String} label Phrase label\n * @property {Array<String>} columnNames Columns names\n */\nexport default function Phrase({\n  inputDimension = 1,\n  outputDimension = 0,\n  columnNames = null,\n  label = '',\n} = {}) {\n  const dimension = inputDimension + outputDimension;\n  return Object.assign(\n    Object.create(phrasePrototype),\n    {\n      bimodal: outputDimension > 0,\n      inputDimension,\n      outputDimension,\n      dimension,\n      length: 0,\n      label,\n      inputData: [],\n      outputData: [],\n      columnNames: columnNames || Array(dimension).fill(''),\n    },\n  );\n}\n","import Phrase from './phrase';\n\n/**\n * Training Set Prototype\n * @ignore\n */\nconst trainingSetPrototype = /** @lends TrainingSet */ {\n  /**\n   * Get the training set size (number of phrases)\n   * @return {number}\n   */\n  size() {\n    return Object.keys(this.phrases).length;\n  },\n\n  /**\n   * Checks if the training set is empty\n   * @return {boolean}\n   */\n  empty() {\n    return this.length === 0;\n  },\n\n  /**\n   * Get a reference to a phrase by index\n   * @param  {number} phraseIndex phrase index\n   * @return {Phrase}\n   */\n  getPhrase(phraseIndex) {\n    if (Object.keys(this.phrases).includes(phraseIndex.toString())) {\n      return this.phrases[phraseIndex.toString()];\n    }\n    return null;\n  },\n\n  /**\n   * Iterate over all phrases in the training set. The callback function\n   * should take 3 arguments: the phrase, its index in the training set,\n   * and the phrases structure.\n   *\n   * @param  {Function} callback Callback function\n   */\n  forEach(callback) {\n    Object.keys(this.phrases).forEach((phraseIndex) => {\n      callback(this.phrases[phraseIndex], phraseIndex, this.phrases);\n    });\n  },\n\n  /**\n   * Add a phrase to the training set and return it.\n   * @param  {number} phraseIndex        phrase index\n   * @param  {string} [label=undefined]  phrase label (its index if undefined)\n   * @param  {Phrase} [phrase=undefined] Phrase data. If unspecified, an empty\n   * phrase is created.\n   * @return {Phrase}\n   */\n  push(phraseIndex, label = undefined, phrase = undefined) {\n    const p = (phrase !== undefined) ? phrase : Phrase({\n      inputDimension: this.inputDimension,\n      outputDimension: this.outputDimension,\n      columnNames: this.columnNames,\n      label: (label !== undefined) ? label : phraseIndex.toString(),\n    });\n    this.phrases[phraseIndex] = p;\n    return p;\n  },\n\n  /**\n   * Remove a phrase\n   * @param  {number} phraseIndex phrase index\n   */\n  remove(phraseIndex) {\n    delete this.phrases[phraseIndex];\n  },\n\n  /**\n   * Remove all phrases with a given label\n   * @param  {string} label class label\n   */\n  removeClass(label) {\n    this.phrases = Object.keys(this.phrases)\n      .filter(i => this.phrases[i].label !== label)\n      .map(i => ({ i: this.phrases[i] }))\n      .reduce((x, p) => ({ ...x, ...p }), {});\n  },\n\n  /**\n   * Clear the training set (delete all phrases)\n   */\n  clear() {\n    this.phrases = {};\n  },\n\n  /**\n   * Get the sub-training set composed of all phrases of a given class\n   * @param  {string} label class label\n   * @return {TrainingSet}\n   */\n  getPhrasesOfClass(label) {\n    const ts = TrainingSet(this); // eslint-disable-line no-use-before-define\n    ts.phrases = Object.keys(this.phrases)\n      .filter(i => this.phrases[i].label === label)\n      .map(i => ({ i: this.phrases[i] }))\n      .reduce((x, p) => ({ ...x, ...p }), {});\n    return ts;\n  },\n\n  /**\n   * Get the list of unique labels in the training set\n   * @return {Array<string>}\n   */\n  labels() {\n    return Object.keys(this.phrases)\n      .map(i => this.phrases[i].label)\n      .reduce((ll, x) => (ll.includes(x) ? ll : ll.concat([x])), []);\n  },\n\n  /**\n   * Get the list of phrase indices\n   * @return {Array<number>}\n   */\n  indices() {\n    return Object.keys(this.phrases);\n  },\n\n  /**\n   * Get the mean of the training set over all phrases\n   * @return {Array<number>} mean (same dimension as the training set)\n   */\n  mean() {\n    const sum = Array(this.dimension).fill(0);\n    let totalLength = 0;\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          sum[d] += this.phrases[i].get(t, d);\n        }\n      }\n      totalLength += this.phrases[i].length;\n    });\n\n    return sum.map(x => x / totalLength);\n  },\n\n  /**\n   * Get the standard deviation of the training set over all phrases\n   * @return {Array<number>} standard deviation (same dimension as the training set)\n   */\n  standardDeviation() {\n    const stddev = Array(this.dimension).fill(0);\n    const mean = this.mean();\n    let totalLength = 0;\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          stddev[d] += (this.phrases[i].get(t, d) - mean[d]) ** 2;\n        }\n      }\n      totalLength += this.phrases[i].length;\n    });\n\n    return stddev.map(x => Math.sqrt(x / totalLength));\n  },\n\n  /**\n   * Get the min and max of the training set over all phrases\n   * @return {Array<{ min: number, max: number }>} min/max (same dimension as the training set)\n   */\n  minmax() {\n    const minmax = Array.from(\n      Array(this.dimension),\n      () => ({ min: +Infinity, max: -Infinity }),\n    );\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          minmax[d].min += Math.min(minmax[d].min, this.phrases[i].get(t, d));\n          minmax[d].max += Math.max(minmax[d].max, this.phrases[i].get(t, d));\n        }\n      }\n    });\n    return minmax;\n  },\n};\n\n/**\n * Create a Training set, composed of a set of indexed data phrases\n * @param {Object} [params]                   Training set parameters\n * @param {Number} [params.inputDimension=1]  Dimension of the input modality\n * @param {Number} [params.outputDimension=0] Dimension of the output modality\n * (optional)\n * @param {Array<String>} [params.columnNames=null] Data column names, e.g.\n * \\['accX', 'accY', 'accZ'\\] (optional)\n * @return {TrainingSet}\n * @function\n *\n * @property {Boolean} bimodal Specifies if the training set is bimodal\n * @property {Number}  inputDimension Dimension of the input modality\n * @property {Number}  outputDimension Dimension of the output modality\n * @property {Number}  dimension Total dimension\n * @property {Array<String>} columnNames Columns names\n */\nexport default function TrainingSet({\n  inputDimension = 1,\n  outputDimension = 0,\n  columnNames = null,\n} = {}) {\n  const dimension = inputDimension + outputDimension;\n  return Object.assign(\n    Object.create(trainingSetPrototype),\n    {\n      bimodal: outputDimension > 0,\n      inputDimension,\n      outputDimension,\n      dimension,\n      columnNames: columnNames || Array(dimension).fill(''),\n      phrases: {},\n    },\n  );\n}\n","/**\n * Create the skeleton of a model\n *\n * @function\n * @param       {Number} inputDimension  input dimension\n * @param       {Number} outputDimension output dimension\n * @param       {Object} parameters      additional parameters to be copied\n * @constructor\n */\nexport default function ModelBase({\n  inputDimension,\n  outputDimension,\n  ...parameters\n}) {\n  const p = parameters;\n  delete p.bimodal;\n  delete p.inputDimension;\n  delete p.outputDimension;\n  delete p.dimension;\n  return /** @lends ModelBase */{\n    params: {\n      ...p,\n      get bimodal() {\n        return outputDimension > 0;\n      },\n      get inputDimension() {\n        return inputDimension;\n      },\n      get outputDimension() {\n        return outputDimension;\n      },\n      get dimension() {\n        return inputDimension + outputDimension;\n      },\n    },\n  };\n}\n\n/**\n * Check if an object is a base model (check for attribute existence)\n * @param  {Object}  o Source object\n * @return {Boolean}\n */\nexport function isBaseModel(o) {\n  if (!Object.keys(o).includes('params')) return false;\n  const keys = ['bimodal', 'inputDimension', 'outputDimension', 'dimension'];\n  return keys.map(key => Object.keys(o.params).includes(key))\n    .reduce((a, b) => a && b, true);\n}\n","/**\n * Compute the euclidean distance between to vectors\n * @param  {Array} v1\n * @param  {Array} v2\n * @return {number}\n */\nexport default function euclidean(v1, v2) {\n  return Math.sqrt(v1\n    .map((x1, i) => (x1 - v2[i]) ** 2)\n    .reduce((a, x) => (a + x), 0));\n}\n","import { isBaseModel } from '../core/model_base_mixin';\nimport euclidean from '../common/euclidean';\n\nconst kMeansTrainingPrototype = {\n  train(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) {\n      throw new Error('The training set is empty');\n    }\n\n    this.params.centers = Array.from(\n      Array(this.params.clusters),\n      () => new Array(this.params.dimension).fill(0),\n    );\n\n    // TODO: improve initialization =>\n    // https://www.slideshare.net/djempol/kmeans-initialization-15041920\n    //\n    if (this.trainingConfig.initialization === 'random') {\n      this.initializeClustersRandom(trainingSet);\n    } else if (this.trainingConfig.initialization === 'forgy') {\n      this.initializeClustersForgy(trainingSet);\n    } else if (this.trainingConfig.initialization === 'data') {\n      this.initClustersWithFirstPhrase(trainingSet);\n    } else {\n      throw new Error('Unknown K-Means initialization, must be `random`, `forgy` or `data`');\n    }\n\n    for (\n      let trainingNbIterations = 0;\n      trainingNbIterations < this.trainingConfig.maxIterations;\n      trainingNbIterations += 1\n    ) {\n      const previousCenters = this.params.centers;\n\n      this.updateCenters(previousCenters, trainingSet);\n\n      let meanClusterDistance = 0;\n      let maxRelativeCenterVariation = 0;\n      for (let k = 0; k < this.params.clusters; k += 1) {\n        for (let l = 0; l < this.params.clusters; l += 1) {\n          if (k !== l) {\n            meanClusterDistance += euclidean(\n              this.params.centers[k],\n              this.params.centers[l],\n            );\n          }\n        }\n        maxRelativeCenterVariation = Math.max(\n          euclidean(\n            previousCenters[k],\n            this.params.centers[k],\n          ),\n          maxRelativeCenterVariation,\n        );\n      }\n      meanClusterDistance /= this.params.clusters * (this.params.clusters - 1);\n      maxRelativeCenterVariation /= this.params.clusters;\n      maxRelativeCenterVariation /= meanClusterDistance;\n      if (maxRelativeCenterVariation < this.trainingConfig.relativeDistanceThreshold) break;\n    }\n    return this.params;\n  },\n\n  initClustersWithFirstPhrase(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const step = Math.floor(phrase.length / this.params.clusters);\n\n    let offset = 0;\n    for (let c = 0; c < this.params.clusters; c += 1) {\n      this.params.centers[c] = new Array(this.params.dimension).fill(0);\n      for (let t = 0; t < step; t += 1) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[c][d] += phrase.get(offset + t, d) / step;\n        }\n      }\n      offset += step;\n    }\n  },\n\n  initializeClustersRandom(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const indices = Array.from(\n      Array(phrase.length),\n      () => Math.floor(Math.random() * this.params.clusters),\n    );\n    const pointsPerCluster = indices.reduce(\n      (ppc, i) => {\n        const p = ppc;\n        p[i] += 1;\n        return p;\n      },\n      Array(this.params.clusters).fill(0),\n    );\n    for (let i = 0; i < indices.length; i += 1) {\n      const clustIdx = indices[i];\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.centers[clustIdx][d] += phrase.get(i, d);\n      }\n    }\n    this.params.centers.forEach((_, c) => {\n      this.params.centers[c] = this.params.centers[c]\n        .map(x => x / pointsPerCluster[c]);\n    });\n  },\n\n  initializeClustersForgy(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const indices = Array.from(\n      Array(this.params.clusters),\n      () => Math.floor(Math.random() * phrase.length),\n    );\n    this.params.centers = indices.map(i => phrase.getFrame(i));\n  },\n\n  updateCenters(previousCenters, trainingSet) {\n    this.params.centers = Array.from(Array(this.params.clusters), () =>\n      new Array(this.params.dimension).fill(0));\n    const numFramesPerCluster = Array(this.params.clusters).fill(0);\n    trainingSet.forEach((phrase) => {\n      for (let t = 0; t < phrase.length; t += 1) {\n        const frame = phrase.getFrame(t);\n        let minDistance = euclidean(frame, previousCenters[0]);\n        let clusterMembership = 0;\n        for (let k = 1; k < this.params.clusters; k += 1) {\n          const distance = euclidean(\n            frame,\n            previousCenters[k],\n            this.params.dimension,\n          );\n          if (distance < minDistance) {\n            clusterMembership = k;\n            minDistance = distance;\n          }\n        }\n        numFramesPerCluster[clusterMembership] += 1;\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[clusterMembership][d] += phrase.get(t, d);\n        }\n      }\n    });\n    for (let k = 0; k < this.params.clusters; k += 1) {\n      if (numFramesPerCluster[k] > 0) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[k][d] /= numFramesPerCluster[k];\n        }\n      }\n    }\n  },\n};\n\nexport default function withKMeansTraining(\n  o,\n  clusters,\n  trainingConfiguration = {},\n) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const trainingConfig = Object.assign({\n    initialization: 'random',\n    relativeDistanceThreshold: 1e-3,\n    minIterations: 5,\n    maxIterations: 100,\n  }, trainingConfiguration);\n  const model = Object.assign(o, kMeansTrainingPrototype, {\n    trainingConfig,\n  });\n  model.params.clusters = clusters;\n  return model;\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withKMeansTraining from './kmeans_training_mixin';\n\n/**\n * Train a K-Means model.\n *\n * @todo K-Means details\n *\n * @param  {TrainingSet} trainingSet           training set\n * @param  {number} clusters                   Number of clusters\n * @param  {Object} [trainingConfig=undefined] Training configuration\n * @return {Object}                            K-Means parameters\n */\nexport default function trainKmeans(\n  trainingSet,\n  clusters,\n  trainingConfig = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withKMeansTraining(\n    ModelBase({\n      inputDimension,\n      outputDimension,\n    }),\n    clusters,\n    trainingConfig,\n  );\n  return model.train(trainingSet);\n}\n","/* eslint-disable no-use-before-define */\nconst kEpsilonPseudoInverse = 1.0e-9;\n\n/**\n * Matrix Prototype\n * @type {Object}\n * @property {Array} data Matrix data\n * @property {Number} ncols Number of columns\n * @property {Number} nrows Number of rows\n *\n * @ignore\n */\nconst matrixPrototype = /** @lends Matrix */ {\n  /**\n   * Compute the Sum of the matrix\n   * @return {Number} Sum of all elements in the matrix\n   */\n  sum() {\n    return this.data.reduce((a, b) => a + b, 0);\n  },\n\n  /**\n   * Compute the transpose matrix\n   * @return {Matrix}\n   */\n  transpose() {\n    const out = Matrix(this.ncols, this.nrows);\n    for (let i = 0; i < this.ncols; i += 1) {\n      for (let j = 0; j < this.nrows; j += 1) {\n        out.data[(i * this.nrows) + j] = this.data[(j * this.ncols) + i];\n      }\n    }\n    return out;\n  },\n\n  /**\n   * Compute the product of matrices\n   * @param  {Matrix} mat Second matrix\n   * @return {Matrix}     Product of the current matrix by `mat`\n   */\n  product(mat) {\n    if (this.ncols !== mat.nrows) {\n      throw new Error('Wrong dimensions for matrix product');\n    }\n    const out = Matrix(this.nrows, mat.ncols);\n    for (let i = 0; i < this.nrows; i += 1) {\n      for (let j = 0; j < mat.ncols; j += 1) {\n        out.data[(i * mat.ncols) + j] = 0;\n        for (let k = 0; k < this.ncols; k += 1) {\n          out.data[(i * mat.ncols) + j] +=\n            this.data[(i * this.ncols) + k] * mat.data[(k * mat.ncols) + j];\n        }\n      }\n    }\n    return out;\n  },\n\n  /**\n   * Compute the Pseudo-Inverse of a Matrix\n   * @param  {Number} determinant Determinant (computed with the inversion)\n   * @return {Matrix}             Pseudo-inverse of the matrix\n   */\n  pinv() {\n    if (this.nrows === this.ncols) {\n      return this.gaussJordanInverse();\n    }\n\n    const transp = this.transpose();\n    if (this.nrows >= this.ncols) {\n      const prod = transp.product(this);\n      const { determinant, matrix: dst } = prod.gaussJordanInverse();\n      return { determinant, matrix: dst.product(transp) };\n    }\n    const prod = this.product(transp);\n    const { determinant, matrix: dst } = prod.gaussJordanInverse();\n    return { determinant, matrix: transp.product(dst) };\n  },\n\n  /**\n   * Compute the Gauss-Jordan Inverse of a Square Matrix\n   * !!! Determinant (computed with the inversion\n   * @private\n   */\n  gaussJordanInverse() {\n    if (this.nrows !== this.ncols) {\n      throw new Error('Gauss-Jordan inversion: Cannot invert Non-square matrix');\n    }\n    let determinant = 1;\n    const mat = Matrix(this.nrows, this.ncols * 2);\n    const newMat = Matrix(this.nrows, this.ncols * 2);\n    const n = this.nrows;\n\n    // Create matrix\n    for (let i = 0; i < n; i += 1) {\n      for (let j = 0; j < n; j += 1) {\n        mat.data[(i * 2 * n) + j] = this.data[(i * n) + j];\n      }\n      mat.data[(i * 2 * n) + n + i] = 1;\n    }\n\n    for (let k = 0; k < n; k += 1) {\n      let i = k;\n      while (Math.abs(mat.data[(i * 2 * n) + k]) < kEpsilonPseudoInverse) {\n        i += 1;\n        if (i === n) {\n          throw new Error('Non-invertible matrix');\n        }\n      }\n      determinant *= mat.data[(i * 2 * n) + k];\n\n      // if found > Exchange lines\n      if (i !== k) {\n        mat.swapLines(i, k);\n      }\n\n      newMat.data = mat.data.slice();\n\n      for (let j = 0; j < 2 * n; j += 1) {\n        newMat.data[(k * 2 * n) + j] /= mat.data[(k * 2 * n) + k];\n      }\n      for (let ii = 0; ii < n; ii += 1) {\n        if (ii !== k) {\n          for (let j = 0; j < 2 * n; j += 1) {\n            newMat.data[(ii * 2 * n) + j] -=\n                mat.data[(ii * 2 * n) + k] *\n                newMat.data[(k * 2 * n) + j];\n          }\n        }\n      }\n      mat.data = newMat.data.slice();\n    }\n\n    const dst = Matrix(this.nrows, this.ncols);\n    for (let i = 0; i < n; i += 1) {\n      for (let j = 0; j < n; j += 1) {\n        dst.data[(i * n) + j] = mat.data[(i * 2 * n) + n + j];\n      }\n    }\n    return { determinant, matrix: dst };\n  },\n\n  /**\n   * Swap 2 lines of the matrix\n   * @param  {[type]} i index of the first line\n   * @param  {[type]} j index of the second line\n   * @private\n   */\n  swapLines(i, j) {\n    for (let k = 0; k < this.ncols; k += 1) {\n      const tmp = this.data[(i * this.ncols) + k];\n      this.data[(i * this.ncols) + k] = this.data[(j * this.ncols) + k];\n      this.data[(j * this.ncols) + k] = tmp;\n    }\n  },\n\n  /**\n   * Swap 2 columns of the matrix\n   * @param  {[type]} i index of the first column\n   * @param  {[type]} j index of the second column\n   * @private\n   */\n  swapColumns(i, j) {\n    for (let k = 0; k < this.nrows; k += 1) {\n      const tmp = this.data[(k * this.ncols) + i];\n      this.data[(k * this.ncols) + i] = this.data[(k * this.ncols) + j];\n      this.data[(k * this.ncols) + j] = tmp;\n    }\n  },\n};\n\n/**\n * Create a matrix\n *\n * @function\n * @param       {Number} [nrows=0]  Number of rows\n * @param       {Number} [ncols=-1] Number of columns\n * @return {matrixPrototype}\n *\n * @property {Array} data Matrix data\n * @property {Number} ncols Number of columns\n * @property {Number} nrows Number of rows\n */\nexport default function Matrix(nrows = 0, ncols = -1) {\n  const nc = ncols < 0 ? nrows : ncols;\n  return Object.assign(\n    Object.create(matrixPrototype), //\n    {\n      nrows,\n      ncols: nc,\n      data: Array(nrows * nc).fill(0),\n    },\n  );\n}\n","import Matrix from './matrix';\n\n/**\n * Gaussian Distribution Prototype\n *\n * @type {Object}\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n *\n * @ignore\n */\nconst baseGaussianPrototype = /** @lends GaussianDistribution */ {\n  /**\n   * Allocate the distribution\n   * @private\n   */\n  allocate() {\n    this.mean = new Array(this.dimension).fill(0);\n    if (this.covarianceMode === 'full') {\n      this.covariance = new Array(this.dimension ** 2).fill(0);\n      this.inverseCovariance = new Array(this.dimension ** 2).fill(0);\n    } else {\n      this.covariance = new Array(this.dimension).fill(0);\n      this.inverseCovariance = new Array(this.dimension).fill(0);\n    }\n    if (this.bimodal) {\n      this.allocateBimodal();\n    }\n  },\n\n  /**\n   * @brief Estimate the likelihood of an observation vector.\n   *\n   * If the distribution is bimodal an the observation is a vector of the size\n   * of the input modality, the likelihood is computed only on the\n   * distribution for the input modality\n   *\n   * @param  {array} observation data observation\n   * @return {number}\n   */\n  likelihood(observation) {\n    if (this.covarianceDeterminant === 0) {\n      throw new Error('Covariance Matrix is not invertible');\n    }\n    if (this.bimodal && observation.length === this.inputDimension) {\n      return this.inputLikelihood(observation);\n    }\n    if (observation.length !== this.dimension) {\n      throw new Error(`GaussianDistribution: observation has wrong dimension. Expected \\`${this.dimension}\\`, got \\`${observation.length}\\``);\n    }\n\n    let euclideanDistance = 0;\n    if (this.covarianceMode === 'full') {\n      for (let l = 0; l < this.dimension; l += 1) {\n        let tmp = 0;\n        for (let k = 0; k < this.dimension; k += 1) {\n          tmp += this.inverseCovariance[(l * this.dimension) + k] *\n            (observation[k] - this.mean[k]);\n        }\n        euclideanDistance += (observation[l] - this.mean[l]) * tmp;\n      }\n    } else {\n      for (let l = 0; l < this.dimension; l += 1) {\n        euclideanDistance += this.inverseCovariance[l] *\n          (observation[l] - this.mean[l]) *\n          (observation[l] - this.mean[l]);\n      }\n    }\n\n    let p = Math.exp(-0.5 * euclideanDistance) /\n      Math.sqrt(this.covarianceDeterminant * ((2 * Math.PI) ** this.dimension));\n\n    if (p < 1e-180 || Number.isNaN(p) || Math.abs(p) === +Infinity) {\n      p = 1e-180;\n    }\n\n    return p;\n  },\n\n  /**\n   * Regularize the distribution, given a regularization vector of the same\n   * dimension. Regularization adds the vector to the variance of the\n   * distribution.\n   *\n   * @param  {Array} regularization regularization vector\n   */\n  regularize(regularization) {\n    if (this.covarianceMode === 'full') {\n      for (let d = 0; d < this.dimension; d += 1) {\n        this.covariance[(d * this.dimension) + d] += regularization[d];\n      }\n    } else {\n      for (let d = 0; d < this.dimension; d += 1) {\n        this.covariance[d] += regularization[d];\n      }\n    }\n  },\n\n  /**\n   * Update the inverse covariance of the distribution\n   * @private\n   */\n  updateInverseCovariance() {\n    if (this.covarianceMode === 'full') {\n      const covMatrix = Matrix(this.dimension, this.dimension);\n\n      covMatrix.data = this.covariance.slice();\n      const inv = covMatrix.pinv();\n      this.covarianceDeterminant = inv.determinant;\n      this.inverseCovariance = inv.matrix.data;\n    } else { // DIAGONAL COVARIANCE\n      this.covarianceDeterminant = 1;\n      for (let d = 0; d < this.dimension; d += 1) {\n        if (this.covariance[d] <= 0) {\n          throw new Error('Non-invertible matrix');\n        }\n        this.inverseCovariance[d] = 1 / this.covariance[d];\n        this.covarianceDeterminant *= this.covariance[d];\n      }\n    }\n    if (this.bimodal) {\n      this.updateInverseCovarianceBimodal();\n    }\n  },\n\n  /**\n   * Convert to an ellipse allong two dimensions\n   *\n   * @param  {number} dimension1 first dimension\n   * @param  {number} dimension2 second dimension\n   * @return {Ellipse}\n   */\n  toEllipse(dimension1, dimension2) {\n    if (dimension1 >= this.dimension || dimension2 >= this.dimension) {\n      throw new Error('dimensions out of range');\n    }\n\n    const gaussianEllipse = {\n      x: 0,\n      y: 0,\n      width: 0,\n      height: 0,\n      angle: 0,\n    };\n    gaussianEllipse.x = this.mean[dimension1];\n    gaussianEllipse.y = this.mean[dimension2];\n\n    // Represent 2D covariance with square matrix\n    // |a b|\n    // |b c|\n    let a;\n    let b;\n    let c;\n    if (this.covarianceMode === 'full') {\n      a = this.covariance[(dimension1 * this.dimension) + dimension1];\n      b = this.covariance[(dimension1 * this.dimension) + dimension2];\n      c = this.covariance[(dimension2 * this.dimension) + dimension2];\n    } else {\n      a = this.covariance[dimension1];\n      b = 0;\n      c = this.covariance[dimension2];\n    }\n\n    // Compute Eigen Values to get width, height and angle\n    const trace = a + c;\n    const determinant = (a * c) - (b * b);\n    const eigenVal1 = 0.5 * (trace + Math.sqrt((trace ** 2) - (4 * determinant)));\n    const eigenVal2 = 0.5 * (trace - Math.sqrt((trace ** 2) - (4 * determinant)));\n    gaussianEllipse.width = Math.sqrt(5.991 * eigenVal1);\n    gaussianEllipse.height = Math.sqrt(5.991 * eigenVal2);\n    gaussianEllipse.angle = Math.atan(b / (eigenVal1 - c));\n    if (Number.isNaN(gaussianEllipse.angle)) {\n      gaussianEllipse.angle = Math.PI / 2;\n    }\n\n    return gaussianEllipse;\n  },\n\n  /**\n   * Modify the distribution along two dimensions given the equivalent values\n   * as an Ellipse representation.\n   *\n   * @param  {Ellipse} gaussianEllipse The Ellipse corresponding to the 2D\n   * covariance along the two target dimensions\n   * @param  {number} dimension1      first dimension\n   * @param  {number} dimension2      second dimension\n   */\n  fromEllipse(gaussianEllipse, dimension1, dimension2) {\n    if (dimension1 >= this.dimension || dimension2 >= this.dimension) {\n      throw new Error('dimensions out of range');\n    }\n\n    this.mean[dimension1] = gaussianEllipse.x;\n    this.mean[dimension2] = gaussianEllipse.y;\n\n    const eigenVal1 = (gaussianEllipse.width * gaussianEllipse.width) / 5.991;\n    const eigenVal2 = (gaussianEllipse.height * gaussianEllipse.height) / 5.991;\n    const tantheta = Math.tan(gaussianEllipse.angle);\n    const b = ((eigenVal1 - eigenVal2) * tantheta) / ((tantheta ** 2) + 1);\n    const c = eigenVal1 - (b / tantheta);\n    const a = eigenVal2 + (b / tantheta);\n\n    if (this.covarianceMode === 'full') {\n      this.covariance[(dimension1 * this.dimension) + dimension1] = a;\n      this.covariance[(dimension1 * this.dimension) + dimension2] = b;\n      this.covariance[(dimension2 * this.dimension) + dimension1] = b;\n      this.covariance[(dimension2 * this.dimension) + dimension2] = c;\n    } else {\n      this.covariance[dimension1] = a;\n      this.covariance[dimension2] = c;\n    }\n    this.updateInverseCovariance();\n  },\n};\n\n/**\n * Bimodal Gaussian Distribution Prototype, for Regression purposes\n *\n * @type {Object}\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n * @property {Array}   inverseCovarianceInput Inverse covariance of the input\n * modality\n *\n * @ignore\n */\nconst bimodalGaussianPrototype = /** @lends GaussianDistribution */ {\n  /**\n   * Allocate the distribution\n   * @private\n   */\n  allocateBimodal() {\n    if (this.covarianceMode === 'full') {\n      this.inverseCovarianceInput = new Array(this.inputDimension ** 2).fill(0);\n    } else {\n      this.inverseCovarianceInput = new Array(this.inputDimension).fill(0);\n    }\n  },\n\n  /**\n   * Estimate the likelihood of an observation for the input modality only.\n   * Called by `likelihood` when relevant.\n   * @param  {Array} inputObservation observation (input modality only)\n   * @return {number}\n   * @private\n   */\n  inputLikelihood(inputObservation) {\n    if (this.covarianceDeterminantInput === 0) {\n      throw new Error('Covariance Matrix of input modality is not invertible');\n    }\n\n    let euclideanDistance = 0;\n    if (this.covarianceMode === 'full') {\n      for (let l = 0; l < this.inputDimension; l += 1) {\n        let tmp = 0;\n        for (let k = 0; k < this.inputDimension; k += 1) {\n          tmp += this.inverseCovarianceInput[(l * this.inputDimension) + k] *\n            (inputObservation[k] - this.mean[k]);\n        }\n        euclideanDistance += (inputObservation[l] - this.mean[l]) * tmp;\n      }\n    } else {\n      for (let l = 0; l < this.inputDimension; l += 1) {\n        euclideanDistance += this.inverseCovariance[l] *\n          (inputObservation[l] - this.mean[l]) *\n          (inputObservation[l] - this.mean[l]);\n      }\n    }\n\n    let p = Math.exp(-0.5 * euclideanDistance) /\n               Math.sqrt(this.covarianceDeterminantInput *\n                    ((2 * Math.PI) ** this.inputDimension));\n\n    if (p < 1e-180 || Number.isNaN(p) || Math.abs(p) === +Infinity) p = 1e-180;\n\n    return p;\n  },\n\n  /**\n   * Estimate the output values associated with an input observation by\n   * regression, given the distribution parameters.\n   *\n   * @todo Clarify the maths here.\n   *\n   * @param  {Array} inputObservation observation (input modality only)\n   * @return {Array} Output values\n   */\n  regression(inputObservation) {\n    const outputDimension = this.dimension - this.inputDimension;\n    const prediction = Array(outputDimension).fill(0);\n\n    if (this.covarianceMode === 'full') {\n      for (let d = 0; d < outputDimension; d += 1) {\n        prediction[d] = this.mean[this.inputDimension + d];\n        for (let e = 0; e < this.inputDimension; e += 1) {\n          let tmp = 0;\n          for (let f = 0; f < this.inputDimension; f += 1) {\n            tmp += this.inverseCovarianceInput[(e * this.inputDimension) + f] *\n              (inputObservation[f] - this.mean[f]);\n          }\n          prediction[d] += tmp *\n            this.covariance[((d + this.inputDimension) * this.dimension) + e];\n        }\n      }\n    } else {\n      for (let d = 0; d < outputDimension; d += 1) {\n        prediction[d] = this.mean[this.inputDimension + d];\n      }\n    }\n    return prediction;\n  },\n\n  /**\n   * Update the inverse covariance\n   * @private\n   */\n  updateInverseCovarianceBimodal() {\n    if (this.covarianceMode === 'full') {\n      const covMatrixInput = Matrix(this.inputDimension, this.inputDimension);\n      for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n        for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n          covMatrixInput.data[(d1 * this.inputDimension) + d2] =\n            this.covariance[(d1 * this.dimension) + d2];\n        }\n      }\n      const invInput = covMatrixInput.pinv();\n      this.covarianceDeterminantInput = invInput.determinant;\n      this.inverseCovarianceInput = invInput.matrix.data;\n    } else { // DIAGONAL COVARIANCE\n      this.covarianceDeterminantInput = 1;\n      for (let d = 0; d < this.inputDimension; d += 1) {\n        if (this.covariance[d] <= 0) {\n          throw new Error('Non-invertible matrix');\n        }\n        this.inverseCovarianceInput[d] = 1 / this.covariance[d];\n        this.covarianceDeterminantInput *= this.covariance[d];\n      }\n    }\n    this.updateOutputCovariance();\n  },\n\n  /**\n   * Update the output covariance\n   * @private\n   */\n  updateOutputCovariance() {\n    if (this.covarianceMode === 'diagonal') {\n      this.outputCovariance = this.covariance.slice(0, this.inputDimension);\n      return;\n    }\n\n    // CASE: FULL COVARIANCE\n    const covMatrixInput = Matrix(this.inputDimension, this.inputDimension);\n    for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n        covMatrixInput.data[(d1 * this.inputDimension) + d2] =\n          this.covariance[(d1 * this.dimension) + d2];\n      }\n    }\n    const inv = covMatrixInput.pinv();\n    const covarianceGS = Matrix(this.inputDimension, this.outputDimension);\n    for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n        covarianceGS.data[(d1 * this.outputDimension) + d2] =\n          this.covariance[(d1 * this.dimension) + this.inputDimension + d2];\n      }\n    }\n    const covarianceSG = Matrix(this.outputDimension, this.inputDimension);\n    for (let d1 = 0; d1 < this.outputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n        covarianceSG.data[(d1 * this.inputDimension) + d2] =\n          this.covariance[((this.inputDimension + d1) * this.dimension) + d2];\n      }\n    }\n    const tmptmptmp = inv.matrix.product(covarianceGS);\n    const covarianceMod = covarianceSG.product(tmptmptmp);\n    this.outputCovariance = Array(this.outputDimension ** 2).fill(0);\n    for (let d1 = 0; d1 < this.outputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n        this.outputCovariance[(d1 * this.outputDimension) + d2] =\n          this.covariance[((this.inputDimension + d1) * this.dimension) +\n            this.inputDimension + d2] -\n            covarianceMod.data[(d1 * this.outputDimension) + d2];\n      }\n    }\n  },\n};\n\n/**\n * Multivariate Gaussian Distribution factory function.\n * Full covariance, optionally multimodal with support for regression.\n *\n * @function\n * @param {Number} [inputDimension=1]      Dimension of the input modality\n * @param {Number} [outputDimension=0]     Dimension of the output\n * modality (positive for regression, otherwise 0 for recognition).\n * @param {String} [covarianceMode='full'] covariance mode (full vs\n * diagonal)\n * @return {baseGaussianPrototype|bimodalGaussianPrototype}\n *\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n */\nexport default function GaussianDistribution(\n  inputDimension = 1,\n  outputDimension = 0,\n  covarianceMode = 'full',\n) {\n  const bimodal = outputDimension > 0;\n  const dimension = inputDimension + outputDimension;\n  const proto = bimodal ?\n    Object.assign({}, baseGaussianPrototype, bimodalGaussianPrototype) :\n    baseGaussianPrototype;\n  const data = Object.assign(\n    {\n      bimodal,\n      dimension,\n      inputDimension,\n      outputDimension,\n      covarianceMode,\n      covarianceDeterminant: 0,\n    },\n    bimodal ? { covarianceDeterminantInput: 0 } : {},\n  );\n  const dist = Object.assign(\n    Object.create(proto),\n    data,\n  );\n  dist.allocate();\n  return dist;\n}\n","const trainerPrototype = /** @lends withEMTraining */ {\n  /**\n   * Train the model from the given training set, using the\n   * Expectation-Maximisation algorithm.\n   *\n   * @param  {TrainingSet} trainingSet Training Set\n   * @return {Object} Parameters of the trained model\n   */\n  train(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) {\n      throw new Error('The training set is empty');\n    }\n\n    this.initTraining(trainingSet);\n\n    let logLikelihood = -Infinity;\n    let iterations = 0;\n    let previousLogLikelihood = logLikelihood;\n\n    while (!this.converged(iterations, logLikelihood, previousLogLikelihood)) {\n      previousLogLikelihood = logLikelihood;\n      logLikelihood = this.updateTraining(trainingSet);\n\n      const pctChg =\n        100 * Math.abs((logLikelihood - previousLogLikelihood) / previousLogLikelihood);\n      if (Number.isNaN(pctChg) && iterations > 1) {\n        throw new Error('An error occured during training');\n      }\n\n      iterations += 1;\n    }\n\n    this.terminateTraining();\n    return this.params;\n  },\n\n  /**\n   * Return `true` if the training has converged according to the criteria\n   * specified at the creation\n   *\n   * @param  {number} iteration       Current iteration\n   * @param  {number} logProb         Current log-likelihood of the training set\n   * @param  {number} previousLogProb Previous log-likelihood of the training\n   * set\n   * @return {boolean}\n   *\n   * @private\n   */\n  converged(iteration, logProb, previousLogProb) {\n    if (iteration >= this.convergenceCriteria.maxIterations) return true;\n    if (this.convergenceCriteria.maxIterations >= this.convergenceCriteria.minIterations) {\n      return iteration >= this.convergenceCriteria.maxIterations;\n    }\n    if (iteration < this.convergenceCriteria.minIterations) return false;\n    const percentChange = 100 * Math.abs((logProb - previousLogProb) / logProb);\n    return percentChange <= this.convergenceCriteria.percentChange;\n  },\n};\n\n/**\n * Add ABSTRACT training capabilities to a model for which the training process\n * use the Expectation-Maximisation (EM) algorithm. This is used in particular\n * for training GMMs and HMMs.\n *\n * The final instance needs to implement `initTraining`, `updateTraining` and\n * `terminateTraining` methods. `updateTraining` will be called until the\n * convergence criteria are met. Convergence depends on\n * - A minimum number of iterations\n * - A maximum number of iterations\n * - A threshold on the relative change of the log-likelihood of the training\n * data between successive iterations.\n *\n * @todo details\n *\n * @param  {Object} [o]                   Source object\n * @param  {Object} [convergenceCriteria] Set of convergence criteria\n * @param  {number} [convergenceCriteria.percentChange=1e-3] Threshold in % of\n * the relative change of the log-likelihood, under which the training stops.\n * @param  {number} [convergenceCriteria.minIterations=5]    minimum number of iterations\n * @param  {number} [convergenceCriteria.maxIterations=100]  maximum number of iterations\n * @return {Object}\n */\nexport default function withEMTraining(\n  o,\n  convergenceCriteria = {\n    percentChange: 1e-3,\n    minIterations: 5,\n    maxIterations: 100,\n  },\n) {\n  return Object.assign(o, trainerPrototype, { convergenceCriteria });\n}\n","import { isBaseModel } from '../core/model_base_mixin';\nimport GaussianDistribution from '../common/gaussian_distribution';\n\n/**\n * GMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst gmmBasePrototype = /** @lends withGMMBase */ {\n  /**\n   * Allocate the training variables\n   * @private\n   */\n  allocate() {\n    this.params.components = Array.from(\n      Array(this.params.gaussians),\n      () => new GaussianDistribution(\n        this.params.inputDimension,\n        this.params.outputDimension,\n        this.params.covarianceMode,\n      ),\n    );\n    this.params.mixtureCoeffs = Array(this.params.gaussians).fill(0);\n    this.beta = new Array(this.params.gaussians).fill(0);\n  },\n\n  /**\n   * Compute the likelihood of an observation given the GMM's parameters\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}\n   */\n  likelihood(observation) {\n    let likelihood = 0;\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.beta[c] = this.componentLikelihood(observation, c);\n      likelihood += this.beta[c];\n    }\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.beta[c] /= likelihood;\n    }\n\n    return likelihood;\n  },\n\n  /**\n   * Compute the likelihood of an observation for a single component\n   * @param  {Array<Number>} observation Observation vector\n   * @param  {Number} mixtureComponent Component index\n   * @return {Number}\n   * @private\n   */\n  componentLikelihood(observation, mixtureComponent) {\n    if (mixtureComponent >= this.params.gaussians) {\n      throw new Error('The index of the Gaussian Mixture Component is out of bounds');\n    }\n    return this.params.mixtureCoeffs[mixtureComponent] *\n        this.params.components[mixtureComponent].likelihood(observation);\n  },\n\n  /**\n   * Update the inverse covariance of each Gaussian component\n   * @private\n   */\n  updateInverseCovariances() {\n    this.params.components.forEach((c) => {\n      c.updateInverseCovariance();\n    });\n    try {\n      this.params.components.forEach((c) => {\n        c.updateInverseCovariance();\n      });\n    } catch (e) {\n      throw new Error('Matrix inversion error: varianceoffset must be too small');\n    }\n  },\n\n  /**\n   * Normalize the mixing coefficients of the Gaussian mixture\n   * @private\n   */\n  normalizeMixtureCoeffs() {\n    let normConst = 0;\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      normConst += this.params.mixtureCoeffs[c];\n    }\n    if (normConst > 0) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.mixtureCoeffs[c] /= normConst;\n      }\n    } else {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      }\n    }\n  },\n\n  /**\n   * Regularize the covariances\n   * @private\n   */\n  regularize() {\n    this.params.components.forEach((c) => {\n      c.regularize(this.currentRegularization);\n    });\n  },\n};\n\n/**\n * Bimodal (regression) GMM Prototype\n * @type {Object}\n * @ignore\n */\nconst gmmBimodalPrototype = /** @lends withGMMBase */ {\n  /**\n   * Estimate the output values corresponding to the input observation, by\n   * regression given the GMM's parameters. This method is called Gaussian\n   * Mixture Regression (GMR).\n   *\n   * @param  {Array<Number>} inputObservation Observation on the input modality\n   * @return {Array<Number>} Output values (length = outputDimension)\n   */\n  regression(inputObservation) {\n    this.results.outputValues = Array(this.params.outputDimension).fill(0);\n    this.results.outputCovariance = Array(this.params.covarianceMode === 'full' ? this.params.outputDimension ** 2 : this.params.outputDimension).fill(0);\n    let tmpOutputValues;\n\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      tmpOutputValues = this.params.components[c].regression(inputObservation);\n      for (let d = 0; d < this.params.outputDimension; d += 1) {\n        this.results.outputValues[d] += this.beta[c] * tmpOutputValues[d];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n            this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n              (this.beta[c] ** 2) *\n              this.params.components[c].outputCovariance[(d * this.params.outputDimension) + d2];\n          }\n        } else {\n          this.results.outputCovariance[d] +=\n            (this.beta[c] ** 2) * this.params.components[c].outputCovariance[d];\n        }\n      }\n    }\n    return this.results.outputValues;\n  },\n};\n\n/**\n * Add basic GMM capabilities to a single-class model. This enables the\n * computation of the likelihoods and regression operations common to\n * training and prediction\n *\n * @see withGMMTraining\n * @see withGMMPrediction\n *\n * @param  {ModelBase} o Source Model\n * @return {GMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withGMMBase(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    gmmBasePrototype,\n    o.params.bimodal ? gmmBimodalPrototype : {},\n  );\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withKMeansTraining from '../kmeans/kmeans_training_mixin';\n\n/**\n * GMM Training Prototype\n * @type {Object}\n * @ignore\n */\nconst gmmTrainerPrototype = /** @lends withGMMTraining */ {\n  /**\n   * Initialize the EM Training process\n   * @param  {TrainingSet} trainingSet Training set\n   */\n  initTraining(trainingSet) {\n    this.allocate();\n    this.initParametersToDefault(trainingSet.standardDeviation());\n    this.initMeansWithKMeans(trainingSet);\n    this.initCovariances(trainingSet);\n    this.regularize();\n    this.updateInverseCovariances();\n  },\n\n  /**\n   * Initialize the model parameters to their default values\n   * @param  {Array<Number>} dataStddev Standard deviation of the training data\n   * @private\n   */\n  initParametersToDefault(dataStddev) {\n    let normCoeffs = 0;\n    this.currentRegularization = dataStddev.map(std => Math.max(\n      this.params.regularization.absolute,\n      this.params.regularization.relative * std,\n    ));\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      if (this.params.covarianceMode === 'full') {\n        this.params.components[c].covariance = Array(this.params.dimension ** 2)\n          .fill(this.params.regularization.absolute / 2);\n      } else {\n        this.params.components[c].covariance = Array(this.params.dimension).fill(0);\n      }\n      this.params.components[c].regularize(this.currentRegularization);\n      this.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      normCoeffs += this.params.mixtureCoeffs[c];\n    }\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.mixtureCoeffs[c] /= normCoeffs;\n    }\n  },\n\n  /**\n   * Initialize the means of the model using a K-Means algorithm\n   *\n   * @see withKMeansTraining\n   *\n   * @param  {TrainingSet} trainingSet training set\n   * @private\n   */\n  initMeansWithKMeans(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n    const kmeans = withKMeansTraining(\n      ModelBase({\n        inputDimension: this.params.inputDimension,\n        outputDimension: this.params.outputDimension,\n      }),\n      this.params.gaussians,\n      { initialization: 'data' },\n    );\n    const kmeansParams = kmeans.train(trainingSet);\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.components[c].mean = kmeansParams.centers[c];\n    }\n  },\n\n  /**\n   * Initialize the covariances of the model from the training set\n   *\n   * @param  {TrainingSet} trainingSet training set\n   * @private\n   */\n  initCovariances(trainingSet) {\n    // TODO: simplify with covariance symmetricity\n    // TODO: If Kmeans, covariances from cluster members\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      this.params.components[n].covariance = Array((this.params.covarianceMode === 'full') ? this.params.dimension ** 2 : this.params.dimension).fill(0);\n    }\n\n    const gmeans = Array(this.params.gaussians * this.params.dimension).fill(0);\n    const factor = Array(this.params.gaussians).fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.gaussians);\n      let offset = 0;\n      for (let n = 0; n < this.params.gaussians; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            gmeans[(n * this.params.dimension) + d1] += phrase.get(offset + t, d1);\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n                this.params.components[n]\n                  .covariance[(d1 * this.params.dimension) + d2] +=\n                  phrase.get(offset + t, d1) * phrase.get(offset + t, d2);\n              }\n            } else {\n              this.params.components[n].covariance[d1] +=\n                phrase.get(offset + t, d1) ** 2;\n            }\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        gmeans[(n * this.params.dimension) + d1] /= factor[n];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[n].covariance[(d1 * this.params.dimension) + d2] /= factor[n];\n          }\n        } else {\n          this.params.components[n].covariance[d1] /= factor[n];\n        }\n      }\n    }\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[n].covariance[(d1 * this.params.dimension) + d2] -=\n              gmeans[(n * this.params.dimension) + d1] *\n              gmeans[(n * this.params.dimension) + d2];\n          }\n        } else {\n          this.params.components[n].covariance[d1] -=\n            gmeans[(n * this.params.dimension) + d1] ** 2;\n        }\n      }\n    }\n  },\n\n  /**\n   * Update the EM Training process (1 EM iteration).\n   * @param  TrainingSet trainingSet training set\n   */\n  updateTraining(trainingSet) {\n    let logProb = 0;\n    let totalLength = 0;\n    trainingSet.forEach((phrase) => {\n      totalLength += phrase.length;\n    });\n    const phraseIndices = Object.keys(trainingSet.phrases);\n\n    const p = Array.from(\n      Array(this.params.gaussians),\n      () => new Array(totalLength).fill(0),\n    );\n    const E = Array(this.params.gaussians).fill(0);\n    let tbase = 0;\n\n    trainingSet.forEach((phrase) => {\n      for (let t = 0; t < phrase.length; t += 1) {\n        let normConst = 0;\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          p[c][tbase + t] = this.componentLikelihood(phrase.getFrame(t), c);\n\n          if (p[c][tbase + t] === 0 ||\n            Number.isNaN(p[c][tbase + t]) ||\n            p[c][tbase + t] === +Infinity) {\n            p[c][tbase + t] = 1e-100;\n          }\n          normConst += p[c][tbase + t];\n        }\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          p[c][tbase + t] /= normConst;\n          E[c] += p[c][tbase + t];\n        }\n        logProb += Math.log(normConst);\n      }\n      tbase += phrase.length;\n    });\n\n    // Estimate Mixture coefficients\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.mixtureCoeffs[c] = E[c] / totalLength;\n    }\n\n    // Estimate means\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.components[c].mean[d] = 0;\n        tbase = 0;\n        for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n          const phrase = trainingSet.phrases[phraseIndices[pix]];\n          for (let t = 0; t < phrase.length; t += 1) {\n            this.params.components[c].mean[d] +=\n              p[c][tbase + t] * phrase.get(t, d);\n          }\n          tbase += phrase.length;\n        }\n        this.params.components[c].mean[d] /= E[c];\n      }\n    }\n\n    // estimate covariances\n    if (this.params.covarianceMode === 'full') {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n          for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[c].covariance[(d1 * this.params.dimension) + d2] = 0;\n            tbase = 0;\n            for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n              const phrase = trainingSet.phrases[phraseIndices[pix]];\n              for (let t = 0; t < phrase.length; t += 1) {\n                this.params.components[c].covariance[(d1 * this.params.dimension) + d2] +=\n                  p[c][tbase + t] *\n                  (phrase.get(t, d1) - this.params.components[c].mean[d1]) *\n                  (phrase.get(t, d2) - this.params.components[c].mean[d2]);\n              }\n              tbase += phrase.length;\n            }\n            this.params.components[c].covariance[(d1 * this.params.dimension) + d2] /= E[c];\n            if (d1 !== d2) {\n              this.params.components[c].covariance[(d2 * this.params.dimension) + d1] =\n                this.params.components[c].covariance[(d1 * this.params.dimension) + d2];\n            }\n          }\n        }\n      }\n    } else {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n          this.params.components[c].covariance[d1] = 0;\n          tbase = 0;\n          for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n            const phrase = trainingSet.phrases[phraseIndices[pix]];\n            for (let t = 0; t < phrase.length; t += 1) {\n              const value = (phrase.get(t, d1) - this.params.components[c].mean[d1]);\n              this.params.components[c].covariance[d1] +=\n                    p[c][tbase + t] * value * value;\n            }\n            tbase += phrase.length;\n          }\n          this.params.components[c].covariance[d1] /= E[c];\n        }\n      }\n    }\n\n    this.regularize();\n    this.updateInverseCovariances();\n\n    return logProb;\n  },\n\n  /**\n   * Terminate the EM Training process\n   */\n  terminateTraining() {},\n};\n\n/**\n * Add GMM Training capabilities to a GMM Model\n * @param  {GMMBase} o               Source GMM Model\n * @param  {Number} [gaussians=1]    Number of Gaussian components\n * @param  {Object} [regularization] Regularization parameters\n * @param  {Number} [regularization.absolute=1e-3] Absolute regularization\n * @param  {Number} [regularization.relative=1e-2] Relative Regularization\n (relative to the training set's variance along each dimension)\n * @param  {String} [covarianceMode='full'] Covariance mode ('full' or diagonal)\n * @return {BMMBase}\n */\nexport default function withGMMTraining(\n  o,\n  gaussians = 1,\n  regularization = { absolute: 1e-3, relative: 1e-2 },\n  covarianceMode = 'full',\n) {\n  if (!Object.keys(o).includes('params')) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    gmmTrainerPrototype,\n    {\n      params: {\n        ...o.params,\n        gaussians,\n        regularization,\n        covarianceMode,\n      },\n    },\n  );\n}\n","import ModelBase from './model_base_mixin';\n\n/**\n * Multiclass Models Mixin\n * @type {Object}\n * @ignore\n */\nconst MulticlassBasePrototype = /** @lends MulticlassModelBase */{\n  /**\n   * Get the number of classes in the model\n   * @return {number} number of classes\n   */\n  size() {\n    return Object.keys(this.models).length;\n  },\n\n  /**\n   * Check if a class with the given label exists\n   * @param  {string} label Class label\n   * @return {boolean}\n   */\n  includes(label) {\n    return Object.keys(this.models).includes(label);\n  },\n\n  /**\n   * Remove a class by label\n   * @param  {string} label Class label\n   */\n  remove(label) {\n    if (this.includes(label)) {\n      delete this.models[label];\n    }\n  },\n};\n\n/**\n * Create an abstract Multiclass Model\n * @param       {number]} inputDimension  input dimension\n * @param       {number]} outputDimension output dimension\n * @param       {Object} parameters       additional parameters to copy\n * @function\n */\nexport default function MulticlassModelBase({\n  inputDimension,\n  outputDimension,\n  ...parameters\n}) {\n  return Object.assign(\n    ModelBase({ inputDimension, outputDimension, ...parameters }),\n    MulticlassBasePrototype,\n  );\n}\n","/**\n * Add multiclass training capabilities to a model. It takes as argument\n * the training function called to train each class of the training set.\n *\n * @param  {MulticlassModelBase} o Source model\n * @param  {Function}  trainingFunction Training function for a single class\n * @return {MulticlassModelBase}\n */\nexport default function withMulticlassTraining(\n  o,\n  trainingFunction,\n) {\n  return Object.assign(\n    o,\n    /** @lends withMulticlassTraining */ {\n      /**\n       * Train the model, optionally specifying a set of classes to train\n       *\n       * @param  {TrainingSet} trainingSet   Training data set\n       * @param  {undefined|Array<String>} [labels=undefined] Labels\n       * corresponding to the classes to be trained (all if unspecified)\n       * @return {Object} the parameters of the trained model\n       *\n       * @throws {Error} if the training set is empty\n       * @throws {Error} if one of the specified class does not exist\n       */\n      train(trainingSet, labels = undefined) {\n        if (!trainingSet || trainingSet.empty()) {\n          throw new Error('The training set is empty');\n        }\n        if (labels) {\n          labels.forEach((l) => {\n            if (!this.includes(l)) {\n              throw new Error(`Class labeled ${l} does not exist`);\n            }\n          });\n        }\n\n        this.params.classes = {};\n        const labs = labels || trainingSet.labels();\n        labs.forEach((label) => {\n          const ts = trainingSet.getPhrasesOfClass(label);\n          // console.log(ts);\n          this.params.classes[label] = trainingFunction(ts);\n        });\n        return this.params;\n      },\n    },\n  );\n}\n","/**\n * Circular Buffer prototype\n *\n * @property {number}  capacity Buffer capacity\n * @property {number}  length Current buffer length\n * @property {boolean} full Specifies if the buffer is full\n *\n * @ignore\n */\nconst circularBufferPrototype = /** @lends CircularBuffer */ {\n  /**\n   * Clear the buffer contents\n   */\n  clear() {\n    this.length = 0;\n    this.index = 0;\n    this.full = false;\n    this.buffer = [];\n  },\n\n  /**\n   * Push a value to the buffer\n   * @param  {*} value data value (any type)\n   */\n  push(value) {\n    if (this.full) {\n      this.buffer[this.index] = value;\n      this.index = (this.index + 1) % this.capacity;\n    } else {\n      this.buffer.push(value);\n      this.length += 1;\n      this.full = (this.length === this.capacity);\n    }\n  },\n\n  /**\n   * Get the value at a given index\n   * @param  {number} idx data index\n   * @return {anything}   value at index\n   */\n  get(idx) {\n    return this.buffer[(idx + this.index) % this.capacity];\n  },\n\n  /**\n   * Fill the buffer with a constant value\n   * @param  {*} value data value (any type)\n   */\n  fill(value) {\n    this.length = this.capacity;\n    this.index = 0;\n    this.full = true;\n    this.buffer = Array(this.capacity).fill(value);\n  },\n\n  /**\n   * Iterate over the buffer's data\n   * @param  {Function} callback Callback function\n   * (@see Array.prototype.forEach).\n   */\n  forEach(callback) {\n    for (let i = 0; i < this.length; i += 1) {\n      callback(this.buffer[(i + this.index) % this.capacity], i);\n    }\n  },\n\n  /**\n   * Get an array of the buffer current values (ordered)\n   * @return {Array} Buffer contents\n   */\n  values() {\n    return this.buffer.slice(this.index)\n      .concat(this.buffer.slice(0, this.index));\n  },\n};\n\n/**\n * Circular Buffer Data Structure (any data type)\n * @param  {number} capacity Buffer capacity\n * @return {circularBufferPrototype}\n * @function\n *\n * @property {number}  capacity Buffer capacity\n * @property {number}  length Current buffer length\n * @property {boolean} full Specifies if the buffer is full\n */\nexport default function CircularBuffer(capacity) {\n  const buffer = Object.create(circularBufferPrototype);\n  buffer.capacity = capacity;\n  buffer.clear();\n  return buffer;\n}\n","import { isBaseModel } from './model_base_mixin';\nimport CircularBuffer from '../common/circular_buffer';\n\n/**\n * Prototype for models with prediction capabilities\n * @param  {Boolean} bimodal Specifies whether the model is bimodal\n * @return {Object}\n * @ignore\n */\nconst predictionBasePrototype = bimodal => (/** @lends withAbtractPrediction */{\n  /**\n   * Likelihood Buffer\n   * @type {CircularBuffer}\n   * @private\n   */\n  likelihoodBuffer: CircularBuffer(1),\n\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @param {Number} [lw] Size (in frames) of the likelihood smoothing window\n   */\n  setLikelihoodWindow(lw) {\n    this.likelihoodWindow = lw;\n    this.likelihoodBuffer = CircularBuffer(lw);\n  },\n\n  /**\n   * Reset the prediction process\n   * @return {Modelbase} the model\n   */\n  reset() {\n    this.likelihoodBuffer.clear();\n    return this;\n  },\n\n  /**\n   * Update the predictions with a new observation\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Object} Prediction results\n   *\n   * @todo document results data structure\n   */\n  predict(observation) {\n    const likelihood = this.likelihood(observation);\n    if (bimodal) {\n      this.regression(observation);\n    }\n    this.updateResults(likelihood);\n    return this.results;\n  },\n\n  /**\n   * Update the prediction results\n   * @param  {Number} instantLikelihood Instantaneous likelihood\n   * @private\n   */\n  updateResults(instantLikelihood) {\n    this.results.instantLikelihood = instantLikelihood;\n    this.likelihoodBuffer.push(Math.log(instantLikelihood));\n    this.results.logLikelihood = 0;\n    const bufSize = this.likelihoodBuffer.length;\n    for (let i = 0; i < bufSize; i += 1) {\n      this.results.logLikelihood += this.likelihoodBuffer.get(i);\n    }\n    this.results.logLikelihood /= bufSize;\n  },\n});\n\n/**\n * Add ABSTRACT prediction capabilities to an existing model\n * @param  {Modelbase} o                 Source model\n * @param  {Number} [likelihoodWindow=1] Size of the likelihood smoothing window\n * @return {Modelbase}\n */\nexport default function withAbtractPrediction(o, likelihoodWindow = 1) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const results = Object.assign(\n    { instantLikelihood: 0, logLikelihood: 0 },\n    o.params.bimodal ? { outputValues: [], outputCovariance: [] } : {},\n  );\n  return Object.assign(\n    o,\n    predictionBasePrototype(o.params.bimodal),\n    { results, likelihoodBuffer: CircularBuffer(likelihoodWindow) },\n  );\n}\n","/**\n * Check if the specification is respected for a given parameter and value,\n * and clip if relevant.\n *\n * @ignore\n *\n * @param  {String}        model      Stream Operator Name (for logging)\n * @param  {String}        parameter     Attribute name\n * @param  {Specification} specification Attribute specification\n * @param  {*}             value         Attribute value\n * @return {*}                           Type-checked parameter value\n */\nfunction checkSpec(model, parameter, specification, value) {\n  if (!specification) return;\n  if (specification.constructor === Array && !specification.includes(value)) {\n    throw new Error(`Attribute '${parameter}' (value: '${value}') is not allowed for model '${model}' (options: [${specification}]).`);\n  } else if (specification.constructor === Object) {\n    if (Object.keys(specification).includes('min') && value < specification.min) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is inferior to the minimum required value of ${specification.min} for model '${model}'.`);\n    }\n    if (Object.keys(specification).includes('max') && value > specification.max) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is superior to the maximum required value of ${specification.min} for model '${model}'.`);\n    }\n  } else if (typeof specification === 'function') {\n    if (!specification(value)) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is incompatible with model '${model}'.`);\n    }\n  }\n}\n\n/**\n * Check the parameters of a model and return the parameters of the\n * output stream.\n *\n * The specification should be a structure of the form:\n * ```\n * const streamSpecification = {\n *   <parameter name>: {\n *     required: <boolean>,\n *     check: <null || Array || { min: <minimum value>, max: <maximum value>} || Function >,\n *     transform: Function,\n *   },\n * };\n * ```\n *\n * @param  {String} model      Name of the model for logging\n * @param  {Object} specification I/O Stream Specification\n * @param  {Object} values        Attributes of the input stream\n * @return {Object}               Attributes of the output stream\n *\n * @example\n * import setupStreamAttributes from 'stream';\n *\n * const specification = {\n *   type: {\n *     required: false,\n *     check: null,\n *     transform: x => x || null,\n *   },\n *   format: {\n *     required: true,\n *     check: ['scalar', 'vector'],\n *     transform: x => x,\n *   },\n *   size: {\n *     required: true,\n *     check: { min: 1 },\n *     transform: x => 2 * x,\n *   },\n *   stuff: {\n *     required: true,\n *     check: x => Math.log2(x) === Math.floor(Math.log2(x)),\n *     transform: x => Math.log2(x),\n *   },\n * };\n *\n * const values = {\n *   type: 'anything',\n *   format: 'vector',\n *   size: 3,\n *   stuff: 8,\n *   another: 'one',\n * };\n *\n * setupStreamAttributes('module name', specification, values);\n * // Returns:\n * // {\n * //   type: 'anything',\n * //   format: 'vector',\n * //   size: 6,\n * //   stuff: 3,\n * //   another: 'one',\n * // }\n */\nexport default function validateParameters(model, specification, values) {\n  const parameters = Object.assign({}, values);\n  Object.keys(specification).forEach((attr) => {\n    const spec = specification[attr];\n\n    // Check for required parameters\n    if (spec.required && !Object.keys(values).includes(attr)) {\n      throw new Error(`Stream parameter '${attr}' is required for model '${model}'.`);\n    }\n\n    // Check the validity of the input parameters\n    checkSpec(model, attr, spec.check, values[attr]);\n\n    parameters[attr] = spec.transform ?\n      spec.transform(values[attr]) :\n      values[attr];\n  });\n  return parameters;\n}\n","import validateParameters from '../common/validation';\nimport { isBaseModel } from '../core/model_base_mixin';\n\nconst gmmParameterSpec = gaussians => ({\n  gaussians: {\n    required: true,\n    check: { min: 1 },\n  },\n  regularization: {\n    required: true,\n    check: ({ absolute, relative }) =>\n      (absolute && relative && absolute > 0 && relative > 0),\n  },\n  covarianceMode: {\n    required: true,\n    check: ['full', 'diagonal'],\n  },\n  mixtureCoeffs: {\n    required: true,\n    check: m => m.length === gaussians,\n  },\n  components: {\n    required: true,\n    check: c => c.length === gaussians,\n  },\n});\n\n/**\n * Add GMM prediction capabilities to a single-class model. Mostly, this checks\n * the validity of the model parameters\n *\n * @todo validate gaussian components\n *\n * @param  {GMMBaseModel} o Source Model\n * @return {GMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withGMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  validateParameters('GMM', gmmParameterSpec(o.params.gaussians), o.params);\n  return Object.assign(\n    o,\n    { beta: new Array(o.params.gaussians).fill(0) },\n  );\n}\n","import { isBaseModel } from './model_base_mixin';\n\n/**\n * Multiclass prediction mixin\n * @type {Object}\n * @ignore\n */\nconst MulticlassPredictionBasePrototype = /** @lends withMulticlassPrediction */ {\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @return {Number}\n   */\n  getLikelihoodWindow() {\n    return this.likelihoodWindow;\n  },\n\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @param {Number} [lw] Size (in frames) of the likelihood smoothing window\n   */\n  setLikelihoodWindow(lw) {\n    this.likelihoodWindow = lw;\n    Object.keys(this.models).forEach((label) => {\n      this.models[label].setLikelihoodWindow(lw);\n    });\n  },\n\n  /**\n   * Reset the prediction process. This is particularly important for temporal\n   * models such as HMMs, that depends on previous observations.\n   */\n  reset() {\n    Object.values(this.models).forEach(m => m.reset());\n    this.results = {\n      labels: [],\n      instantLikelihoods: [],\n      smoothedLikelihoods: [],\n      smoothedLogLikelihoods: [],\n      smoothedNormalizedLikelihoods: [],\n      likeliest: null,\n      classes: {},\n    };\n    if (this.params.bimodal) {\n      this.resetBimodal();\n    }\n  },\n\n  /**\n   * Make a prediction from a new observation (updates the results member)\n   * @param  {Array<Number>} observation Observation vector\n   */\n  predict(observation) {\n    Object.values(this.models).forEach(m => m.predict(observation));\n    this.updateResults();\n  },\n\n  updateResults() {\n    const labs = Object.keys(this.models).sort();\n    this.results.labels = labs;\n    let normInstant = 0;\n    let normSmoothed = 0;\n    let maxLogLikelihood = -Infinity;\n    this.results.classes = labs\n      .map((lab, i) => {\n        this.results.instantLikelihoods[i] =\n          this.models[lab].results.instantLikelihood;\n        this.results.smoothedLogLikelihoods[i] =\n          this.models[lab].results.logLikelihood;\n        this.results.smoothedLikelihoods[i] =\n          Math.exp(this.results.smoothedLogLikelihoods[i]);\n        normInstant += this.results.instantLikelihoods[i];\n        normSmoothed += this.results.smoothedLikelihoods[i];\n        if (this.results.smoothedLogLikelihoods[i] > maxLogLikelihood) {\n          maxLogLikelihood = this.results.smoothedLogLikelihoods[i];\n          this.results.likeliest = lab;\n        }\n        return { [lab]: this.models[lab].results };\n      })\n      .reduce((o, x) => ({ ...o, ...x }), {});\n    this.results.smoothedNormalizedLikelihoods =\n      this.results.smoothedLikelihoods.map(x => x / normSmoothed);\n    this.results.instantNormalizedLikelihoods =\n      this.results.instantLikelihoods.map(x => x / normInstant);\n    if (this.params.bimodal) {\n      this.updateRegressionResults();\n    }\n  },\n};\n\nconst MulticlassPredictionBimodalPrototype = {\n  resetBimodal() {\n    this.results.outputValues = [];\n    this.results.outputCovariance = [];\n  },\n\n  updateRegressionResults() {\n    if (this.params.multiClassRegressionEstimator === 'likeliest') {\n      this.results.outputValues =\n        this.models[this.results.likeliest].results.outputValues;\n      this.results.outputCovariance =\n        this.models[this.results.likeliest].results.outputCovariance;\n    } else if (this.params.multiClassRegressionEstimator === 'mixture') {\n      this.results.outputValues = Array(this.outputDimension).fill(0);\n      this.results.outputCovariance = Array(this.outputDimension ** (this.configuration.covarianceMode === 'full' ? 2 : 1)).fill(0);\n      this.results.labels.forEach((lab) => {\n        this.results.outputValues.map((x, i) => x + (\n          this.results.smoothedNormalizedLikelihoods[i] *\n          this.models[lab].results.outputValues[i]\n        ));\n        this.results.outputCovariance.map((x, i) => x + (\n          this.results.smoothedNormalizedLikelihoods[i] *\n          this.models[lab].results.outputCovariance[i]\n        ));\n      });\n    } else {\n      throw new Error('Unknown regression estimator, use `likeliest` or `mixture`');\n    }\n  },\n};\n\n/**\n * Add multiclass prediction capabilities to a multiclass model\n * @param  {MulticlassModelBase} o Source model\n * @param  {String} [multiClassRegressionEstimator='likeliest'] Type of\n * regression estimator:\n * - `likeliest` selects the output values from the likeliest class\n * - `mixture` computes the output values as the weighted sum of the\n * contributions of each class, weighed by their normalized likelihood\n * @return {MulticlassPredictionBasePrototype}\n * @function\n */\nexport default function withMulticlassPrediction(o, multiClassRegressionEstimator = 'likeliest') {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const m = Object.assign(\n    o,\n    MulticlassPredictionBasePrototype,\n    o.params.bimodal ? MulticlassPredictionBimodalPrototype : {},\n  );\n  m.params.multiClassRegressionEstimator = multiClassRegressionEstimator;\n  return m;\n}\n","import GaussianDistribution from '../common/gaussian_distribution';\nimport ModelBase from '../core/model_base_mixin';\nimport withEMTraining from '../core/em_training_mixin';\nimport withGMMBase from './gmm_base_mixin';\nimport withGMMTraining from './gmm_training_mixin';\nimport MulticlassModelBase from '../core/multiclass_mixin';\nimport withMulticlassTraining from '../core/multiclass_training_mixin';\nimport withAbtractPrediction from '../core/prediction_mixin';\nimport withGMMPrediction from './gmm_prediction_mixin';\nimport withMulticlassPrediction from '../core/multiclass_prediction_mixin';\n\n/**\n * @typedef {Object} GMMParameters\n * @property {Boolean} bimodal Specifies if the model is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} gaussians Number of gaussian components in the mixture\n * @property {String} covarianceMode Covariance mode ('full' or 'diagonal')\n * @property {Array<Number>} mixtureCoeffs mixture coefficients ('weight' of\n * each gaussian component)\n * @property {Array<GaussianDistribution>} components Gaussian components\n */\n\n/**\n * Train a single-class GMM Model.\n *\n * @todo GMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {GMMParameters} Parameters of the trained GMM\n */\nexport function trainGMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const { gaussians, regularization, covarianceMode } = configuration;\n  const model = withGMMTraining(\n    withEMTraining(\n      withGMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        ...configuration,\n      })),\n      convergenceCriteria,\n    ),\n    gaussians,\n    regularization,\n    covarianceMode,\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Train a multi-class GMM Model.\n *\n * @todo GMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {Object} Parameters of the trained GMM\n */\nexport function trainMulticlassGMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withMulticlassTraining(\n    MulticlassModelBase({ inputDimension, outputDimension, ...configuration }),\n    ts => trainGMM(ts, configuration, convergenceCriteria),\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Create a GMM Predictor from a full set of parameters (generated by trainGMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function GMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withGMMPrediction(withAbtractPrediction(\n    withGMMBase(ModelBase(params)),\n    likelihoodWindow,\n  ));\n  params.components.forEach((c, i) => {\n    model.params.components[i] = Object.assign(GaussianDistribution(\n      params.inputDimension,\n      params.outputDimension,\n      params.covarianceMode,\n    ), c);\n  });\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass GMM Predictor from a full set of parameters\n * (generated by trainMulticlassGMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function MulticlassGMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withMulticlassPrediction(MulticlassModelBase(params));\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = GMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model.reset();\n  return model;\n}\n","import { isBaseModel } from '../core/model_base_mixin';\n\n//\n// TODO: hierarchical + exit probabilities methods.\n//\n\n/**\n * HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hmmBasePrototype = /** @lends withHMMBase */ {\n  /**\n   * Specifies if the forward algorithm has been initialized\n   * @type {Boolean}\n   * @private\n   */\n  forwardInitialized: false,\n\n  /**\n   * Specifies if the containing multiclass model is isHierarchical\n   * @todo check that\n   * @type {Boolean}\n   * @private\n   */\n  isHierarchical: false,\n\n  /**\n   * Initialize the forward algorithm (See rabiner, 1989)\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}                    `ct` (inverse likelihood)\n   */\n  initializeForwardAlgorithm(observation) {\n    let normConst = 0;\n    if (this.params.transitionMode === 'ergodic') {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.alpha[i] = this.params.prior[i] *\n          this.params.xStates[i].likelihood(observation);\n        normConst += this.alpha[i];\n      }\n    } else {\n      this.alpha = new Array(this.params.states).fill(0);\n      this.alpha[0] = this.params.xStates[0].likelihood(observation);\n      normConst += this.alpha[0];\n    }\n    this.forwardInitialized = true;\n    if (normConst > 0) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.alpha[i] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 1 / this.params.states;\n    }\n    return 1;\n  },\n\n  /**\n   * Update the forward algorithm (See rabiner, 1989)\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}                    `ct` (inverse likelihood)\n   */\n  updateForwardAlgorithm(observation) {\n    let normConst = 0;\n    this.previousAlpha = this.alpha.slice();\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.alpha[j] += this.previousAlpha[i] *\n            this.params.transition[i][j];\n        }\n      } else {\n        this.alpha[j] += this.previousAlpha[j] * this.params.transition[j * 2];\n        if (j > 0) {\n          this.alpha[j] += this.previousAlpha[j - 1] *\n            this.params.transition[((j - 1) * 2) + 1];\n        } else {\n          this.alpha[0] += this.previousAlpha[this.params.states - 1] *\n            this.params.transition[(this.params.states * 2) - 1];\n        }\n      }\n      this.alpha[j] *= this.params.xStates[j].likelihood(observation);\n      normConst += this.alpha[j];\n    }\n    if (normConst > 1e-300) {\n      for (let j = 0; j < this.params.states; j += 1) {\n        this.alpha[j] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    return 0;\n  },\n};\n\n/**\n * Add basic HMM capabilities to a single-class model. This enables the\n * computation of the likelihoods and regression operations common to\n * training and prediction\n *\n * @see withHMMTraining\n * @see withHMMPrediction\n *\n * @param  {ModelBase} o Source Model\n * @return {HMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHMMBase(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(o, hmmBasePrototype);\n}\n","import TrainingSet from '../training_set';\nimport ModelBase from '../core/model_base_mixin';\nimport withGMMBase from '../gmm/gmm_base_mixin';\nimport { trainGMM } from '../gmm';\n\nconst TRANSITION_REGULARIZATION = 1e-5;\n\n/**\n * HMM Training Prototype\n * @type {Object}\n * @ignore\n */\nconst hmmTrainerPrototype = /** @lends withHMMTraining */ {\n  /**\n   * Initialize the EM Training process\n   * @param  {TrainingSet} trainingSet Training set\n   */\n  initTraining(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    this.allocate(trainingSet);\n    this.initParametersToDefault(trainingSet.standardDeviation());\n    if (this.params.gaussians > 1) {\n      this.initMeansCovariancesWithGMMEM(trainingSet);\n    } else {\n      this.initMeansWithAllPhrases(trainingSet);\n      this.initCovariancesFullyObserved(trainingSet);\n    }\n  },\n\n  /**\n   * Allocate the model's parameters and training variables\n   * @param  {TrainingSet} trainingSet The training set\n   * @private\n   */\n  allocate(trainingSet) {\n    const {\n      inputDimension,\n      outputDimension,\n      gaussians,\n      regularization,\n      covarianceMode,\n    } = this.params;\n    this.params.xStates = Array.from(\n      new Array(this.params.states),\n      () => withGMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        gaussians,\n        regularization,\n        covarianceMode,\n      })),\n    );\n    this.params.xStates.forEach(s => s.allocate());\n    this.alpha = new Array(this.params.states).fill(0);\n    this.previousAlpha = new Array(this.params.states).fill(0);\n    this.beta = new Array(this.params.states).fill(0);\n    this.previousBeta = new Array(this.params.states).fill(0);\n\n    // Initialize Algorithm variables\n    // ---------------------------------------\n    const nbPhrases = trainingSet.size();\n    this.gammaSequence = new Array(nbPhrases).fill(null);\n    this.epsilonSequence = new Array(nbPhrases).fill(null);\n    this.gammaSequenceperMixture = new Array(nbPhrases).fill(null);\n    let maxT = 0;\n    let i = 0;\n    trainingSet.forEach((phrase) => {\n      const T = phrase.length;\n      this.gammaSequence[i] = Array.from(\n        new Array(T),\n        () => new Array(this.params.states).fill(0),\n      );\n      if (this.params.transitionMode === 'ergodic') {\n        this.epsilonSequence[i] = Array.from(\n          new Array(T),\n          () => Array.from(\n            new Array(this.params.states),\n            () => new Array(this.params.states).fill(0),\n          ),\n        );\n      } else {\n        this.epsilonSequence[i] = Array.from(\n          new Array(T),\n          () => new Array(this.params.states * 2).fill(0),\n        );\n      }\n      this.gammaSequenceperMixture[i] =\n        new Array(this.params.gaussians).fill(0);\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.gammaSequenceperMixture[i][c] =\n          Array.from(\n            new Array(T),\n            () => new Array(this.params.states).fill(0),\n          );\n      }\n      if (T > maxT) {\n        maxT = T;\n      }\n      i += 1;\n    });\n\n    this.gammaSum = new Array(this.params.states).fill(0);\n    this.gammaSumPerMixture = new Array(this.params.states * this.params.gaussians).fill(0);\n  },\n\n  /**\n   * Update the EM Training process (1 EM iteration).\n   * @param  TrainingSet trainingSet training set\n   */\n  updateTraining(trainingSet) {\n    let logProb = 0;\n\n    // Forward-backward for each phrase\n    // =================================================\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      if (phrase.length > 0) {\n        logProb += this.baumWelchForwardBackward(phrase, phraseIndex);\n      }\n      phraseIndex += 1;\n    });\n    this.baumWelchGammaSum(trainingSet);\n\n    // Re-estimate model parameters\n    // =================================================\n\n    // set covariance and mixture coefficients to zero for each state\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.xStates[i].params.mixtureCoeffs[c] = 0;\n        if (this.params.covarianceMode === 'full') {\n          this.params.xStates[i].params.components[c].covariance =\n            new Array(this.params.dimension ** 2).fill(0);\n        } else {\n          this.params.xStates[i].params.components[c].covariance =\n            new Array(this.params.dimension).fill(0);\n        }\n      }\n    }\n\n    this.baumWelchEstimateMixtureCoefficients(trainingSet);\n    this.baumWelchEstimateMeans(trainingSet);\n    this.baumWelchEstimateCovariances(trainingSet);\n    if (this.params.transitionMode === 'ergodic') {\n      this.baumWelchEstimatePrior(trainingSet);\n    }\n    this.baumWelchEstimateTransitions(trainingSet);\n    return logProb;\n  },\n\n  /**\n   * terminate the EM Training process\n   * @param  TrainingSet trainingSet training set\n   */\n  terminateTraining() {\n    this.normalizeTransitions();\n    this.gammaSequence = null;\n    this.epsilonSequence = null;\n    this.gammaSequenceperMixture = null;\n    this.alphaSeq = null;\n    this.betaSeq = null;\n    this.gammaSum = null;\n    this.gammaSumPerMixture = null;\n    this.params.xStates = this.params.xStates.map(s => s.params);\n  },\n\n  /**\n   * Initialize the model parameters to their default values\n   * @param  {Array<Number>} dataStddev Standard deviation of the training data\n   * @private\n   */\n  initParametersToDefault(dataStddev) {\n    if (this.params.transitionMode === 'ergodic') {\n      this.setErgodic();\n    } else {\n      this.setLeftRight();\n    }\n    const currentRegularization = dataStddev.map(std => Math.max(\n      this.params.regularization.absolute,\n      this.params.regularization.relative * std,\n    ));\n    const initCovariance = (this.params.covarianceMode === 'full') ?\n      () => new Array(this.params.dimension ** 2)\n        .fill(this.params.regularization.absolute / 2) :\n      () => new Array(this.params.dimension)\n        .fill(0);\n    for (let i = 0; i < this.params.states; i += 1) {\n      // this.params.xStates[i].initParametersToDefault(dataStddev);\n      const s = this.params.xStates[i];\n      s.currentRegularization = currentRegularization;\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        s.params.components[c].covariance = initCovariance();\n        s.params.components[c].regularize(currentRegularization);\n        s.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      }\n    }\n  },\n\n  /**\n   * Initialize the means of each state using all available phrases in the\n   * training set\n   * @param  {TrainingSet} trainingSet Training set\n   * @private\n   */\n  initMeansWithAllPhrases(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.xStates[n].params.components[0].mean[d] = 0.0;\n      }\n    }\n\n    const factor = new Array(this.params.states).fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.states);\n      let offset = 0;\n      for (let n = 0; n < this.params.states; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d = 0; d < this.params.dimension; d += 1) {\n            this.params.xStates[n].params.components[0].mean[d] +=\n              phrase.get(offset + t, d);\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.xStates[n].params.components[0].mean[d] /= factor[n];\n      }\n    }\n  },\n\n  /**\n   * Initialize the covariance by direct (fully-observed) estimation from the\n   * training data.\n   * @param  {[type]} trainingSet [description]\n   * @private\n   */\n  initCovariancesFullyObserved(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      this.params.xStates[n].params.components[0].covariance =\n        new Array(this.params.dimension ** (this.params.covarianceMode === 'full' ? 2 : 1)).fill(0);\n    }\n\n    const factor = new Array(this.params.states).fill(0);\n    const othermeans = new Array(this.params.states * this.params.dimension)\n      .fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.states);\n      let offset = 0;\n      for (let n = 0; n < this.params.states; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            othermeans[((n * this.params.dimension)) + d1] +=\n                phrase.get(offset + t, d1);\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n                this.params.xStates[n].params.components[0]\n                  .covariance[(d1 * this.params.dimension) + d2] +=\n                    phrase.get(offset + t, d1) *\n                    phrase.get(offset + t, d2);\n              }\n            } else {\n              this.params.xStates[n].params.components[0].covariance[d1] +=\n                phrase.get(offset + t, d1) ** 2;\n            }\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        othermeans[(n * this.params.dimension) + d1] /= factor[n];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.xStates[n].params.components[0]\n              .covariance[(d1 * this.params.dimension) + d2] /=\n                factor[n];\n          }\n        } else {\n          this.params.xStates[n].params.components[0].covariance[d1] /= factor[n];\n        }\n      }\n    }\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.xStates[n].params.components[0]\n              .covariance[(d1 * this.params.dimension) + d2] -=\n                othermeans[(n * this.params.dimension) + d1] *\n                othermeans[(n * this.params.dimension) + d2];\n          }\n        } else {\n          this.params.xStates[n].params.components[0].covariance[d1] -=\n            othermeans[(n * this.params.dimension) + d1] *\n            othermeans[(n * this.params.dimension) + d1];\n        }\n      }\n      this.params.xStates[n].regularize();\n      this.params.xStates[n].updateInverseCovariances();\n    }\n  },\n\n  /**\n   * Initialize the means and covariance of each state's observation probability\n   * distribution using the Expectation-Maximization algorithm for GMMs\n   * @param  {[type]} trainingSet [description]\n   * @private\n   */\n  initMeansCovariancesWithGMMEM(trainingSet) {\n    for (let n = 0; n < this.params.states; n += 1) {\n      const ts = TrainingSet(this.params);\n      // eslint-disable-next-line no-loop-func\n      trainingSet.forEach((phrase, phraseIndex) => {\n        const step = Math.floor(phrase.length / this.params.states);\n        if (step > 0) {\n          ts.push(phraseIndex, phrase.label);\n          for (let t = n * step; t < (n + 1) * step; t += 1) {\n            ts.getPhrase(phraseIndex).push(phrase.getFrame(t));\n          }\n        }\n      });\n      if (!ts.empty()) {\n        const gmmParams = trainGMM(ts, this.params);\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          this.params.xStates[n].params.components[c].mean =\n            gmmParams.components[c].mean;\n          this.params.xStates[n].params.components[c].covariance =\n            gmmParams.components[c].covariance;\n          this.params.xStates[n].updateInverseCovariances();\n        }\n      }\n    }\n  },\n\n  /**\n   * Initialize the transition matrix to an ergodic transition matrix\n   * @private\n   */\n  setErgodic() {\n    const p = 1 / this.params.states;\n    this.params.prior = new Array(this.params.states).fill(p);\n    this.params.transition = Array.from(\n      new Array(this.params.states),\n      () => new Array(this.params.states).fill(p),\n    );\n  },\n\n  /**\n   * Initialize the transition matrix to a left-right transition matrix\n   * @private\n   */\n  setLeftRight() {\n    this.params.prior = new Array(this.params.states).fill(0);\n    this.params.prior[0] = 1;\n    this.params.transition = new Array(this.params.states * 2).fill(0.5);\n    this.params.transition[(this.params.states - 1) * 2] = 1;\n    this.params.transition[((this.params.states - 1) * 2) + 1] = 0;\n  },\n\n  /**\n   * Normalize the hidden state transition parameters\n   * (prior + transition matrix)\n   * @private\n   */\n  normalizeTransitions() {\n    if (this.params.transitionMode === 'ergodic') {\n      const normPrior = this.params.prior.reduce((a, b) => a + b, 0);\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] /= normPrior;\n        let transitionNorm = 0;\n        for (let j = 0; j < this.params.states; j += 1) {\n          transitionNorm += this.params.transition[i][j];\n        }\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.params.transition[i][j] /= transitionNorm;\n        }\n      }\n    } else {\n      for (let i = 0; i < this.params.states; i += 1) {\n        const transitionNorm = this.params.transition[i * 2] + this.params.transition[(i * 2) + 1];\n        this.params.transition[i * 2] /= transitionNorm;\n        this.params.transition[(i * 2) + 1] /= transitionNorm;\n      }\n    }\n  },\n\n  /**\n   * Initialize the backward algorithm (see rabiner, 1989)\n   * @param  {Number} ct Inverse probability at time T - 1 (last observation of\n   * the sequence)\n   * @private\n   */\n  initializeBackwardAlgorithm(ct) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = ct;\n    }\n  },\n\n  /**\n   * Initialize the backward algorithm (see rabiner, 1989)\n   * @param  {Number} ct Inverse probability at time t\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  updateBackwardAlgorithm(ct, observation) {\n    this.previousBeta = this.beta.slice();\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.beta[i] += this.params.transition[i][j] *\n            this.previousBeta[j] *\n            this.params.xStates[j].likelihood(observation);\n        }\n      } else {\n        this.beta[i] += this.params.transition[i * 2] *\n          this.previousBeta[i] *\n          this.params.xStates[i].likelihood(observation);\n        if (i < this.params.states - 1) {\n          this.beta[i] += this.params.transition[(i * 2) + 1] *\n            this.previousBeta[i + 1] *\n            this.params.xStates[i + 1].likelihood(observation);\n        }\n      }\n      this.beta[i] *= ct;\n      if (Number.isNaN(this.beta[i]) || Math.abs(this.beta[i]) === +Infinity) {\n        this.beta[i] = 1e100;\n      }\n    }\n  },\n\n  /**\n   * Forward algorithm update step for the Baum-Welch algorithms. It is similar\n   * to `updateForwardAlgorithm` except it takes precomputed observation\n   * likelihoods as argument.\n   * @param  {Array<Number>} observationLikelihoods observation likelihoods\n   * @private\n   */\n  baumWelchForwardUpdate(observationLikelihoods) {\n    let normConst = 0;\n    this.previousAlpha = this.alpha.slice();\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.alpha[j] += this.previousAlpha[i] *\n            this.params.transition[i][j];\n        }\n      } else {\n        this.alpha[j] += this.previousAlpha[j] * this.params.transition[j * 2];\n        if (j > 0) {\n          this.alpha[j] += this.previousAlpha[j - 1] *\n            this.params.transition[((j - 1) * 2) + 1];\n        } else {\n          this.alpha[0] += this.previousAlpha[this.params.states - 1] *\n            this.params.transition[(this.params.states * 2) - 1];\n        }\n      }\n      this.alpha[j] *= observationLikelihoods[j];\n      normConst += this.alpha[j];\n    }\n    if (Number.isNaN(normConst)) {\n      throw new Error('Holy molly');\n    }\n    if (normConst > 1e-300) {\n      for (let j = 0; j < this.params.states; j += 1) {\n        this.alpha[j] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    return 0;\n  },\n\n  /**\n   * Backward algorithm update step for the Baum-Welch algorithms. It is similar\n   * to `updatebackwardAlgorithm` except it takes precomputed observation\n   * likelihoods as argument.\n   * @param  {Number} ct Inverse probability at time t\n   * @param  {Array<Number>} observationLikelihoods observation likelihoods\n   * @private\n   */\n  baumWelchBackwardUpdate(ct, observationLikelihoods) {\n    this.previousBeta = this.beta.slice();\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.beta[i] +=\n            this.params.transition[i][j] *\n            this.previousBeta[j] *\n            observationLikelihoods[j];\n        }\n      } else {\n        this.beta[i] += this.params.transition[i * 2] *\n          this.previousBeta[i] *\n          observationLikelihoods[i];\n        if (i < this.params.states - 1) {\n          this.beta[i] += this.params.transition[(i * 2) + 1] *\n            this.previousBeta[i + 1] *\n            observationLikelihoods[i + 1];\n        }\n      }\n      this.beta[i] *= ct;\n      if (Number.isNaN(this.beta[i]) || Math.abs(this.beta[i]) === +Infinity) {\n        this.beta[i] = 1e100;\n      }\n    }\n  },\n\n  /**\n   * Forward-Backward algorithm for the Baum-Welch training algorithm\n   * @param  {Phrase} currentPhrase Current data phrase\n   * @param  {Number} phraseIndex   Current phrase index\n   * @return {Number} Log-likelihood\n   * @private\n   */\n  baumWelchForwardBackward(currentPhrase, phraseIndex) {\n    const T = currentPhrase.length;\n\n    const ct = new Array(T).fill(0);\n    let logProb;\n    this.alphaSeq = [];\n    this.betaSeq = [];\n\n    const observationProbabilities = Array.from(\n      new Array(T),\n      () => new Array(this.params.states).fill(0),\n    );\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        observationProbabilities[t][i] =\n          this.params.xStates[i].likelihood(currentPhrase.getFrame(t));\n      }\n    }\n\n    // Forward algorithm\n    ct[0] = this.initializeForwardAlgorithm(currentPhrase.getFrame(0));\n    logProb = -Math.log(ct[0]);\n    this.alphaSeq.push(this.alpha.slice());\n\n    for (let t = 1; t < T; t += 1) {\n      ct[t] = this.baumWelchForwardUpdate(observationProbabilities[t]);\n      logProb -= Math.log(ct[t]);\n      this.alphaSeq.push(this.alpha.slice());\n    }\n\n    // Backward algorithm\n    this.initializeBackwardAlgorithm(ct[T - 1]);\n    this.betaSeq.push(this.beta.slice());\n\n    for (let t = T - 2; t >= 0; t -= 1) {\n      this.baumWelchBackwardUpdate(ct[t], observationProbabilities[t + 1]);\n      this.betaSeq.push(this.beta.slice());\n    }\n    this.betaSeq.reverse();\n\n    // Compute Gamma Variable\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.gammaSequence[phraseIndex][t][i] =\n          (this.alphaSeq[t][i] * this.betaSeq[t][i]) / ct[t];\n      }\n    }\n\n    // Compute Gamma variable for each mixture component\n    let normConst;\n\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        normConst = 0;\n        if (this.params.gaussians === 1) {\n          const oo = observationProbabilities[t][i];\n          this.gammaSequenceperMixture[phraseIndex][0][t][i] =\n            this.gammaSequence[phraseIndex][t][i] * oo;\n          normConst += oo;\n        } else {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            const oo = this.params.xStates[i]\n              .componentLikelihood(currentPhrase.getFrame(t), c);\n            this.gammaSequenceperMixture[phraseIndex][c][t][i] =\n              this.gammaSequence[phraseIndex][t][i] *\n              oo;\n            normConst += oo;\n          }\n        }\n        if (normConst > 0) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.gammaSequenceperMixture[phraseIndex][c][t][i] /= normConst;\n          }\n        }\n      }\n    }\n\n    // Compute Epsilon Variable\n    if (this.params.transitionMode === 'ergodic') {\n      for (let t = 0; t < T - 1; t += 1) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          for (let j = 0; j < this.params.states; j += 1) {\n            this.epsilonSequence[phraseIndex][t][i][j] =\n              this.alphaSeq[t][i] *\n              this.params.transition[i][j] *\n              this.betaSeq[t + 1][j];\n            this.epsilonSequence[phraseIndex][t][i][j] *=\n              observationProbabilities[t + 1][j];\n          }\n        }\n      }\n    } else {\n      for (let t = 0; t < T - 1; t += 1) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.epsilonSequence[phraseIndex][t][i * 2] =\n            this.alphaSeq[t][i] *\n            this.params.transition[i * 2] *\n            this.betaSeq[t + 1][i];\n          this.epsilonSequence[phraseIndex][t][i * 2] *=\n            observationProbabilities[t + 1][i];\n          if (i < this.params.states - 1) {\n            this.epsilonSequence[phraseIndex][t][(i * 2) + 1] =\n              this.alphaSeq[t][i] *\n              this.params.transition[(i * 2) + 1] *\n              this.betaSeq[t + 1][i + 1];\n            this.epsilonSequence[phraseIndex][t][(i * 2) + 1] *=\n              observationProbabilities[t + 1][i + 1];\n          }\n        }\n      }\n    }\n\n    return logProb;\n  },\n\n  /**\n   * Sums the Gamma variables used for parameter estimation during training\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchGammaSum(trainingSet) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.gammaSum[i] = 0;\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.gammaSumPerMixture[(i * this.params.gaussians) + c] = 0;\n      }\n    }\n\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          this.gammaSum[i] +=\n            this.gammaSequence[phraseIndex][t][i];\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.gammaSumPerMixture[(i * this.params.gaussians) + c] +=\n              this.gammaSequenceperMixture[phraseIndex][c][t][i];\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n  },\n\n  /**\n   * Estimate the mixture coefficients of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateMixtureCoefficients(trainingSet) {\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.params.xStates[i].params.mixtureCoeffs[c] +=\n              this.gammaSequenceperMixture[phraseIndex][c][t][i];\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale mixture coefficients\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.params.xStates[i].normalizeMixtureCoeffs();\n    }\n  },\n\n  /**\n   * Estimate the means of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateMeans(trainingSet) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.xStates[i].params.components[c].mean.fill(0);\n      }\n    }\n\n    // Re-estimate Mean\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            for (let d = 0; d < this.params.dimension; d += 1) {\n              this.params.xStates[i].params.components[c].mean[d] +=\n                this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                phrase.get(t, d);\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Normalize mean\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          if (this.gammaSumPerMixture[(i * this.params.gaussians) + c] > 0) {\n            this.params.xStates[i].params.components[c].mean[d] /=\n              this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n          }\n          if (Number.isNaN(this.params.xStates[i].params.components[c].mean[d])) {\n            throw new Error('Convergence Error');\n          }\n        }\n      }\n    }\n  },\n\n  /**\n   * Estimate the covariances of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateCovariances(trainingSet) {\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n              if (this.params.covarianceMode === 'full') {\n                for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n                  this.params.xStates[i].params.components[c]\n                    .covariance[(d1 * this.params.dimension) + d2] +=\n                    this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                    (phrase.get(t, d1) -\n                      this.params.xStates[i].params.components[c].mean[d1]) *\n                    (phrase.get(t, d2) -\n                      this.params.xStates[i].params.components[c].mean[d2]);\n                }\n              } else {\n                const value = phrase.get(t, d1) -\n                  this.params.xStates[i].params.components[c].mean[d1];\n                this.params.xStates[i].params.components[c].covariance[d1] +=\n                  this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                  (value ** 2);\n              }\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale covariance\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        if (this.gammaSumPerMixture[(i * this.params.gaussians) + c] > 0) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n                this.params.xStates[i].params.components[c]\n                  .covariance[(d1 * this.params.dimension) + d2] /=\n                  this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n                if (d1 !== d2) {\n                  this.params.xStates[i].params.components[c]\n                    .covariance[(d2 * this.params.dimension) + d1] =\n                    this.params.xStates[i].params.components[c]\n                      .covariance[(d1 * this.params.dimension) + d2];\n                }\n              }\n            } else {\n              this.params.xStates[i].params.components[c].covariance[d1] /=\n                this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n            }\n          }\n        }\n      }\n      this.params.xStates[i].regularize();\n      this.params.xStates[i].updateInverseCovariances();\n    }\n  },\n\n  /**\n   * Estimate the prior probabilities of the model\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimatePrior(trainingSet) {\n    this.params.prior.fill(0);\n\n    // Re-estimate Prior probabilities\n    let sumprior = 0;\n    for (let phraseIndex = 0;\n      phraseIndex < trainingSet.size();\n      phraseIndex += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] += this.gammaSequence[phraseIndex][0][i];\n        sumprior += this.params.prior[i];\n      }\n    }\n\n    // Scale Prior vector\n    if (sumprior > 0) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] /= sumprior;\n      }\n    } else {\n      throw new Error('The Prior is all ZERO.....');\n    }\n  },\n\n  /**\n   * Estimate the transition probabilities of the model\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateTransitions(trainingSet) {\n    // Set transition matrix to 0\n    this.params.transition = this.params.transitionMode === 'ergodic' ?\n      Array.from(\n        new Array(this.params.states),\n        () => new Array(this.params.states).fill(0),\n      ) :\n      new Array(this.params.states * 2).fill(0);\n\n    // Re-estimate Transition probabilities\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      if (phrase.length > 0) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          // Experimental: A bit of regularization (sometimes avoids\n          // numerical errors)\n          if (this.params.transitionMode === 'leftright') {\n            this.params.transition[i * 2] += TRANSITION_REGULARIZATION;\n            if (i < this.params.states - 1) {\n              this.params.transition[(i * 2) + 1] += TRANSITION_REGULARIZATION;\n            } else {\n              this.params.transition[i * 2] += TRANSITION_REGULARIZATION;\n            }\n          }\n          // End Regularization\n          if (this.params.transitionMode === 'ergodic') {\n            for (let j = 0; j < this.params.states; j += 1) {\n              for (let t = 0; t < phrase.length - 1; t += 1) {\n                this.params.transition[i][j] +=\n                  this.epsilonSequence[phraseIndex][t][i][j];\n              }\n            }\n          } else {\n            for (let t = 0; t < phrase.length - 1; t += 1) {\n              this.params.transition[i * 2] +=\n                this.epsilonSequence[phraseIndex][t][i * 2];\n            }\n            if (i < this.params.states - 1) {\n              for (let t = 0; t < phrase.length - 1; t += 1) {\n                this.params.transition[(i * 2) + 1] +=\n                  this.epsilonSequence[phraseIndex][t][(i * 2) + 1];\n              }\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale transition matrix\n    if (this.params.transitionMode === 'ergodic') {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.params.transition[i][j] /=\n            (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n          if (Number.isNaN(this.params.transition[i][j])) {\n            throw new Error('Convergence Error. Check your training data or increase the variance offset');\n          }\n        }\n      }\n    } else {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.transition[i * 2] /=\n          (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n        if (Number.isNaN(this.params.transition[i * 2])) {\n          throw new Error('Convergence Error. Check your training data or increase the variance offset');\n        }\n        if (i < this.params.states - 1) {\n          this.params.transition[(i * 2) + 1] /=\n            (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n          if (Number.isNaN(this.params.transition[(i * 2) + 1])) {\n            throw new Error('Convergence Error. Check your training data or increase the variance offset');\n          }\n        }\n      }\n    }\n  },\n};\n\n/**\n * Add HMM Training capabilities to a HMM Model\n * @param  {HMMBase} o               Source HMM Model\n * @param  {Number} [states=1]       Number of hidden states\n * @param  {Number} [gaussians=1]    Number of Gaussian components\n * @param  {Object} [regularization] Regularization parameters\n * @param  {Number} [regularization.absolute=1e-3] Absolute regularization\n * @param  {Number} [regularization.relative=1e-2] Relative Regularization\n (relative to the training set's variance along each dimension)\n * @param  {String} [transitionMode='ergodic'] Structure of the transition\n * matrix ('ergodic' or 'left-right').\n * @param  {String} [covarianceMode='full'] Covariance mode ('full' or diagonal)\n * @return {BMMBase}\n */\nexport default function withHMMTraining(\n  o,\n  states = 1,\n  gaussians = 1,\n  regularization = { absolute: 1e-3, relative: 1e-2 },\n  transitionMode = 'leftright',\n  covarianceMode = 'full',\n) {\n  if (!Object.keys(o).includes('params')) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    hmmTrainerPrototype,\n    {\n      params: {\n        ...o.params,\n        states,\n        gaussians,\n        regularization,\n        transitionMode,\n        covarianceMode,\n      },\n    },\n  );\n}\n","import validateParameters from '../common/validation';\nimport { isBaseModel } from '../core/model_base_mixin';\nimport { GMMPredictor } from '../gmm';\n\nconst hmmParameterSpec = (states, transitionMode) => ({\n  states: {\n    required: true,\n    check: { min: 1 },\n  },\n  gaussians: {\n    required: true,\n    check: { min: 1 },\n  },\n  regularization: {\n    required: true,\n    check: ({ absolute, relative }) =>\n      (absolute && relative && absolute > 0 && relative > 0),\n  },\n  transitionMode: {\n    required: true,\n    check: ['ergodic', 'leftright'],\n  },\n  covarianceMode: {\n    required: true,\n    check: ['full', 'diagonal'],\n  },\n  prior: {\n    required: true,\n    check: m => transitionMode === 'leftright' || m.length === states,\n  },\n  transition: {\n    required: true,\n    check: m => (transitionMode === 'leftright' ?\n      m.length === 2 * states :\n      m.length === states),\n  },\n  xStates: {\n    required: true,\n    check: m => m.length === states,\n  },\n});\n\n\n/**\n * HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hmmPredictionPrototype = /** @lends withHMMPrediction */ {\n  forwardInitialized: false,\n  isHierarchical: false,\n\n  /**\n   * Setup the Model by allocating GMM predictors to each of the hidden states\n   * @return {HMMBaseModel} the model\n   * @private\n   */\n  setup() {\n    this.params.xStates = this.params.xStates.map(s => GMMPredictor(s).reset());\n    return this;\n  },\n\n  /**\n   * Reset the prediction process\n   * @return {HMMBaseModel} the model\n   */\n  reset() {\n    this.likelihoodBuffer.clear();\n    this.params.xStates.forEach((s) => { s.reset(); });\n    return this;\n  },\n\n  /**\n   * Compute the likelihood of an observation given the HMM's parameters\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}\n   */\n  likelihood(observation) {\n    const ct = (this.forwardInitialized) ?\n      this.updateForwardAlgorithm(observation) :\n      this.initializeForwardAlgorithm(observation);\n    this.updateAlphaWindow();\n    this.updateProgress();\n    return 1 / ct;\n  },\n\n  updateProgress() {\n    this.results.progress = 0.0;\n    for (let i = this.windowMinindex; i < this.windowMaxindex; i += 1) {\n      if (this.isHierarchical) {\n        this.results.progress += (this.alpha[i] + this.alpha1[i] + this.alpha2[i]) *\n          (i / this.windowNormalizationConstant);\n      } else {\n        this.results.progress += (this.alpha[i] * i) /\n          this.windowNormalizationConstant;\n      }\n    }\n    this.results.progress /= this.params.states - 1;\n  },\n\n  /**\n   * Update the state probabilities filtering window (for multiclass\n   * hierarchical HMM I think...)\n   * @private\n   */\n  updateAlphaWindow() {\n    this.results.likeliestState = 0;\n    // Get likeliest State\n    let bestAlpha = this.isHierarchical ?\n      (this.alpha[0] + this.alpha1[0]) :\n      this.alpha[0];\n    for (let i = 1; i < this.params.states; i += 1) {\n      if (this.isHierarchical) {\n        if ((this.alpha[i] + this.alpha1[i]) > bestAlpha) {\n          bestAlpha = this.alpha[i] + this.alpha1[i];\n          this.results.likeliestState = i;\n        }\n      } else if (this.alpha[i] > bestAlpha) {\n        bestAlpha = this.alpha[i];\n        this.results.likeliestState = i;\n      }\n    }\n\n    // Compute Window\n    this.windowMinindex = this.results.likeliestState - Math.floor(this.params.states / 2);\n    this.windowMaxindex = this.results.likeliestState + Math.floor(this.params.states / 2);\n    this.windowMinindex = (this.windowMinindex >= 0) ? this.windowMinindex : 0;\n    this.windowMaxindex = (this.windowMaxindex <= this.params.states) ?\n      this.windowMaxindex : this.params.states;\n    this.windowNormalizationConstant = 0.0;\n    for (let i = this.windowMinindex; i < this.windowMaxindex; i += 1) {\n      this.windowNormalizationConstant += this.isHierarchical ?\n        (this.alpha[i] + this.alpha1[i]) :\n        this.alpha[i];\n    }\n  },\n};\n\n/**\n * Bimodal (regression) HMM Prototype\n * @type {Object}\n * @ignore\n */\nconst hmmBimodalPredictionPrototype = /** @lends withHMMPrediction */ {\n  /**\n   * Estimate the output values corresponding to the input observation, by\n   * regression given the HMM's parameters. This method is called Hidden\n   * Mixture Regression (GMR).\n   *\n   * @param  {Array<Number>} inputObservation Observation on the input modality\n   * @return {Array<Number>} Output values (length = outputDimension)\n   */\n  regression(inputObservation) {\n    this.results.outputValues = Array(this.params.outputDimension).fill(0);\n    this.results.outputCovariance = Array(this.params.covarianceMode === 'full' ? this.params.outputDimension ** 2 : this.params.outputDimension).fill(0);\n\n    if (this.params.regressionEstimator === 'likeliest') {\n      this.params.xStates[this.results.likeliestState].predict(inputObservation);\n      this.results.outputValues =\n        this.params.xStates[this.results.likeliestState].results.outputValues;\n      return this.results.outputValues;\n    }\n\n    const clipMinState = (this.params.regressionEstimator === 'full') ?\n      0 : this.windowMinindex;\n    const clipMaxState = (this.params.regressionEstimator === 'full') ?\n      this.params.states : this.windowMaxindex;\n    let normalizationConstant = (this.params.regressionEstimator === 'full') ?\n      1 : this.windowNormalizationConstant;\n\n    if (normalizationConstant <= 0.0) normalizationConstant = 1;\n\n    // Compute Regression\n    for (let i = clipMinState; i < clipMaxState; i += 1) {\n      this.params.xStates[i].likelihood(inputObservation);\n      this.params.xStates[i].regression(inputObservation);\n      const tmpPredictedOutput = this.params.xStates[i].results.outputValues;\n      for (let d = 0; d < this.params.outputDimension; d += 1) {\n        if (this.isHierarchical) {\n          this.results.outputValues[d] +=\n            (this.alpha[i] + this.alpha1[i]) *\n            (tmpPredictedOutput[d] / normalizationConstant);\n          if (this.params.covarianceMode === 'full') {\n            for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n              this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n                (this.alpha[i] + this.alpha1[i]) *\n                (this.alpha[i] + this.alpha1[i]) *\n                (this.params.xStates[i].results\n                  .outputCovariance[(d * this.params.outputDimension) + d2] /\n                normalizationConstant);\n            }\n          } else {\n            this.results.outputCovariance[d] +=\n              (this.alpha[i] + this.alpha1[i]) *\n              (this.alpha[i] + this.alpha1[i]) *\n              (this.params.xStates[i].results.outputCovariance[d] /\n              normalizationConstant);\n          }\n        } else {\n          this.results.outputValues[d] += this.alpha[i] *\n            (tmpPredictedOutput[d] / normalizationConstant);\n          if (this.params.covarianceMode === 'full') {\n            for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n              this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n                (this.alpha[i] ** 2) *\n                (this.params.xStates[i].results\n                  .outputCovariance[(d * this.params.outputDimension) + d2] /\n                normalizationConstant);\n            }\n          } else {\n            this.results.outputCovariance[d] +=\n              ((this.alpha[i] ** 2) *\n              this.params.xStates[i].results.outputCovariance[d]) /\n              normalizationConstant;\n          }\n        }\n      }\n    }\n    return this.results.outputValues;\n  },\n};\n\n/**\n * Add HMM prediction capabilities to a single-class model. Mostly, this checks\n * the validity of the model parameters\n *\n * @todo validate gaussian components\n *\n * @param  {HMMBaseModel} o Source Model\n * @return {HMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  validateParameters('HMM', hmmParameterSpec(o.params.states, o.params.transitionMode), o.params);\n  return Object.assign(\n    o,\n    hmmPredictionPrototype,\n    o.params.bimodal ? hmmBimodalPredictionPrototype : {},\n    {\n      alpha: new Array(o.params.states).fill(0),\n      previous_alpha_: new Array(o.params.states).fill(0),\n    },\n  ).setup();\n}\n","import { isBaseModel } from '../core/model_base_mixin';\n\nconst DEFAULT_EXITPROBABILITY_LAST_STATE = 0.1;\n\n/**\n * Hierarchical HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hierarchicalHmmPredictionPrototype =\n/** @lends withHierarchicalHMMPrediction */\n{\n  /**\n   * Specificies if the forward algorithm has been initialized\n   * @type {Boolean}\n   * @private\n   */\n  forwardInitialized: false,\n\n  /**\n   * Setup the model (allocate transition parameters)\n   * @return {HierarchicalHMM} [description]\n   * @private\n   */\n  setup() {\n    const numClasses = this.size();\n    this.params.prior = new Array(numClasses).fill(1 / numClasses);\n    this.params.transition = Array.from(\n      new Array(numClasses),\n      () => new Array(numClasses).fill(1 / numClasses),\n    );\n    this.params.exitTransition = new Array(numClasses).fill(0.1);\n    Object.values(this.models).forEach((model) => {\n      const m = model;\n      m.isHierarchical = true;\n    });\n    this.updateExitProbabilities();\n    return this;\n  },\n\n  /**\n   * Update the exit probabilities of each sub-Markov model\n   * @param  {Array<Number>|undefined} [exitProbabilities=undefined] Vector of\n   * exit probabilities (optional)\n   * @private\n   */\n  updateExitProbabilities(exitProbabilities = undefined) {\n    const exitProb = (exitProbabilities !== undefined) ?\n      exitProbabilities :\n      new Array(this.params.states - 1).fill(0)\n        .concat([DEFAULT_EXITPROBABILITY_LAST_STATE]);\n    Object.keys(this.models).forEach((label) => {\n      this.models[label].params.exitProbabilities = exitProb.slice();\n    });\n  },\n\n  /**\n   * Reset the prediction process. This is particularly important for temporal\n   * models such as HMMs, that depends on previous observations.\n   */\n  reset() {\n    Object.values(this.models).forEach(m => m.reset());\n    this.results = {\n      labels: [],\n      instantLikelihoods: [],\n      smoothedLikelihoods: [],\n      smoothedLogLikelihoods: [],\n      smoothedNormalizedLikelihoods: [],\n      exitLikelihood: [],\n      likeliest: null,\n      classes: {},\n    };\n    if (this.params.bimodal) {\n      this.resetBimodal();\n    }\n    this.forwardInitialized = false;\n  },\n\n  /**\n   * Make a prediction from a new observation (updates the results member)\n   * @param  {Array<Number>} observation Observation vector\n   */\n  predict(observation) {\n    if (this.forwardInitialized) {\n      this.updateForwardAlgorithm(observation);\n    } else {\n      this.initializeForwardAlgorithm(observation);\n    }\n    Object.keys(this.models).sort().forEach((label) => {\n      const model = this.models[label];\n      model.updateAlphaWindow();\n      model.updateProgress();\n      model.updateResults(model.results.instantLikelihood);\n    });\n    this.updateResults();\n\n    if (this.params.bimodal) {\n      Object.values(this.models).forEach(m => m.regression(observation));\n\n      if (this.params.multiClassRegressionEstimator === 'likeliest') {\n        this.results.outputValues =\n          this.models[this.results.likeliest].results.outputValues;\n        this.results.outputCovariance =\n          this.models[this.results.likeliest].results.outputCovariance;\n      } else {\n        this.results.outputValues = new Array(this.outputDimension).fill(0);\n        this.results.outputCovariance =\n          new Array(this.params.covarianceMode === 'full' ?\n            this.outputDimension ** 2 :\n            this.outputDimension).fill(0);\n\n        let modelIndex = 0;\n        Object.values(this.models).forEach((model) => {\n          for (let d = 0; d < this.outputDimension; d += 1) {\n            this.results.outputValues[d] +=\n              this.results.smoothedNormalizedLikelihoods[modelIndex] *\n              model.second.results.outputValues[d];\n\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n                this.results.outputCovariance[(d * this.outputDimension) + d2] +=\n                  this.results.smoothedNormalizedLikelihoods[modelIndex] *\n                  model.results.outputCovariance[(d * this.outputDimension) + d2];\n              }\n            } else {\n              this.results.outputCovariance[d] +=\n                this.results.smoothedNormalizedLikelihoods[modelIndex] *\n                model.second.results.outputCovariance[d];\n            }\n          }\n          modelIndex += 1;\n        });\n      }\n    }\n  },\n\n  /**\n   * Initialize the forward algorithm of the hierarchical HMM\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  initializeForwardAlgorithm(observation) {\n    let normConst = 0;\n    let modelIndex = 0;\n    const classes = Object.keys(this.models).sort();\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      model.alpha1 = new Array(N).fill(0);\n      model.alpha2 = new Array(N).fill(0);\n\n      // Compute Emission probability and initialize on the first state of\n      // the primitive\n      if (model.params.transitionMode === 'ergodic') {\n        model.results.instantLikelihood = 0;\n        for (let i = 0; i < N; i += 1) {\n          model.alpha[i] = this.params.prior[modelIndex] *\n            model.params.prior[i] *\n            model.params.xStates[i].likelihood(observation);\n          model.results.instantLikelihood += model.alpha[i];\n        }\n      } else {\n        model.alpha[0] = this.params.prior[modelIndex] *\n          model.params.xStates[0].likelihood(observation);\n        [model.results.instantLikelihood] = model.alpha;\n      }\n      normConst += model.results.instantLikelihood;\n      modelIndex += 1;\n    });\n\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      for (let i = 0; i < N; i += 1) {\n        model.alpha[i] /= normConst;\n      }\n    });\n\n\n    this.frontierV1 = new Array(this.size).fill(0);\n    this.frontierV2 = new Array(this.size).fill(0);\n    this.forwardInitialized = true;\n  },\n\n  /**\n   * Update the forward algorithm of the hierarchical HMM\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  updateForwardAlgorithm(observation) {\n    let normConst = 0;\n\n    // Frontier Algorithm: variables\n    let tmp = 0;\n\n    // Intermediate variables: compute the sum of probabilities of making a\n    // transition to a new primitive\n    this.frontierV1 = this.likelihoodAlpha(1);\n    this.frontierV2 = this.likelihoodAlpha(2);\n\n    // FORWARD UPDATE\n    // --------------------------------------\n    let dstModelIndex = 0;\n    const classes = Object.keys(this.models).sort();\n    classes.forEach((label) => {\n      const dstModel = this.models[label];\n      const N = dstModel.params.states;\n\n      // 1) COMPUTE FRONTIER VARIABLE\n      //    --------------------------------------\n      // frontier variable : intermediate computation variable\n      const front = new Array(N).fill(0);\n\n      if (dstModel.params.transitionMode === 'ergodic') {\n        for (let k = 0; k < N; k += 1) {\n          for (let j = 0; j < N; j += 1) {\n            front[k] += (dstModel.params.transition[j][k] /\n              (1 - dstModel.params.exitProbabilities[j]))\n              * dstModel.alpha[j];\n          }\n\n          for (\n            let srcModelIndex = 0;\n            srcModelIndex < this.size();\n            srcModelIndex += 1\n          ) {\n            front[k] += dstModel.params.prior[k] * (\n              (this.frontierV1[srcModelIndex] *\n              this.params.transition[srcModelIndex][dstModelIndex]) +\n              (this.params.prior[dstModelIndex] *\n              this.frontierV2[srcModelIndex])\n            );\n          }\n        }\n      } else {\n        // k=0: first state of the primitive\n        front[0] = dstModel.params.transition[0] * dstModel.alpha[0];\n\n        for (\n          let srcModelIndex = 0;\n          srcModelIndex < this.size();\n          srcModelIndex += 1\n        ) {\n          front[0] += (this.frontierV1[srcModelIndex] *\n            this.params.transition[srcModelIndex][dstModelIndex]) +\n            (this.params.prior[dstModelIndex] *\n              this.frontierV2[srcModelIndex]);\n        }\n\n        // k>0: rest of the primitive\n        for (let k = 1; k < N; k += 1) {\n          front[k] += (dstModel.params.transition[k * 2] /\n            (1 - dstModel.params.exitProbabilities[k])) *\n            dstModel.alpha[k];\n          front[k] += (dstModel.params.transition[((k - 1) * 2) + 1] /\n            (1 - dstModel.params.exitProbabilities[k - 1])) *\n            dstModel.alpha[k - 1];\n        }\n\n        for (let k = 0; k < N; k += 1) {\n          dstModel.alpha[k] = 0;\n          dstModel.alpha1[k] = 0;\n          dstModel.alpha2[k] = 0;\n        }\n      }\n\n      // 2) UPDATE FORWARD VARIABLE\n      //    --------------------------------------\n      dstModel.results.exitLikelihood = 0.0;\n      dstModel.results.instantLikelihood = 0.0;\n\n      // end of the primitive: handle exit states\n      for (let k = 0; k < N; k += 1) {\n        tmp = dstModel.params.xStates[k].likelihood(observation) * front[k];\n        dstModel.alpha2[k] = this.params.exitTransition[dstModelIndex] *\n          dstModel.params.exitProbabilities[k] * tmp;\n        dstModel.alpha1[k] = (1 - this.params.exitTransition[dstModelIndex]) *\n          dstModel.params.exitProbabilities[k] * tmp;\n        dstModel.alpha[k] = (1 - dstModel.params.exitProbabilities[k]) * tmp;\n\n        dstModel.results.exitLikelihood += dstModel.alpha1[k] + dstModel.alpha2[k];\n        dstModel.results.instantLikelihood += dstModel.alpha[k] +\n          dstModel.alpha1[k] + dstModel.alpha2[k];\n        normConst += tmp;\n      }\n\n      dstModel.results.exitRatio = dstModel.results.exitLikelihood /\n        dstModel.results.instantLikelihood;\n\n      dstModelIndex += 1;\n    });\n\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      for (let k = 0; k < N; k += 1) {\n        model.alpha[k] /= normConst;\n        model.alpha1[k] /= normConst;\n        model.alpha2[k] /= normConst;\n      }\n    });\n  },\n\n  /**\n   * Compute the likelihood of a given probability.\n   * @param  {Number} exitNum Exit level number\n   * @return {Array<Number>}\n   */\n  likelihoodAlpha(exitNum) {\n    const likelihoodVector = new Array(this.size()).fill(0);\n    if (exitNum < 0) {\n      // Likelihood over all exit states\n      let modelIndex = 0;\n      Object.keys(this.models).sort().forEach((label) => {\n        const model = this.models[label];\n        likelihoodVector[modelIndex] = 0.0;\n        for (let k = 0; k < model.params.states; k += 1) {\n          likelihoodVector[modelIndex] += model.second.alpha[k] +\n            model.second.alpha1[k] +\n            model.second.alpha2[k];\n        }\n        modelIndex += 1;\n      });\n    } else {\n      // Likelihood for exit state \"exitNum\"\n      let modelIndex = 0;\n      Object.keys(this.models).sort().forEach((label) => {\n        const model = this.models[label];\n        likelihoodVector[modelIndex] = 0;\n        let { alpha } = model;\n        if (exitNum === 1) {\n          alpha = model.alpha1;\n        }\n        if (exitNum === 2) {\n          alpha = model.alpha2;\n        }\n        for (let k = 0; k < model.params.states; k += 1) {\n          likelihoodVector[modelIndex] += alpha[k];\n        }\n        modelIndex += 1;\n      });\n    }\n    return likelihoodVector;\n  },\n};\n\n/**\n * Add Hierarchical HMM prediction capabilities to a multi-class model.\n *\n * @todo algorithmic details\n * @todo validate parameters\n * @todo validate gaussian components\n *\n * @param  {MulticlassBaseModel} o Source Model\n * @return {HierarchicalHMM}\n *\n * @extends withMulticlassPrediction\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHierarchicalHMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  // validateParameters(\n  //   'Hierarchical HMM',\n  //   hierarchicalHmmParameterSpec(o.params.states, o.params.transitionMode),\n  //   o.params,\n  // );\n  return Object.assign(\n    o,\n    hierarchicalHmmPredictionPrototype,\n    {\n      // alpha: new Array(o.params.states).fill(0),\n      // previous_alpha_: new Array(o.params.states).fill(0),\n    },\n  ).setup();\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withEMTraining from '../core/em_training_mixin';\nimport withHMMBase from './hmm_base_mixin';\nimport withHMMTraining from './hmm_training_mixin';\nimport MulticlassModelBase from '../core/multiclass_mixin';\nimport withMulticlassTraining from '../core/multiclass_training_mixin';\nimport withAbtractPrediction from '../core/prediction_mixin';\nimport withHMMPrediction from './hmm_prediction_mixin';\nimport withMulticlassPrediction from '../core/multiclass_prediction_mixin';\nimport withHierarchicalHMMPrediction from './hierarchical_hmm_prediction_mixin';\n\n/**\n * @typedef {Object} HMMParameters\n * @property {Boolean} bimodal Specifies if the model is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} states Number of hidden states in the Markov model\n * @property {Number} gaussians Number of components in the Gaussian mixture\n * observation distribution of each state\n * @property {String} transitionMode Transition matrix mode ('ergodic' or 'leftright')\n * @property {String} covarianceMode Covariance mode ('full' or 'diagonal')\n * @property {Array<Number>} mixtureCoeffs mixture coefficients ('weight' of\n * each gaussian component)\n * @property {Array<GaussianDistribution>} components Gaussian components\n */\n\n/**\n * Train a single-class HMM Model.\n *\n * @todo HMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {HMMParameters} Parameters of the trained HMM\n */\nexport function trainHMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const {\n    states,\n    gaussians,\n    regularization,\n    transitionMode,\n    covarianceMode,\n  } = configuration;\n  const model = withHMMTraining(\n    withEMTraining(\n      withHMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        ...configuration,\n      })),\n      convergenceCriteria,\n    ),\n    states,\n    gaussians,\n    regularization,\n    transitionMode,\n    covarianceMode,\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Train a multi-class HMM Model.\n *\n * @todo HMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {Object} Parameters of the trained HMM\n */\nexport function trainMulticlassHMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withMulticlassTraining(\n    MulticlassModelBase({ inputDimension, outputDimension, ...configuration }),\n    ts => trainHMM(ts, configuration, convergenceCriteria),\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Create a HMM Predictor from a full set of parameters (generated by trainHMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function HMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withHMMPrediction(withAbtractPrediction(\n    withHMMBase(ModelBase(params)),\n    likelihoodWindow,\n  ));\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass HMM Predictor from a full set of parameters\n * (generated by trainMulticlassHMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function MulticlassHMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withMulticlassPrediction(MulticlassModelBase(params));\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = HMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass HMM Predictor from a full set of parameters\n * (generated by trainMulticlassHMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function HierarchicalHMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  let model = MulticlassModelBase(params);\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = HMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model = withHierarchicalHMMPrediction(withMulticlassPrediction(model));\n  model.reset();\n  return model;\n}\n"],"names":["phrasePrototype","index","dim","Math","floor","Error","this","dimension","bimodal","inputDimension","inputData","length","outputData","concat","observation","push","slice","trim","outputDimension","mean","Array","fill","d","t","get","stddev","sqrt","minmax","from","min","Infinity","max","Phrase","columnNames","label","Object","assign","create","trainingSetPrototype","keys","phrases","phraseIndex","includes","toString","callback","forEach","phrase","p","undefined","filter","i","map","reduce","x","ts","TrainingSet","ll","sum","totalLength","ModelBase","isBaseModel","o","key","params","a","b","euclidean","v1","v2","x1","kMeansTrainingPrototype","trainingSet","empty","centers","clusters","trainingConfig","initialization","initializeClustersRandom","initializeClustersForgy","initClustersWithFirstPhrase","trainingNbIterations","maxIterations","previousCenters","updateCenters","meanClusterDistance","maxRelativeCenterVariation","k","l","relativeDistanceThreshold","getPhrase","indices","step","offset","c","random","pointsPerCluster","ppc","clustIdx","_","getFrame","numFramesPerCluster","frame","minDistance","clusterMembership","distance","withKMeansTraining","trainingConfiguration","model","trainKmeans","train","kEpsilonPseudoInverse","matrixPrototype","data","out","Matrix","ncols","nrows","j","mat","gaussJordanInverse","transp","transpose","prod","product","determinant","matrix","dst","newMat","n","abs","swapLines","ii","tmp","nc","baseGaussianPrototype","covarianceMode","covariance","inverseCovariance","allocateBimodal","covarianceDeterminant","inputLikelihood","euclideanDistance","exp","PI","Number","isNaN","regularization","covMatrix","inv","pinv","updateInverseCovarianceBimodal","dimension1","dimension2","gaussianEllipse","y","trace","eigenVal1","eigenVal2","width","height","angle","atan","tantheta","tan","updateInverseCovariance","bimodalGaussianPrototype","inverseCovarianceInput","inputObservation","covarianceDeterminantInput","prediction","e","f","covMatrixInput","d1","d2","invInput","updateOutputCovariance","outputCovariance","covarianceGS","covarianceSG","tmptmptmp","covarianceMod","GaussianDistribution","proto","dist","allocate","trainerPrototype","initTraining","logLikelihood","iterations","previousLogLikelihood","converged","updateTraining","pctChg","terminateTraining","iteration","logProb","previousLogProb","convergenceCriteria","minIterations","percentChange","withEMTraining","gmmBasePrototype","components","gaussians","mixtureCoeffs","beta","likelihood","componentLikelihood","mixtureComponent","normConst","regularize","currentRegularization","gmmBimodalPrototype","tmpOutputValues","results","outputValues","regression","withGMMBase","gmmTrainerPrototype","initParametersToDefault","standardDeviation","initMeansWithKMeans","initCovariances","updateInverseCovariances","dataStddev","normCoeffs","std","absolute","relative","kmeansParams","gmeans","factor","phraseIndices","E","tbase","log","pix","value","withGMMTraining","MulticlassBasePrototype","models","MulticlassModelBase","parameters","withMulticlassTraining","trainingFunction","labels","classes","getPhrasesOfClass","circularBufferPrototype","full","buffer","capacity","idx","CircularBuffer","clear","predictionBasePrototype","lw","likelihoodWindow","likelihoodBuffer","updateResults","instantLikelihood","bufSize","withAbtractPrediction","checkSpec","parameter","specification","constructor","validateParameters","values","attr","spec","required","check","transform","gmmParameterSpec","m","withGMMPrediction","MulticlassPredictionBasePrototype","setLikelihoodWindow","reset","resetBimodal","predict","labs","sort","normInstant","normSmoothed","maxLogLikelihood","lab","instantLikelihoods","smoothedLogLikelihoods","smoothedLikelihoods","likeliest","[object Object]","smoothedNormalizedLikelihoods","instantNormalizedLikelihoods","updateRegressionResults","MulticlassPredictionBimodalPrototype","multiClassRegressionEstimator","configuration","withMulticlassPrediction","trainGMM","trainMulticlassGMM","GMMPredictor","MulticlassGMMPredictor","hmmBasePrototype","transitionMode","states","alpha","prior","xStates","forwardInitialized","previousAlpha","transition","withHMMBase","TRANSITION_REGULARIZATION","hmmTrainerPrototype","initMeansCovariancesWithGMMEM","initMeansWithAllPhrases","initCovariancesFullyObserved","s","previousBeta","nbPhrases","size","gammaSequence","epsilonSequence","gammaSequenceperMixture","T","gammaSum","gammaSumPerMixture","baumWelchForwardBackward","baumWelchGammaSum","baumWelchEstimateMixtureCoefficients","baumWelchEstimateMeans","baumWelchEstimateCovariances","baumWelchEstimatePrior","baumWelchEstimateTransitions","normalizeTransitions","alphaSeq","betaSeq","setErgodic","setLeftRight","initCovariance","othermeans","gmmParams","normPrior","transitionNorm","ct","observationLikelihoods","currentPhrase","observationProbabilities","initializeForwardAlgorithm","baumWelchForwardUpdate","initializeBackwardAlgorithm","baumWelchBackwardUpdate","reverse","oo","normalizeMixtureCoeffs","sumprior","withHMMTraining","hmmParameterSpec","hmmPredictionPrototype","updateForwardAlgorithm","updateAlphaWindow","updateProgress","progress","windowMinindex","windowMaxindex","isHierarchical","alpha1","alpha2","windowNormalizationConstant","likeliestState","bestAlpha","hmmBimodalPredictionPrototype","regressionEstimator","clipMinState","clipMaxState","normalizationConstant","tmpPredictedOutput","withHMMPrediction","setup","DEFAULT_EXITPROBABILITY_LAST_STATE","hierarchicalHmmPredictionPrototype","numClasses","exitTransition","updateExitProbabilities","exitProbabilities","exitProb","modelIndex","second","N","frontierV1","frontierV2","likelihoodAlpha","dstModelIndex","dstModel","front","srcModelIndex","exitLikelihood","exitRatio","exitNum","likelihoodVector","withHierarchicalHMMPrediction","trainHMM","trainMulticlassHMM","HMMPredictor","MulticlassHMMPredictor","HierarchicalHMMPredictor"],"mappings":"AAIA,MAAMA,qBAOAC,EAAOC,MACY,iBAAVD,GAAsBE,KAAKC,MAAMH,KAAWA,QAC/C,IAAII,MAAM,mCAEdH,GAAOI,KAAKC,gBACR,IAAIF,MAAM,sCAEdC,KAAKE,QAAS,IACZN,EAAMI,KAAKG,eAAgB,IACzBR,GAASK,KAAKI,UAAUC,aACpB,IAAIN,MAAM,sCAEXC,KAAKI,UAAUT,GAAOC,MAE3BD,GAASK,KAAKM,WAAWD,aACrB,IAAIN,MAAM,sCAEXC,KAAKM,WAAWX,GAAOC,EAAMI,KAAKG,mBAEvCR,GAASK,KAAKK,aACV,IAAIN,MAAM,mCAEbC,KAAKI,UAAUT,SACZ,IAAII,MAAM,eAEXC,KAAKI,UAAUT,GAAOC,aAStBD,MACHA,GAASK,KAAKK,aACV,IAAIN,MAAM,sCAEdC,KAAKE,QACAF,KAAKI,UAAUT,GAAOY,OAAOP,KAAKM,WAAWX,IAE/CK,KAAKI,UAAUT,SASnBa,MAECA,EAAYH,SAAWL,KAAKC,gBACxB,IAAIF,MAAM,mCAGdC,KAAKE,cACFE,UAAUK,KAAKD,EAAYE,MAAM,EAAGV,KAAKG,sBACzCG,WAAWG,KAAKD,EAAYE,MAAMV,KAAKG,eAAgBH,KAAKC,kBAE5DG,UAAUK,KAAKD,QAGjBH,QAAU,aAUPG,OACHR,KAAKE,cACF,IAAIH,MAAM,0CAEdS,EAAYH,SAAWL,KAAKG,qBACxB,IAAIJ,MAAM,wCAGbK,UAAUK,KAAKD,QACfG,mBAUIH,OACJR,KAAKE,cACF,IAAIH,MAAM,0CAEdS,EAAYH,SAAWL,KAAKY,sBACxB,IAAIb,MAAM,wCAGbO,WAAWG,KAAKD,QAChBG,qBAOAN,OAAS,OACTD,kBACAE,iCAOAF,kBACAO,2BAOAL,mBACAK,qBASCE,EAAOC,MAAMd,KAAKC,WAAWc,KAAK,OACnC,IAAIC,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,KACrC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC/BD,IAAMhB,KAAKkB,IAAID,EAAGD,KAEpBA,IAAMhB,KAAKK,cAEXQ,6BASDM,EAASL,MAAMd,KAAKC,WAAWc,KAAK,GACpCF,EAAOb,KAAKa,WACb,IAAIG,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,KACrC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC7BD,KAAOhB,KAAKkB,IAAID,EAAGD,GAAKH,EAAKG,KAAOhB,KAAKkB,IAAID,EAAGD,GAAKH,EAAKG,MAE5DA,IAAMhB,KAAKK,SACXW,GAAKnB,KAAKuB,KAAKD,EAAOH,WAExBG,kBASDE,EAASP,MAAMQ,KACnBR,MAAMd,KAAKC,WACX,MAASsB,IAAMC,EAAAA,EAAUC,KAAMD,EAAAA,SAE5B,IAAIR,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC7BD,GAAGO,IAAM1B,KAAK0B,IAAIvB,KAAKkB,IAAID,EAAGD,GAAIK,EAAOL,GAAGO,OAC5CP,GAAGS,IAAM5B,KAAK4B,IAAIzB,KAAKkB,IAAID,EAAGD,GAAIK,EAAOL,GAAGS,YAGhDJ,UAQHrB,KAAKE,eACFG,OAASR,KAAK0B,IAAIvB,KAAKI,UAAUC,OAAQL,KAAKM,WAAWD,WA2BpE,SAAwBqB,QAAOvB,iBACZ,EADYS,kBAEX,EAFWe,cAGf,KAHeC,QAIrB,cAEF3B,EAAYE,EAAiBS,SAC5BiB,OAAOC,OACZD,OAAOE,OAAOrC,0BAEHkB,EAAkB,wDAInB,iDAIKe,GAAeb,MAAMb,GAAWc,KAAK,qUC9OxD,MAAMiB,oCAMKH,OAAOI,KAAKjC,KAAKkC,SAAS7B,uBAQV,IAAhBL,KAAKK,kBAQJ8B,UACJN,OAAOI,KAAKjC,KAAKkC,SAASE,SAASD,EAAYE,YAC1CrC,KAAKkC,QAAQC,EAAYE,YAE3B,cAUDC,UACCL,KAAKjC,KAAKkC,SAASK,QAASJ,MACxBnC,KAAKkC,QAAQC,GAAcA,EAAanC,KAAKkC,iBAYrDC,EAAaP,EAAmBY,SAC7BC,OAAgBC,IAAXF,EAAwBA,EAASd,uBAC1B1B,KAAKG,+BACJH,KAAKY,4BACTZ,KAAK2B,uBACAe,IAAVd,EAAuBA,EAAQO,EAAYE,yBAEhDH,QAAQC,GAAeM,EACrBA,UAOFN,UACEnC,KAAKkC,QAAQC,gBAOVP,QACLM,QAAUL,OAAOI,KAAKjC,KAAKkC,SAC7BS,OAAOC,GAAK5C,KAAKkC,QAAQU,GAAGhB,QAAUA,GACtCiB,IAAID,KAAQA,EAAG5C,KAAKkC,QAAQU,MAC5BE,OAAO,CAACC,EAAGN,gBAAYM,EAAMN,qBAO3BP,8BAQWN,SACVoB,EAAKC,YAAYjD,eACpBkC,QAAUL,OAAOI,KAAKjC,KAAKkC,SAC3BS,OAAOC,GAAK5C,KAAKkC,QAAQU,GAAGhB,QAAUA,GACtCiB,IAAID,KAAQA,EAAG5C,KAAKkC,QAAQU,MAC5BE,OAAO,CAACC,EAAGN,gBAAYM,EAAMN,OACzBO,mBAQAnB,OAAOI,KAAKjC,KAAKkC,SACrBW,IAAID,GAAK5C,KAAKkC,QAAQU,GAAGhB,OACzBkB,OAAO,CAACI,EAAIH,IAAOG,EAAGd,SAASW,GAAKG,EAAKA,EAAG3C,QAAQwC,0BAQhDlB,OAAOI,KAAKjC,KAAKkC,uBAQlBiB,EAAMrC,MAAMd,KAAKC,WAAWc,KAAK,OACnCqC,EAAc,gBACXnB,KAAKjC,KAAKkC,SAASK,QAASK,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKkC,QAAQU,GAAGvC,OAAQY,GAAK,IAC3CD,IAAMhB,KAAKkC,QAAQU,GAAG1B,IAAID,EAAGD,MAGtBhB,KAAKkC,QAAQU,GAAGvC,SAG1B8C,EAAIN,IAAIE,GAAKA,EAAIK,8BAQlBjC,EAASL,MAAMd,KAAKC,WAAWc,KAAK,GACpCF,EAAOb,KAAKa,WACduC,EAAc,gBACXnB,KAAKjC,KAAKkC,SAASK,QAASK,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKkC,QAAQU,GAAGvC,OAAQY,GAAK,IACxCD,KAAOhB,KAAKkC,QAAQU,GAAG1B,IAAID,EAAGD,GAAKH,EAAKG,KAAO,KAG3ChB,KAAKkC,QAAQU,GAAGvC,SAG1Bc,EAAO0B,IAAIE,GAAKlD,KAAKuB,KAAK2B,EAAIK,oBAQ/B/B,EAASP,MAAMQ,KACnBR,MAAMd,KAAKC,WACX,MAASsB,IAAMC,EAAAA,EAAUC,KAAMD,EAAAA,mBAE1BS,KAAKjC,KAAKkC,SAASK,QAASK,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKkC,QAAQU,GAAGvC,OAAQY,GAAK,IACxCD,GAAGO,KAAO1B,KAAK0B,IAAIF,EAAOL,GAAGO,IAAKvB,KAAKkC,QAAQU,GAAG1B,IAAID,EAAGD,MACzDA,GAAGS,KAAO5B,KAAK4B,IAAIJ,EAAOL,GAAGS,IAAKzB,KAAKkC,QAAQU,GAAG1B,IAAID,EAAGD,MAI/DK,IAqBX,SAAwB4B,aAAY9C,iBACjB,EADiBS,kBAEhB,EAFgBe,cAGpB,gBAER1B,EAAYE,EAAiBS,SAC5BiB,OAAOC,OACZD,OAAOE,OAAOC,+BAEHpB,EAAkB,6DAIde,GAAeb,MAAMb,GAAWc,KAAK,iBC9MzC,SAASsC,iBAAUlD,iBAAAS,2BAK1B6B,gFACCA,EAAEvC,eACFuC,EAAEtC,sBACFsC,EAAE7B,uBACF6B,EAAExC,8BAGFwC,wBAEM7B,EAAkB,+BAGlBT,gCAGAS,0BAGAT,EAAiBS,MAWzB,SAAS0C,YAAYC,OACrB1B,OAAOI,KAAKsB,GAAGnB,SAAS,UAAW,OAAO,SACjC,UAAW,iBAAkB,kBAAmB,aAClDS,IAAIW,GAAO3B,OAAOI,KAAKsB,EAAEE,QAAQrB,SAASoB,IACnDV,OAAO,CAACY,EAAGC,IAAMD,GAAKC,GAAG,GCzCf,SAASC,UAAUC,EAAIC,UAC7BjE,KAAKuB,KAAKyC,EACdhB,IAAI,CAACkB,EAAInB,KAAOmB,EAAKD,EAAGlB,KAAO,GAC/BE,OAAO,CAACY,EAAGX,IAAOW,EAAIX,EAAI,UCNzBiB,+BACEC,OACCA,GAAeA,EAAYC,cACxB,IAAInE,MAAM,qCAGb0D,OAAOU,QAAUrD,MAAMQ,KAC1BR,MAAMd,KAAKyD,OAAOW,UAClB,IAAM,IAAItD,MAAMd,KAAKyD,OAAOxD,WAAWc,KAAK,IAMH,WAAvCf,KAAKqE,eAAeC,oBACjBC,yBAAyBN,QACzB,GAA2C,UAAvCjE,KAAKqE,eAAeC,oBACxBE,wBAAwBP,OACxB,CAAA,GAA2C,SAAvCjE,KAAKqE,eAAeC,qBAGvB,IAAIvE,MAAM,4EAFX0E,4BAA4BR,OAMjC,IAAIS,EAAuB,EAC3BA,EAAuB1E,KAAKqE,eAAeM,cAC3CD,GAAwB,EACxB,OACME,EAAkB5E,KAAKyD,OAAOU,aAE/BU,cAAcD,EAAiBX,OAEhCa,EAAsB,EACtBC,EAA6B,MAC5B,IAAIC,EAAI,EAAGA,EAAIhF,KAAKyD,OAAOW,SAAUY,GAAK,EAAG,KAC3C,IAAIC,EAAI,EAAGA,EAAIjF,KAAKyD,OAAOW,SAAUa,GAAK,EACzCD,IAAMC,OACerB,UACrB5D,KAAKyD,OAAOU,QAAQa,GACpBhF,KAAKyD,OAAOU,QAAQc,OAIGpF,KAAK4B,IAChCmC,UACEgB,EAAgBI,GAChBhF,KAAKyD,OAAOU,QAAQa,IAEtBD,SAGmB/E,KAAKyD,OAAOW,UAAYpE,KAAKyD,OAAOW,SAAW,MACxCpE,KAAKyD,OAAOW,aACZU,GACG9E,KAAKqE,eAAea,0BAA2B,aAE3ElF,KAAKyD,oCAGcQ,SACpBzB,EAASyB,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDC,EAAOxF,KAAKC,MAAM0C,EAAOnC,OAASL,KAAKyD,OAAOW,cAEhDkB,EAAS,MACR,IAAIC,EAAI,EAAGA,EAAIvF,KAAKyD,OAAOW,SAAUmB,GAAK,EAAG,MAC3C9B,OAAOU,QAAQoB,GAAK,IAAIzE,MAAMd,KAAKyD,OAAOxD,WAAWc,KAAK,OAC1D,IAAIE,EAAI,EAAGA,EAAIoE,EAAMpE,GAAK,MACxB,IAAID,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOU,QAAQoB,GAAGvE,IAAMwB,EAAOtB,IAAIoE,EAASrE,EAAGD,GAAKqE,KAGnDA,6BAIWpB,SACjBzB,EAASyB,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDA,EAAUtE,MAAMQ,KACpBR,MAAM0B,EAAOnC,QACb,IAAMR,KAAKC,MAAMD,KAAK2F,SAAWxF,KAAKyD,OAAOW,WAEzCqB,EAAmBL,EAAQtC,OAC/B,CAAC4C,EAAK9C,WACEH,EAAIiD,WACR9C,IAAM,EACDH,GAET3B,MAAMd,KAAKyD,OAAOW,UAAUrD,KAAK,QAE9B,IAAI6B,EAAI,EAAGA,EAAIwC,EAAQ/E,OAAQuC,GAAK,EAAG,OACpC+C,EAAWP,EAAQxC,OACpB,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOU,QAAQwB,GAAU3E,IAAMwB,EAAOtB,IAAI0B,EAAG5B,QAGjDyC,OAAOU,QAAQ5B,QAAQ,CAACqD,EAAGL,UACzB9B,OAAOU,QAAQoB,GAAKvF,KAAKyD,OAAOU,QAAQoB,GAC1C1C,IAAIE,GAAKA,EAAI0C,EAAiBF,+BAIbtB,SAChBzB,EAASyB,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDA,EAAUtE,MAAMQ,KACpBR,MAAMd,KAAKyD,OAAOW,UAClB,IAAMvE,KAAKC,MAAMD,KAAK2F,SAAWhD,EAAOnC,cAErCoD,OAAOU,QAAUiB,EAAQvC,IAAID,GAAKJ,EAAOqD,SAASjD,mBAG3CgC,EAAiBX,QACxBR,OAAOU,QAAUrD,MAAMQ,KAAKR,MAAMd,KAAKyD,OAAOW,UAAW,IAC5D,IAAItD,MAAMd,KAAKyD,OAAOxD,WAAWc,KAAK,UAClC+E,EAAsBhF,MAAMd,KAAKyD,OAAOW,UAAUrD,KAAK,KACjDwB,QAASC,QACd,IAAIvB,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,EAAG,OACnC8E,EAAQvD,EAAOqD,SAAS5E,OAC1B+E,EAAcpC,UAAUmC,EAAOnB,EAAgB,IAC/CqB,EAAoB,MACnB,IAAIjB,EAAI,EAAGA,EAAIhF,KAAKyD,OAAOW,SAAUY,GAAK,EAAG,OAC1CkB,EAAWtC,UACfmC,EACAnB,EAAgBI,GAChBhF,KAAKyD,OAAOxD,WAEViG,EAAWF,MACOhB,IACNkB,KAGED,IAAsB,MACrC,IAAIjF,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOU,QAAQ8B,GAAmBjF,IAAMwB,EAAOtB,IAAID,EAAGD,UAI5D,IAAIgE,EAAI,EAAGA,EAAIhF,KAAKyD,OAAOW,SAAUY,GAAK,KACzCc,EAAoBd,GAAK,MACtB,IAAIhE,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOU,QAAQa,GAAGhE,IAAM8E,EAAoBd,KAO3D,SAAwBmB,mBACtB5C,EACAa,EACAgC,UAEK9C,YAAYC,SACT,IAAIxD,MAAM,qGAEZsE,EAAiBxC,OAAOC,uBACZ,mCACW,mBACZ,gBACA,KACdsE,GACGC,EAAQxE,OAAOC,OAAOyB,EAAGS,qDAGzBP,OAAOW,SAAWA,EACjBiC,EC3JT,SAAwBC,YACtBrC,EACAG,EACAC,SAEMlE,eAAEA,EAAFS,gBAAkBA,GAAoBqD,SAC9BkC,mBACZ9C,gDAIAe,EACAC,GAEWkC,MAAMtC,GC1BrB,MAAMuC,sBAAwB,KAWxBC,8BAMKzG,KAAK0G,KAAK5D,OAAO,CAACY,EAAGC,IAAMD,EAAIC,EAAG,sBAQnCgD,EAAMC,OAAO5G,KAAK6G,MAAO7G,KAAK8G,WAC/B,IAAIlE,EAAI,EAAGA,EAAI5C,KAAK6G,MAAOjE,GAAK,MAC9B,IAAImE,EAAI,EAAGA,EAAI/G,KAAK8G,MAAOC,GAAK,IAC/BL,KAAM9D,EAAI5C,KAAK8G,MAASC,GAAK/G,KAAK0G,KAAMK,EAAI/G,KAAK6G,MAASjE,UAG3D+D,WAQDK,MACFhH,KAAK6G,QAAUG,EAAIF,YACf,IAAI/G,MAAM,6CAEZ4G,EAAMC,OAAO5G,KAAK8G,MAAOE,EAAIH,WAC9B,IAAIjE,EAAI,EAAGA,EAAI5C,KAAK8G,MAAOlE,GAAK,MAC9B,IAAImE,EAAI,EAAGA,EAAIC,EAAIH,MAAOE,GAAK,EAAG,GACjCL,KAAM9D,EAAIoE,EAAIH,MAASE,GAAK,MAC3B,IAAI/B,EAAI,EAAGA,EAAIhF,KAAK6G,MAAO7B,GAAK,IAC/B0B,KAAM9D,EAAIoE,EAAIH,MAASE,IACzB/G,KAAK0G,KAAM9D,EAAI5C,KAAK6G,MAAS7B,GAAKgC,EAAIN,KAAM1B,EAAIgC,EAAIH,MAASE,UAI9DJ,aASH3G,KAAK8G,QAAU9G,KAAK6G,aACf7G,KAAKiH,2BAGRC,EAASlH,KAAKmH,eAChBnH,KAAK8G,OAAS9G,KAAK6G,MAAO,OACtBO,EAAOF,EAAOG,QAAQrH,OACtBsH,YAAEA,EAAaC,OAAQC,GAAQJ,EAAKH,4BACjCK,YAAAA,EAAaC,OAAQC,EAAIH,QAAQH,UAEtCE,EAAOpH,KAAKqH,QAAQH,IACpBI,YAAEA,EAAaC,OAAQC,GAAQJ,EAAKH,4BACjCK,YAAAA,EAAaC,OAAQL,EAAOG,QAAQG,6BASzCxH,KAAK8G,QAAU9G,KAAK6G,YAChB,IAAI9G,MAAM,+DAEduH,EAAc,QACZN,EAAMJ,OAAO5G,KAAK8G,MAAoB,EAAb9G,KAAK6G,OAC9BY,EAASb,OAAO5G,KAAK8G,MAAoB,EAAb9G,KAAK6G,OACjCa,EAAI1H,KAAK8G,UAGV,IAAIlE,EAAI,EAAGA,EAAI8E,EAAG9E,GAAK,EAAG,KACxB,IAAImE,EAAI,EAAGA,EAAIW,EAAGX,GAAK,IACtBL,KAAU,EAAJ9D,EAAQ8E,EAAKX,GAAK/G,KAAK0G,KAAM9D,EAAI8E,EAAKX,KAE9CL,KAAU,EAAJ9D,EAAQ8E,EAAKA,EAAI9E,GAAK,MAG7B,IAAIoC,EAAI,EAAGA,EAAI0C,EAAG1C,GAAK,EAAG,KACzBpC,EAAIoC,OACDnF,KAAK8H,IAAIX,EAAIN,KAAU,EAAJ9D,EAAQ8E,EAAK1C,IArGf,aAsGjB,KACK0C,QACF,IAAI3H,MAAM,4BAGLiH,EAAIN,KAAU,EAAJ9D,EAAQ8E,EAAK1C,GAGlCpC,IAAMoC,KACJ4C,UAAUhF,EAAGoC,KAGZ0B,KAAOM,EAAIN,KAAKhG,YAElB,IAAIqG,EAAI,EAAGA,EAAI,EAAIW,EAAGX,GAAK,IACvBL,KAAU,EAAJ1B,EAAQ0C,EAAKX,IAAMC,EAAIN,KAAU,EAAJ1B,EAAQ0C,EAAK1C,OAEpD,IAAI6C,EAAK,EAAGA,EAAKH,EAAGG,GAAM,KACzBA,IAAO7C,MACJ,IAAI+B,EAAI,EAAGA,EAAI,EAAIW,EAAGX,GAAK,IACvBL,KAAW,EAALmB,EAASH,EAAKX,IACvBC,EAAIN,KAAW,EAALmB,EAASH,EAAK1C,GACxByC,EAAOf,KAAU,EAAJ1B,EAAQ0C,EAAKX,KAIhCL,KAAOe,EAAOf,KAAKhG,cAGnB8G,EAAMZ,OAAO5G,KAAK8G,MAAO9G,KAAK6G,WAC/B,IAAIjE,EAAI,EAAGA,EAAI8E,EAAG9E,GAAK,MACrB,IAAImE,EAAI,EAAGA,EAAIW,EAAGX,GAAK,IACtBL,KAAM9D,EAAI8E,EAAKX,GAAKC,EAAIN,KAAU,EAAJ9D,EAAQ8E,EAAKA,EAAIX,UAG9CO,YAAAA,EAAaC,OAAQC,cAStB5E,EAAGmE,OACN,IAAI/B,EAAI,EAAGA,EAAIhF,KAAK6G,MAAO7B,GAAK,EAAG,OAChC8C,EAAM9H,KAAK0G,KAAM9D,EAAI5C,KAAK6G,MAAS7B,QACpC0B,KAAM9D,EAAI5C,KAAK6G,MAAS7B,GAAKhF,KAAK0G,KAAMK,EAAI/G,KAAK6G,MAAS7B,QAC1D0B,KAAMK,EAAI/G,KAAK6G,MAAS7B,GAAK8C,gBAU1BlF,EAAGmE,OACR,IAAI/B,EAAI,EAAGA,EAAIhF,KAAK8G,MAAO9B,GAAK,EAAG,OAChC8C,EAAM9H,KAAK0G,KAAM1B,EAAIhF,KAAK6G,MAASjE,QACpC8D,KAAM1B,EAAIhF,KAAK6G,MAASjE,GAAK5C,KAAK0G,KAAM1B,EAAIhF,KAAK6G,MAASE,QAC1DL,KAAM1B,EAAIhF,KAAK6G,MAASE,GAAKe,KAiBxC,SAAwBlB,OAAOE,EAAQ,EAAGD,GAAQ,SAC1CkB,EAAKlB,EAAQ,EAAIC,EAAQD,SACxBhF,OAAOC,OACZD,OAAOE,OAAO0E,gCAGLsB,OACDjH,MAAMgG,EAAQiB,GAAIhH,KAAK,KC5KnC,MAAMiH,uCAMGnH,KAAO,IAAIC,MAAMd,KAAKC,WAAWc,KAAK,GACf,SAAxBf,KAAKiI,qBACFC,WAAa,IAAIpH,MAAMd,KAAKC,WAAa,GAAGc,KAAK,QACjDoH,kBAAoB,IAAIrH,MAAMd,KAAKC,WAAa,GAAGc,KAAK,UAExDmH,WAAa,IAAIpH,MAAMd,KAAKC,WAAWc,KAAK,QAC5CoH,kBAAoB,IAAIrH,MAAMd,KAAKC,WAAWc,KAAK,IAEtDf,KAAKE,cACFkI,8BAcE5H,MAC0B,IAA/BR,KAAKqI,4BACD,IAAItI,MAAM,0CAEdC,KAAKE,SAAWM,EAAYH,SAAWL,KAAKG,sBACvCH,KAAKsI,gBAAgB9H,MAE1BA,EAAYH,SAAWL,KAAKC,gBACxB,IAAIF,2EAA2EC,KAAKC,sBAAsBO,EAAYH,gBAG1HkI,EAAoB,KACI,SAAxBvI,KAAKiI,mBACF,IAAIhD,EAAI,EAAGA,EAAIjF,KAAKC,UAAWgF,GAAK,EAAG,KACtC6C,EAAM,MACL,IAAI9C,EAAI,EAAGA,EAAIhF,KAAKC,UAAW+E,GAAK,KAChChF,KAAKmI,kBAAmBlD,EAAIjF,KAAKC,UAAa+E,IAClDxE,EAAYwE,GAAKhF,KAAKa,KAAKmE,QAEVxE,EAAYyE,GAAKjF,KAAKa,KAAKoE,IAAM6C,WAGpD,IAAI7C,EAAI,EAAGA,EAAIjF,KAAKC,UAAWgF,GAAK,KAClBjF,KAAKmI,kBAAkBlD,IACzCzE,EAAYyE,GAAKjF,KAAKa,KAAKoE,KAC3BzE,EAAYyE,GAAKjF,KAAKa,KAAKoE,QAI9BxC,EAAI5C,KAAK2I,KAAK,GAAMD,GACtB1I,KAAKuB,KAAKpB,KAAKqI,uBAA0B,EAAIxI,KAAK4I,KAAOzI,KAAKC,kBAE5DwC,EAAI,QAAUiG,OAAOC,MAAMlG,IAAM5C,KAAK8H,IAAIlF,KAAQjB,EAAAA,OAChD,QAGCiB,cAUEmG,MACmB,SAAxB5I,KAAKiI,mBACF,IAAIjH,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,OAClCkH,WAAYlH,EAAIhB,KAAKC,UAAae,IAAM4H,EAAe5H,YAGzD,IAAIA,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,OAClCkH,WAAWlH,IAAM4H,EAAe5H,iCAUb,SAAxBhB,KAAKiI,eAA2B,OAC5BY,EAAYjC,OAAO5G,KAAKC,UAAWD,KAAKC,aAEpCyG,KAAO1G,KAAKkI,WAAWxH,cAC3BoI,EAAMD,EAAUE,YACjBV,sBAAwBS,EAAIxB,iBAC5Ba,kBAAoBW,EAAIvB,OAAOb,SAC/B,MACA2B,sBAAwB,MACxB,IAAIrH,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,IACtChB,KAAKkI,WAAWlH,IAAM,QAClB,IAAIjB,MAAM,8BAEboI,kBAAkBnH,GAAK,EAAIhB,KAAKkI,WAAWlH,QAC3CqH,uBAAyBrI,KAAKkI,WAAWlH,IAG9ChB,KAAKE,cACF8I,4CAWCC,EAAYC,MAChBD,GAAcjJ,KAAKC,WAAaiJ,GAAclJ,KAAKC,gBAC/C,IAAIF,MAAM,iCAGZoJ,KACD,IACA,QACI,SACC,QACD,OAQLzF,EACAC,EACA4B,IARYxC,EAAI/C,KAAKa,KAAKoI,KACdG,EAAIpJ,KAAKa,KAAKqI,GAQF,SAAxBlJ,KAAKiI,kBACHjI,KAAKkI,WAAYe,EAAajJ,KAAKC,UAAagJ,KAChDjJ,KAAKkI,WAAYe,EAAajJ,KAAKC,UAAaiJ,KAChDlJ,KAAKkI,WAAYgB,EAAalJ,KAAKC,UAAaiJ,OAEhDlJ,KAAKkI,WAAWe,KAChB,IACAjJ,KAAKkI,WAAWgB,UAIhBG,EAAQ3F,EAAI6B,EACZ+B,EAAe5D,EAAI6B,EAAM5B,EAAIA,EAC7B2F,EAAY,IAAOD,EAAQxJ,KAAKuB,KAAMiI,GAAS,EAAM,EAAI/B,IACzDiC,EAAY,IAAOF,EAAQxJ,KAAKuB,KAAMiI,GAAS,EAAM,EAAI/B,aAC/CkC,MAAQ3J,KAAKuB,KAAK,MAAQkI,KAC1BG,OAAS5J,KAAKuB,KAAK,MAAQmI,KAC3BG,MAAQ7J,KAAK8J,KAAKhG,GAAK2F,EAAY/D,IAC/CmD,OAAOC,MAAMQ,EAAgBO,WACfA,MAAQ7J,KAAK4I,GAAK,GAG7BU,eAYGA,EAAiBF,EAAYC,MACnCD,GAAcjJ,KAAKC,WAAaiJ,GAAclJ,KAAKC,gBAC/C,IAAIF,MAAM,gCAGbc,KAAKoI,GAAcE,EAAgBpG,OACnClC,KAAKqI,GAAcC,EAAgBC,QAElCE,EAAaH,EAAgBK,MAAQL,EAAgBK,MAAS,MAC9DD,EAAaJ,EAAgBM,OAASN,EAAgBM,OAAU,MAChEG,EAAW/J,KAAKgK,IAAIV,EAAgBO,OACpC/F,GAAM2F,EAAYC,GAAaK,GAAcA,GAAY,EAAK,GAC9DrE,EAAI+D,EAAa3F,EAAIiG,EACrBlG,EAAI6F,EAAa5F,EAAIiG,EAEC,SAAxB5J,KAAKiI,qBACFC,WAAYe,EAAajJ,KAAKC,UAAagJ,GAAcvF,OACzDwE,WAAYe,EAAajJ,KAAKC,UAAaiJ,GAAcvF,OACzDuE,WAAYgB,EAAalJ,KAAKC,UAAagJ,GAActF,OACzDuE,WAAYgB,EAAalJ,KAAKC,UAAaiJ,GAAc3D,SAEzD2C,WAAWe,GAAcvF,OACzBwE,WAAWgB,GAAc3D,QAE3BuE,4BAqBHC,4CAM0B,SAAxB/J,KAAKiI,oBACF+B,uBAAyB,IAAIlJ,MAAMd,KAAKG,gBAAkB,GAAGY,KAAK,QAElEiJ,uBAAyB,IAAIlJ,MAAMd,KAAKG,gBAAgBY,KAAK,oBAWtDkJ,MAC0B,IAApCjK,KAAKkK,iCACD,IAAInK,MAAM,6DAGdwI,EAAoB,KACI,SAAxBvI,KAAKiI,mBACF,IAAIhD,EAAI,EAAGA,EAAIjF,KAAKG,eAAgB8E,GAAK,EAAG,KAC3C6C,EAAM,MACL,IAAI9C,EAAI,EAAGA,EAAIhF,KAAKG,eAAgB6E,GAAK,KACrChF,KAAKgK,uBAAwB/E,EAAIjF,KAAKG,eAAkB6E,IAC5DiF,EAAiBjF,GAAKhF,KAAKa,KAAKmE,QAEfiF,EAAiBhF,GAAKjF,KAAKa,KAAKoE,IAAM6C,WAGzD,IAAI7C,EAAI,EAAGA,EAAIjF,KAAKG,eAAgB8E,GAAK,KACvBjF,KAAKmI,kBAAkBlD,IACzCgF,EAAiBhF,GAAKjF,KAAKa,KAAKoE,KAChCgF,EAAiBhF,GAAKjF,KAAKa,KAAKoE,QAInCxC,EAAI5C,KAAK2I,KAAK,GAAMD,GACb1I,KAAKuB,KAAKpB,KAAKkK,4BACR,EAAIrK,KAAK4I,KAAOzI,KAAKG,uBAEnCsC,EAAI,QAAUiG,OAAOC,MAAMlG,IAAM5C,KAAK8H,IAAIlF,KAAQjB,EAAAA,KAAUiB,EAAI,QAE7DA,cAYEwH,SACHrJ,EAAkBZ,KAAKC,UAAYD,KAAKG,eACxCgK,EAAarJ,MAAMF,GAAiBG,KAAK,MAEnB,SAAxBf,KAAKiI,mBACF,IAAIjH,EAAI,EAAGA,EAAIJ,EAAiBI,GAAK,EAAG,GAChCA,GAAKhB,KAAKa,KAAKb,KAAKG,eAAiBa,OAC3C,IAAIoJ,EAAI,EAAGA,EAAIpK,KAAKG,eAAgBiK,GAAK,EAAG,KAC3CtC,EAAM,MACL,IAAIuC,EAAI,EAAGA,EAAIrK,KAAKG,eAAgBkK,GAAK,KACrCrK,KAAKgK,uBAAwBI,EAAIpK,KAAKG,eAAkBkK,IAC5DJ,EAAiBI,GAAKrK,KAAKa,KAAKwJ,MAE1BrJ,IAAM8G,EACf9H,KAAKkI,YAAalH,EAAIhB,KAAKG,gBAAkBH,KAAKC,UAAamK,aAIhE,IAAIpJ,EAAI,EAAGA,EAAIJ,EAAiBI,GAAK,IAC7BA,GAAKhB,KAAKa,KAAKb,KAAKG,eAAiBa,UAG7CmJ,uCAQqB,SAAxBnK,KAAKiI,eAA2B,OAC5BqC,EAAiB1D,OAAO5G,KAAKG,eAAgBH,KAAKG,oBACnD,IAAIoK,EAAK,EAAGA,EAAKvK,KAAKG,eAAgBoK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKxK,KAAKG,eAAgBqK,GAAM,IAChC9D,KAAM6D,EAAKvK,KAAKG,eAAkBqK,GAC/CxK,KAAKkI,WAAYqC,EAAKvK,KAAKC,UAAauK,SAGxCC,EAAWH,EAAevB,YAC3BmB,2BAA6BO,EAASnD,iBACtC0C,uBAAyBS,EAASlD,OAAOb,SACzC,MACAwD,2BAA6B,MAC7B,IAAIlJ,EAAI,EAAGA,EAAIhB,KAAKG,eAAgBa,GAAK,EAAG,IAC3ChB,KAAKkI,WAAWlH,IAAM,QAClB,IAAIjB,MAAM,8BAEbiK,uBAAuBhJ,GAAK,EAAIhB,KAAKkI,WAAWlH,QAChDkJ,4BAA8BlK,KAAKkI,WAAWlH,SAGlD0J,sDAQuB,aAAxB1K,KAAKiI,gCACF0C,iBAAmB3K,KAAKkI,WAAWxH,MAAM,EAAGV,KAAKG,uBAKlDmK,EAAiB1D,OAAO5G,KAAKG,eAAgBH,KAAKG,oBACnD,IAAIoK,EAAK,EAAGA,EAAKvK,KAAKG,eAAgBoK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKxK,KAAKG,eAAgBqK,GAAM,IAChC9D,KAAM6D,EAAKvK,KAAKG,eAAkBqK,GAC/CxK,KAAKkI,WAAYqC,EAAKvK,KAAKC,UAAauK,SAGxC1B,EAAMwB,EAAevB,OACrB6B,EAAehE,OAAO5G,KAAKG,eAAgBH,KAAKY,qBACjD,IAAI2J,EAAK,EAAGA,EAAKvK,KAAKG,eAAgBoK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKxK,KAAKY,gBAAiB4J,GAAM,IACnC9D,KAAM6D,EAAKvK,KAAKY,gBAAmB4J,GAC9CxK,KAAKkI,WAAYqC,EAAKvK,KAAKC,UAAaD,KAAKG,eAAiBqK,SAG9DK,EAAejE,OAAO5G,KAAKY,gBAAiBZ,KAAKG,oBAClD,IAAIoK,EAAK,EAAGA,EAAKvK,KAAKY,gBAAiB2J,GAAM,MAC3C,IAAIC,EAAK,EAAGA,EAAKxK,KAAKG,eAAgBqK,GAAM,IAClC9D,KAAM6D,EAAKvK,KAAKG,eAAkBqK,GAC7CxK,KAAKkI,YAAalI,KAAKG,eAAiBoK,GAAMvK,KAAKC,UAAauK,SAGhEM,EAAYhC,EAAIvB,OAAOF,QAAQuD,GAC/BG,EAAgBF,EAAaxD,QAAQyD,QACtCH,iBAAmB7J,MAAMd,KAAKY,iBAAmB,GAAGG,KAAK,OACzD,IAAIwJ,EAAK,EAAGA,EAAKvK,KAAKY,gBAAiB2J,GAAM,MAC3C,IAAIC,EAAK,EAAGA,EAAKxK,KAAKY,gBAAiB4J,GAAM,OAC3CG,iBAAkBJ,EAAKvK,KAAKY,gBAAmB4J,GAClDxK,KAAKkI,YAAalI,KAAKG,eAAiBoK,GAAMvK,KAAKC,UACjDD,KAAKG,eAAiBqK,GACtBO,EAAcrE,KAAM6D,EAAKvK,KAAKY,gBAAmB4J,KA2B9C,SAASQ,qBACtB7K,EAAiB,EACjBS,EAAkB,EAClBqH,EAAiB,cAEX/H,EAAUU,EAAkB,EAC5BX,EAAYE,EAAiBS,EAC7BqK,EAAQ/K,EACZ2B,OAAOC,UAAWkG,sBAAuB+B,0BACzC/B,sBACItB,EAAO7E,OAAOC,wGAOO,GAEzB5B,GAAYgK,2BAA4B,OAEpCgB,EAAOrJ,OAAOC,OAClBD,OAAOE,OAAOkJ,GACdvE,YAEGyE,WACED,EC/bT,MAAME,wBAQEnH,OACCA,GAAeA,EAAYC,cACxB,IAAInE,MAAM,kCAGbsL,aAAapH,OAEdqH,GAAiB9J,EAAAA,EACjB+J,EAAa,EACbC,EAAwBF,QAEpBtL,KAAKyL,UAAUF,EAAYD,EAAeE,IAAwB,GAChDF,IACRtL,KAAK0L,eAAezH,SAE9B0H,EACJ,IAAM9L,KAAK8H,KAAK2D,EAAgBE,GAAyBA,MACvD9C,OAAOC,MAAMgD,IAAWJ,EAAa,QACjC,IAAIxL,MAAM,uCAGJ,cAGX6L,oBACE5L,KAAKyD,kBAeJoI,EAAWC,EAASC,MACxBF,GAAa7L,KAAKgM,oBAAoBrH,cAAe,OAAO,KAC5D3E,KAAKgM,oBAAoBrH,eAAiB3E,KAAKgM,oBAAoBC,qBAC9DJ,GAAa7L,KAAKgM,oBAAoBrH,iBAE3CkH,EAAY7L,KAAKgM,oBAAoBC,cAAe,OAAO,SACzC,IAAMpM,KAAK8H,KAAKmE,EAAUC,GAAmBD,IAC3C9L,KAAKgM,oBAAoBE,gBA2BtC,SAASC,eACtB5I,EACAyI,iBACiB,mBACA,gBACA,aAGVnK,OAAOC,OAAOyB,EAAG6H,kBAAoBY,oBAAAA,IClF9C,MAAMI,kCAMG3I,OAAO4I,WAAavL,MAAMQ,KAC7BR,MAAMd,KAAKyD,OAAO6I,WAClB,IAAM,IAAItB,qBACRhL,KAAKyD,OAAOtD,eACZH,KAAKyD,OAAO7C,gBACZZ,KAAKyD,OAAOwE,sBAGXxE,OAAO8I,cAAgBzL,MAAMd,KAAKyD,OAAO6I,WAAWvL,KAAK,QACzDyL,KAAO,IAAI1L,MAAMd,KAAKyD,OAAO6I,WAAWvL,KAAK,eAQzCP,OACLiM,EAAa,MACZ,IAAIlH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzCiH,KAAKjH,GAAKvF,KAAK0M,oBAAoBlM,EAAa+E,MACvCvF,KAAKwM,KAAKjH,OAErB,IAAIA,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzCiH,KAAKjH,IAAMkH,SAGXA,uBAUWjM,EAAamM,MAC3BA,GAAoB3M,KAAKyD,OAAO6I,gBAC5B,IAAIvM,MAAM,uEAEXC,KAAKyD,OAAO8I,cAAcI,GAC7B3M,KAAKyD,OAAO4I,WAAWM,GAAkBF,WAAWjM,oCAQnDiD,OAAO4I,WAAW9J,QAASgD,MAC5BuE,qCAGGrG,OAAO4I,WAAW9J,QAASgD,MAC5BuE,4BAEJ,MAAOM,SACD,IAAIrK,MAAM,2FASd6M,EAAY,MACX,IAAIrH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,KACjCvF,KAAKyD,OAAO8I,cAAchH,MAErCqH,EAAY,MACT,IAAIrH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAO8I,cAAchH,IAAMqH,WAG7B,IAAIrH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAO8I,cAAchH,GAAK,EAAIvF,KAAKyD,OAAO6I,6BAU9C7I,OAAO4I,WAAW9J,QAASgD,MAC5BsH,WAAW7M,KAAK8M,2BAUlBC,gCASO9C,OAGL+C,OAFCC,QAAQC,aAAepM,MAAMd,KAAKyD,OAAO7C,iBAAiBG,KAAK,QAC/DkM,QAAQtC,iBAAmB7J,MAAqC,SAA/Bd,KAAKyD,OAAOwE,eAA4BjI,KAAKyD,OAAO7C,iBAAmB,EAAIZ,KAAKyD,OAAO7C,iBAAiBG,KAAK,OAG9I,IAAIwE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,EAAG,GAC/BvF,KAAKyD,OAAO4I,WAAW9G,GAAG4H,WAAWlD,OAClD,IAAIjJ,EAAI,EAAGA,EAAIhB,KAAKyD,OAAO7C,gBAAiBI,GAAK,UAC/CiM,QAAQC,aAAalM,IAAMhB,KAAKwM,KAAKjH,GAAKyH,EAAgBhM,GAC5B,SAA/BhB,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKxK,KAAKyD,OAAO7C,gBAAiB4J,GAAM,OAClDyC,QAAQtC,iBAAkB3J,EAAIhB,KAAKyD,OAAO7C,gBAAmB4J,IAC/DxK,KAAKwM,KAAKjH,IAAM,EACjBvF,KAAKyD,OAAO4I,WAAW9G,GAAGoF,iBAAkB3J,EAAIhB,KAAKyD,OAAO7C,gBAAmB4J,aAG9EyC,QAAQtC,iBAAiB3J,IAC3BhB,KAAKwM,KAAKjH,IAAM,EAAKvF,KAAKyD,OAAO4I,WAAW9G,GAAGoF,iBAAiB3J,UAIlEhB,KAAKiN,QAAQC,eAiBT,SAASE,YAAY7J,OAC7BD,YAAYC,SACT,IAAIxD,MAAM,sGAEX8B,OAAOC,OACZyB,EACA6I,iBACA7I,EAAEE,OAAOvD,QAAU6M,wBC9JvB,MAAMM,kCAKSpJ,QACNkH,gBACAmC,wBAAwBrJ,EAAYsJ,0BACpCC,oBAAoBvJ,QACpBwJ,gBAAgBxJ,QAChB4I,kBACAa,oDAQiBC,OAClBC,EAAa,OACZd,sBAAwBa,EAAW9K,IAAIgL,GAAOhO,KAAK4B,IACtDzB,KAAKyD,OAAOmF,eAAekF,SAC3B9N,KAAKyD,OAAOmF,eAAemF,SAAWF,QAEnC,IAAItI,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,EACX,SAA/BvF,KAAKyD,OAAOwE,oBACTxE,OAAO4I,WAAW9G,GAAG2C,WAAapH,MAAMd,KAAKyD,OAAOxD,WAAa,GACnEc,KAAKf,KAAKyD,OAAOmF,eAAekF,SAAW,QAEzCrK,OAAO4I,WAAW9G,GAAG2C,WAAapH,MAAMd,KAAKyD,OAAOxD,WAAWc,KAAK,QAEtE0C,OAAO4I,WAAW9G,GAAGsH,WAAW7M,KAAK8M,4BACrCrJ,OAAO8I,cAAchH,GAAK,EAAIvF,KAAKyD,OAAO6I,aACjCtM,KAAKyD,OAAO8I,cAAchH,OAErC,IAAIA,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAO8I,cAAchH,IAAMqI,uBAYhB3J,OACbA,GAAeA,EAAYC,QAAS,aASnC8J,EARS7H,mBACb9C,0BACkBrD,KAAKyD,OAAOtD,+BACXH,KAAKyD,OAAO7C,kBAE/BZ,KAAKyD,OAAO6I,WACVhI,eAAgB,SAEQiC,MAAMtC,OAC7B,IAAIsB,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAO4I,WAAW9G,GAAG1E,KAAOmN,EAAa7J,QAAQoB,oBAU1CtB,OAGTA,GAAeA,EAAYC,QAAS,WAEpC,IAAIwD,EAAI,EAAGA,EAAI1H,KAAKyD,OAAO6I,UAAW5E,GAAK,OACzCjE,OAAO4I,WAAW3E,GAAGQ,WAAapH,MAAsC,SAA/Bd,KAAKyD,OAAOwE,eAA6BjI,KAAKyD,OAAOxD,WAAa,EAAID,KAAKyD,OAAOxD,WAAWc,KAAK,SAG5IkN,EAASnN,MAAMd,KAAKyD,OAAO6I,UAAYtM,KAAKyD,OAAOxD,WAAWc,KAAK,GACnEmN,EAASpN,MAAMd,KAAKyD,OAAO6I,WAAWvL,KAAK,KACrCwB,QAASC,UACb6C,EAAOxF,KAAKC,MAAM0C,EAAOnC,OAASL,KAAKyD,OAAO6I,eAChDhH,EAAS,MACR,IAAIoC,EAAI,EAAGA,EAAI1H,KAAKyD,OAAO6I,UAAW5E,GAAK,EAAG,KAC5C,IAAIzG,EAAI,EAAGA,EAAIoE,EAAMpE,GAAK,MACxB,IAAIsJ,EAAK,EAAGA,EAAKvK,KAAKyD,OAAOxD,UAAWsK,GAAM,OACzC7C,EAAI1H,KAAKyD,OAAOxD,UAAasK,IAAO/H,EAAOtB,IAAIoE,EAASrE,EAAGsJ,GAChC,SAA/BvK,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKxK,KAAKyD,OAAOxD,UAAWuK,GAAM,OAC5C/G,OAAO4I,WAAW3E,GACpBQ,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,IAC3ChI,EAAOtB,IAAIoE,EAASrE,EAAGsJ,GAAM/H,EAAOtB,IAAIoE,EAASrE,EAAGuJ,aAGnD/G,OAAO4I,WAAW3E,GAAGQ,WAAWqC,IACnC/H,EAAOtB,IAAIoE,EAASrE,EAAGsJ,IAAO,KAI5BlF,IACHqC,IAAMrC,SAIZ,IAAIqC,EAAI,EAAGA,EAAI1H,KAAKyD,OAAO6I,UAAW5E,GAAK,MACzC,IAAI6C,EAAK,EAAGA,EAAKvK,KAAKyD,OAAOxD,UAAWsK,GAAM,OACzC7C,EAAI1H,KAAKyD,OAAOxD,UAAasK,IAAO2D,EAAOxG,GAChB,SAA/B1H,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKxK,KAAKyD,OAAOxD,UAAWuK,GAAM,OAC5C/G,OAAO4I,WAAW3E,GAAGQ,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,IAAO0D,EAAOxG,aAG/EjE,OAAO4I,WAAW3E,GAAGQ,WAAWqC,IAAO2D,EAAOxG,OAKpD,IAAIA,EAAI,EAAGA,EAAI1H,KAAKyD,OAAO6I,UAAW5E,GAAK,MACzC,IAAI6C,EAAK,EAAGA,EAAKvK,KAAKyD,OAAOxD,UAAWsK,GAAM,KACd,SAA/BvK,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKxK,KAAKyD,OAAOxD,UAAWuK,GAAM,OAC5C/G,OAAO4I,WAAW3E,GAAGQ,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,IAClEyD,EAAQvG,EAAI1H,KAAKyD,OAAOxD,UAAasK,GACrC0D,EAAQvG,EAAI1H,KAAKyD,OAAOxD,UAAauK,aAGpC/G,OAAO4I,WAAW3E,GAAGQ,WAAWqC,IACnC0D,EAAQvG,EAAI1H,KAAKyD,OAAOxD,UAAasK,IAAO,kBAUvCtG,OACT6H,EAAU,EACV1I,EAAc,IACNb,QAASC,OACJA,EAAOnC,eAElB8N,EAAgBtM,OAAOI,KAAKgC,EAAY/B,SAExCO,EAAI3B,MAAMQ,KACdR,MAAMd,KAAKyD,OAAO6I,WAClB,IAAM,IAAIxL,MAAMsC,GAAarC,KAAK,IAE9BqN,EAAItN,MAAMd,KAAKyD,OAAO6I,WAAWvL,KAAK,OACxCsN,EAAQ,IAEA9L,QAASC,QACd,IAAIvB,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,EAAG,KACrC2L,EAAY,MACX,IAAIrH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,IAC5CA,GAAG8I,EAAQpN,GAAKjB,KAAK0M,oBAAoBlK,EAAOqD,SAAS5E,GAAIsE,IAEvC,IAApB9C,EAAE8C,GAAG8I,EAAQpN,IACfyH,OAAOC,MAAMlG,EAAE8C,GAAG8I,EAAQpN,KAC1BwB,EAAE8C,GAAG8I,EAAQpN,KAAQO,EAAAA,OACnB+D,GAAG8I,EAAQpN,GAAK,WAEPwB,EAAE8C,GAAG8I,EAAQpN,OAEvB,IAAIsE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,IAC5CA,GAAG8I,EAAQpN,IAAM2L,IACjBrH,IAAM9C,EAAE8C,GAAG8I,EAAQpN,MAEZpB,KAAKyO,IAAI1B,MAEbpK,EAAOnC,aAIb,IAAIkF,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAO8I,cAAchH,GAAK6I,EAAE7I,GAAKnC,MAInC,IAAImC,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,MACzC,IAAIvE,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,EAAG,MAC5CyC,OAAO4I,WAAW9G,GAAG1E,KAAKG,GAAK,IAC5B,MACH,IAAIuN,EAAM,EAAGA,EAAMJ,EAAc9N,OAAQkO,GAAO,EAAG,OAChD/L,EAASyB,EAAY/B,QAAQiM,EAAcI,QAC5C,IAAItN,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,OACjCwC,OAAO4I,WAAW9G,GAAG1E,KAAKG,IAC7ByB,EAAE8C,GAAG8I,EAAQpN,GAAKuB,EAAOtB,IAAID,EAAGD,MAE3BwB,EAAOnC,YAEboD,OAAO4I,WAAW9G,GAAG1E,KAAKG,IAAMoN,EAAE7I,MAKR,SAA/BvF,KAAKyD,OAAOwE,mBACT,IAAI1C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,MACzC,IAAIgF,EAAK,EAAGA,EAAKvK,KAAKyD,OAAOxD,UAAWsK,GAAM,MAC5C,IAAIC,EAAKD,EAAIC,EAAKxK,KAAKyD,OAAOxD,UAAWuK,GAAM,EAAG,MAChD/G,OAAO4I,WAAW9G,GAAG2C,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,GAAM,IAClE,MACH,IAAI+D,EAAM,EAAGA,EAAMJ,EAAc9N,OAAQkO,GAAO,EAAG,OAChD/L,EAASyB,EAAY/B,QAAQiM,EAAcI,QAC5C,IAAItN,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,OACjCwC,OAAO4I,WAAW9G,GAAG2C,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,IAClE/H,EAAE8C,GAAG8I,EAAQpN,IACZuB,EAAOtB,IAAID,EAAGsJ,GAAMvK,KAAKyD,OAAO4I,WAAW9G,GAAG1E,KAAK0J,KACnD/H,EAAOtB,IAAID,EAAGuJ,GAAMxK,KAAKyD,OAAO4I,WAAW9G,GAAG1E,KAAK2J,OAE/ChI,EAAOnC,YAEboD,OAAO4I,WAAW9G,GAAG2C,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,IAAO4D,EAAE7I,GACzEgF,IAAOC,SACJ/G,OAAO4I,WAAW9G,GAAG2C,WAAYsC,EAAKxK,KAAKyD,OAAOxD,UAAasK,GAClEvK,KAAKyD,OAAO4I,WAAW9G,GAAG2C,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,aAMzE,IAAIjF,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,MACzC,IAAIgF,EAAK,EAAGA,EAAKvK,KAAKyD,OAAOxD,UAAWsK,GAAM,EAAG,MAC/C9G,OAAO4I,WAAW9G,GAAG2C,WAAWqC,GAAM,IACnC,MACH,IAAIgE,EAAM,EAAGA,EAAMJ,EAAc9N,OAAQkO,GAAO,EAAG,OAChD/L,EAASyB,EAAY/B,QAAQiM,EAAcI,QAC5C,IAAItN,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,EAAG,OACnCuN,EAAShM,EAAOtB,IAAID,EAAGsJ,GAAMvK,KAAKyD,OAAO4I,WAAW9G,GAAG1E,KAAK0J,QAC7D9G,OAAO4I,WAAW9G,GAAG2C,WAAWqC,IAC/B9H,EAAE8C,GAAG8I,EAAQpN,GAAKuN,EAAQA,KAEzBhM,EAAOnC,YAEboD,OAAO4I,WAAW9G,GAAG2C,WAAWqC,IAAO6D,EAAE7I,eAK/CsH,kBACAa,2BAEE5B,0BAoBX,SAAwB2C,gBACtBlL,EACA+I,EAAY,EACZ1D,GAAmBkF,SAAU,KAAMC,SAAU,KAC7C9F,EAAiB,YAEZpG,OAAOI,KAAKsB,GAAGnB,SAAS,gBACrB,IAAIrC,MAAM,sGAEX8B,OAAOC,OACZyB,EACA8J,wCAGO9J,EAAEE,0DCxRb,MAAMiL,uCAMK7M,OAAOI,KAAKjC,KAAK2O,QAAQtO,iBAQzBuB,UACAC,OAAOI,KAAKjC,KAAK2O,QAAQvM,SAASR,WAOpCA,GACD5B,KAAKoC,SAASR,WACT5B,KAAK2O,OAAO/M,KAYV,SAASgN,2BAAoBzO,iBAAAS,qBAGvCiO,yEAEIhN,OAAOC,OACZuB,oBAAYlD,eAAAA,EAAgBS,gBAAAA,GAAoBiO,IAChDH,yBC1CW,SAASI,uBACtBvL,EACAwL,UAEOlN,OAAOC,OACZyB,SAaQU,EAAa+K,OACZ/K,GAAeA,EAAYC,cACxB,IAAInE,MAAM,oCAEdiP,KACKzM,QAAS0C,QACTjF,KAAKoC,SAAS6C,SACX,IAAIlF,uBAAuBkF,2BAKlCxB,OAAOwL,YACCD,GAAU/K,EAAY+K,UAC9BzM,QAASX,UACNoB,EAAKiB,EAAYiL,kBAAkBtN,QAEpC6B,OAAOwL,QAAQrN,GAASmN,EAAiB/L,KAEzChD,KAAKyD,UCpCpB,MAAM0L,sCAKG9O,OAAS,OACTV,MAAQ,OACRyP,MAAO,OACPC,gBAOFb,GACCxO,KAAKoP,WACFC,OAAOrP,KAAKL,OAAS6O,OACrB7O,OAASK,KAAKL,MAAQ,GAAKK,KAAKsP,gBAEhCD,OAAO5O,KAAK+N,QACZnO,QAAU,OACV+O,KAAQpP,KAAKK,SAAWL,KAAKsP,eASlCC,UACKvP,KAAKqP,QAAQE,EAAMvP,KAAKL,OAASK,KAAKsP,gBAO1Cd,QACEnO,OAASL,KAAKsP,cACd3P,MAAQ,OACRyP,MAAO,OACPC,OAASvO,MAAMd,KAAKsP,UAAUvO,KAAKyN,YAQlClM,OACD,IAAIM,EAAI,EAAGA,EAAI5C,KAAKK,OAAQuC,GAAK,IAC3B5C,KAAKqP,QAAQzM,EAAI5C,KAAKL,OAASK,KAAKsP,UAAW1M,oBASnD5C,KAAKqP,OAAO3O,MAAMV,KAAKL,OAC3BY,OAAOP,KAAKqP,OAAO3O,MAAM,EAAGV,KAAKL,UAczB,SAAS6P,eAAeF,SAC/BD,EAASxN,OAAOE,OAAOoN,kCACtBG,SAAWA,IACXG,QACAJ,ECjFT,MAAMK,wBAA0BxP,sBAMZsP,eAAe,uBAMbG,QACbC,iBAAmBD,OACnBE,iBAAmBL,eAAeG,wBAQlCE,iBAAiBJ,QACfzP,cAUDQ,SACAiM,EAAazM,KAAKyM,WAAWjM,UAC/BN,QACGiN,WAAW3M,QAEbsP,cAAcrD,GACZzM,KAAKiN,uBAQA8C,QACP9C,QAAQ8C,kBAAoBA,OAC5BF,iBAAiBpP,KAAKZ,KAAKyO,IAAIyB,SAC/B9C,QAAQ3B,cAAgB,QACvB0E,EAAUhQ,KAAK6P,iBAAiBxP,WACjC,IAAIuC,EAAI,EAAGA,EAAIoN,EAASpN,GAAK,OAC3BqK,QAAQ3B,eAAiBtL,KAAK6P,iBAAiB3O,IAAI0B,QAErDqK,QAAQ3B,eAAiB0E,KAUlC,SAAwBC,sBAAsB1M,EAAGqM,EAAmB,OAC7DtM,YAAYC,SACT,IAAIxD,MAAM,qGAEZkN,EAAUpL,OAAOC,QACnBiO,kBAAmB,EAAGzE,cAAe,GACvC/H,EAAEE,OAAOvD,SAAYgN,gBAAkBvC,gCAElC9I,OAAOC,OACZyB,EACAmM,wBAAwBnM,EAAEE,OAAOvD,UAC/B+M,QAAAA,EAAS4C,iBAAkBL,eAAeI,KCzEhD,SAASM,UAAU7J,EAAO8J,EAAWC,EAAe5B,MAC7C4B,MACDA,EAAcC,cAAgBvP,QAAUsP,EAAchO,SAASoM,SAC3D,IAAIzO,oBAAoBoQ,eAAuB3B,iCAAqCnI,iBAAqB+J,QAC1G,GAAIA,EAAcC,cAAgBxO,OAAQ,IAC3CA,OAAOI,KAAKmO,GAAehO,SAAS,QAAUoM,EAAQ4B,EAAc7O,UAChE,IAAIxB,oBAAoBoQ,cAAsB3B,mDAAuD4B,EAAc7O,kBAAkB8E,UAEzIxE,OAAOI,KAAKmO,GAAehO,SAAS,QAAUoM,EAAQ4B,EAAc3O,UAChE,IAAI1B,oBAAoBoQ,cAAsB3B,mDAAuD4B,EAAc7O,kBAAkB8E,YAExI,GAA6B,mBAAlB+J,IACXA,EAAc5B,SACX,IAAIzO,oBAAoBoQ,cAAsB3B,kCAAsCnI,QAqEhG,SAAwBiK,mBAAmBjK,EAAO+J,EAAeG,SACzD1B,EAAahN,OAAOC,UAAWyO,iBAC9BtO,KAAKmO,GAAe7N,QAASiO,UAC5BC,EAAOL,EAAcI,MAGvBC,EAAKC,WAAa7O,OAAOI,KAAKsO,GAAQnO,SAASoO,SAC3C,IAAIzQ,2BAA2ByQ,6BAAgCnK,iBAI7DA,EAAOmK,EAAMC,EAAKE,MAAOJ,EAAOC,MAE/BA,GAAQC,EAAKG,UACtBH,EAAKG,UAAUL,EAAOC,IACtBD,EAAOC,KAEJ3B,EC5GT,MAAMgC,iBAAmBvE,0BAEX,SACD/K,IAAK,8BAGJ,QACH,EAAGuM,SAAAA,EAAUC,SAAAA,KACjBD,GAAYC,GAAYD,EAAW,GAAKC,EAAW,6BAG5C,SACF,OAAQ,sCAGN,QACH+C,GAAKA,EAAEzQ,SAAWiM,yBAGf,QACH/G,GAAKA,EAAElF,SAAWiM,KAed,SAASyE,kBAAkBxN,OACnCD,YAAYC,SACT,IAAIxD,MAAM,yHAEC,MAAO8Q,iBAAiBtN,EAAEE,OAAO6I,WAAY/I,EAAEE,QAC3D5B,OAAOC,OACZyB,GACEiJ,KAAM,IAAI1L,MAAMyC,EAAEE,OAAO6I,WAAWvL,KAAK,KCtC/C,MAAMiQ,gEAMKhR,KAAK4P,sCAOMD,QACbC,iBAAmBD,SACjB1N,KAAKjC,KAAK2O,QAAQpM,QAASX,SAC3B+M,OAAO/M,GAAOqP,oBAAoBtB,qBASlCY,OAAOvQ,KAAK2O,QAAQpM,QAAQuO,GAAKA,EAAEI,cACrCjE,qIAMQ,iBAGTjN,KAAKyD,OAAOvD,cACTiR,wBAQD3Q,UACC+P,OAAOvQ,KAAK2O,QAAQpM,QAAQuO,GAAKA,EAAEM,QAAQ5Q,SAC7CsP,uCAICuB,EAAOxP,OAAOI,KAAKjC,KAAK2O,QAAQ2C,YACjCrE,QAAQ+B,OAASqC,MAClBE,EAAc,EACdC,EAAe,EACfC,GAAoBjQ,EAAAA,OACnByL,QAAQgC,QAAUoC,EACpBxO,IAAI,CAAC6O,EAAK9O,UACJqK,QAAQ0E,mBAAmB/O,GAC9B5C,KAAK2O,OAAO+C,GAAKzE,QAAQ8C,uBACtB9C,QAAQ2E,uBAAuBhP,GAClC5C,KAAK2O,OAAO+C,GAAKzE,QAAQ3B,mBACtB2B,QAAQ4E,oBAAoBjP,GAC/B/C,KAAK2I,IAAIxI,KAAKiN,QAAQ2E,uBAAuBhP,OAChC5C,KAAKiN,QAAQ0E,mBAAmB/O,MAC/B5C,KAAKiN,QAAQ4E,oBAAoBjP,GAC7C5C,KAAKiN,QAAQ2E,uBAAuBhP,GAAK6O,MACxBzR,KAAKiN,QAAQ2E,uBAAuBhP,QAClDqK,QAAQ6E,UAAYJ,IAElBK,CAACL,GAAM1R,KAAK2O,OAAO+C,GAAKzE,WAElCnK,OAAO,CAACS,EAAGR,gBAAYQ,EAAMR,YAC3BkK,QAAQ+E,8BACXhS,KAAKiN,QAAQ4E,oBAAoBhP,IAAIE,GAAKA,EAAIyO,QAC3CvE,QAAQgF,6BACXjS,KAAKiN,QAAQ0E,mBAAmB9O,IAAIE,GAAKA,EAAIwO,GAC3CvR,KAAKyD,OAAOvD,cACTgS,4BAKLC,0DAEGlF,QAAQC,qBACRD,QAAQtC,kDAIqC,cAA9C3K,KAAKyD,OAAO2O,mCACTnF,QAAQC,aACXlN,KAAK2O,OAAO3O,KAAKiN,QAAQ6E,WAAW7E,QAAQC,kBACzCD,QAAQtC,iBACX3K,KAAK2O,OAAO3O,KAAKiN,QAAQ6E,WAAW7E,QAAQtC,qBACzC,CAAA,GAAkD,YAA9C3K,KAAKyD,OAAO2O,oCAcf,IAAIrS,MAAM,mEAbXkN,QAAQC,aAAepM,MAAMd,KAAKY,iBAAiBG,KAAK,QACxDkM,QAAQtC,iBAAmB7J,MAAMd,KAAKY,kBAA0D,SAAtCZ,KAAKqS,cAAcpK,eAA4B,EAAI,IAAIlH,KAAK,QACtHkM,QAAQ+B,OAAOzM,QAASmP,SACtBzE,QAAQC,aAAarK,IAAI,CAACE,EAAGH,IAAMG,EACtC/C,KAAKiN,QAAQ+E,8BAA8BpP,GAC3C5C,KAAK2O,OAAO+C,GAAKzE,QAAQC,aAAatK,SAEnCqK,QAAQtC,iBAAiB9H,IAAI,CAACE,EAAGH,IAAMG,EAC1C/C,KAAKiN,QAAQ+E,8BAA8BpP,GAC3C5C,KAAK2O,OAAO+C,GAAKzE,QAAQtC,iBAAiB/H,SAoBpD,SAAwB0P,yBAAyB/O,EAAG6O,EAAgC,iBAC7E9O,YAAYC,SACT,IAAIxD,MAAM,qGAEZ+Q,EAAIjP,OAAOC,OACfyB,EACAyN,kCACAzN,EAAEE,OAAOvD,QAAUiS,kDAEnB1O,OAAO2O,8BAAgCA,EAClCtB,EC1GT,SAAgByB,SACdtO,EACAoO,EACArG,SAEM7L,eAAEA,EAAFS,gBAAkBA,GAAoBqD,GACtCqI,UAAEA,EAAF1D,eAAaA,EAAbX,eAA6BA,GAAmBoK,SACxC5D,gBACZtC,eACEiB,YAAY/J,wDAGPgP,KAELrG,GAEFM,EACA1D,EACAX,GAEW1B,MAAMtC,GAcrB,SAAgBuO,mBACdvO,EACAoO,EACArG,SAEM7L,eAAEA,EAAFS,gBAAkBA,GAAoBqD,SAC9B6K,uBACZF,8BAAsBzO,eAAAA,EAAgBS,gBAAAA,GAAoByR,IAC1DrP,GAAMuP,SAASvP,EAAIqP,EAAerG,IAEvBzF,MAAMtC,GASrB,SAAgBwO,aACdhP,EACAmM,SAEMvJ,EAAQ0K,kBAAkBd,sBAC9B7C,YAAY/J,UAAUI,IACtBmM,aAEKvD,WAAW9J,QAAQ,CAACgD,EAAG3C,OACtBa,OAAO4I,WAAWzJ,GAAKf,OAAOC,OAAOkJ,qBACzCvH,EAAOtD,eACPsD,EAAO7C,gBACP6C,EAAOwE,gBACN1C,OAEC2L,QACC7K,EAUT,SAAgBqM,uBACdjP,EACAmM,SAEMvJ,EAAQiM,yBAAyB1D,oBAAoBnL,aACrDkL,iBACC1M,KAAKwB,EAAOwL,SAAS1M,QAASX,MAC7B+M,OAAO/M,GAAS6Q,aAAahP,EAAOwL,QAAQrN,GAAQgO,OAEtDsB,QACC7K,ECjHT,MAAMsM,sCAMgB,kBAQJ,6BAOWnS,OACrBoM,EAAY,KACmB,YAA/B5M,KAAKyD,OAAOmP,mBACT,IAAIhQ,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,OACtCkQ,MAAMlQ,GAAK5C,KAAKyD,OAAOsP,MAAMnQ,GAChC5C,KAAKyD,OAAOuP,QAAQpQ,GAAG6J,WAAWjM,MACvBR,KAAK8S,MAAMlQ,aAGrBkQ,MAAQ,IAAIhS,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,QAC3C+R,MAAM,GAAK9S,KAAKyD,OAAOuP,QAAQ,GAAGvG,WAAWjM,MACrCR,KAAK8S,MAAM,WAErBG,oBAAqB,EACtBrG,EAAY,EAAG,KACZ,IAAIhK,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,OACtCkQ,MAAMlQ,IAAMgK,SAEZ,EAAIA,MAER,IAAI7F,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,OACtC+L,MAAM/L,GAAK,EAAI/G,KAAKyD,OAAOoP,cAE3B,0BAQcrS,OACjBoM,EAAY,OACXsG,cAAgBlT,KAAK8S,MAAMpS,YAC3B,IAAIqG,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,EAAG,SACzC+L,MAAM/L,GAAK,EACmB,YAA/B/G,KAAKyD,OAAOmP,mBACT,IAAIhQ,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,OACtCkQ,MAAM/L,IAAM/G,KAAKkT,cAActQ,GAClC5C,KAAKyD,OAAO0P,WAAWvQ,GAAGmE,aAGzB+L,MAAM/L,IAAM/G,KAAKkT,cAAcnM,GAAK/G,KAAKyD,OAAO0P,WAAe,EAAJpM,GAC5DA,EAAI,OACD+L,MAAM/L,IAAM/G,KAAKkT,cAAcnM,EAAI,GACtC/G,KAAKyD,OAAO0P,WAAsB,GAATpM,EAAI,GAAU,QAEpC+L,MAAM,IAAM9S,KAAKkT,cAAclT,KAAKyD,OAAOoP,OAAS,GACvD7S,KAAKyD,OAAO0P,WAAiC,EAArBnT,KAAKyD,OAAOoP,OAAc,QAGnDC,MAAM/L,IAAM/G,KAAKyD,OAAOuP,QAAQjM,GAAG0F,WAAWjM,MACtCR,KAAK8S,MAAM/L,MAEtB6F,EAAY,OAAQ,KACjB,IAAI7F,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,OACtC+L,MAAM/L,IAAM6F,SAEZ,EAAIA,SAEN,IAiBI,SAASwG,YAAY7P,OAC7BD,YAAYC,SACT,IAAIxD,MAAM,sGAEX8B,OAAOC,OAAOyB,EAAGoP,kBC5G1B,MAAMU,0BAA4B,KAO5BC,kCAKSrP,GACNA,IAAeA,EAAYC,eAE3BiH,SAASlH,QACTqJ,wBAAwBrJ,EAAYsJ,qBACrCvN,KAAKyD,OAAO6I,UAAY,OACrBiH,8BAA8BtP,SAE9BuP,wBAAwBvP,QACxBwP,6BAA6BxP,eAS7BA,SACD9D,iBAAAS,kBAAA0L,YAAA1D,iBAAAX,kBAMFjI,KAAKyD,YACJA,OAAOuP,QAAUlS,MAAMQ,KAC1B,IAAIR,MAAMd,KAAKyD,OAAOoP,QACtB,IAAMzF,YAAY/J,qGAQfI,OAAOuP,QAAQzQ,QAAQmR,GAAKA,EAAEvI,iBAC9B2H,MAAQ,IAAIhS,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,QAC3CmS,cAAgB,IAAIpS,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,QACnDyL,KAAO,IAAI1L,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,QAC1C4S,aAAe,IAAI7S,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,SAIjD6S,EAAY3P,EAAY4P,YACzBC,cAAgB,IAAIhT,MAAM8S,GAAW7S,KAAK,WAC1CgT,gBAAkB,IAAIjT,MAAM8S,GAAW7S,KAAK,WAC5CiT,wBAA0B,IAAIlT,MAAM8S,GAAW7S,KAAK,UAErD6B,EAAI,IACIL,QAASC,UACbyR,EAAIzR,EAAOnC,YACZyT,cAAclR,GAAK9B,MAAMQ,KAC5B,IAAIR,MAAMmT,GACV,IAAM,IAAInT,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,IAER,YAA/Bf,KAAKyD,OAAOmP,oBACTmB,gBAAgBnR,GAAK9B,MAAMQ,KAC9B,IAAIR,MAAMmT,GACV,IAAMnT,MAAMQ,KACV,IAAIR,MAAMd,KAAKyD,OAAOoP,QACtB,IAAM,IAAI/R,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,UAIxCgT,gBAAgBnR,GAAK9B,MAAMQ,KAC9B,IAAIR,MAAMmT,GACV,IAAM,IAAInT,MAA2B,EAArBd,KAAKyD,OAAOoP,QAAY9R,KAAK,SAG5CiT,wBAAwBpR,GAC3B,IAAI9B,MAAMd,KAAKyD,OAAO6I,WAAWvL,KAAK,OACnC,IAAIwE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzCyO,wBAAwBpR,GAAG2C,GAC9BzE,MAAMQ,KACJ,IAAIR,MAAMmT,GACV,IAAM,IAAInT,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,OAM1C,SAGFmT,SAAW,IAAIpT,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,QAC9CoT,mBAAqB,IAAIrT,MAAMd,KAAKyD,OAAOoP,OAAS7S,KAAKyD,OAAO6I,WAAWvL,KAAK,mBAOxEkD,OACT6H,EAAU,EAIV3J,EAAc,IACNI,QAASC,IACfA,EAAOnC,OAAS,OACPL,KAAKoU,yBAAyB5R,EAAQL,OAEpC,SAEZkS,kBAAkBpQ,OAMlB,IAAIrB,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,MACtC,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAOuP,QAAQpQ,GAAGa,OAAO8I,cAAchH,GAAK,EACd,SAA/BvF,KAAKyD,OAAOwE,oBACTxE,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GAAG2C,WAC1C,IAAIpH,MAAMd,KAAKyD,OAAOxD,WAAa,GAAGc,KAAK,QAExC0C,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GAAG2C,WAC1C,IAAIpH,MAAMd,KAAKyD,OAAOxD,WAAWc,KAAK,eAKzCuT,qCAAqCrQ,QACrCsQ,uBAAuBtQ,QACvBuQ,6BAA6BvQ,GACC,YAA/BjE,KAAKyD,OAAOmP,qBACT6B,uBAAuBxQ,QAEzByQ,6BAA6BzQ,GAC3B6H,4BAQF6I,4BACAb,cAAgB,UAChBC,gBAAkB,UAClBC,wBAA0B,UAC1BY,SAAW,UACXC,QAAU,UACVX,SAAW,UACXC,mBAAqB,UACrB1Q,OAAOuP,QAAUhT,KAAKyD,OAAOuP,QAAQnQ,IAAI6Q,GAAKA,EAAEjQ,iCAQ/BkK,GACa,YAA/B3N,KAAKyD,OAAOmP,oBACTkC,kBAEAC,qBAEDjI,EAAwBa,EAAW9K,IAAIgL,GAAOhO,KAAK4B,IACvDzB,KAAKyD,OAAOmF,eAAekF,SAC3B9N,KAAKyD,OAAOmF,eAAemF,SAAWF,IAElCmH,EAAiD,SAA/BhV,KAAKyD,OAAOwE,eAClC,IAAM,IAAInH,MAAMd,KAAKyD,OAAOxD,WAAa,GACtCc,KAAKf,KAAKyD,OAAOmF,eAAekF,SAAW,GAC9C,IAAM,IAAIhN,MAAMd,KAAKyD,OAAOxD,WACzBc,KAAK,OACL,IAAI6B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,EAAG,OAExC8Q,EAAI1T,KAAKyD,OAAOuP,QAAQpQ,KAC5BkK,sBAAwBA,MACrB,IAAIvH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,IAC5C9B,OAAO4I,WAAW9G,GAAG2C,WAAa8M,MAClCvR,OAAO4I,WAAW9G,GAAGsH,WAAWC,KAChCrJ,OAAO8I,cAAchH,GAAK,EAAIvF,KAAKyD,OAAO6I,oCAW1BrI,OACjBA,GAAeA,EAAYC,QAAS,WAEpC,IAAIwD,EAAI,EAAGA,EAAI1H,KAAKyD,OAAOoP,OAAQnL,GAAK,MACtC,IAAI1G,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW,GAAGxL,KAAKG,GAAK,QAIpDkN,EAAS,IAAIpN,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,KACtCwB,QAASC,UACb6C,EAAOxF,KAAKC,MAAM0C,EAAOnC,OAASL,KAAKyD,OAAOoP,YAChDvN,EAAS,MACR,IAAIoC,EAAI,EAAGA,EAAI1H,KAAKyD,OAAOoP,OAAQnL,GAAK,EAAG,KACzC,IAAIzG,EAAI,EAAGA,EAAIoE,EAAMpE,GAAK,MACxB,IAAID,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW,GAAGxL,KAAKG,IAC/CwB,EAAOtB,IAAIoE,EAASrE,EAAGD,MAGnBqE,IACHqC,IAAMrC,SAGZ,IAAIqC,EAAI,EAAGA,EAAI1H,KAAKyD,OAAOoP,OAAQnL,GAAK,MACtC,IAAI1G,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW,GAAGxL,KAAKG,IAAMkN,EAAOxG,iCAWvCzD,OACtBA,GAAeA,EAAYC,QAAS,WAEpC,IAAIwD,EAAI,EAAGA,EAAI1H,KAAKyD,OAAOoP,OAAQnL,GAAK,OACtCjE,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW,GAAGnE,WAC1C,IAAIpH,MAAMd,KAAKyD,OAAOxD,YAA6C,SAA/BD,KAAKyD,OAAOwE,eAA4B,EAAI,IAAIlH,KAAK,SAGvFmN,EAAS,IAAIpN,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,GAC5CkU,EAAa,IAAInU,MAAMd,KAAKyD,OAAOoP,OAAS7S,KAAKyD,OAAOxD,WAC3Dc,KAAK,KACIwB,QAASC,UACb6C,EAAOxF,KAAKC,MAAM0C,EAAOnC,OAASL,KAAKyD,OAAOoP,YAChDvN,EAAS,MACR,IAAIoC,EAAI,EAAGA,EAAI1H,KAAKyD,OAAOoP,OAAQnL,GAAK,EAAG,KACzC,IAAIzG,EAAI,EAAGA,EAAIoE,EAAMpE,GAAK,MACxB,IAAIsJ,EAAK,EAAGA,EAAKvK,KAAKyD,OAAOxD,UAAWsK,GAAM,OACpC7C,EAAI1H,KAAKyD,OAAOxD,UAAcsK,IACvC/H,EAAOtB,IAAIoE,EAASrE,EAAGsJ,GACQ,SAA/BvK,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKxK,KAAKyD,OAAOxD,UAAWuK,GAAM,OAC5C/G,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW,GACtCnE,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,IACzChI,EAAOtB,IAAIoE,EAASrE,EAAGsJ,GACvB/H,EAAOtB,IAAIoE,EAASrE,EAAGuJ,aAGxB/G,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW,GAAGnE,WAAWqC,IACrD/H,EAAOtB,IAAIoE,EAASrE,EAAGsJ,IAAO,KAI5BlF,IACHqC,IAAMrC,SAIZ,IAAIqC,EAAI,EAAGA,EAAI1H,KAAKyD,OAAOoP,OAAQnL,GAAK,MACtC,IAAI6C,EAAK,EAAGA,EAAKvK,KAAKyD,OAAOxD,UAAWsK,GAAM,OACrC7C,EAAI1H,KAAKyD,OAAOxD,UAAasK,IAAO2D,EAAOxG,GACpB,SAA/B1H,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKxK,KAAKyD,OAAOxD,UAAWuK,GAAM,OAC5C/G,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW,GACtCnE,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,IACzC0D,EAAOxG,aAGRjE,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW,GAAGnE,WAAWqC,IAAO2D,EAAOxG,OAKtE,IAAIA,EAAI,EAAGA,EAAI1H,KAAKyD,OAAOoP,OAAQnL,GAAK,EAAG,KACzC,IAAI6C,EAAK,EAAGA,EAAKvK,KAAKyD,OAAOxD,UAAWsK,GAAM,KACd,SAA/BvK,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKxK,KAAKyD,OAAOxD,UAAWuK,GAAM,OAC5C/G,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW,GACtCnE,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,IACzCyK,EAAYvN,EAAI1H,KAAKyD,OAAOxD,UAAasK,GACzC0K,EAAYvN,EAAI1H,KAAKyD,OAAOxD,UAAauK,aAG1C/G,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW,GAAGnE,WAAWqC,IACrD0K,EAAYvN,EAAI1H,KAAKyD,OAAOxD,UAAasK,GACzC0K,EAAYvN,EAAI1H,KAAKyD,OAAOxD,UAAasK,QAG1C9G,OAAOuP,QAAQtL,GAAGmF,kBAClBpJ,OAAOuP,QAAQtL,GAAGgG,2DAUGzJ,OACvB,IAAIyD,EAAI,EAAGA,EAAI1H,KAAKyD,OAAOoP,OAAQnL,GAAK,EAAG,OACxC1E,EAAKC,YAAYjD,KAAKyD,aAEhBlB,QAAQ,CAACC,EAAQL,WACrBkD,EAAOxF,KAAKC,MAAM0C,EAAOnC,OAASL,KAAKyD,OAAOoP,WAChDxN,EAAO,EAAG,GACT5E,KAAK0B,EAAaK,EAAOZ,WACvB,IAAIX,EAAIyG,EAAIrC,EAAMpE,GAAKyG,EAAI,GAAKrC,EAAMpE,GAAK,IAC3CkE,UAAUhD,GAAa1B,KAAK+B,EAAOqD,SAAS5E,QAIhD+B,EAAGkB,QAAS,OACTgR,EAAY3C,SAASvP,EAAIhD,KAAKyD,YAC/B,IAAI8B,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW9G,GAAG1E,KAC1CqU,EAAU7I,WAAW9G,GAAG1E,UACrB4C,OAAOuP,QAAQtL,GAAGjE,OAAO4I,WAAW9G,GAAG2C,WAC1CgN,EAAU7I,WAAW9G,GAAG2C,gBACrBzE,OAAOuP,QAAQtL,GAAGgG,iDAWvBjL,EAAI,EAAIzC,KAAKyD,OAAOoP,YACrBpP,OAAOsP,MAAQ,IAAIjS,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK0B,QAClDgB,OAAO0P,WAAarS,MAAMQ,KAC7B,IAAIR,MAAMd,KAAKyD,OAAOoP,QACtB,IAAM,IAAI/R,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK0B,yBAStCgB,OAAOsP,MAAQ,IAAIjS,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,QAClD0C,OAAOsP,MAAM,GAAK,OAClBtP,OAAO0P,WAAa,IAAIrS,MAA2B,EAArBd,KAAKyD,OAAOoP,QAAY9R,KAAK,SAC3D0C,OAAO0P,WAAsC,GAA1BnT,KAAKyD,OAAOoP,OAAS,IAAU,OAClDpP,OAAO0P,WAAuC,GAA1BnT,KAAKyD,OAAOoP,OAAS,GAAU,GAAK,6BAS1B,YAA/B7S,KAAKyD,OAAOmP,eAA8B,OACtCuC,EAAYnV,KAAKyD,OAAOsP,MAAMjQ,OAAO,CAACY,EAAGC,IAAMD,EAAIC,EAAG,OACvD,IAAIf,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,EAAG,MACzCa,OAAOsP,MAAMnQ,IAAMuS,MACpBC,EAAiB,MAChB,IAAIrO,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,KACzB/G,KAAKyD,OAAO0P,WAAWvQ,GAAGmE,OAEzC,IAAIA,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,OACtCtD,OAAO0P,WAAWvQ,GAAGmE,IAAMqO,YAI/B,IAAIxS,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,EAAG,OACxCwS,EAAiBpV,KAAKyD,OAAO0P,WAAe,EAAJvQ,GAAS5C,KAAKyD,OAAO0P,WAAgB,EAAJvQ,EAAS,QACnFa,OAAO0P,WAAe,EAAJvQ,IAAUwS,OAC5B3R,OAAO0P,WAAgB,EAAJvQ,EAAS,IAAMwS,gCAWjBC,OACrB,IAAIzS,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,OACtC4J,KAAK5J,GAAKyS,2BAUKA,EAAI7U,QACrBmT,aAAe3T,KAAKwM,KAAK9L,YACzB,IAAIkC,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,EAAG,SACzC4J,KAAK5J,GAAK,EACoB,YAA/B5C,KAAKyD,OAAOmP,mBACT,IAAI7L,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,OACtCyF,KAAK5J,IAAM5C,KAAKyD,OAAO0P,WAAWvQ,GAAGmE,GACxC/G,KAAK2T,aAAa5M,GAClB/G,KAAKyD,OAAOuP,QAAQjM,GAAG0F,WAAWjM,aAGjCgM,KAAK5J,IAAM5C,KAAKyD,OAAO0P,WAAe,EAAJvQ,GACrC5C,KAAK2T,aAAa/Q,GAClB5C,KAAKyD,OAAOuP,QAAQpQ,GAAG6J,WAAWjM,GAChCoC,EAAI5C,KAAKyD,OAAOoP,OAAS,SACtBrG,KAAK5J,IAAM5C,KAAKyD,OAAO0P,WAAgB,EAAJvQ,EAAS,GAC/C5C,KAAK2T,aAAa/Q,EAAI,GACtB5C,KAAKyD,OAAOuP,QAAQpQ,EAAI,GAAG6J,WAAWjM,SAGvCgM,KAAK5J,IAAMyS,GACZ3M,OAAOC,MAAM3I,KAAKwM,KAAK5J,KAAO/C,KAAK8H,IAAI3H,KAAKwM,KAAK5J,MAASpB,EAAAA,UACvDgL,KAAK5J,GAAK,gCAYE0S,OACjB1I,EAAY,OACXsG,cAAgBlT,KAAK8S,MAAMpS,YAC3B,IAAIqG,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,EAAG,SACzC+L,MAAM/L,GAAK,EACmB,YAA/B/G,KAAKyD,OAAOmP,mBACT,IAAIhQ,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,OACtCkQ,MAAM/L,IAAM/G,KAAKkT,cAActQ,GAClC5C,KAAKyD,OAAO0P,WAAWvQ,GAAGmE,aAGzB+L,MAAM/L,IAAM/G,KAAKkT,cAAcnM,GAAK/G,KAAKyD,OAAO0P,WAAe,EAAJpM,GAC5DA,EAAI,OACD+L,MAAM/L,IAAM/G,KAAKkT,cAAcnM,EAAI,GACtC/G,KAAKyD,OAAO0P,WAAsB,GAATpM,EAAI,GAAU,QAEpC+L,MAAM,IAAM9S,KAAKkT,cAAclT,KAAKyD,OAAOoP,OAAS,GACvD7S,KAAKyD,OAAO0P,WAAiC,EAArBnT,KAAKyD,OAAOoP,OAAc,QAGnDC,MAAM/L,IAAMuO,EAAuBvO,MAC3B/G,KAAK8S,MAAM/L,MAEtB2B,OAAOC,MAAMiE,SACT,IAAI7M,MAAM,iBAEd6M,EAAY,OAAQ,KACjB,IAAI7F,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,OACtC+L,MAAM/L,IAAM6F,SAEZ,EAAIA,SAEN,2BAWeyI,EAAIC,QACrB3B,aAAe3T,KAAKwM,KAAK9L,YACzB,IAAIkC,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,EAAG,SACzC4J,KAAK5J,GAAK,EACoB,YAA/B5C,KAAKyD,OAAOmP,mBACT,IAAI7L,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,OACtCyF,KAAK5J,IACR5C,KAAKyD,OAAO0P,WAAWvQ,GAAGmE,GAC1B/G,KAAK2T,aAAa5M,GAClBuO,EAAuBvO,aAGtByF,KAAK5J,IAAM5C,KAAKyD,OAAO0P,WAAe,EAAJvQ,GACrC5C,KAAK2T,aAAa/Q,GAClB0S,EAAuB1S,GACrBA,EAAI5C,KAAKyD,OAAOoP,OAAS,SACtBrG,KAAK5J,IAAM5C,KAAKyD,OAAO0P,WAAgB,EAAJvQ,EAAS,GAC/C5C,KAAK2T,aAAa/Q,EAAI,GACtB0S,EAAuB1S,EAAI,SAG5B4J,KAAK5J,IAAMyS,GACZ3M,OAAOC,MAAM3I,KAAKwM,KAAK5J,KAAO/C,KAAK8H,IAAI3H,KAAKwM,KAAK5J,MAASpB,EAAAA,UACvDgL,KAAK5J,GAAK,kCAYI2S,EAAepT,SAChC8R,EAAIsB,EAAclV,OAElBgV,EAAK,IAAIvU,MAAMmT,GAAGlT,KAAK,OACzB+K,OACC8I,iBACAC,iBAECW,EAA2B1U,MAAMQ,KACrC,IAAIR,MAAMmT,GACV,IAAM,IAAInT,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,QAEtC,IAAIE,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,IAClB3B,GAAG2B,GAC1B5C,KAAKyD,OAAOuP,QAAQpQ,GAAG6J,WAAW8I,EAAc1P,SAAS5E,MAK5D,GAAKjB,KAAKyV,2BAA2BF,EAAc1P,SAAS,OACpDhG,KAAKyO,IAAI+G,EAAG,SAClBT,SAASnU,KAAKT,KAAK8S,MAAMpS,aAEzB,IAAIO,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,IACvBA,GAAKjB,KAAK0V,uBAAuBF,EAAyBvU,OAClDpB,KAAKyO,IAAI+G,EAAGpU,SAClB2T,SAASnU,KAAKT,KAAK8S,MAAMpS,cAI3BiV,4BAA4BN,EAAGpB,EAAI,SACnCY,QAAQpU,KAAKT,KAAKwM,KAAK9L,aAEvB,IAAIO,EAAIgT,EAAI,EAAGhT,GAAK,EAAGA,GAAK,OAC1B2U,wBAAwBP,EAAGpU,GAAIuU,EAAyBvU,EAAI,SAC5D4T,QAAQpU,KAAKT,KAAKwM,KAAK9L,cAEzBmU,QAAQgB,cAGR,IAAI5U,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,OACtCkR,cAAc3R,GAAalB,GAAG2B,GAChC5C,KAAK4U,SAAS3T,GAAG2B,GAAK5C,KAAK6U,QAAQ5T,GAAG2B,GAAMyS,EAAGpU,OAKlD2L,MAEC,IAAI3L,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,EAAG,MAClC,EACkB,IAA1B5C,KAAKyD,OAAO6I,UAAiB,OACzBwJ,EAAKN,EAAyBvU,GAAG2B,QAClCoR,wBAAwB7R,GAAa,GAAGlB,GAAG2B,GAC9C5C,KAAK8T,cAAc3R,GAAalB,GAAG2B,GAAKkT,KAC7BA,WAER,IAAIvQ,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,EAAG,OAC3CuQ,EAAK9V,KAAKyD,OAAOuP,QAAQpQ,GAC5B8J,oBAAoB6I,EAAc1P,SAAS5E,GAAIsE,QAC7CyO,wBAAwB7R,GAAaoD,GAAGtE,GAAG2B,GAC9C5C,KAAK8T,cAAc3R,GAAalB,GAAG2B,GACnCkT,KACWA,KAGblJ,EAAY,MACT,IAAIrH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzCyO,wBAAwB7R,GAAaoD,GAAGtE,GAAG2B,IAAMgK,KAO3B,YAA/B5M,KAAKyD,OAAOmP,mBACT,IAAI3R,EAAI,EAAGA,EAAIgT,EAAI,EAAGhT,GAAK,MACzB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,MACtC,IAAImE,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,OACtCgN,gBAAgB5R,GAAalB,GAAG2B,GAAGmE,GACtC/G,KAAK4U,SAAS3T,GAAG2B,GACjB5C,KAAKyD,OAAO0P,WAAWvQ,GAAGmE,GAC1B/G,KAAK6U,QAAQ5T,EAAI,GAAG8F,QACjBgN,gBAAgB5R,GAAalB,GAAG2B,GAAGmE,IACtCyO,EAAyBvU,EAAI,GAAG8F,YAKnC,IAAI9F,EAAI,EAAGA,EAAIgT,EAAI,EAAGhT,GAAK,MACzB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,OACtCmR,gBAAgB5R,GAAalB,GAAO,EAAJ2B,GACnC5C,KAAK4U,SAAS3T,GAAG2B,GACjB5C,KAAKyD,OAAO0P,WAAe,EAAJvQ,GACvB5C,KAAK6U,QAAQ5T,EAAI,GAAG2B,QACjBmR,gBAAgB5R,GAAalB,GAAO,EAAJ2B,IACnC4S,EAAyBvU,EAAI,GAAG2B,GAC9BA,EAAI5C,KAAKyD,OAAOoP,OAAS,SACtBkB,gBAAgB5R,GAAalB,GAAQ,EAAJ2B,EAAS,GAC7C5C,KAAK4U,SAAS3T,GAAG2B,GACjB5C,KAAKyD,OAAO0P,WAAgB,EAAJvQ,EAAS,GACjC5C,KAAK6U,QAAQ5T,EAAI,GAAG2B,EAAI,QACrBmR,gBAAgB5R,GAAalB,GAAQ,EAAJ2B,EAAS,IAC7C4S,EAAyBvU,EAAI,GAAG2B,EAAI,WAMvCkJ,qBAQS7H,OACX,IAAIrB,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,EAAG,MACzCsR,SAAStR,GAAK,MACd,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzC4O,mBAAoBvR,EAAI5C,KAAKyD,OAAO6I,UAAa/G,GAAK,MAI3DpD,EAAc,IACNI,QAASC,QACd,IAAII,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,EAAG,MACpCiT,SAAStR,IACZ5C,KAAK8T,cAAc3R,GAAalB,GAAG2B,OAChC,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzC4O,mBAAoBvR,EAAI5C,KAAKyD,OAAO6I,UAAa/G,IACpDvF,KAAKgU,wBAAwB7R,GAAaoD,GAAGtE,GAAG2B,MAIzC,0CAUkBqB,OAC/B9B,EAAc,IACNI,QAASC,QACd,IAAII,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,MACjC,IAAIsE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAOuP,QAAQpQ,GAAGa,OAAO8I,cAAchH,IAC1CvF,KAAKgU,wBAAwB7R,GAAaoD,GAAGtE,GAAG2B,MAIzC,QAIZ,IAAIA,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,OACtCa,OAAOuP,QAAQpQ,GAAGmT,iDAUJ9R,OAChB,IAAIrB,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,MACtC,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GAAG1E,KAAKE,KAAK,OAKtDoB,EAAc,IACNI,QAASC,QACd,IAAII,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,MACjC,IAAIsE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,MACzC,IAAIvE,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GAAG1E,KAAKG,IAC/ChB,KAAKgU,wBAAwB7R,GAAaoD,GAAGtE,GAAG2B,GAChDJ,EAAOtB,IAAID,EAAGD,MAKT,QAIZ,IAAI4B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,MACtC,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,MACzC,IAAIvE,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,KAC1ChB,KAAKmU,mBAAoBvR,EAAI5C,KAAKyD,OAAO6I,UAAa/G,GAAK,SACxD9B,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GAAG1E,KAAKG,IAC/ChB,KAAKmU,mBAAoBvR,EAAI5C,KAAKyD,OAAO6I,UAAa/G,IAEtDmD,OAAOC,MAAM3I,KAAKyD,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GAAG1E,KAAKG,UAC1D,IAAIjB,MAAM,mDAaGkE,OACvB9B,EAAc,IACNI,QAASC,QACd,IAAII,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,MACjC,IAAIsE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,MACzC,IAAIgF,EAAK,EAAGA,EAAKvK,KAAKyD,OAAOxD,UAAWsK,GAAM,KACd,SAA/BvK,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAKD,EAAIC,EAAKxK,KAAKyD,OAAOxD,UAAWuK,GAAM,OAC7C/G,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GACtC2C,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,IAC3CxK,KAAKgU,wBAAwB7R,GAAaoD,GAAGtE,GAAG2B,IAC/CJ,EAAOtB,IAAID,EAAGsJ,GACbvK,KAAKyD,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GAAG1E,KAAK0J,KAClD/H,EAAOtB,IAAID,EAAGuJ,GACbxK,KAAKyD,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GAAG1E,KAAK2J,QAElD,OACCgE,EAAQhM,EAAOtB,IAAID,EAAGsJ,GAC1BvK,KAAKyD,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GAAG1E,KAAK0J,QAC9C9G,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GAAG2C,WAAWqC,IACrDvK,KAAKgU,wBAAwB7R,GAAaoD,GAAGtE,GAAG2B,GAC/C4L,GAAS,KAMP,QAIZ,IAAI5L,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,EAAG,KACzC,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO6I,UAAW/G,GAAK,KAC1CvF,KAAKmU,mBAAoBvR,EAAI5C,KAAKyD,OAAO6I,UAAa/G,GAAK,MACxD,IAAIgF,EAAK,EAAGA,EAAKvK,KAAKyD,OAAOxD,UAAWsK,GAAM,KACd,SAA/BvK,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAKD,EAAIC,EAAKxK,KAAKyD,OAAOxD,UAAWuK,GAAM,OAC7C/G,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GACtC2C,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,IAC3CxK,KAAKmU,mBAAoBvR,EAAI5C,KAAKyD,OAAO6I,UAAa/G,GACpDgF,IAAOC,SACJ/G,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GACtC2C,WAAYsC,EAAKxK,KAAKyD,OAAOxD,UAAasK,GAC3CvK,KAAKyD,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GACtC2C,WAAYqC,EAAKvK,KAAKyD,OAAOxD,UAAauK,cAI9C/G,OAAOuP,QAAQpQ,GAAGa,OAAO4I,WAAW9G,GAAG2C,WAAWqC,IACrDvK,KAAKmU,mBAAoBvR,EAAI5C,KAAKyD,OAAO6I,UAAa/G,QAK3D9B,OAAOuP,QAAQpQ,GAAGiK,kBAClBpJ,OAAOuP,QAAQpQ,GAAG8K,oDASJzJ,QAChBR,OAAOsP,MAAMhS,KAAK,OAGnBiV,EAAW,MACV,IAAI7T,EAAc,EACrBA,EAAc8B,EAAY4P,OAC1B1R,GAAe,MACV,IAAIS,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,OACtCa,OAAOsP,MAAMnQ,IAAM5C,KAAK8T,cAAc3R,GAAa,GAAGS,MAC/C5C,KAAKyD,OAAOsP,MAAMnQ,QAK9BoT,EAAW,SAKP,IAAIjW,MAAM,kCAJX,IAAI6C,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,OACtCa,OAAOsP,MAAMnQ,IAAMoT,gCAYD/R,QAEtBR,OAAO0P,WAA4C,YAA/BnT,KAAKyD,OAAOmP,eACnC9R,MAAMQ,KACJ,IAAIR,MAAMd,KAAKyD,OAAOoP,QACtB,IAAM,IAAI/R,MAAMd,KAAKyD,OAAOoP,QAAQ9R,KAAK,IAE3C,IAAID,MAA2B,EAArBd,KAAKyD,OAAOoP,QAAY9R,KAAK,OAGrCoB,EAAc,OACNI,QAASC,OACfA,EAAOnC,OAAS,MACb,IAAIuC,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,KAGR,cAA/B5C,KAAKyD,OAAOmP,sBACTnP,OAAO0P,WAAe,EAAJvQ,IAx1BD,KAy1BlBA,EAAI5C,KAAKyD,OAAOoP,OAAS,OACtBpP,OAAO0P,WAAgB,EAAJvQ,EAAS,IA11Bb,UA41Bfa,OAAO0P,WAAe,EAAJvQ,IA51BH,MAg2BW,YAA/B5C,KAAKyD,OAAOmP,mBACT,IAAI7L,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,MACtC,IAAI9F,EAAI,EAAGA,EAAIuB,EAAOnC,OAAS,EAAGY,GAAK,OACrCwC,OAAO0P,WAAWvQ,GAAGmE,IACxB/G,KAAK+T,gBAAgB5R,GAAalB,GAAG2B,GAAGmE,OAGzC,KACA,IAAI9F,EAAI,EAAGA,EAAIuB,EAAOnC,OAAS,EAAGY,GAAK,OACrCwC,OAAO0P,WAAe,EAAJvQ,IACrB5C,KAAK+T,gBAAgB5R,GAAalB,GAAO,EAAJ2B,MAErCA,EAAI5C,KAAKyD,OAAOoP,OAAS,MACtB,IAAI5R,EAAI,EAAGA,EAAIuB,EAAOnC,OAAS,EAAGY,GAAK,OACrCwC,OAAO0P,WAAgB,EAAJvQ,EAAS,IAC/B5C,KAAK+T,gBAAgB5R,GAAalB,GAAQ,EAAJ2B,EAAS,MAM5C,IAIkB,YAA/B5C,KAAKyD,OAAOmP,oBACT,IAAIhQ,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,MACtC,IAAImE,EAAI,EAAGA,EAAI/G,KAAKyD,OAAOoP,OAAQ9L,GAAK,UACtCtD,OAAO0P,WAAWvQ,GAAGmE,IACvB/G,KAAKkU,SAAStR,GAAM,KACnB8F,OAAOC,MAAM3I,KAAKyD,OAAO0P,WAAWvQ,GAAGmE,UACnC,IAAIhH,MAAM,wFAKjB,IAAI6C,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,EAAG,SACzCa,OAAO0P,WAAe,EAAJvQ,IACpB5C,KAAKkU,SAAStR,GAAM,KACnB8F,OAAOC,MAAM3I,KAAKyD,OAAO0P,WAAe,EAAJvQ,UAChC,IAAI7C,MAAM,kFAEd6C,EAAI5C,KAAKyD,OAAOoP,OAAS,SACtBpP,OAAO0P,WAAgB,EAAJvQ,EAAS,IAC9B5C,KAAKkU,SAAStR,GAAM,KACnB8F,OAAOC,MAAM3I,KAAKyD,OAAO0P,WAAgB,EAAJvQ,EAAS,WAC1C,IAAI7C,MAAM,kFAsBb,SAASkW,gBACtB1S,EACAsP,EAAS,EACTvG,EAAY,EACZ1D,GAAmBkF,SAAU,KAAMC,SAAU,KAC7C6E,EAAiB,YACjB3K,EAAiB,YAEZpG,OAAOI,KAAKsB,GAAGnB,SAAS,gBACrB,IAAIrC,MAAM,sGAEX8B,OAAOC,OACZyB,EACA+P,wCAGO/P,EAAEE,oFCr7Bb,MAAMyS,iBAAmB,CAACrD,EAAQD,wBAEpB,SACDrR,IAAK,yBAGJ,SACDA,IAAK,8BAGJ,QACH,EAAGuM,SAAAA,EAAUC,SAAAA,KACjBD,GAAYC,GAAYD,EAAW,GAAKC,EAAW,6BAG5C,SACF,UAAW,wCAGT,SACF,OAAQ,8BAGN,QACH+C,GAAwB,cAAnB8B,GAAkC9B,EAAEzQ,SAAWwS,yBAGjD,QACH/B,GAAyB,cAAnB8B,EACX9B,EAAEzQ,SAAW,EAAIwS,EACjB/B,EAAEzQ,SAAWwS,sBAGL,QACH/B,GAAKA,EAAEzQ,SAAWwS,KAUvBsD,4CACgB,kBACJ,sBAQT1S,OAAOuP,QAAUhT,KAAKyD,OAAOuP,QAAQnQ,IAAI6Q,GAAKjB,aAAaiB,GAAGxC,SAC5DlR,0BAQF6P,iBAAiBJ,aACjBhM,OAAOuP,QAAQzQ,QAASmR,MAAUxC,UAChClR,iBAQEQ,SACH6U,EAAMrV,KAAKiT,mBACfjT,KAAKoW,uBAAuB5V,GAC5BR,KAAKyV,2BAA2BjV,eAC7B6V,yBACAC,iBACE,EAAIjB,yBAINpI,QAAQsJ,SAAW,MACnB,IAAI3T,EAAI5C,KAAKwW,eAAgB5T,EAAI5C,KAAKyW,eAAgB7T,GAAK,EAC1D5C,KAAK0W,oBACFzJ,QAAQsJ,WAAavW,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,GAAK5C,KAAK4W,OAAOhU,KACpEA,EAAI5C,KAAK6W,kCAEP5J,QAAQsJ,UAAavW,KAAK8S,MAAMlQ,GAAKA,EACxC5C,KAAK6W,iCAGN5J,QAAQsJ,UAAYvW,KAAKyD,OAAOoP,OAAS,4BASzC5F,QAAQ6J,eAAiB,MAE1BC,EAAY/W,KAAK0W,eAClB1W,KAAK8S,MAAM,GAAK9S,KAAK2W,OAAO,GAC7B3W,KAAK8S,MAAM,OACR,IAAIlQ,EAAI,EAAGA,EAAI5C,KAAKyD,OAAOoP,OAAQjQ,GAAK,EACvC5C,KAAK0W,eACF1W,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,GAAMmU,MACzB/W,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,QACnCqK,QAAQ6J,eAAiBlU,GAEvB5C,KAAK8S,MAAMlQ,GAAKmU,MACb/W,KAAK8S,MAAMlQ,QAClBqK,QAAQ6J,eAAiBlU,QAK7B4T,eAAiBxW,KAAKiN,QAAQ6J,eAAiBjX,KAAKC,MAAME,KAAKyD,OAAOoP,OAAS,QAC/E4D,eAAiBzW,KAAKiN,QAAQ6J,eAAiBjX,KAAKC,MAAME,KAAKyD,OAAOoP,OAAS,QAC/E2D,eAAkBxW,KAAKwW,gBAAkB,EAAKxW,KAAKwW,eAAiB,OACpEC,eAAkBzW,KAAKyW,gBAAkBzW,KAAKyD,OAAOoP,OACxD7S,KAAKyW,eAAiBzW,KAAKyD,OAAOoP,YAC/BgE,4BAA8B,MAC9B,IAAIjU,EAAI5C,KAAKwW,eAAgB5T,EAAI5C,KAAKyW,eAAgB7T,GAAK,OACzDiU,6BAA+B7W,KAAK0W,eACtC1W,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,GAC7B5C,KAAK8S,MAAMlQ,KAUboU,0CASO/M,WACJgD,QAAQC,aAAepM,MAAMd,KAAKyD,OAAO7C,iBAAiBG,KAAK,QAC/DkM,QAAQtC,iBAAmB7J,MAAqC,SAA/Bd,KAAKyD,OAAOwE,eAA4BjI,KAAKyD,OAAO7C,iBAAmB,EAAIZ,KAAKyD,OAAO7C,iBAAiBG,KAAK,GAE3G,cAApCf,KAAKyD,OAAOwT,gCACTxT,OAAOuP,QAAQhT,KAAKiN,QAAQ6J,gBAAgB1F,QAAQnH,QACpDgD,QAAQC,aACXlN,KAAKyD,OAAOuP,QAAQhT,KAAKiN,QAAQ6J,gBAAgB7J,QAAQC,aACpDlN,KAAKiN,QAAQC,mBAGhBgK,EAAoD,SAApClX,KAAKyD,OAAOwT,oBAChC,EAAIjX,KAAKwW,eACLW,EAAoD,SAApCnX,KAAKyD,OAAOwT,oBAChCjX,KAAKyD,OAAOoP,OAAS7S,KAAKyW,mBACxBW,EAA6D,SAApCpX,KAAKyD,OAAOwT,oBACvC,EAAIjX,KAAK6W,4BAEPO,GAAyB,IAAKA,EAAwB,OAGrD,IAAIxU,EAAIsU,EAActU,EAAIuU,EAAcvU,GAAK,EAAG,MAC9Ca,OAAOuP,QAAQpQ,GAAG6J,WAAWxC,QAC7BxG,OAAOuP,QAAQpQ,GAAGuK,WAAWlD,SAC5BoN,EAAqBrX,KAAKyD,OAAOuP,QAAQpQ,GAAGqK,QAAQC,iBACrD,IAAIlM,EAAI,EAAGA,EAAIhB,KAAKyD,OAAO7C,gBAAiBI,GAAK,KAChDhB,KAAK0W,uBACFzJ,QAAQC,aAAalM,KACvBhB,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,KAC5ByU,EAAmBrW,GAAKoW,GACQ,SAA/BpX,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKxK,KAAKyD,OAAO7C,gBAAiB4J,GAAM,OAClDyC,QAAQtC,iBAAkB3J,EAAIhB,KAAKyD,OAAO7C,gBAAmB4J,KAC/DxK,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,KAC5B5C,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,KAC5B5C,KAAKyD,OAAOuP,QAAQpQ,GAAGqK,QACrBtC,iBAAkB3J,EAAIhB,KAAKyD,OAAO7C,gBAAmB4J,GACxD4M,aAGCnK,QAAQtC,iBAAiB3J,KAC3BhB,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,KAC5B5C,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,KAC5B5C,KAAKyD,OAAOuP,QAAQpQ,GAAGqK,QAAQtC,iBAAiB3J,GACjDoW,gBAGCnK,QAAQC,aAAalM,IAAMhB,KAAK8S,MAAMlQ,IACxCyU,EAAmBrW,GAAKoW,GACQ,SAA/BpX,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKxK,KAAKyD,OAAO7C,gBAAiB4J,GAAM,OAClDyC,QAAQtC,iBAAkB3J,EAAIhB,KAAKyD,OAAO7C,gBAAmB4J,IAC/DxK,KAAK8S,MAAMlQ,IAAM,GACjB5C,KAAKyD,OAAOuP,QAAQpQ,GAAGqK,QACrBtC,iBAAkB3J,EAAIhB,KAAKyD,OAAO7C,gBAAmB4J,GACxD4M,aAGCnK,QAAQtC,iBAAiB3J,IAC1BhB,KAAK8S,MAAMlQ,IAAM,EACnB5C,KAAKyD,OAAOuP,QAAQpQ,GAAGqK,QAAQtC,iBAAiB3J,GAChDoW,SAKHpX,KAAKiN,QAAQC,eAeT,SAASoK,kBAAkB/T,OACnCD,YAAYC,SACT,IAAIxD,MAAM,yHAEC,MAAOmW,iBAAiB3S,EAAEE,OAAOoP,OAAQtP,EAAEE,OAAOmP,gBAAiBrP,EAAEE,QACjF5B,OAAOC,OACZyB,EACA4S,uBACA5S,EAAEE,OAAOvD,QAAU8W,wCAEV,IAAIlW,MAAMyC,EAAEE,OAAOoP,QAAQ9R,KAAK,mBACtB,IAAID,MAAMyC,EAAEE,OAAOoP,QAAQ9R,KAAK,KAEnDwW,QCpPJ,MAAMC,mCAAqC,GAOrCC,wDAQgB,gBAQZC,EAAa1X,KAAK6T,mBACnBpQ,OAAOsP,MAAQ,IAAIjS,MAAM4W,GAAY3W,KAAK,EAAI2W,QAC9CjU,OAAO0P,WAAarS,MAAMQ,KAC7B,IAAIR,MAAM4W,GACV,IAAM,IAAI5W,MAAM4W,GAAY3W,KAAK,EAAI2W,SAElCjU,OAAOkU,eAAiB,IAAI7W,MAAM4W,GAAY3W,KAAK,WACjDwP,OAAOvQ,KAAK2O,QAAQpM,QAAS8D,IACxBA,EACRqQ,gBAAiB,SAEhBkB,0BACE5X,8BASe6X,SAChBC,OAAkCpV,IAAtBmV,EAChBA,EACA,IAAI/W,MAAMd,KAAKyD,OAAOoP,OAAS,GAAG9R,KAAK,GACpCR,QAhDkC,YAiDhC0B,KAAKjC,KAAK2O,QAAQpM,QAASX,SAC3B+M,OAAO/M,GAAO6B,OAAOoU,kBAAoBC,EAASpX,0BASlD6P,OAAOvQ,KAAK2O,QAAQpM,QAAQuO,GAAKA,EAAEI,cACrCjE,uJAOQ,iBAGTjN,KAAKyD,OAAOvD,cACTiR,oBAEF8B,oBAAqB,WAOpBzS,MACFR,KAAKiT,wBACFmD,uBAAuB5V,QAEvBiV,2BAA2BjV,UAE3ByB,KAAKjC,KAAK2O,QAAQ2C,OAAO/O,QAASX,UACjCyE,EAAQrG,KAAK2O,OAAO/M,KACpByU,sBACAC,mBACAxG,cAAczJ,EAAM4G,QAAQ8C,0BAE/BD,gBAED9P,KAAKyD,OAAOvD,kBACPqQ,OAAOvQ,KAAK2O,QAAQpM,QAAQuO,GAAKA,EAAE3D,WAAW3M,IAEH,cAA9CR,KAAKyD,OAAO2O,mCACTnF,QAAQC,aACXlN,KAAK2O,OAAO3O,KAAKiN,QAAQ6E,WAAW7E,QAAQC,kBACzCD,QAAQtC,iBACX3K,KAAK2O,OAAO3O,KAAKiN,QAAQ6E,WAAW7E,QAAQtC,qBACzC,MACAsC,QAAQC,aAAe,IAAIpM,MAAMd,KAAKY,iBAAiBG,KAAK,QAC5DkM,QAAQtC,iBACX,IAAI7J,MAAqC,SAA/Bd,KAAKyD,OAAOwE,eACpBjI,KAAKY,iBAAmB,EACxBZ,KAAKY,iBAAiBG,KAAK,OAE3BgX,EAAa,SACVxH,OAAOvQ,KAAK2O,QAAQpM,QAAS8D,QAC7B,IAAIrF,EAAI,EAAGA,EAAIhB,KAAKY,gBAAiBI,GAAK,UACxCiM,QAAQC,aAAalM,IACxBhB,KAAKiN,QAAQ+E,8BAA8B+F,GAC3C1R,EAAM2R,OAAO/K,QAAQC,aAAalM,GAED,SAA/BhB,KAAKyD,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKxK,KAAKY,gBAAiB4J,GAAM,OAC3CyC,QAAQtC,iBAAkB3J,EAAIhB,KAAKY,gBAAmB4J,IACzDxK,KAAKiN,QAAQ+E,8BAA8B+F,GAC3C1R,EAAM4G,QAAQtC,iBAAkB3J,EAAIhB,KAAKY,gBAAmB4J,aAG3DyC,QAAQtC,iBAAiB3J,IAC5BhB,KAAKiN,QAAQ+E,8BAA8B+F,GAC3C1R,EAAM2R,OAAO/K,QAAQtC,iBAAiB3J,MAG9B,iCAWKR,OACrBoM,EAAY,EACZmL,EAAa,QACX9I,EAAUpN,OAAOI,KAAKjC,KAAK2O,QAAQ2C,SACjC/O,QAASX,UACTyE,EAAQrG,KAAK2O,OAAO/M,GACpBqW,EAAI5R,EAAM5C,OAAOoP,YACjB8D,OAAS,IAAI7V,MAAMmX,GAAGlX,KAAK,KAC3B6V,OAAS,IAAI9V,MAAMmX,GAAGlX,KAAK,GAIG,YAAhCsF,EAAM5C,OAAOmP,eAA8B,GACvC3F,QAAQ8C,kBAAoB,MAC7B,IAAInN,EAAI,EAAGA,EAAIqV,EAAGrV,GAAK,IACpBkQ,MAAMlQ,GAAK5C,KAAKyD,OAAOsP,MAAMgF,GACjC1R,EAAM5C,OAAOsP,MAAMnQ,GACnByD,EAAM5C,OAAOuP,QAAQpQ,GAAG6J,WAAWjM,KAC/ByM,QAAQ8C,mBAAqB1J,EAAMyM,MAAMlQ,UAG3CkQ,MAAM,GAAK9S,KAAKyD,OAAOsP,MAAMgF,GACjC1R,EAAM5C,OAAOuP,QAAQ,GAAGvG,WAAWjM,IACpC6F,EAAM4G,QAAQ8C,mBAAqB1J,EAAMyM,SAE/BzM,EAAM4G,QAAQ8C,qBACb,MAGRxN,QAASX,UACTyE,EAAQrG,KAAK2O,OAAO/M,GACpBqW,EAAI5R,EAAM5C,OAAOoP,WAClB,IAAIjQ,EAAI,EAAGA,EAAIqV,EAAGrV,GAAK,IACpBkQ,MAAMlQ,IAAMgK,SAKjBsL,WAAa,IAAIpX,MAAMd,KAAK6T,MAAM9S,KAAK,QACvCoX,WAAa,IAAIrX,MAAMd,KAAK6T,MAAM9S,KAAK,QACvCkS,oBAAqB,0BAQLzS,OACjBoM,EAAY,EAGZ9E,EAAM,OAILoQ,WAAalY,KAAKoY,gBAAgB,QAClCD,WAAanY,KAAKoY,gBAAgB,OAInCC,EAAgB,QACdpJ,EAAUpN,OAAOI,KAAKjC,KAAK2O,QAAQ2C,SACjC/O,QAASX,UACT0W,EAAWtY,KAAK2O,OAAO/M,GACvBqW,EAAIK,EAAS7U,OAAOoP,OAKpB0F,EAAQ,IAAIzX,MAAMmX,GAAGlX,KAAK,MAEO,YAAnCuX,EAAS7U,OAAOmP,mBACb,IAAI5N,EAAI,EAAGA,EAAIiT,EAAGjT,GAAK,EAAG,KACxB,IAAI+B,EAAI,EAAGA,EAAIkR,EAAGlR,GAAK,IACpB/B,IAAOsT,EAAS7U,OAAO0P,WAAWpM,GAAG/B,IACxC,EAAIsT,EAAS7U,OAAOoU,kBAAkB9Q,IACrCuR,EAASxF,MAAM/L,OAInB,IAAIyR,EAAgB,EACpBA,EAAgBxY,KAAK6T,OACrB2E,GAAiB,IAEXxT,IAAMsT,EAAS7U,OAAOsP,MAAM/N,IAC/BhF,KAAKkY,WAAWM,GACjBxY,KAAKyD,OAAO0P,WAAWqF,GAAeH,GACrCrY,KAAKyD,OAAOsP,MAAMsF,GACnBrY,KAAKmY,WAAWK,QAIjB,GAEC,GAAKF,EAAS7U,OAAO0P,WAAW,GAAKmF,EAASxF,MAAM,OAGxD,IAAI0F,EAAgB,EACpBA,EAAgBxY,KAAK6T,OACrB2E,GAAiB,IAEX,IAAOxY,KAAKkY,WAAWM,GAC3BxY,KAAKyD,OAAO0P,WAAWqF,GAAeH,GACrCrY,KAAKyD,OAAOsP,MAAMsF,GACjBrY,KAAKmY,WAAWK,OAIjB,IAAIxT,EAAI,EAAGA,EAAIiT,EAAGjT,GAAK,IACpBA,IAAOsT,EAAS7U,OAAO0P,WAAe,EAAJnO,IACrC,EAAIsT,EAAS7U,OAAOoU,kBAAkB7S,IACvCsT,EAASxF,MAAM9N,KACXA,IAAOsT,EAAS7U,OAAO0P,WAAsB,GAATnO,EAAI,GAAU,IACrD,EAAIsT,EAAS7U,OAAOoU,kBAAkB7S,EAAI,IAC3CsT,EAASxF,MAAM9N,EAAI,OAGlB,IAAIA,EAAI,EAAGA,EAAIiT,EAAGjT,GAAK,IACjB8N,MAAM9N,GAAK,IACX2R,OAAO3R,GAAK,IACZ4R,OAAO5R,GAAK,IAMhBiI,QAAQwL,eAAiB,IACzBxL,QAAQ8C,kBAAoB,MAGhC,IAAI/K,EAAI,EAAGA,EAAIiT,EAAGjT,GAAK,IACpBsT,EAAS7U,OAAOuP,QAAQhO,GAAGyH,WAAWjM,GAAe+X,EAAMvT,KACxD4R,OAAO5R,GAAKhF,KAAKyD,OAAOkU,eAAeU,GAC9CC,EAAS7U,OAAOoU,kBAAkB7S,GAAK8C,IAChC6O,OAAO3R,IAAM,EAAIhF,KAAKyD,OAAOkU,eAAeU,IACnDC,EAAS7U,OAAOoU,kBAAkB7S,GAAK8C,IAChCgL,MAAM9N,IAAM,EAAIsT,EAAS7U,OAAOoU,kBAAkB7S,IAAM8C,IAExDmF,QAAQwL,gBAAkBH,EAAS3B,OAAO3R,GAAKsT,EAAS1B,OAAO5R,KAC/DiI,QAAQ8C,mBAAqBuI,EAASxF,MAAM9N,GACnDsT,EAAS3B,OAAO3R,GAAKsT,EAAS1B,OAAO5R,MAC1B8C,IAGNmF,QAAQyL,UAAYJ,EAASrL,QAAQwL,eAC5CH,EAASrL,QAAQ8C,qBAEF,MAGXxN,QAASX,UACTyE,EAAQrG,KAAK2O,OAAO/M,GACpBqW,EAAI5R,EAAM5C,OAAOoP,WAClB,IAAI7N,EAAI,EAAGA,EAAIiT,EAAGjT,GAAK,IACpB8N,MAAM9N,IAAM4H,IACZ+J,OAAO3R,IAAM4H,IACbgK,OAAO5R,IAAM4H,qBAUT+L,SACRC,EAAmB,IAAI9X,MAAMd,KAAK6T,QAAQ9S,KAAK,MACjD4X,EAAU,EAAG,KAEXZ,EAAa,SACV9V,KAAKjC,KAAK2O,QAAQ2C,OAAO/O,QAASX,UACjCyE,EAAQrG,KAAK2O,OAAO/M,KACTmW,GAAc,MAC1B,IAAI/S,EAAI,EAAGA,EAAIqB,EAAM5C,OAAOoP,OAAQ7N,GAAK,IAC3B+S,IAAe1R,EAAM2R,OAAOlF,MAAM9N,GACjDqB,EAAM2R,OAAOrB,OAAO3R,GACpBqB,EAAM2R,OAAOpB,OAAO5R,MAEV,QAEX,KAED+S,EAAa,SACV9V,KAAKjC,KAAK2O,QAAQ2C,OAAO/O,QAASX,UACjCyE,EAAQrG,KAAK2O,OAAO/M,KACTmW,GAAc,MAC3BjF,MAAEA,GAAUzM,EACA,IAAZsS,MACMtS,EAAMsQ,QAEA,IAAZgC,MACMtS,EAAMuQ,YAEX,IAAI5R,EAAI,EAAGA,EAAIqB,EAAM5C,OAAOoP,OAAQ7N,GAAK,IAC3B+S,IAAejF,EAAM9N,MAE1B,WAGX4T,IAkBI,SAASC,8BAA8BtV,OAC/CD,YAAYC,SACT,IAAIxD,MAAM,sGAOX8B,OAAOC,OACZyB,EACAkU,uCAKAF,QClVJ,SAAgBuB,SACd7U,EACAoO,EACArG,SAEM7L,eAAEA,EAAFS,gBAAkBA,GAAoBqD,GACtC4O,SAAAvG,YAAA1D,iBAAAgK,iBAAA3K,kBAMFoK,SACU4D,gBACZ9J,eACEiH,YAAY/P,wDAGPgP,KAELrG,GAEF6G,EACAvG,EACA1D,EACAgK,EACA3K,GAEW1B,MAAMtC,GAcrB,SAAgB8U,mBACd9U,EACAoO,EACArG,SAEM7L,eAAEA,EAAFS,gBAAkBA,GAAoBqD,SAC9B6K,uBACZF,8BAAsBzO,eAAAA,EAAgBS,gBAAAA,GAAoByR,IAC1DrP,GAAM8V,SAAS9V,EAAIqP,EAAerG,IAEvBzF,MAAMtC,GASrB,SAAgB+U,aACdvV,EACAmM,SAEMvJ,EAAQiR,kBAAkBrH,sBAC9BmD,YAAY/P,UAAUI,IACtBmM,aAEIsB,QACC7K,EAUT,SAAgB4S,uBACdxV,EACAmM,SAEMvJ,EAAQiM,yBAAyB1D,oBAAoBnL,aACrDkL,iBACC1M,KAAKwB,EAAOwL,SAAS1M,QAASX,MAC7B+M,OAAO/M,GAASoX,aAAavV,EAAOwL,QAAQrN,GAAQgO,OAEtDsB,QACC7K,EAUT,SAAgB6S,yBACdzV,EACAmM,OAEIvJ,EAAQuI,oBAAoBnL,YAC1BkL,iBACC1M,KAAKwB,EAAOwL,SAAS1M,QAASX,MAC7B+M,OAAO/M,GAASoX,aAAavV,EAAOwL,QAAQrN,GAAQgO,QAEpDiJ,8BAA8BvG,yBAAyBjM,KACzD6K,QACC7K"}