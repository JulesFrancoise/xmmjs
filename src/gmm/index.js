import GaussianDistribution from '../common/gaussian_distribution';
import ModelBase from '../core/model_base_mixin';
import withEMTraining from '../core/em_training_mixin';
import withGMMBase from './gmm_base_mixin';
import withGMMTraining from './gmm_training_mixin';
import MulticlassModelBase from '../core/multiclass_mixin';
import withMulticlassTraining from '../core/multiclass_training_mixin';
import withAbtractPrediction from '../core/prediction_mixin';
import withGMMPrediction from './gmm_prediction_mixin';
import withMulticlassPrediction from '../core/multiclass_prediction_mixin';

/**
 * Set of criteria that define when the EM algorithm (for either GMMs or HMMs) has converged.
 * Convergence depends on
 * - A minimum number of iterations
 * - A maximum number of iterations
 * - A threshold on the relative change of the log-likelihood of the training
 * data between successive iterations.
 *
 * @typedef {Object} ConvergenceCriteria
 *
 * @property {number} [percentChange=1e-3] Threshold in % of
 * the relative change of the log-likelihood, under which the training stops.
 * @property {number} [minIterations=5]    minimum number of iterations
 * @property {number} [maxIterations=100]  maximum number of iterations
 */

/**
 * GMM training configuration
 *
 * @typedef {Object} GMMConfiguration
 * @property {Number} gaussians Number of Gaussian components
 * @property {{ absolute: 1e-3, relative: 1e-2 }} regularization An object containing the
 * relative and absolute regularization values. Regularization is an offset value added to the
 * diagonal of covariance matrices for convergence and generalization. The two values represent:
 * - `relative`: the offset relative to the variance of the training data
 * - `absolute`: an absolute lower threshold for the offset
 * @property {String} covarianceMode Type of covariance matrix ('full' or 'diagonal')
 */

/**
 * @typedef {Object} GMMParameters
 * @property {Boolean} bimodal Specifies if the model is bimodal
 * @property {Number} inputDimension Dimension of the input modality
 * @property {Number} outputDimension Dimension of the output modality
 * @property {Number} dimension Total dimension
 * @property {Number} gaussians Number of gaussian components in the mixture
 * @property {String} covarianceMode Covariance mode ('full' or 'diagonal')
 * @property {Array<Number>} mixtureCoeffs mixture coefficients ('weight' of
 * each gaussian component)
 * @property {Array<GaussianDistribution>} components Gaussian components
 */

/**
 * Train a single-class GMM Model.
 *
 * @todo GMM details
 *
 * @param  {TrainingSet} trainingSet Training set
 * @param  {GMMConfiguration} configuration Training configuration
 * @param  {ConvergenceCriteria} [convergenceCriteria=undefined] Convergence criteria of the
 * EM algorithm
 * @return {GMMParameters} Parameters of the trained GMM
 */
export function trainGMM(
  trainingSet,
  configuration,
  convergenceCriteria = undefined,
) {
  const { inputDimension, outputDimension } = trainingSet;
  const { gaussians, regularization, covarianceMode } = configuration;
  const model = withGMMTraining(
    withEMTraining(
      withGMMBase(ModelBase({
        inputDimension,
        outputDimension,
        ...configuration,
      })),
      convergenceCriteria,
    ),
    gaussians,
    regularization,
    covarianceMode,
  );
  return model.train(trainingSet);
}

/**
 * Train a multi-class GMM Model.
 *
 * @todo GMM details
 *
 * @param  {TrainingSet} trainingSet                training set
 * @param  {GMMConfiguration} configuration                   Training configuration
 * @param  {ConvergenceCriteria} [convergenceCriteria=undefined] Convergence criteria of the
 * EM algorithm
 * @return {GMMParameters} Parameters of the trained GMM
 */
export function trainMulticlassGMM(
  trainingSet,
  configuration,
  convergenceCriteria = undefined,
) {
  const { inputDimension, outputDimension } = trainingSet;
  const model = withMulticlassTraining(
    MulticlassModelBase({ inputDimension, outputDimension, ...configuration }),
    (ts) => trainGMM(ts, configuration, convergenceCriteria),
  );
  return model.train(trainingSet);
}

/**
 * Create a GMM Predictor from a full set of parameters (generated by trainGMM).
 * @param {GMMParameters} params Model parameters
 * @param {number} [likelihoodWindow=1] Likelihoow window size
 * @function
 */
export function GMMPredictor(
  params,
  likelihoodWindow = 1,
) {
  const model = withGMMPrediction(withAbtractPrediction(
    withGMMBase(ModelBase(params)),
    likelihoodWindow,
  ));
  params.components.forEach((c, i) => {
    model.params.components[i] = Object.assign(GaussianDistribution(
      params.inputDimension,
      params.outputDimension,
      params.covarianceMode,
    ), c);
  });
  model.reset();
  return model;
}

/**
 * Create a Multiclass GMM Predictor from a full set of parameters
 * (generated by trainMulticlassGMM).
 * @param {GMMParameters} params Model parameters
 * @param {number} [likelihoodWindow=1] Likelihoow window size
 * @function
 */
export function MulticlassGMMPredictor(
  params,
  likelihoodWindow = 1,
) {
  const model = withMulticlassPrediction(MulticlassModelBase(params));
  model.models = {};
  Object.keys(params.classes).forEach((label) => {
    model.models[label] = GMMPredictor(params.classes[label], likelihoodWindow);
  });
  model.reset();
  return model;
}
