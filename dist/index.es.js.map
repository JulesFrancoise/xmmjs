{"version":3,"file":"index.es.js","sources":["../src/training_set/phrase.js","../src/training_set/index.js","../src/core/model_base_mixin.js","../src/common/euclidean.js","../src/kmeans/kmeans_training_mixin.js","../src/kmeans/index.js","../src/common/matrix.js","../src/common/gaussian_distribution.js","../src/core/em_training_mixin.js","../src/gmm/gmm_base_mixin.js","../src/gmm/gmm_training_mixin.js","../src/core/multiclass_mixin.js","../src/core/multiclass_training_mixin.js","../src/common/circular_buffer.js","../src/core/prediction_mixin.js","../src/common/validation.js","../src/gmm/gmm_prediction_mixin.js","../src/core/multiclass_prediction_mixin.js","../src/gmm/index.js","../src/hmm/hmm_base_mixin.js","../src/hmm/hmm_training_mixin.js","../src/hmm/hmm_prediction_mixin.js","../src/hmm/hierarchical_hmm_prediction_mixin.js","../src/hmm/index.js"],"sourcesContent":["/**\n * Data Phrase Prototype\n * @ignore\n */\nconst phrasePrototype = /** @lends Phrase */ {\n  /**\n   * Get the value at a given index and dimension\n   * @param  {Number} index index\n   * @param  {Number} dim   dimension\n   * @return {Number}\n   */\n  get(index, dim) {\n    if (typeof index !== 'number' || Math.floor(index) !== index) {\n      throw new Error('The index must be an integer');\n    }\n    if (dim >= this.dimension) {\n      throw new Error('Phrase: dimension out of bounds');\n    }\n    if (this.bimodal) {\n      if (dim < this.inputDimension) {\n        if (index >= this.inputData.length) {\n          throw new Error('Phrase: index out of bounds');\n        }\n        return this.inputData[index][dim];\n      }\n      if (index >= this.outputData.length) {\n        throw new Error('Phrase: index out of bounds');\n      }\n      return this.outputData[index][dim - this.inputDimension];\n    }\n    if (index >= this.length) {\n      throw new Error('Phrase: index out of bounds');\n    }\n    if (!this.inputData[index]) {\n      throw new Error('WTF?');\n    }\n    return this.inputData[index][dim];\n  },\n\n  /**\n   * Get the data frame at a given index\n   * @param  {Number} index index\n   * @return {Array<number>}\n   * @throws {Error} if the index is out of bounds\n   */\n  getFrame(index) {\n    if (index >= this.length) {\n      throw new Error('Phrase: index out of bounds');\n    }\n    if (this.bimodal) {\n      return this.inputData[index].concat(this.outputData[index]);\n    }\n    return this.inputData[index];\n  },\n\n  /**\n   * Push an observation vector to the phrase\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the observation's dimension does not match the\n   * dimension of the training set\n   */\n  push(observation) {\n    // console.log('push:', observation);\n    if (observation.length !== this.dimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    if (this.bimodal) {\n      this.inputData.push(observation.slice(0, this.inputDimension));\n      this.outputData.push(observation.slice(this.inputDimension, this.dimension));\n    } else {\n      this.inputData.push(observation);\n    }\n\n    this.length += 1;\n  },\n\n  /**\n   * Push an observation to the input modality only\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the phrase is not bimodal\n   * @throws {Error} if the observation's dimension does not match the\n   * input dimension of the training set\n   */\n  pushInput(observation) {\n    if (!this.bimodal) {\n      throw new Error('this phrase is unimodal, use `push`');\n    }\n    if (observation.length !== this.inputDimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    this.inputData.push(observation);\n    this.trim();\n  },\n\n  /**\n   * Push an observation to the output modality only\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the phrase is not bimodal\n   * @throws {Error} if the observation's dimension does not match the\n   * output dimension of the training set\n   */\n  pushOutput(observation) {\n    if (!this.bimodal) {\n      throw new Error('this phrase is unimodal, use `push`');\n    }\n    if (observation.length !== this.outputDimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    this.outputData.push(observation);\n    this.trim();\n  },\n\n  /**\n   * Clear the phrase's data\n   */\n  clear() {\n    this.length = 0;\n    this.inputData = [];\n    this.outputData = [];\n  },\n\n  /**\n   * Clear the phrase's input data\n   */\n  clearInput() {\n    this.inputData = [];\n    this.trim();\n  },\n\n  /**\n   * Clear the phrase's output data\n   */\n  clearOutput() {\n    this.outputData = [];\n    this.trim();\n  },\n\n  /**\n   * Compute the mean of the phrase (across time)\n   * @return {Array<number>} The mean vector (same dimension as the\n   * training set)\n   */\n  mean() {\n    const mean = Array(this.dimension).fill(0);\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        mean[d] += this.get(t, d);\n      }\n      mean[d] /= this.length;\n    }\n    return mean;\n  },\n\n  /**\n   * Compute the standard deviation of the phrase (across time)\n   * @return {Array<number>} The standard deviation vector (same dimension as\n   * the training set)\n   */\n  standardDeviation() {\n    const stddev = Array(this.dimension).fill(0);\n    const mean = this.mean();\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        stddev[d] += (this.get(t, d) - mean[d]) * (this.get(t, d) - mean[d]);\n      }\n      stddev[d] /= this.length;\n      stddev[d] = Math.sqrt(stddev[d]);\n    }\n    return stddev;\n  },\n\n  /**\n   * Compute the minimum and maximum of the phrase (across time)\n   * @return {Array<{ min: number, max: number }>} The min/max vector (same\n   * dimension as the training set)\n   */\n  minmax() {\n    const minmax = Array.from(\n      Array(this.dimension),\n      () => ({ min: +Infinity, max: -Infinity }),\n    );\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        minmax[d].min = Math.min(this.get(t, d), minmax[d].min);\n        minmax[d].max = Math.max(this.get(t, d), minmax[d].max);\n      }\n    }\n    return minmax;\n  },\n\n  /**\n   * Trim the phrase length to the minimum of the input and output lengths\n   * @private\n   */\n  trim() {\n    if (this.bimodal) {\n      this.length = Math.min(this.inputData.length, this.outputData.length);\n    }\n  },\n};\n\n/**\n * Create a data phrase, potentially bimodal. Phrases are data structures for\n * temporal data (e.g. gestures), used to constitute training sets.\n *\n * @param {Object} [params]                   Phrase parameters\n * @param {Number} [params.inputDimension=1]  Dimension of the input modality\n * @param {Number} [params.outputDimension=0] Dimension of the output modality\n * (optional)\n * @param {Array<String>} [params.columnNames=null] Data column names, e.g.\n * \\['accX', 'accY', 'accZ'\\] (optional)\n * @param {String} [params.label='']          Phrase label\n * @return {Phrase}\n * @function\n *\n * @property {Boolean} bimodal Specifies if the phrase is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} length Phrase length (number of frames)\n * @property {String} label Phrase label\n * @property {Array<String>} columnNames Columns names\n */\nexport default function Phrase({\n  inputDimension = 1,\n  outputDimension = 0,\n  columnNames = null,\n  label = '',\n} = {}) {\n  const dimension = inputDimension + outputDimension;\n  return Object.assign(\n    Object.create(phrasePrototype),\n    {\n      bimodal: outputDimension > 0,\n      inputDimension,\n      outputDimension,\n      dimension,\n      length: 0,\n      label,\n      inputData: [],\n      outputData: [],\n      columnNames: columnNames || Array(dimension).fill(''),\n    },\n  );\n}\n","import Phrase from './phrase';\n\n/**\n * Training Set Prototype\n * @ignore\n */\nconst trainingSetPrototype = /** @lends TrainingSet */ {\n  /**\n   * Get the training set size (number of phrases)\n   * @return {number}\n   */\n  size() {\n    return Object.keys(this.phrases).length;\n  },\n\n  /**\n   * Checks if the training set is empty\n   * @return {boolean}\n   */\n  empty() {\n    return this.length === 0;\n  },\n\n  /**\n   * Get a reference to a phrase by index\n   * @param  {number} phraseIndex phrase index\n   * @return {Phrase}\n   */\n  getPhrase(phraseIndex) {\n    if (Object.keys(this.phrases).includes(phraseIndex.toString())) {\n      return this.phrases[phraseIndex.toString()];\n    }\n    return null;\n  },\n\n  /**\n   * Iterate over all phrases in the training set. The callback function\n   * should take 3 arguments: the phrase, its index in the training set,\n   * and the phrases structure.\n   *\n   * @param  {Function} callback Callback function\n   */\n  forEach(callback) {\n    Object.keys(this.phrases).forEach((phraseIndex) => {\n      callback(this.phrases[phraseIndex], phraseIndex, this.phrases);\n    });\n  },\n\n  /**\n   * Add a phrase to the training set and return it.\n   * @param  {number} phraseIndex        phrase index\n   * @param  {string} [label=undefined]  phrase label (its index if undefined)\n   * @param  {Phrase} [phrase=undefined] Phrase data. If unspecified, an empty\n   * phrase is created.\n   * @return {Phrase}\n   */\n  push(phraseIndex, label = undefined, phrase = undefined) {\n    const p = (phrase !== undefined) ? phrase : Phrase({\n      inputDimension: this.inputDimension,\n      outputDimension: this.outputDimension,\n      columnNames: this.columnNames,\n      label: (label !== undefined) ? label : phraseIndex.toString(),\n    });\n    this.phrases[phraseIndex] = p;\n    return p;\n  },\n\n  /**\n   * Remove a phrase\n   * @param  {number} phraseIndex phrase index\n   */\n  remove(phraseIndex) {\n    delete this.phrases[phraseIndex];\n  },\n\n  /**\n   * Remove all phrases with a given label\n   * @param  {string} label class label\n   */\n  removeClass(label) {\n    this.phrases = Object.keys(this.phrases)\n      .filter(i => this.phrases[i].label !== label)\n      .map(i => ({ i: this.phrases[i] }))\n      .reduce((x, p) => ({ ...x, ...p }), {});\n  },\n\n  /**\n   * Clear the training set (delete all phrases)\n   */\n  clear() {\n    this.phrases = {};\n  },\n\n  /**\n   * Get the sub-training set composed of all phrases of a given class\n   * @param  {string} label class label\n   * @return {TrainingSet}\n   */\n  getPhrasesOfClass(label) {\n    const ts = TrainingSet(this); // eslint-disable-line no-use-before-define\n    ts.phrases = Object.keys(this.phrases)\n      .filter(i => this.phrases[i].label === label)\n      .map(i => ({ [i]: this.phrases[i] }))\n      .reduce((x, p) => ({ ...x, ...p }), {});\n    return ts;\n  },\n\n  /**\n   * Get the list of unique labels in the training set\n   * @return {Array<string>}\n   */\n  labels() {\n    return Object.keys(this.phrases)\n      .map(i => this.phrases[i].label)\n      .reduce((ll, x) => (ll.includes(x) ? ll : ll.concat([x])), []);\n  },\n\n  /**\n   * Get the list of phrase indices\n   * @return {Array<number>}\n   */\n  indices() {\n    return Object.keys(this.phrases);\n  },\n\n  /**\n   * Get the mean of the training set over all phrases\n   * @return {Array<number>} mean (same dimension as the training set)\n   */\n  mean() {\n    const sum = Array(this.dimension).fill(0);\n    let totalLength = 0;\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          sum[d] += this.phrases[i].get(t, d);\n        }\n      }\n      totalLength += this.phrases[i].length;\n    });\n\n    return sum.map(x => x / totalLength);\n  },\n\n  /**\n   * Get the standard deviation of the training set over all phrases\n   * @return {Array<number>} standard deviation (same dimension as the training set)\n   */\n  standardDeviation() {\n    const stddev = Array(this.dimension).fill(0);\n    const mean = this.mean();\n    let totalLength = 0;\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          stddev[d] += (this.phrases[i].get(t, d) - mean[d]) ** 2;\n        }\n      }\n      totalLength += this.phrases[i].length;\n    });\n\n    return stddev.map(x => Math.sqrt(x / totalLength));\n  },\n\n  /**\n   * Get the min and max of the training set over all phrases\n   * @return {Array<{ min: number, max: number }>} min/max (same dimension as the training set)\n   */\n  minmax() {\n    const minmax = Array.from(\n      Array(this.dimension),\n      () => ({ min: +Infinity, max: -Infinity }),\n    );\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          minmax[d].min += Math.min(minmax[d].min, this.phrases[i].get(t, d));\n          minmax[d].max += Math.max(minmax[d].max, this.phrases[i].get(t, d));\n        }\n      }\n    });\n    return minmax;\n  },\n};\n\n/**\n * Create a Training set, composed of a set of indexed data phrases\n * @param {Object} [params]                   Training set parameters\n * @param {Number} [params.inputDimension=1]  Dimension of the input modality\n * @param {Number} [params.outputDimension=0] Dimension of the output modality\n * (optional)\n * @param {Array<String>} [params.columnNames=null] Data column names, e.g.\n * \\['accX', 'accY', 'accZ'\\] (optional)\n * @return {TrainingSet}\n * @function\n *\n * @property {Boolean} bimodal Specifies if the training set is bimodal\n * @property {Number}  inputDimension Dimension of the input modality\n * @property {Number}  outputDimension Dimension of the output modality\n * @property {Number}  dimension Total dimension\n * @property {Array<String>} columnNames Columns names\n *\n * @example\n * // Create a training dataset for data with 3 channels\n * const ts = TrainingSet({ inputDimension: 2 });\n *\n * // Add a new phrase to the training set, and record data frames\n * const phrase = ts.push(0, 'default');\n * for (let i = 0; i < 1000; i += 1) {\n *   const frame = ...; // get data from somewhere\n *   phrase.push(frame);\n * }\n *\n * console.log(ts);\n */\nexport default function TrainingSet({\n  inputDimension = 1,\n  outputDimension = 0,\n  columnNames = null,\n} = {}) {\n  const dimension = inputDimension + outputDimension;\n  return Object.assign(\n    Object.create(trainingSetPrototype),\n    {\n      bimodal: outputDimension > 0,\n      inputDimension,\n      outputDimension,\n      dimension,\n      columnNames: columnNames || Array(dimension).fill(''),\n      phrases: {},\n    },\n  );\n}\n","/**\n * Create the skeleton of a model\n *\n * @function\n * @param       {Number} inputDimension  input dimension\n * @param       {Number} outputDimension output dimension\n * @param       {Object} parameters      additional parameters to be copied\n * @constructor\n */\nexport default function ModelBase({\n  inputDimension,\n  outputDimension,\n  ...parameters\n}) {\n  const p = parameters;\n  delete p.bimodal;\n  delete p.inputDimension;\n  delete p.outputDimension;\n  delete p.dimension;\n  return /** @lends ModelBase */{\n    params: {\n      ...p,\n      get bimodal() {\n        return outputDimension > 0;\n      },\n      get inputDimension() {\n        return inputDimension;\n      },\n      get outputDimension() {\n        return outputDimension;\n      },\n      get dimension() {\n        return inputDimension + outputDimension;\n      },\n    },\n  };\n}\n\n/**\n * Check if an object is a base model (check for attribute existence)\n * @param  {Object}  o Source object\n * @return {Boolean}\n */\nexport function isBaseModel(o) {\n  if (!Object.keys(o).includes('params')) return false;\n  const keys = ['bimodal', 'inputDimension', 'outputDimension', 'dimension'];\n  return keys.map(key => Object.keys(o.params).includes(key))\n    .reduce((a, b) => a && b, true);\n}\n","/**\n * Compute the euclidean distance between to vectors\n * @param  {Array} v1\n * @param  {Array} v2\n * @return {number}\n */\nexport default function euclidean(v1, v2) {\n  return Math.sqrt(v1\n    .map((x1, i) => (x1 - v2[i]) ** 2)\n    .reduce((a, x) => (a + x), 0));\n}\n","import { isBaseModel } from '../core/model_base_mixin';\nimport euclidean from '../common/euclidean';\n\nconst kMeansTrainingPrototype = {\n  train(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) {\n      throw new Error('The training set is empty');\n    }\n\n    this.params.centers = Array.from(\n      Array(this.params.clusters),\n      () => new Array(this.params.dimension).fill(0),\n    );\n\n    // TODO: improve initialization =>\n    // https://www.slideshare.net/djempol/kmeans-initialization-15041920\n    //\n    if (this.trainingConfig.initialization === 'random') {\n      this.initializeClustersRandom(trainingSet);\n    } else if (this.trainingConfig.initialization === 'forgy') {\n      this.initializeClustersForgy(trainingSet);\n    } else if (this.trainingConfig.initialization === 'data') {\n      this.initClustersWithFirstPhrase(trainingSet);\n    } else {\n      throw new Error('Unknown K-Means initialization, must be `random`, `forgy` or `data`');\n    }\n\n    for (\n      let trainingNbIterations = 0;\n      trainingNbIterations < this.trainingConfig.maxIterations;\n      trainingNbIterations += 1\n    ) {\n      const previousCenters = this.params.centers;\n\n      this.updateCenters(previousCenters, trainingSet);\n\n      let meanClusterDistance = 0;\n      let maxRelativeCenterVariation = 0;\n      for (let k = 0; k < this.params.clusters; k += 1) {\n        for (let l = 0; l < this.params.clusters; l += 1) {\n          if (k !== l) {\n            meanClusterDistance += euclidean(\n              this.params.centers[k],\n              this.params.centers[l],\n            );\n          }\n        }\n        maxRelativeCenterVariation = Math.max(\n          euclidean(\n            previousCenters[k],\n            this.params.centers[k],\n          ),\n          maxRelativeCenterVariation,\n        );\n      }\n      meanClusterDistance /= this.params.clusters * (this.params.clusters - 1);\n      maxRelativeCenterVariation /= this.params.clusters;\n      maxRelativeCenterVariation /= meanClusterDistance;\n      if (maxRelativeCenterVariation < this.trainingConfig.relativeDistanceThreshold) break;\n    }\n    return this.params;\n  },\n\n  initClustersWithFirstPhrase(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const step = Math.floor(phrase.length / this.params.clusters);\n\n    let offset = 0;\n    for (let c = 0; c < this.params.clusters; c += 1) {\n      this.params.centers[c] = new Array(this.params.dimension).fill(0);\n      for (let t = 0; t < step; t += 1) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[c][d] += phrase.get(offset + t, d) / step;\n        }\n      }\n      offset += step;\n    }\n  },\n\n  initializeClustersRandom(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const indices = Array.from(\n      Array(phrase.length),\n      () => Math.floor(Math.random() * this.params.clusters),\n    );\n    const pointsPerCluster = indices.reduce(\n      (ppc, i) => {\n        const p = ppc;\n        p[i] += 1;\n        return p;\n      },\n      Array(this.params.clusters).fill(0),\n    );\n    for (let i = 0; i < indices.length; i += 1) {\n      const clustIdx = indices[i];\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.centers[clustIdx][d] += phrase.get(i, d);\n      }\n    }\n    this.params.centers.forEach((_, c) => {\n      this.params.centers[c] = this.params.centers[c]\n        .map(x => x / pointsPerCluster[c]);\n    });\n  },\n\n  initializeClustersForgy(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const indices = Array.from(\n      Array(this.params.clusters),\n      () => Math.floor(Math.random() * phrase.length),\n    );\n    this.params.centers = indices.map(i => phrase.getFrame(i));\n  },\n\n  updateCenters(previousCenters, trainingSet) {\n    this.params.centers = Array.from(Array(this.params.clusters), () =>\n      new Array(this.params.dimension).fill(0));\n    const numFramesPerCluster = Array(this.params.clusters).fill(0);\n    trainingSet.forEach((phrase) => {\n      for (let t = 0; t < phrase.length; t += 1) {\n        const frame = phrase.getFrame(t);\n        let minDistance = euclidean(frame, previousCenters[0]);\n        let clusterMembership = 0;\n        for (let k = 1; k < this.params.clusters; k += 1) {\n          const distance = euclidean(\n            frame,\n            previousCenters[k],\n            this.params.dimension,\n          );\n          if (distance < minDistance) {\n            clusterMembership = k;\n            minDistance = distance;\n          }\n        }\n        numFramesPerCluster[clusterMembership] += 1;\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[clusterMembership][d] += phrase.get(t, d);\n        }\n      }\n    });\n    for (let k = 0; k < this.params.clusters; k += 1) {\n      if (numFramesPerCluster[k] > 0) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[k][d] /= numFramesPerCluster[k];\n        }\n      }\n    }\n  },\n};\n\nexport default function withKMeansTraining(\n  o,\n  clusters,\n  trainingConfiguration = {},\n) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const trainingConfig = Object.assign({\n    initialization: 'random',\n    relativeDistanceThreshold: 1e-3,\n    minIterations: 5,\n    maxIterations: 100,\n  }, trainingConfiguration);\n  const model = Object.assign(o, kMeansTrainingPrototype, {\n    trainingConfig,\n  });\n  model.params.clusters = clusters;\n  return model;\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withKMeansTraining from './kmeans_training_mixin';\n\n/**\n * Train a K-Means model.\n *\n * @todo K-Means details\n *\n * @param  {TrainingSet} trainingSet           training set\n * @param  {number} clusters                   Number of clusters\n * @param  {Object} [trainingConfig=undefined] Training configuration\n * @return {Object}                            K-Means parameters\n */\nexport default function trainKmeans(\n  trainingSet,\n  clusters,\n  trainingConfig = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withKMeansTraining(\n    ModelBase({\n      inputDimension,\n      outputDimension,\n    }),\n    clusters,\n    trainingConfig,\n  );\n  return model.train(trainingSet);\n}\n","/* eslint-disable no-use-before-define */\nconst kEpsilonPseudoInverse = 1.0e-9;\n\n/**\n * Matrix Prototype\n * @type {Object}\n * @property {Array} data Matrix data\n * @property {Number} ncols Number of columns\n * @property {Number} nrows Number of rows\n *\n * @ignore\n */\nconst matrixPrototype = /** @lends Matrix */ {\n  /**\n   * Compute the Sum of the matrix\n   * @return {Number} Sum of all elements in the matrix\n   */\n  sum() {\n    return this.data.reduce((a, b) => a + b, 0);\n  },\n\n  /**\n   * Compute the transpose matrix\n   * @return {Matrix}\n   */\n  transpose() {\n    const out = Matrix(this.ncols, this.nrows);\n    for (let i = 0; i < this.ncols; i += 1) {\n      for (let j = 0; j < this.nrows; j += 1) {\n        out.data[(i * this.nrows) + j] = this.data[(j * this.ncols) + i];\n      }\n    }\n    return out;\n  },\n\n  /**\n   * Compute the product of matrices\n   * @param  {Matrix} mat Second matrix\n   * @return {Matrix}     Product of the current matrix by `mat`\n   */\n  product(mat) {\n    if (this.ncols !== mat.nrows) {\n      throw new Error('Wrong dimensions for matrix product');\n    }\n    const out = Matrix(this.nrows, mat.ncols);\n    for (let i = 0; i < this.nrows; i += 1) {\n      for (let j = 0; j < mat.ncols; j += 1) {\n        out.data[(i * mat.ncols) + j] = 0;\n        for (let k = 0; k < this.ncols; k += 1) {\n          out.data[(i * mat.ncols) + j] +=\n            this.data[(i * this.ncols) + k] * mat.data[(k * mat.ncols) + j];\n        }\n      }\n    }\n    return out;\n  },\n\n  /**\n   * Compute the Pseudo-Inverse of a Matrix\n   * @param  {Number} determinant Determinant (computed with the inversion)\n   * @return {Matrix}             Pseudo-inverse of the matrix\n   */\n  pinv() {\n    if (this.nrows === this.ncols) {\n      return this.gaussJordanInverse();\n    }\n\n    const transp = this.transpose();\n    if (this.nrows >= this.ncols) {\n      const prod = transp.product(this);\n      const { determinant, matrix: dst } = prod.gaussJordanInverse();\n      return { determinant, matrix: dst.product(transp) };\n    }\n    const prod = this.product(transp);\n    const { determinant, matrix: dst } = prod.gaussJordanInverse();\n    return { determinant, matrix: transp.product(dst) };\n  },\n\n  /**\n   * Compute the Gauss-Jordan Inverse of a Square Matrix\n   * !!! Determinant (computed with the inversion\n   * @private\n   */\n  gaussJordanInverse() {\n    if (this.nrows !== this.ncols) {\n      throw new Error('Gauss-Jordan inversion: Cannot invert Non-square matrix');\n    }\n    let determinant = 1;\n    const mat = Matrix(this.nrows, this.ncols * 2);\n    const newMat = Matrix(this.nrows, this.ncols * 2);\n    const n = this.nrows;\n\n    // Create matrix\n    for (let i = 0; i < n; i += 1) {\n      for (let j = 0; j < n; j += 1) {\n        mat.data[(i * 2 * n) + j] = this.data[(i * n) + j];\n      }\n      mat.data[(i * 2 * n) + n + i] = 1;\n    }\n\n    for (let k = 0; k < n; k += 1) {\n      let i = k;\n      while (Math.abs(mat.data[(i * 2 * n) + k]) < kEpsilonPseudoInverse) {\n        i += 1;\n        if (i === n) {\n          throw new Error('Non-invertible matrix');\n        }\n      }\n      determinant *= mat.data[(i * 2 * n) + k];\n\n      // if found > Exchange lines\n      if (i !== k) {\n        mat.swapLines(i, k);\n      }\n\n      newMat.data = mat.data.slice();\n\n      for (let j = 0; j < 2 * n; j += 1) {\n        newMat.data[(k * 2 * n) + j] /= mat.data[(k * 2 * n) + k];\n      }\n      for (let ii = 0; ii < n; ii += 1) {\n        if (ii !== k) {\n          for (let j = 0; j < 2 * n; j += 1) {\n            newMat.data[(ii * 2 * n) + j] -=\n                mat.data[(ii * 2 * n) + k] *\n                newMat.data[(k * 2 * n) + j];\n          }\n        }\n      }\n      mat.data = newMat.data.slice();\n    }\n\n    const dst = Matrix(this.nrows, this.ncols);\n    for (let i = 0; i < n; i += 1) {\n      for (let j = 0; j < n; j += 1) {\n        dst.data[(i * n) + j] = mat.data[(i * 2 * n) + n + j];\n      }\n    }\n    return { determinant, matrix: dst };\n  },\n\n  /**\n   * Swap 2 lines of the matrix\n   * @param  {[type]} i index of the first line\n   * @param  {[type]} j index of the second line\n   * @private\n   */\n  swapLines(i, j) {\n    for (let k = 0; k < this.ncols; k += 1) {\n      const tmp = this.data[(i * this.ncols) + k];\n      this.data[(i * this.ncols) + k] = this.data[(j * this.ncols) + k];\n      this.data[(j * this.ncols) + k] = tmp;\n    }\n  },\n\n  /**\n   * Swap 2 columns of the matrix\n   * @param  {[type]} i index of the first column\n   * @param  {[type]} j index of the second column\n   * @private\n   */\n  swapColumns(i, j) {\n    for (let k = 0; k < this.nrows; k += 1) {\n      const tmp = this.data[(k * this.ncols) + i];\n      this.data[(k * this.ncols) + i] = this.data[(k * this.ncols) + j];\n      this.data[(k * this.ncols) + j] = tmp;\n    }\n  },\n};\n\n/**\n * Create a matrix\n *\n * @function\n * @param       {Number} [nrows=0]  Number of rows\n * @param       {Number} [ncols=-1] Number of columns\n * @return {matrixPrototype}\n *\n * @property {Array} data Matrix data\n * @property {Number} ncols Number of columns\n * @property {Number} nrows Number of rows\n */\nexport default function Matrix(nrows = 0, ncols = -1) {\n  const nc = ncols < 0 ? nrows : ncols;\n  return Object.assign(\n    Object.create(matrixPrototype), //\n    {\n      nrows,\n      ncols: nc,\n      data: Array(nrows * nc).fill(0),\n    },\n  );\n}\n","import Matrix from './matrix';\n\n/**\n * Gaussian Distribution Prototype\n *\n * @type {Object}\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n *\n * @ignore\n */\nconst baseGaussianPrototype = /** @lends GaussianDistribution */ {\n  /**\n   * Allocate the distribution\n   * @private\n   */\n  allocate() {\n    this.mean = new Array(this.dimension).fill(0);\n    if (this.covarianceMode === 'full') {\n      this.covariance = new Array(this.dimension ** 2).fill(0);\n      this.inverseCovariance = new Array(this.dimension ** 2).fill(0);\n    } else {\n      this.covariance = new Array(this.dimension).fill(0);\n      this.inverseCovariance = new Array(this.dimension).fill(0);\n    }\n    if (this.bimodal) {\n      this.allocateBimodal();\n    }\n  },\n\n  /**\n   * @brief Estimate the likelihood of an observation vector.\n   *\n   * If the distribution is bimodal an the observation is a vector of the size\n   * of the input modality, the likelihood is computed only on the\n   * distribution for the input modality\n   *\n   * @param  {array} observation data observation\n   * @return {number}\n   */\n  likelihood(observation) {\n    if (this.covarianceDeterminant === 0) {\n      throw new Error('Covariance Matrix is not invertible');\n    }\n    if (this.bimodal && observation.length === this.inputDimension) {\n      return this.inputLikelihood(observation);\n    }\n    if (observation.length !== this.dimension) {\n      throw new Error(`GaussianDistribution: observation has wrong dimension. Expected \\`${this.dimension}\\`, got \\`${observation.length}\\``);\n    }\n\n    let euclideanDistance = 0;\n    if (this.covarianceMode === 'full') {\n      for (let l = 0; l < this.dimension; l += 1) {\n        let tmp = 0;\n        for (let k = 0; k < this.dimension; k += 1) {\n          tmp += this.inverseCovariance[(l * this.dimension) + k] *\n            (observation[k] - this.mean[k]);\n        }\n        euclideanDistance += (observation[l] - this.mean[l]) * tmp;\n      }\n    } else {\n      for (let l = 0; l < this.dimension; l += 1) {\n        euclideanDistance += this.inverseCovariance[l] *\n          (observation[l] - this.mean[l]) *\n          (observation[l] - this.mean[l]);\n      }\n    }\n\n    let p = Math.exp(-0.5 * euclideanDistance) /\n      Math.sqrt(this.covarianceDeterminant * ((2 * Math.PI) ** this.dimension));\n\n    if (p < 1e-180 || Number.isNaN(p) || Math.abs(p) === +Infinity) {\n      p = 1e-180;\n    }\n\n    return p;\n  },\n\n  /**\n   * Regularize the distribution, given a regularization vector of the same\n   * dimension. Regularization adds the vector to the variance of the\n   * distribution.\n   *\n   * @param  {Array} regularization regularization vector\n   */\n  regularize(regularization) {\n    if (this.covarianceMode === 'full') {\n      for (let d = 0; d < this.dimension; d += 1) {\n        this.covariance[(d * this.dimension) + d] += regularization[d];\n      }\n    } else {\n      for (let d = 0; d < this.dimension; d += 1) {\n        this.covariance[d] += regularization[d];\n      }\n    }\n  },\n\n  /**\n   * Update the inverse covariance of the distribution\n   * @private\n   */\n  updateInverseCovariance() {\n    if (this.covarianceMode === 'full') {\n      const covMatrix = Matrix(this.dimension, this.dimension);\n\n      covMatrix.data = this.covariance.slice();\n      const inv = covMatrix.pinv();\n      this.covarianceDeterminant = inv.determinant;\n      this.inverseCovariance = inv.matrix.data;\n    } else { // DIAGONAL COVARIANCE\n      this.covarianceDeterminant = 1;\n      for (let d = 0; d < this.dimension; d += 1) {\n        if (this.covariance[d] <= 0) {\n          throw new Error('Non-invertible matrix');\n        }\n        this.inverseCovariance[d] = 1 / this.covariance[d];\n        this.covarianceDeterminant *= this.covariance[d];\n      }\n    }\n    if (this.bimodal) {\n      this.updateInverseCovarianceBimodal();\n    }\n  },\n\n  /**\n   * Convert to an ellipse allong two dimensions\n   *\n   * @param  {number} dimension1 first dimension\n   * @param  {number} dimension2 second dimension\n   * @return {Ellipse}\n   */\n  toEllipse(dimension1, dimension2) {\n    if (dimension1 >= this.dimension || dimension2 >= this.dimension) {\n      throw new Error('dimensions out of range');\n    }\n\n    const gaussianEllipse = {\n      x: 0,\n      y: 0,\n      width: 0,\n      height: 0,\n      angle: 0,\n    };\n    gaussianEllipse.x = this.mean[dimension1];\n    gaussianEllipse.y = this.mean[dimension2];\n\n    // Represent 2D covariance with square matrix\n    // |a b|\n    // |b c|\n    let a;\n    let b;\n    let c;\n    if (this.covarianceMode === 'full') {\n      a = this.covariance[(dimension1 * this.dimension) + dimension1];\n      b = this.covariance[(dimension1 * this.dimension) + dimension2];\n      c = this.covariance[(dimension2 * this.dimension) + dimension2];\n    } else {\n      a = this.covariance[dimension1];\n      b = 0;\n      c = this.covariance[dimension2];\n    }\n\n    // Compute Eigen Values to get width, height and angle\n    const trace = a + c;\n    const determinant = (a * c) - (b * b);\n    const eigenVal1 = 0.5 * (trace + Math.sqrt((trace ** 2) - (4 * determinant)));\n    const eigenVal2 = 0.5 * (trace - Math.sqrt((trace ** 2) - (4 * determinant)));\n    gaussianEllipse.width = Math.sqrt(5.991 * eigenVal1);\n    gaussianEllipse.height = Math.sqrt(5.991 * eigenVal2);\n    gaussianEllipse.angle = Math.atan(b / (eigenVal1 - c));\n    if (Number.isNaN(gaussianEllipse.angle)) {\n      gaussianEllipse.angle = Math.PI / 2;\n    }\n\n    return gaussianEllipse;\n  },\n\n  /**\n   * Modify the distribution along two dimensions given the equivalent values\n   * as an Ellipse representation.\n   *\n   * @param  {Ellipse} gaussianEllipse The Ellipse corresponding to the 2D\n   * covariance along the two target dimensions\n   * @param  {number} dimension1      first dimension\n   * @param  {number} dimension2      second dimension\n   */\n  fromEllipse(gaussianEllipse, dimension1, dimension2) {\n    if (dimension1 >= this.dimension || dimension2 >= this.dimension) {\n      throw new Error('dimensions out of range');\n    }\n\n    this.mean[dimension1] = gaussianEllipse.x;\n    this.mean[dimension2] = gaussianEllipse.y;\n\n    const eigenVal1 = (gaussianEllipse.width * gaussianEllipse.width) / 5.991;\n    const eigenVal2 = (gaussianEllipse.height * gaussianEllipse.height) / 5.991;\n    const tantheta = Math.tan(gaussianEllipse.angle);\n    const b = ((eigenVal1 - eigenVal2) * tantheta) / ((tantheta ** 2) + 1);\n    const c = eigenVal1 - (b / tantheta);\n    const a = eigenVal2 + (b / tantheta);\n\n    if (this.covarianceMode === 'full') {\n      this.covariance[(dimension1 * this.dimension) + dimension1] = a;\n      this.covariance[(dimension1 * this.dimension) + dimension2] = b;\n      this.covariance[(dimension2 * this.dimension) + dimension1] = b;\n      this.covariance[(dimension2 * this.dimension) + dimension2] = c;\n    } else {\n      this.covariance[dimension1] = a;\n      this.covariance[dimension2] = c;\n    }\n    this.updateInverseCovariance();\n  },\n};\n\n/**\n * Bimodal Gaussian Distribution Prototype, for Regression purposes\n *\n * @type {Object}\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n * @property {Array}   inverseCovarianceInput Inverse covariance of the input\n * modality\n *\n * @ignore\n */\nconst bimodalGaussianPrototype = /** @lends GaussianDistribution */ {\n  /**\n   * Allocate the distribution\n   * @private\n   */\n  allocateBimodal() {\n    if (this.covarianceMode === 'full') {\n      this.inverseCovarianceInput = new Array(this.inputDimension ** 2).fill(0);\n    } else {\n      this.inverseCovarianceInput = new Array(this.inputDimension).fill(0);\n    }\n  },\n\n  /**\n   * Estimate the likelihood of an observation for the input modality only.\n   * Called by `likelihood` when relevant.\n   * @param  {Array} inputObservation observation (input modality only)\n   * @return {number}\n   * @private\n   */\n  inputLikelihood(inputObservation) {\n    if (this.covarianceDeterminantInput === 0) {\n      throw new Error('Covariance Matrix of input modality is not invertible');\n    }\n\n    let euclideanDistance = 0;\n    if (this.covarianceMode === 'full') {\n      for (let l = 0; l < this.inputDimension; l += 1) {\n        let tmp = 0;\n        for (let k = 0; k < this.inputDimension; k += 1) {\n          tmp += this.inverseCovarianceInput[(l * this.inputDimension) + k] *\n            (inputObservation[k] - this.mean[k]);\n        }\n        euclideanDistance += (inputObservation[l] - this.mean[l]) * tmp;\n      }\n    } else {\n      for (let l = 0; l < this.inputDimension; l += 1) {\n        euclideanDistance += this.inverseCovariance[l] *\n          (inputObservation[l] - this.mean[l]) *\n          (inputObservation[l] - this.mean[l]);\n      }\n    }\n\n    let p = Math.exp(-0.5 * euclideanDistance) /\n               Math.sqrt(this.covarianceDeterminantInput *\n                    ((2 * Math.PI) ** this.inputDimension));\n\n    if (p < 1e-180 || Number.isNaN(p) || Math.abs(p) === +Infinity) p = 1e-180;\n\n    return p;\n  },\n\n  /**\n   * Estimate the output values associated with an input observation by\n   * regression, given the distribution parameters.\n   *\n   * @todo Clarify the maths here.\n   *\n   * @param  {Array} inputObservation observation (input modality only)\n   * @return {Array} Output values\n   */\n  regression(inputObservation) {\n    const outputDimension = this.dimension - this.inputDimension;\n    const prediction = Array(outputDimension).fill(0);\n\n    if (this.covarianceMode === 'full') {\n      for (let d = 0; d < outputDimension; d += 1) {\n        prediction[d] = this.mean[this.inputDimension + d];\n        for (let e = 0; e < this.inputDimension; e += 1) {\n          let tmp = 0;\n          for (let f = 0; f < this.inputDimension; f += 1) {\n            tmp += this.inverseCovarianceInput[(e * this.inputDimension) + f] *\n              (inputObservation[f] - this.mean[f]);\n          }\n          prediction[d] += tmp *\n            this.covariance[((d + this.inputDimension) * this.dimension) + e];\n        }\n      }\n    } else {\n      for (let d = 0; d < outputDimension; d += 1) {\n        prediction[d] = this.mean[this.inputDimension + d];\n      }\n    }\n    return prediction;\n  },\n\n  /**\n   * Update the inverse covariance\n   * @private\n   */\n  updateInverseCovarianceBimodal() {\n    if (this.covarianceMode === 'full') {\n      const covMatrixInput = Matrix(this.inputDimension, this.inputDimension);\n      for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n        for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n          covMatrixInput.data[(d1 * this.inputDimension) + d2] =\n            this.covariance[(d1 * this.dimension) + d2];\n        }\n      }\n      const invInput = covMatrixInput.pinv();\n      this.covarianceDeterminantInput = invInput.determinant;\n      this.inverseCovarianceInput = invInput.matrix.data;\n    } else { // DIAGONAL COVARIANCE\n      this.covarianceDeterminantInput = 1;\n      for (let d = 0; d < this.inputDimension; d += 1) {\n        if (this.covariance[d] <= 0) {\n          throw new Error('Non-invertible matrix');\n        }\n        this.inverseCovarianceInput[d] = 1 / this.covariance[d];\n        this.covarianceDeterminantInput *= this.covariance[d];\n      }\n    }\n    this.updateOutputCovariance();\n  },\n\n  /**\n   * Update the output covariance\n   * @private\n   */\n  updateOutputCovariance() {\n    if (this.covarianceMode === 'diagonal') {\n      this.outputCovariance = this.covariance.slice(0, this.inputDimension);\n      return;\n    }\n\n    // CASE: FULL COVARIANCE\n    const covMatrixInput = Matrix(this.inputDimension, this.inputDimension);\n    for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n        covMatrixInput.data[(d1 * this.inputDimension) + d2] =\n          this.covariance[(d1 * this.dimension) + d2];\n      }\n    }\n    const inv = covMatrixInput.pinv();\n    const covarianceGS = Matrix(this.inputDimension, this.outputDimension);\n    for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n        covarianceGS.data[(d1 * this.outputDimension) + d2] =\n          this.covariance[(d1 * this.dimension) + this.inputDimension + d2];\n      }\n    }\n    const covarianceSG = Matrix(this.outputDimension, this.inputDimension);\n    for (let d1 = 0; d1 < this.outputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n        covarianceSG.data[(d1 * this.inputDimension) + d2] =\n          this.covariance[((this.inputDimension + d1) * this.dimension) + d2];\n      }\n    }\n    const tmptmptmp = inv.matrix.product(covarianceGS);\n    const covarianceMod = covarianceSG.product(tmptmptmp);\n    this.outputCovariance = Array(this.outputDimension ** 2).fill(0);\n    for (let d1 = 0; d1 < this.outputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n        this.outputCovariance[(d1 * this.outputDimension) + d2] =\n          this.covariance[((this.inputDimension + d1) * this.dimension) +\n            this.inputDimension + d2] -\n            covarianceMod.data[(d1 * this.outputDimension) + d2];\n      }\n    }\n  },\n};\n\n/**\n * Multivariate Gaussian Distribution factory function.\n * Full covariance, optionally multimodal with support for regression.\n *\n * @function\n * @param {Number} [inputDimension=1]      Dimension of the input modality\n * @param {Number} [outputDimension=0]     Dimension of the output\n * modality (positive for regression, otherwise 0 for recognition).\n * @param {String} [covarianceMode='full'] covariance mode (full vs\n * diagonal)\n * @return {baseGaussianPrototype|bimodalGaussianPrototype}\n *\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n */\nexport default function GaussianDistribution(\n  inputDimension = 1,\n  outputDimension = 0,\n  covarianceMode = 'full',\n) {\n  const bimodal = outputDimension > 0;\n  const dimension = inputDimension + outputDimension;\n  const proto = bimodal ?\n    Object.assign({}, baseGaussianPrototype, bimodalGaussianPrototype) :\n    baseGaussianPrototype;\n  const data = Object.assign(\n    {\n      bimodal,\n      dimension,\n      inputDimension,\n      outputDimension,\n      covarianceMode,\n      covarianceDeterminant: 0,\n    },\n    bimodal ? { covarianceDeterminantInput: 0 } : {},\n  );\n  const dist = Object.assign(\n    Object.create(proto),\n    data,\n  );\n  dist.allocate();\n  return dist;\n}\n","const trainerPrototype = /** @lends withEMTraining */ {\n  /**\n   * Train the model from the given training set, using the\n   * Expectation-Maximisation algorithm.\n   *\n   * @param  {TrainingSet} trainingSet Training Set\n   * @return {Object} Parameters of the trained model\n   */\n  train(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) {\n      throw new Error('The training set is empty');\n    }\n\n    this.initTraining(trainingSet);\n\n    let logLikelihood = -Infinity;\n    let iterations = 0;\n    let previousLogLikelihood = logLikelihood;\n\n    while (!this.converged(iterations, logLikelihood, previousLogLikelihood)) {\n      previousLogLikelihood = logLikelihood;\n      logLikelihood = this.updateTraining(trainingSet);\n\n      const pctChg =\n        100 * Math.abs((logLikelihood - previousLogLikelihood) / previousLogLikelihood);\n      if (Number.isNaN(pctChg) && iterations > 1) {\n        throw new Error('An error occured during training');\n      }\n\n      iterations += 1;\n    }\n\n    this.terminateTraining();\n    return this.params;\n  },\n\n  /**\n   * Return `true` if the training has converged according to the criteria\n   * specified at the creation\n   *\n   * @param  {number} iteration       Current iteration\n   * @param  {number} logProb         Current log-likelihood of the training set\n   * @param  {number} previousLogProb Previous log-likelihood of the training\n   * set\n   * @return {boolean}\n   *\n   * @private\n   */\n  converged(iteration, logProb, previousLogProb) {\n    if (iteration >= this.convergenceCriteria.maxIterations) return true;\n    if (this.convergenceCriteria.maxIterations >= this.convergenceCriteria.minIterations) {\n      return iteration >= this.convergenceCriteria.maxIterations;\n    }\n    if (iteration < this.convergenceCriteria.minIterations) return false;\n    const percentChange = 100 * Math.abs((logProb - previousLogProb) / logProb);\n    return percentChange <= this.convergenceCriteria.percentChange;\n  },\n};\n\n/**\n * Add ABSTRACT training capabilities to a model for which the training process\n * use the Expectation-Maximisation (EM) algorithm. This is used in particular\n * for training GMMs and HMMs.\n *\n * The final instance needs to implement `initTraining`, `updateTraining` and\n * `terminateTraining` methods. `updateTraining` will be called until the\n * convergence criteria are met. Convergence depends on\n * - A minimum number of iterations\n * - A maximum number of iterations\n * - A threshold on the relative change of the log-likelihood of the training\n * data between successive iterations.\n *\n * @todo details\n *\n * @param  {Object} [o]                   Source object\n * @param  {Object} [convergenceCriteria] Set of convergence criteria\n * @param  {number} [convergenceCriteria.percentChange=1e-3] Threshold in % of\n * the relative change of the log-likelihood, under which the training stops.\n * @param  {number} [convergenceCriteria.minIterations=5]    minimum number of iterations\n * @param  {number} [convergenceCriteria.maxIterations=100]  maximum number of iterations\n * @return {Object}\n */\nexport default function withEMTraining(\n  o,\n  convergenceCriteria = {\n    percentChange: 1e-3,\n    minIterations: 5,\n    maxIterations: 100,\n  },\n) {\n  return Object.assign(o, trainerPrototype, { convergenceCriteria });\n}\n","import { isBaseModel } from '../core/model_base_mixin';\nimport GaussianDistribution from '../common/gaussian_distribution';\n\n/**\n * GMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst gmmBasePrototype = /** @lends withGMMBase */ {\n  /**\n   * Allocate the training variables\n   * @private\n   */\n  allocate() {\n    this.params.components = Array.from(\n      Array(this.params.gaussians),\n      () => new GaussianDistribution(\n        this.params.inputDimension,\n        this.params.outputDimension,\n        this.params.covarianceMode,\n      ),\n    );\n    this.params.mixtureCoeffs = Array(this.params.gaussians).fill(0);\n    this.beta = new Array(this.params.gaussians).fill(0);\n  },\n\n  /**\n   * Compute the likelihood of an observation given the GMM's parameters\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}\n   */\n  likelihood(observation) {\n    let likelihood = 0;\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.beta[c] = this.componentLikelihood(observation, c);\n      likelihood += this.beta[c];\n    }\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.beta[c] /= likelihood;\n    }\n\n    return likelihood;\n  },\n\n  /**\n   * Compute the likelihood of an observation for a single component\n   * @param  {Array<Number>} observation Observation vector\n   * @param  {Number} mixtureComponent Component index\n   * @return {Number}\n   * @private\n   */\n  componentLikelihood(observation, mixtureComponent) {\n    if (mixtureComponent >= this.params.gaussians) {\n      throw new Error('The index of the Gaussian Mixture Component is out of bounds');\n    }\n    return this.params.mixtureCoeffs[mixtureComponent] *\n        this.params.components[mixtureComponent].likelihood(observation);\n  },\n\n  /**\n   * Update the inverse covariance of each Gaussian component\n   * @private\n   */\n  updateInverseCovariances() {\n    this.params.components.forEach((c) => {\n      c.updateInverseCovariance();\n    });\n    try {\n      this.params.components.forEach((c) => {\n        c.updateInverseCovariance();\n      });\n    } catch (e) {\n      throw new Error('Matrix inversion error: varianceoffset must be too small');\n    }\n  },\n\n  /**\n   * Normalize the mixing coefficients of the Gaussian mixture\n   * @private\n   */\n  normalizeMixtureCoeffs() {\n    let normConst = 0;\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      normConst += this.params.mixtureCoeffs[c];\n    }\n    if (normConst > 0) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.mixtureCoeffs[c] /= normConst;\n      }\n    } else {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      }\n    }\n  },\n\n  /**\n   * Regularize the covariances\n   * @private\n   */\n  regularize() {\n    this.params.components.forEach((c) => {\n      c.regularize(this.currentRegularization);\n    });\n  },\n};\n\n/**\n * Bimodal (regression) GMM Prototype\n * @type {Object}\n * @ignore\n */\nconst gmmBimodalPrototype = /** @lends withGMMBase */ {\n  /**\n   * Estimate the output values corresponding to the input observation, by\n   * regression given the GMM's parameters. This method is called Gaussian\n   * Mixture Regression (GMR).\n   *\n   * @param  {Array<Number>} inputObservation Observation on the input modality\n   * @return {Array<Number>} Output values (length = outputDimension)\n   */\n  regression(inputObservation) {\n    this.results.outputValues = Array(this.params.outputDimension).fill(0);\n    this.results.outputCovariance = Array(this.params.covarianceMode === 'full' ? this.params.outputDimension ** 2 : this.params.outputDimension).fill(0);\n    let tmpOutputValues;\n\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      tmpOutputValues = this.params.components[c].regression(inputObservation);\n      for (let d = 0; d < this.params.outputDimension; d += 1) {\n        this.results.outputValues[d] += this.beta[c] * tmpOutputValues[d];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n            this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n              (this.beta[c] ** 2) *\n              this.params.components[c].outputCovariance[(d * this.params.outputDimension) + d2];\n          }\n        } else {\n          this.results.outputCovariance[d] +=\n            (this.beta[c] ** 2) * this.params.components[c].outputCovariance[d];\n        }\n      }\n    }\n    return this.results.outputValues;\n  },\n};\n\n/**\n * Add basic GMM capabilities to a single-class model. This enables the\n * computation of the likelihoods and regression operations common to\n * training and prediction\n *\n * @see withGMMTraining\n * @see withGMMPrediction\n *\n * @param  {ModelBase} o Source Model\n * @return {GMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withGMMBase(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    gmmBasePrototype,\n    o.params.bimodal ? gmmBimodalPrototype : {},\n  );\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withKMeansTraining from '../kmeans/kmeans_training_mixin';\n\n/**\n * GMM Training Prototype\n * @type {Object}\n * @ignore\n */\nconst gmmTrainerPrototype = /** @lends withGMMTraining */ {\n  /**\n   * Initialize the EM Training process\n   * @param  {TrainingSet} trainingSet Training set\n   */\n  initTraining(trainingSet) {\n    this.allocate();\n    this.initParametersToDefault(trainingSet.standardDeviation());\n    this.initMeansWithKMeans(trainingSet);\n    this.initCovariances(trainingSet);\n    this.regularize();\n    this.updateInverseCovariances();\n  },\n\n  /**\n   * Initialize the model parameters to their default values\n   * @param  {Array<Number>} dataStddev Standard deviation of the training data\n   * @private\n   */\n  initParametersToDefault(dataStddev) {\n    let normCoeffs = 0;\n    this.currentRegularization = dataStddev.map(std => Math.max(\n      this.params.regularization.absolute,\n      this.params.regularization.relative * std,\n    ));\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      if (this.params.covarianceMode === 'full') {\n        this.params.components[c].covariance = Array(this.params.dimension ** 2)\n          .fill(this.params.regularization.absolute / 2);\n      } else {\n        this.params.components[c].covariance = Array(this.params.dimension).fill(0);\n      }\n      this.params.components[c].regularize(this.currentRegularization);\n      this.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      normCoeffs += this.params.mixtureCoeffs[c];\n    }\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.mixtureCoeffs[c] /= normCoeffs;\n    }\n  },\n\n  /**\n   * Initialize the means of the model using a K-Means algorithm\n   *\n   * @see withKMeansTraining\n   *\n   * @param  {TrainingSet} trainingSet training set\n   * @private\n   */\n  initMeansWithKMeans(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n    const kmeans = withKMeansTraining(\n      ModelBase({\n        inputDimension: this.params.inputDimension,\n        outputDimension: this.params.outputDimension,\n      }),\n      this.params.gaussians,\n      { initialization: 'data' },\n    );\n    const kmeansParams = kmeans.train(trainingSet);\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.components[c].mean = kmeansParams.centers[c];\n    }\n  },\n\n  /**\n   * Initialize the covariances of the model from the training set\n   *\n   * @param  {TrainingSet} trainingSet training set\n   * @private\n   */\n  initCovariances(trainingSet) {\n    // TODO: simplify with covariance symmetricity\n    // TODO: If Kmeans, covariances from cluster members\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      this.params.components[n].covariance = Array((this.params.covarianceMode === 'full') ? this.params.dimension ** 2 : this.params.dimension).fill(0);\n    }\n\n    const gmeans = Array(this.params.gaussians * this.params.dimension).fill(0);\n    const factor = Array(this.params.gaussians).fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.gaussians);\n      let offset = 0;\n      for (let n = 0; n < this.params.gaussians; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            gmeans[(n * this.params.dimension) + d1] += phrase.get(offset + t, d1);\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n                this.params.components[n]\n                  .covariance[(d1 * this.params.dimension) + d2] +=\n                  phrase.get(offset + t, d1) * phrase.get(offset + t, d2);\n              }\n            } else {\n              this.params.components[n].covariance[d1] +=\n                phrase.get(offset + t, d1) ** 2;\n            }\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        gmeans[(n * this.params.dimension) + d1] /= factor[n];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[n].covariance[(d1 * this.params.dimension) + d2] /= factor[n];\n          }\n        } else {\n          this.params.components[n].covariance[d1] /= factor[n];\n        }\n      }\n    }\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[n].covariance[(d1 * this.params.dimension) + d2] -=\n              gmeans[(n * this.params.dimension) + d1] *\n              gmeans[(n * this.params.dimension) + d2];\n          }\n        } else {\n          this.params.components[n].covariance[d1] -=\n            gmeans[(n * this.params.dimension) + d1] ** 2;\n        }\n      }\n    }\n  },\n\n  /**\n   * Update the EM Training process (1 EM iteration).\n   * @param  TrainingSet trainingSet training set\n   */\n  updateTraining(trainingSet) {\n    let logProb = 0;\n    let totalLength = 0;\n    trainingSet.forEach((phrase) => {\n      totalLength += phrase.length;\n    });\n    const phraseIndices = Object.keys(trainingSet.phrases);\n\n    const p = Array.from(\n      Array(this.params.gaussians),\n      () => new Array(totalLength).fill(0),\n    );\n    const E = Array(this.params.gaussians).fill(0);\n    let tbase = 0;\n\n    trainingSet.forEach((phrase) => {\n      for (let t = 0; t < phrase.length; t += 1) {\n        let normConst = 0;\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          p[c][tbase + t] = this.componentLikelihood(phrase.getFrame(t), c);\n\n          if (p[c][tbase + t] === 0 ||\n            Number.isNaN(p[c][tbase + t]) ||\n            p[c][tbase + t] === +Infinity) {\n            p[c][tbase + t] = 1e-100;\n          }\n          normConst += p[c][tbase + t];\n        }\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          p[c][tbase + t] /= normConst;\n          E[c] += p[c][tbase + t];\n        }\n        logProb += Math.log(normConst);\n      }\n      tbase += phrase.length;\n    });\n\n    // Estimate Mixture coefficients\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.mixtureCoeffs[c] = E[c] / totalLength;\n    }\n\n    // Estimate means\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.components[c].mean[d] = 0;\n        tbase = 0;\n        for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n          const phrase = trainingSet.phrases[phraseIndices[pix]];\n          for (let t = 0; t < phrase.length; t += 1) {\n            this.params.components[c].mean[d] +=\n              p[c][tbase + t] * phrase.get(t, d);\n          }\n          tbase += phrase.length;\n        }\n        this.params.components[c].mean[d] /= E[c];\n      }\n    }\n\n    // estimate covariances\n    if (this.params.covarianceMode === 'full') {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n          for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[c].covariance[(d1 * this.params.dimension) + d2] = 0;\n            tbase = 0;\n            for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n              const phrase = trainingSet.phrases[phraseIndices[pix]];\n              for (let t = 0; t < phrase.length; t += 1) {\n                this.params.components[c].covariance[(d1 * this.params.dimension) + d2] +=\n                  p[c][tbase + t] *\n                  (phrase.get(t, d1) - this.params.components[c].mean[d1]) *\n                  (phrase.get(t, d2) - this.params.components[c].mean[d2]);\n              }\n              tbase += phrase.length;\n            }\n            this.params.components[c].covariance[(d1 * this.params.dimension) + d2] /= E[c];\n            if (d1 !== d2) {\n              this.params.components[c].covariance[(d2 * this.params.dimension) + d1] =\n                this.params.components[c].covariance[(d1 * this.params.dimension) + d2];\n            }\n          }\n        }\n      }\n    } else {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n          this.params.components[c].covariance[d1] = 0;\n          tbase = 0;\n          for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n            const phrase = trainingSet.phrases[phraseIndices[pix]];\n            for (let t = 0; t < phrase.length; t += 1) {\n              const value = (phrase.get(t, d1) - this.params.components[c].mean[d1]);\n              this.params.components[c].covariance[d1] +=\n                    p[c][tbase + t] * value * value;\n            }\n            tbase += phrase.length;\n          }\n          this.params.components[c].covariance[d1] /= E[c];\n        }\n      }\n    }\n\n    this.regularize();\n    this.updateInverseCovariances();\n\n    return logProb;\n  },\n\n  /**\n   * Terminate the EM Training process\n   */\n  terminateTraining() {},\n};\n\n/**\n * Add GMM Training capabilities to a GMM Model\n * @param  {GMMBase} o               Source GMM Model\n * @param  {Number} [gaussians=1]    Number of Gaussian components\n * @param  {Object} [regularization] Regularization parameters\n * @param  {Number} [regularization.absolute=1e-3] Absolute regularization\n * @param  {Number} [regularization.relative=1e-2] Relative Regularization\n (relative to the training set's variance along each dimension)\n * @param  {String} [covarianceMode='full'] Covariance mode ('full' or diagonal)\n * @return {BMMBase}\n */\nexport default function withGMMTraining(\n  o,\n  gaussians = 1,\n  regularization = { absolute: 1e-3, relative: 1e-2 },\n  covarianceMode = 'full',\n) {\n  if (!Object.keys(o).includes('params')) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    gmmTrainerPrototype,\n    {\n      params: {\n        ...o.params,\n        gaussians,\n        regularization,\n        covarianceMode,\n      },\n    },\n  );\n}\n","import ModelBase from './model_base_mixin';\n\n/**\n * Multiclass Models Mixin\n * @type {Object}\n * @ignore\n */\nconst MulticlassBasePrototype = /** @lends MulticlassModelBase */{\n  /**\n   * Get the number of classes in the model\n   * @return {number} number of classes\n   */\n  size() {\n    return Object.keys(this.models).length;\n  },\n\n  /**\n   * Check if a class with the given label exists\n   * @param  {string} label Class label\n   * @return {boolean}\n   */\n  includes(label) {\n    return Object.keys(this.models).includes(label);\n  },\n\n  /**\n   * Remove a class by label\n   * @param  {string} label Class label\n   */\n  remove(label) {\n    if (this.includes(label)) {\n      delete this.models[label];\n    }\n  },\n};\n\n/**\n * Create an abstract Multiclass Model\n * @param       {number]} inputDimension  input dimension\n * @param       {number]} outputDimension output dimension\n * @param       {Object} parameters       additional parameters to copy\n * @function\n */\nexport default function MulticlassModelBase({\n  inputDimension,\n  outputDimension,\n  ...parameters\n}) {\n  return Object.assign(\n    ModelBase({ inputDimension, outputDimension, ...parameters }),\n    MulticlassBasePrototype,\n  );\n}\n","/**\n * Add multiclass training capabilities to a model. It takes as argument\n * the training function called to train each class of the training set.\n *\n * @param  {MulticlassModelBase} o Source model\n * @param  {Function}  trainingFunction Training function for a single class\n * @return {MulticlassModelBase}\n */\nexport default function withMulticlassTraining(\n  o,\n  trainingFunction,\n) {\n  return Object.assign(\n    o,\n    /** @lends withMulticlassTraining */ {\n      /**\n       * Train the model, optionally specifying a set of classes to train\n       *\n       * @param  {TrainingSet} trainingSet   Training data set\n       * @param  {undefined|Array<String>} [labels=undefined] Labels\n       * corresponding to the classes to be trained (all if unspecified)\n       * @return {Object} the parameters of the trained model\n       *\n       * @throws {Error} if the training set is empty\n       * @throws {Error} if one of the specified class does not exist\n       */\n      train(trainingSet, labels = undefined) {\n        if (!trainingSet || trainingSet.empty()) {\n          throw new Error('The training set is empty');\n        }\n        if (labels) {\n          labels.forEach((l) => {\n            if (!this.includes(l)) {\n              throw new Error(`Class labeled ${l} does not exist`);\n            }\n          });\n        }\n\n        this.params.classes = {};\n        const labs = labels || trainingSet.labels();\n        labs.forEach((label) => {\n          const ts = trainingSet.getPhrasesOfClass(label);\n          // console.log(ts);\n          this.params.classes[label] = trainingFunction(ts);\n        });\n        return this.params;\n      },\n    },\n  );\n}\n","/**\n * Circular Buffer prototype\n *\n * @property {number}  capacity Buffer capacity\n * @property {number}  length Current buffer length\n * @property {boolean} full Specifies if the buffer is full\n *\n * @ignore\n */\nconst circularBufferPrototype = /** @lends CircularBuffer */ {\n  /**\n   * Clear the buffer contents\n   */\n  clear() {\n    this.length = 0;\n    this.index = 0;\n    this.full = false;\n    this.buffer = [];\n  },\n\n  /**\n   * Push a value to the buffer\n   * @param  {*} value data value (any type)\n   */\n  push(value) {\n    if (this.full) {\n      this.buffer[this.index] = value;\n      this.index = (this.index + 1) % this.capacity;\n    } else {\n      this.buffer.push(value);\n      this.length += 1;\n      this.full = (this.length === this.capacity);\n    }\n  },\n\n  /**\n   * Get the value at a given index\n   * @param  {number} idx data index\n   * @return {anything}   value at index\n   */\n  get(idx) {\n    return this.buffer[(idx + this.index) % this.capacity];\n  },\n\n  /**\n   * Fill the buffer with a constant value\n   * @param  {*} value data value (any type)\n   */\n  fill(value) {\n    this.length = this.capacity;\n    this.index = 0;\n    this.full = true;\n    this.buffer = Array(this.capacity).fill(value);\n  },\n\n  /**\n   * Iterate over the buffer's data\n   * @param  {Function} callback Callback function\n   * (@see Array.prototype.forEach).\n   */\n  forEach(callback) {\n    for (let i = 0; i < this.length; i += 1) {\n      callback(this.buffer[(i + this.index) % this.capacity], i);\n    }\n  },\n\n  /**\n   * Get an array of the buffer current values (ordered)\n   * @return {Array} Buffer contents\n   */\n  values() {\n    return this.buffer.slice(this.index)\n      .concat(this.buffer.slice(0, this.index));\n  },\n};\n\n/**\n * Circular Buffer Data Structure (any data type)\n * @param  {number} capacity Buffer capacity\n * @return {circularBufferPrototype}\n * @function\n *\n * @property {number}  capacity Buffer capacity\n * @property {number}  length Current buffer length\n * @property {boolean} full Specifies if the buffer is full\n */\nexport default function CircularBuffer(capacity) {\n  const buffer = Object.create(circularBufferPrototype);\n  buffer.capacity = capacity;\n  buffer.clear();\n  return buffer;\n}\n","import { isBaseModel } from './model_base_mixin';\nimport CircularBuffer from '../common/circular_buffer';\n\n/**\n * Prototype for models with prediction capabilities\n * @param  {Boolean} bimodal Specifies whether the model is bimodal\n * @return {Object}\n * @ignore\n */\nconst predictionBasePrototype = bimodal => (/** @lends withAbtractPrediction */{\n  /**\n   * Likelihood Buffer\n   * @type {CircularBuffer}\n   * @private\n   */\n  likelihoodBuffer: CircularBuffer(1),\n\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @param {Number} [lw] Size (in frames) of the likelihood smoothing window\n   */\n  setLikelihoodWindow(lw) {\n    this.likelihoodWindow = lw;\n    this.likelihoodBuffer = CircularBuffer(lw);\n  },\n\n  /**\n   * Reset the prediction process\n   * @return {Modelbase} the model\n   */\n  reset() {\n    this.likelihoodBuffer.clear();\n    return this;\n  },\n\n  /**\n   * Update the predictions with a new observation\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Object} Prediction results\n   *\n   * @todo document results data structure\n   */\n  predict(observation) {\n    const likelihood = this.likelihood(observation);\n    if (bimodal) {\n      this.regression(observation);\n    }\n    this.updateResults(likelihood);\n    return this.results;\n  },\n\n  /**\n   * Update the prediction results\n   * @param  {Number} instantLikelihood Instantaneous likelihood\n   * @private\n   */\n  updateResults(instantLikelihood) {\n    this.results.instantLikelihood = instantLikelihood;\n    this.likelihoodBuffer.push(Math.log(instantLikelihood));\n    this.results.logLikelihood = 0;\n    const bufSize = this.likelihoodBuffer.length;\n    for (let i = 0; i < bufSize; i += 1) {\n      this.results.logLikelihood += this.likelihoodBuffer.get(i);\n    }\n    this.results.logLikelihood /= bufSize;\n  },\n});\n\n/**\n * Add ABSTRACT prediction capabilities to an existing model\n * @param  {Modelbase} o                 Source model\n * @param  {Number} [likelihoodWindow=1] Size of the likelihood smoothing window\n * @return {Modelbase}\n */\nexport default function withAbtractPrediction(o, likelihoodWindow = 1) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const results = Object.assign(\n    { instantLikelihood: 0, logLikelihood: 0 },\n    o.params.bimodal ? { outputValues: [], outputCovariance: [] } : {},\n  );\n  return Object.assign(\n    o,\n    predictionBasePrototype(o.params.bimodal),\n    { results, likelihoodBuffer: CircularBuffer(likelihoodWindow) },\n  );\n}\n","/**\n * Check if the specification is respected for a given parameter and value,\n * and clip if relevant.\n *\n * @ignore\n *\n * @param  {String}        model      Stream Operator Name (for logging)\n * @param  {String}        parameter     Attribute name\n * @param  {Specification} specification Attribute specification\n * @param  {*}             value         Attribute value\n * @return {*}                           Type-checked parameter value\n */\nfunction checkSpec(model, parameter, specification, value) {\n  if (!specification) return;\n  if (specification.constructor === Array && !specification.includes(value)) {\n    throw new Error(`Attribute '${parameter}' (value: '${value}') is not allowed for model '${model}' (options: [${specification}]).`);\n  } else if (specification.constructor === Object) {\n    if (Object.keys(specification).includes('min') && value < specification.min) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is inferior to the minimum required value of ${specification.min} for model '${model}'.`);\n    }\n    if (Object.keys(specification).includes('max') && value > specification.max) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is superior to the maximum required value of ${specification.min} for model '${model}'.`);\n    }\n  } else if (typeof specification === 'function') {\n    if (!specification(value)) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is incompatible with model '${model}'.`);\n    }\n  }\n}\n\n/**\n * Check the parameters of a model and return the parameters of the\n * output stream.\n *\n * The specification should be a structure of the form:\n * ```\n * const streamSpecification = {\n *   <parameter name>: {\n *     required: <boolean>,\n *     check: <null || Array || { min: <minimum value>, max: <maximum value>} || Function >,\n *     transform: Function,\n *   },\n * };\n * ```\n *\n * @param  {String} model      Name of the model for logging\n * @param  {Object} specification I/O Stream Specification\n * @param  {Object} values        Attributes of the input stream\n * @return {Object}               Attributes of the output stream\n *\n * @example\n * import setupStreamAttributes from 'stream';\n *\n * const specification = {\n *   type: {\n *     required: false,\n *     check: null,\n *     transform: x => x || null,\n *   },\n *   format: {\n *     required: true,\n *     check: ['scalar', 'vector'],\n *     transform: x => x,\n *   },\n *   size: {\n *     required: true,\n *     check: { min: 1 },\n *     transform: x => 2 * x,\n *   },\n *   stuff: {\n *     required: true,\n *     check: x => Math.log2(x) === Math.floor(Math.log2(x)),\n *     transform: x => Math.log2(x),\n *   },\n * };\n *\n * const values = {\n *   type: 'anything',\n *   format: 'vector',\n *   size: 3,\n *   stuff: 8,\n *   another: 'one',\n * };\n *\n * setupStreamAttributes('module name', specification, values);\n * // Returns:\n * // {\n * //   type: 'anything',\n * //   format: 'vector',\n * //   size: 6,\n * //   stuff: 3,\n * //   another: 'one',\n * // }\n */\nexport default function validateParameters(model, specification, values) {\n  const parameters = Object.assign({}, values);\n  Object.keys(specification).forEach((attr) => {\n    const spec = specification[attr];\n\n    // Check for required parameters\n    if (spec.required && !Object.keys(values).includes(attr)) {\n      throw new Error(`Stream parameter '${attr}' is required for model '${model}'.`);\n    }\n\n    // Check the validity of the input parameters\n    checkSpec(model, attr, spec.check, values[attr]);\n\n    parameters[attr] = spec.transform ?\n      spec.transform(values[attr]) :\n      values[attr];\n  });\n  return parameters;\n}\n","import validateParameters from '../common/validation';\nimport { isBaseModel } from '../core/model_base_mixin';\n\nconst gmmParameterSpec = gaussians => ({\n  gaussians: {\n    required: true,\n    check: { min: 1 },\n  },\n  regularization: {\n    required: true,\n    check: ({ absolute, relative }) =>\n      (absolute && relative && absolute > 0 && relative > 0),\n  },\n  covarianceMode: {\n    required: true,\n    check: ['full', 'diagonal'],\n  },\n  mixtureCoeffs: {\n    required: true,\n    check: m => m.length === gaussians,\n  },\n  components: {\n    required: true,\n    check: c => c.length === gaussians,\n  },\n});\n\n/**\n * Add GMM prediction capabilities to a single-class model. Mostly, this checks\n * the validity of the model parameters\n *\n * @todo validate gaussian components\n *\n * @param  {GMMBaseModel} o Source Model\n * @return {GMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withGMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  validateParameters('GMM', gmmParameterSpec(o.params.gaussians), o.params);\n  return Object.assign(\n    o,\n    { beta: new Array(o.params.gaussians).fill(0) },\n  );\n}\n","import { isBaseModel } from './model_base_mixin';\n\n/**\n * Multiclass prediction mixin\n * @type {Object}\n * @ignore\n */\nconst MulticlassPredictionBasePrototype = /** @lends withMulticlassPrediction */ {\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @return {Number}\n   */\n  getLikelihoodWindow() {\n    return this.likelihoodWindow;\n  },\n\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @param {Number} [lw] Size (in frames) of the likelihood smoothing window\n   */\n  setLikelihoodWindow(lw) {\n    this.likelihoodWindow = lw;\n    Object.keys(this.models).forEach((label) => {\n      this.models[label].setLikelihoodWindow(lw);\n    });\n  },\n\n  /**\n   * Reset the prediction process. This is particularly important for temporal\n   * models such as HMMs, that depends on previous observations.\n   */\n  reset() {\n    Object.values(this.models).forEach(m => m.reset());\n    this.results = {\n      labels: [],\n      instantLikelihoods: [],\n      smoothedLikelihoods: [],\n      smoothedLogLikelihoods: [],\n      smoothedNormalizedLikelihoods: [],\n      likeliest: null,\n      classes: {},\n    };\n    if (this.params.bimodal) {\n      this.resetBimodal();\n    }\n  },\n\n  /**\n   * Make a prediction from a new observation (updates the results member)\n   * @param  {Array<Number>} observation Observation vector\n   */\n  predict(observation) {\n    Object.values(this.models).forEach(m => m.predict(observation));\n    this.updateResults();\n  },\n\n  updateResults() {\n    const labs = Object.keys(this.models).sort();\n    this.results.labels = labs;\n    let normInstant = 0;\n    let normSmoothed = 0;\n    let maxLogLikelihood = -Infinity;\n    this.results.classes = labs\n      .map((lab, i) => {\n        this.results.instantLikelihoods[i] =\n          this.models[lab].results.instantLikelihood;\n        this.results.smoothedLogLikelihoods[i] =\n          this.models[lab].results.logLikelihood;\n        this.results.smoothedLikelihoods[i] =\n          Math.exp(this.results.smoothedLogLikelihoods[i]);\n        normInstant += this.results.instantLikelihoods[i];\n        normSmoothed += this.results.smoothedLikelihoods[i];\n        if (this.results.smoothedLogLikelihoods[i] > maxLogLikelihood) {\n          maxLogLikelihood = this.results.smoothedLogLikelihoods[i];\n          this.results.likeliest = lab;\n        }\n        return { [lab]: this.models[lab].results };\n      })\n      .reduce((o, x) => ({ ...o, ...x }), {});\n    this.results.smoothedNormalizedLikelihoods =\n      this.results.smoothedLikelihoods.map(x => x / normSmoothed);\n    this.results.instantNormalizedLikelihoods =\n      this.results.instantLikelihoods.map(x => x / normInstant);\n    if (this.params.bimodal) {\n      this.updateRegressionResults();\n    }\n  },\n};\n\nconst MulticlassPredictionBimodalPrototype = {\n  resetBimodal() {\n    this.results.outputValues = [];\n    this.results.outputCovariance = [];\n  },\n\n  updateRegressionResults() {\n    if (this.params.multiClassRegressionEstimator === 'likeliest') {\n      this.results.outputValues =\n        this.models[this.results.likeliest].results.outputValues;\n      this.results.outputCovariance =\n        this.models[this.results.likeliest].results.outputCovariance;\n    } else if (this.params.multiClassRegressionEstimator === 'mixture') {\n      this.results.outputValues = Array(this.outputDimension).fill(0);\n      this.results.outputCovariance = Array(this.outputDimension ** (this.configuration.covarianceMode === 'full' ? 2 : 1)).fill(0);\n      this.results.labels.forEach((lab) => {\n        this.results.outputValues.map((x, i) => x + (\n          this.results.smoothedNormalizedLikelihoods[i] *\n          this.models[lab].results.outputValues[i]\n        ));\n        this.results.outputCovariance.map((x, i) => x + (\n          this.results.smoothedNormalizedLikelihoods[i] *\n          this.models[lab].results.outputCovariance[i]\n        ));\n      });\n    } else {\n      throw new Error('Unknown regression estimator, use `likeliest` or `mixture`');\n    }\n  },\n};\n\n/**\n * Add multiclass prediction capabilities to a multiclass model\n * @param  {MulticlassModelBase} o Source model\n * @param  {String} [multiClassRegressionEstimator='likeliest'] Type of\n * regression estimator:\n * - `likeliest` selects the output values from the likeliest class\n * - `mixture` computes the output values as the weighted sum of the\n * contributions of each class, weighed by their normalized likelihood\n * @return {MulticlassPredictionBasePrototype}\n * @function\n */\nexport default function withMulticlassPrediction(o, multiClassRegressionEstimator = 'likeliest') {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const m = Object.assign(\n    o,\n    MulticlassPredictionBasePrototype,\n    o.params.bimodal ? MulticlassPredictionBimodalPrototype : {},\n  );\n  m.params.multiClassRegressionEstimator = multiClassRegressionEstimator;\n  return m;\n}\n","import GaussianDistribution from '../common/gaussian_distribution';\nimport ModelBase from '../core/model_base_mixin';\nimport withEMTraining from '../core/em_training_mixin';\nimport withGMMBase from './gmm_base_mixin';\nimport withGMMTraining from './gmm_training_mixin';\nimport MulticlassModelBase from '../core/multiclass_mixin';\nimport withMulticlassTraining from '../core/multiclass_training_mixin';\nimport withAbtractPrediction from '../core/prediction_mixin';\nimport withGMMPrediction from './gmm_prediction_mixin';\nimport withMulticlassPrediction from '../core/multiclass_prediction_mixin';\n\n/**\n * Set of criteria that define when the EM algorithm (for either GMMs or HMMs) has converged.\n * Convergence depends on\n * - A minimum number of iterations\n * - A maximum number of iterations\n * - A threshold on the relative change of the log-likelihood of the training\n * data between successive iterations.\n *\n * @typedef {Object} ConvergenceCriteria\n *\n * @property {number} [percentChange=1e-3] Threshold in % of\n * the relative change of the log-likelihood, under which the training stops.\n * @property {number} [minIterations=5]    minimum number of iterations\n * @property {number} [maxIterations=100]  maximum number of iterations\n */\n\n/**\n * GMM training configuration\n *\n * @typedef {Object} GMMConfiguration\n * @property {Number} gaussians Number of Gaussian components\n * @property {{ absolute: 1e-3, relative: 1e-2 }} regularization An object containing the\n * relative and absolute regularization values. Regularization is an offset value added to the\n * diagonal of covariance matrices for convergence and generalization. The two values represent:\n * - `relative`: the offset relative to the variance of the training data\n * - `absolute`: an absolute lower threshold for the offset\n * @property {String} covarianceMode Type of covariance matrix ('full' or 'diagonal')\n */\n\n/**\n * @typedef {Object} GMMParameters\n * @property {Boolean} bimodal Specifies if the model is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} gaussians Number of gaussian components in the mixture\n * @property {String} covarianceMode Covariance mode ('full' or 'diagonal')\n * @property {Array<Number>} mixtureCoeffs mixture coefficients ('weight' of\n * each gaussian component)\n * @property {Array<GaussianDistribution>} components Gaussian components\n */\n\n/**\n * Train a single-class GMM Model.\n *\n * @todo GMM details\n *\n * @param  {TrainingSet} trainingSet Training set\n * @param  {GMMConfiguration} configuration Training configuration\n * @param  {ConvergenceCriteria} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {GMMParameters} Parameters of the trained GMM\n */\nexport function trainGMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const { gaussians, regularization, covarianceMode } = configuration;\n  const model = withGMMTraining(\n    withEMTraining(\n      withGMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        ...configuration,\n      })),\n      convergenceCriteria,\n    ),\n    gaussians,\n    regularization,\n    covarianceMode,\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Train a multi-class GMM Model.\n *\n * @todo GMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {GMMConfiguration} configuration                   Training configuration\n * @param  {ConvergenceCriteria} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {GMMParameters} Parameters of the trained GMM\n */\nexport function trainMulticlassGMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withMulticlassTraining(\n    MulticlassModelBase({ inputDimension, outputDimension, ...configuration }),\n    ts => trainGMM(ts, configuration, convergenceCriteria),\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Create a GMM Predictor from a full set of parameters (generated by trainGMM).\n * @param {GMMParameters} params Model parameters\n * @param {number} [likelihoodWindow=1] Likelihoow window size\n * @function\n */\nexport function GMMPredictor(\n  params,\n  likelihoodWindow = 1,\n) {\n  const model = withGMMPrediction(withAbtractPrediction(\n    withGMMBase(ModelBase(params)),\n    likelihoodWindow,\n  ));\n  params.components.forEach((c, i) => {\n    model.params.components[i] = Object.assign(GaussianDistribution(\n      params.inputDimension,\n      params.outputDimension,\n      params.covarianceMode,\n    ), c);\n  });\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass GMM Predictor from a full set of parameters\n * (generated by trainMulticlassGMM).\n * @param {GMMParameters} params Model parameters\n * @param {number} [likelihoodWindow=1] Likelihoow window size\n * @function\n */\nexport function MulticlassGMMPredictor(\n  params,\n  likelihoodWindow = 1,\n) {\n  const model = withMulticlassPrediction(MulticlassModelBase(params));\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = GMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model.reset();\n  return model;\n}\n","import { isBaseModel } from '../core/model_base_mixin';\n\n//\n// TODO: hierarchical + exit probabilities methods.\n//\n\n/**\n * HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hmmBasePrototype = /** @lends withHMMBase */ {\n  /**\n   * Specifies if the forward algorithm has been initialized\n   * @type {Boolean}\n   * @private\n   */\n  forwardInitialized: false,\n\n  /**\n   * Specifies if the containing multiclass model is isHierarchical\n   * @todo check that\n   * @type {Boolean}\n   * @private\n   */\n  isHierarchical: false,\n\n  /**\n   * Initialize the forward algorithm (See rabiner, 1989)\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}                    `ct` (inverse likelihood)\n   */\n  initializeForwardAlgorithm(observation) {\n    let normConst = 0;\n    if (this.params.transitionMode === 'ergodic') {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.alpha[i] = this.params.prior[i] *\n          this.params.xStates[i].likelihood(observation);\n        normConst += this.alpha[i];\n      }\n    } else {\n      this.alpha = new Array(this.params.states).fill(0);\n      this.alpha[0] = this.params.xStates[0].likelihood(observation);\n      normConst += this.alpha[0];\n    }\n    this.forwardInitialized = true;\n    if (normConst > 0) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.alpha[i] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 1 / this.params.states;\n    }\n    return 1;\n  },\n\n  /**\n   * Update the forward algorithm (See rabiner, 1989)\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}                    `ct` (inverse likelihood)\n   */\n  updateForwardAlgorithm(observation) {\n    let normConst = 0;\n    this.previousAlpha = this.alpha.slice();\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.alpha[j] += this.previousAlpha[i] *\n            this.params.transition[i][j];\n        }\n      } else {\n        this.alpha[j] += this.previousAlpha[j] * this.params.transition[j * 2];\n        if (j > 0) {\n          this.alpha[j] += this.previousAlpha[j - 1] *\n            this.params.transition[((j - 1) * 2) + 1];\n        } else {\n          this.alpha[0] += this.previousAlpha[this.params.states - 1] *\n            this.params.transition[(this.params.states * 2) - 1];\n        }\n      }\n      this.alpha[j] *= this.params.xStates[j].likelihood(observation);\n      normConst += this.alpha[j];\n    }\n    if (normConst > 1e-300) {\n      for (let j = 0; j < this.params.states; j += 1) {\n        this.alpha[j] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    return 0;\n  },\n};\n\n/**\n * Add basic HMM capabilities to a single-class model. This enables the\n * computation of the likelihoods and regression operations common to\n * training and prediction\n *\n * @see withHMMTraining\n * @see withHMMPrediction\n *\n * @param  {ModelBase} o Source Model\n * @return {HMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHMMBase(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(o, hmmBasePrototype);\n}\n","import TrainingSet from '../training_set';\nimport ModelBase from '../core/model_base_mixin';\nimport withGMMBase from '../gmm/gmm_base_mixin';\nimport { trainGMM } from '../gmm';\n\nconst TRANSITION_REGULARIZATION = 1e-5;\n\n/**\n * HMM Training Prototype\n * @type {Object}\n * @ignore\n */\nconst hmmTrainerPrototype = /** @lends withHMMTraining */ {\n  /**\n   * Initialize the EM Training process\n   * @param  {TrainingSet} trainingSet Training set\n   */\n  initTraining(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    this.allocate(trainingSet);\n    this.initParametersToDefault(trainingSet.standardDeviation());\n    if (this.params.gaussians > 1) {\n      this.initMeansCovariancesWithGMMEM(trainingSet);\n    } else {\n      this.initMeansWithAllPhrases(trainingSet);\n      this.initCovariancesFullyObserved(trainingSet);\n    }\n  },\n\n  /**\n   * Allocate the model's parameters and training variables\n   * @param  {TrainingSet} trainingSet The training set\n   * @private\n   */\n  allocate(trainingSet) {\n    const {\n      inputDimension,\n      outputDimension,\n      gaussians,\n      regularization,\n      covarianceMode,\n    } = this.params;\n    this.params.xStates = Array.from(\n      new Array(this.params.states),\n      () => withGMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        gaussians,\n        regularization,\n        covarianceMode,\n      })),\n    );\n    this.params.xStates.forEach(s => s.allocate());\n    this.alpha = new Array(this.params.states).fill(0);\n    this.previousAlpha = new Array(this.params.states).fill(0);\n    this.beta = new Array(this.params.states).fill(0);\n    this.previousBeta = new Array(this.params.states).fill(0);\n\n    // Initialize Algorithm variables\n    // ---------------------------------------\n    const nbPhrases = trainingSet.size();\n    this.gammaSequence = new Array(nbPhrases).fill(null);\n    this.epsilonSequence = new Array(nbPhrases).fill(null);\n    this.gammaSequenceperMixture = new Array(nbPhrases).fill(null);\n    let maxT = 0;\n    let i = 0;\n    trainingSet.forEach((phrase) => {\n      const T = phrase.length;\n      this.gammaSequence[i] = Array.from(\n        new Array(T),\n        () => new Array(this.params.states).fill(0),\n      );\n      if (this.params.transitionMode === 'ergodic') {\n        this.epsilonSequence[i] = Array.from(\n          new Array(T),\n          () => Array.from(\n            new Array(this.params.states),\n            () => new Array(this.params.states).fill(0),\n          ),\n        );\n      } else {\n        this.epsilonSequence[i] = Array.from(\n          new Array(T),\n          () => new Array(this.params.states * 2).fill(0),\n        );\n      }\n      this.gammaSequenceperMixture[i] =\n        new Array(this.params.gaussians).fill(0);\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.gammaSequenceperMixture[i][c] =\n          Array.from(\n            new Array(T),\n            () => new Array(this.params.states).fill(0),\n          );\n      }\n      if (T > maxT) {\n        maxT = T;\n      }\n      i += 1;\n    });\n\n    this.gammaSum = new Array(this.params.states).fill(0);\n    this.gammaSumPerMixture = new Array(this.params.states * this.params.gaussians).fill(0);\n  },\n\n  /**\n   * Update the EM Training process (1 EM iteration).\n   * @param  TrainingSet trainingSet training set\n   */\n  updateTraining(trainingSet) {\n    let logProb = 0;\n\n    // Forward-backward for each phrase\n    // =================================================\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      if (phrase.length > 0) {\n        logProb += this.baumWelchForwardBackward(phrase, phraseIndex);\n      }\n      phraseIndex += 1;\n    });\n    this.baumWelchGammaSum(trainingSet);\n\n    // Re-estimate model parameters\n    // =================================================\n\n    // set covariance and mixture coefficients to zero for each state\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.xStates[i].params.mixtureCoeffs[c] = 0;\n        if (this.params.covarianceMode === 'full') {\n          this.params.xStates[i].params.components[c].covariance =\n            new Array(this.params.dimension ** 2).fill(0);\n        } else {\n          this.params.xStates[i].params.components[c].covariance =\n            new Array(this.params.dimension).fill(0);\n        }\n      }\n    }\n\n    this.baumWelchEstimateMixtureCoefficients(trainingSet);\n    this.baumWelchEstimateMeans(trainingSet);\n    this.baumWelchEstimateCovariances(trainingSet);\n    if (this.params.transitionMode === 'ergodic') {\n      this.baumWelchEstimatePrior(trainingSet);\n    }\n    this.baumWelchEstimateTransitions(trainingSet);\n    return logProb;\n  },\n\n  /**\n   * terminate the EM Training process\n   * @param  TrainingSet trainingSet training set\n   */\n  terminateTraining() {\n    this.normalizeTransitions();\n    this.gammaSequence = null;\n    this.epsilonSequence = null;\n    this.gammaSequenceperMixture = null;\n    this.alphaSeq = null;\n    this.betaSeq = null;\n    this.gammaSum = null;\n    this.gammaSumPerMixture = null;\n    this.params.xStates = this.params.xStates.map(s => s.params);\n  },\n\n  /**\n   * Initialize the model parameters to their default values\n   * @param  {Array<Number>} dataStddev Standard deviation of the training data\n   * @private\n   */\n  initParametersToDefault(dataStddev) {\n    if (this.params.transitionMode === 'ergodic') {\n      this.setErgodic();\n    } else {\n      this.setLeftRight();\n    }\n    const currentRegularization = dataStddev.map(std => Math.max(\n      this.params.regularization.absolute,\n      this.params.regularization.relative * std,\n    ));\n    const initCovariance = (this.params.covarianceMode === 'full') ?\n      () => new Array(this.params.dimension ** 2)\n        .fill(this.params.regularization.absolute / 2) :\n      () => new Array(this.params.dimension)\n        .fill(0);\n    for (let i = 0; i < this.params.states; i += 1) {\n      // this.params.xStates[i].initParametersToDefault(dataStddev);\n      const s = this.params.xStates[i];\n      s.currentRegularization = currentRegularization;\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        s.params.components[c].covariance = initCovariance();\n        s.params.components[c].regularize(currentRegularization);\n        s.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      }\n    }\n  },\n\n  /**\n   * Initialize the means of each state using all available phrases in the\n   * training set\n   * @param  {TrainingSet} trainingSet Training set\n   * @private\n   */\n  initMeansWithAllPhrases(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.xStates[n].params.components[0].mean[d] = 0.0;\n      }\n    }\n\n    const factor = new Array(this.params.states).fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.states);\n      let offset = 0;\n      for (let n = 0; n < this.params.states; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d = 0; d < this.params.dimension; d += 1) {\n            this.params.xStates[n].params.components[0].mean[d] +=\n              phrase.get(offset + t, d);\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.xStates[n].params.components[0].mean[d] /= factor[n];\n      }\n    }\n  },\n\n  /**\n   * Initialize the covariance by direct (fully-observed) estimation from the\n   * training data.\n   * @param  {[type]} trainingSet [description]\n   * @private\n   */\n  initCovariancesFullyObserved(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      this.params.xStates[n].params.components[0].covariance =\n        new Array(this.params.dimension ** (this.params.covarianceMode === 'full' ? 2 : 1)).fill(0);\n    }\n\n    const factor = new Array(this.params.states).fill(0);\n    const othermeans = new Array(this.params.states * this.params.dimension)\n      .fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.states);\n      let offset = 0;\n      for (let n = 0; n < this.params.states; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            othermeans[((n * this.params.dimension)) + d1] +=\n                phrase.get(offset + t, d1);\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n                this.params.xStates[n].params.components[0]\n                  .covariance[(d1 * this.params.dimension) + d2] +=\n                    phrase.get(offset + t, d1) *\n                    phrase.get(offset + t, d2);\n              }\n            } else {\n              this.params.xStates[n].params.components[0].covariance[d1] +=\n                phrase.get(offset + t, d1) ** 2;\n            }\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        othermeans[(n * this.params.dimension) + d1] /= factor[n];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.xStates[n].params.components[0]\n              .covariance[(d1 * this.params.dimension) + d2] /=\n                factor[n];\n          }\n        } else {\n          this.params.xStates[n].params.components[0].covariance[d1] /= factor[n];\n        }\n      }\n    }\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.xStates[n].params.components[0]\n              .covariance[(d1 * this.params.dimension) + d2] -=\n                othermeans[(n * this.params.dimension) + d1] *\n                othermeans[(n * this.params.dimension) + d2];\n          }\n        } else {\n          this.params.xStates[n].params.components[0].covariance[d1] -=\n            othermeans[(n * this.params.dimension) + d1] *\n            othermeans[(n * this.params.dimension) + d1];\n        }\n      }\n      this.params.xStates[n].regularize();\n      this.params.xStates[n].updateInverseCovariances();\n    }\n  },\n\n  /**\n   * Initialize the means and covariance of each state's observation probability\n   * distribution using the Expectation-Maximization algorithm for GMMs\n   * @param  {[type]} trainingSet [description]\n   * @private\n   */\n  initMeansCovariancesWithGMMEM(trainingSet) {\n    for (let n = 0; n < this.params.states; n += 1) {\n      const ts = TrainingSet(this.params);\n      // eslint-disable-next-line no-loop-func\n      trainingSet.forEach((phrase, phraseIndex) => {\n        const step = Math.floor(phrase.length / this.params.states);\n        if (step > 0) {\n          ts.push(phraseIndex, phrase.label);\n          for (let t = n * step; t < (n + 1) * step; t += 1) {\n            ts.getPhrase(phraseIndex).push(phrase.getFrame(t));\n          }\n        }\n      });\n      if (!ts.empty()) {\n        const gmmParams = trainGMM(ts, this.params);\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          this.params.xStates[n].params.components[c].mean =\n            gmmParams.components[c].mean;\n          this.params.xStates[n].params.components[c].covariance =\n            gmmParams.components[c].covariance;\n          this.params.xStates[n].updateInverseCovariances();\n        }\n      }\n    }\n  },\n\n  /**\n   * Initialize the transition matrix to an ergodic transition matrix\n   * @private\n   */\n  setErgodic() {\n    const p = 1 / this.params.states;\n    this.params.prior = new Array(this.params.states).fill(p);\n    this.params.transition = Array.from(\n      new Array(this.params.states),\n      () => new Array(this.params.states).fill(p),\n    );\n  },\n\n  /**\n   * Initialize the transition matrix to a left-right transition matrix\n   * @private\n   */\n  setLeftRight() {\n    this.params.prior = new Array(this.params.states).fill(0);\n    this.params.prior[0] = 1;\n    this.params.transition = new Array(this.params.states * 2).fill(0.5);\n    this.params.transition[(this.params.states - 1) * 2] = 1;\n    this.params.transition[((this.params.states - 1) * 2) + 1] = 0;\n  },\n\n  /**\n   * Normalize the hidden state transition parameters\n   * (prior + transition matrix)\n   * @private\n   */\n  normalizeTransitions() {\n    if (this.params.transitionMode === 'ergodic') {\n      const normPrior = this.params.prior.reduce((a, b) => a + b, 0);\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] /= normPrior;\n        let transitionNorm = 0;\n        for (let j = 0; j < this.params.states; j += 1) {\n          transitionNorm += this.params.transition[i][j];\n        }\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.params.transition[i][j] /= transitionNorm;\n        }\n      }\n    } else {\n      for (let i = 0; i < this.params.states; i += 1) {\n        const transitionNorm = this.params.transition[i * 2] + this.params.transition[(i * 2) + 1];\n        this.params.transition[i * 2] /= transitionNorm;\n        this.params.transition[(i * 2) + 1] /= transitionNorm;\n      }\n    }\n  },\n\n  /**\n   * Initialize the backward algorithm (see rabiner, 1989)\n   * @param  {Number} ct Inverse probability at time T - 1 (last observation of\n   * the sequence)\n   * @private\n   */\n  initializeBackwardAlgorithm(ct) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = ct;\n    }\n  },\n\n  /**\n   * Initialize the backward algorithm (see rabiner, 1989)\n   * @param  {Number} ct Inverse probability at time t\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  updateBackwardAlgorithm(ct, observation) {\n    this.previousBeta = this.beta.slice();\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.beta[i] += this.params.transition[i][j] *\n            this.previousBeta[j] *\n            this.params.xStates[j].likelihood(observation);\n        }\n      } else {\n        this.beta[i] += this.params.transition[i * 2] *\n          this.previousBeta[i] *\n          this.params.xStates[i].likelihood(observation);\n        if (i < this.params.states - 1) {\n          this.beta[i] += this.params.transition[(i * 2) + 1] *\n            this.previousBeta[i + 1] *\n            this.params.xStates[i + 1].likelihood(observation);\n        }\n      }\n      this.beta[i] *= ct;\n      if (Number.isNaN(this.beta[i]) || Math.abs(this.beta[i]) === +Infinity) {\n        this.beta[i] = 1e100;\n      }\n    }\n  },\n\n  /**\n   * Forward algorithm update step for the Baum-Welch algorithms. It is similar\n   * to `updateForwardAlgorithm` except it takes precomputed observation\n   * likelihoods as argument.\n   * @param  {Array<Number>} observationLikelihoods observation likelihoods\n   * @private\n   */\n  baumWelchForwardUpdate(observationLikelihoods) {\n    let normConst = 0;\n    this.previousAlpha = this.alpha.slice();\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.alpha[j] += this.previousAlpha[i] *\n            this.params.transition[i][j];\n        }\n      } else {\n        this.alpha[j] += this.previousAlpha[j] * this.params.transition[j * 2];\n        if (j > 0) {\n          this.alpha[j] += this.previousAlpha[j - 1] *\n            this.params.transition[((j - 1) * 2) + 1];\n        } else {\n          this.alpha[0] += this.previousAlpha[this.params.states - 1] *\n            this.params.transition[(this.params.states * 2) - 1];\n        }\n      }\n      this.alpha[j] *= observationLikelihoods[j];\n      normConst += this.alpha[j];\n    }\n    if (Number.isNaN(normConst)) {\n      throw new Error('Holy molly');\n    }\n    if (normConst > 1e-300) {\n      for (let j = 0; j < this.params.states; j += 1) {\n        this.alpha[j] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    return 0;\n  },\n\n  /**\n   * Backward algorithm update step for the Baum-Welch algorithms. It is similar\n   * to `updatebackwardAlgorithm` except it takes precomputed observation\n   * likelihoods as argument.\n   * @param  {Number} ct Inverse probability at time t\n   * @param  {Array<Number>} observationLikelihoods observation likelihoods\n   * @private\n   */\n  baumWelchBackwardUpdate(ct, observationLikelihoods) {\n    this.previousBeta = this.beta.slice();\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.beta[i] +=\n            this.params.transition[i][j] *\n            this.previousBeta[j] *\n            observationLikelihoods[j];\n        }\n      } else {\n        this.beta[i] += this.params.transition[i * 2] *\n          this.previousBeta[i] *\n          observationLikelihoods[i];\n        if (i < this.params.states - 1) {\n          this.beta[i] += this.params.transition[(i * 2) + 1] *\n            this.previousBeta[i + 1] *\n            observationLikelihoods[i + 1];\n        }\n      }\n      this.beta[i] *= ct;\n      if (Number.isNaN(this.beta[i]) || Math.abs(this.beta[i]) === +Infinity) {\n        this.beta[i] = 1e100;\n      }\n    }\n  },\n\n  /**\n   * Forward-Backward algorithm for the Baum-Welch training algorithm\n   * @param  {Phrase} currentPhrase Current data phrase\n   * @param  {Number} phraseIndex   Current phrase index\n   * @return {Number} Log-likelihood\n   * @private\n   */\n  baumWelchForwardBackward(currentPhrase, phraseIndex) {\n    const T = currentPhrase.length;\n\n    const ct = new Array(T).fill(0);\n    let logProb;\n    this.alphaSeq = [];\n    this.betaSeq = [];\n\n    const observationProbabilities = Array.from(\n      new Array(T),\n      () => new Array(this.params.states).fill(0),\n    );\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        observationProbabilities[t][i] =\n          this.params.xStates[i].likelihood(currentPhrase.getFrame(t));\n      }\n    }\n\n    // Forward algorithm\n    ct[0] = this.initializeForwardAlgorithm(currentPhrase.getFrame(0));\n    logProb = -Math.log(ct[0]);\n    this.alphaSeq.push(this.alpha.slice());\n\n    for (let t = 1; t < T; t += 1) {\n      ct[t] = this.baumWelchForwardUpdate(observationProbabilities[t]);\n      logProb -= Math.log(ct[t]);\n      this.alphaSeq.push(this.alpha.slice());\n    }\n\n    // Backward algorithm\n    this.initializeBackwardAlgorithm(ct[T - 1]);\n    this.betaSeq.push(this.beta.slice());\n\n    for (let t = T - 2; t >= 0; t -= 1) {\n      this.baumWelchBackwardUpdate(ct[t], observationProbabilities[t + 1]);\n      this.betaSeq.push(this.beta.slice());\n    }\n    this.betaSeq.reverse();\n\n    // Compute Gamma Variable\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.gammaSequence[phraseIndex][t][i] =\n          (this.alphaSeq[t][i] * this.betaSeq[t][i]) / ct[t];\n      }\n    }\n\n    // Compute Gamma variable for each mixture component\n    let normConst;\n\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        normConst = 0;\n        if (this.params.gaussians === 1) {\n          const oo = observationProbabilities[t][i];\n          this.gammaSequenceperMixture[phraseIndex][0][t][i] =\n            this.gammaSequence[phraseIndex][t][i] * oo;\n          normConst += oo;\n        } else {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            const oo = this.params.xStates[i]\n              .componentLikelihood(currentPhrase.getFrame(t), c);\n            this.gammaSequenceperMixture[phraseIndex][c][t][i] =\n              this.gammaSequence[phraseIndex][t][i] *\n              oo;\n            normConst += oo;\n          }\n        }\n        if (normConst > 0) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.gammaSequenceperMixture[phraseIndex][c][t][i] /= normConst;\n          }\n        }\n      }\n    }\n\n    // Compute Epsilon Variable\n    if (this.params.transitionMode === 'ergodic') {\n      for (let t = 0; t < T - 1; t += 1) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          for (let j = 0; j < this.params.states; j += 1) {\n            this.epsilonSequence[phraseIndex][t][i][j] =\n              this.alphaSeq[t][i] *\n              this.params.transition[i][j] *\n              this.betaSeq[t + 1][j];\n            this.epsilonSequence[phraseIndex][t][i][j] *=\n              observationProbabilities[t + 1][j];\n          }\n        }\n      }\n    } else {\n      for (let t = 0; t < T - 1; t += 1) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.epsilonSequence[phraseIndex][t][i * 2] =\n            this.alphaSeq[t][i] *\n            this.params.transition[i * 2] *\n            this.betaSeq[t + 1][i];\n          this.epsilonSequence[phraseIndex][t][i * 2] *=\n            observationProbabilities[t + 1][i];\n          if (i < this.params.states - 1) {\n            this.epsilonSequence[phraseIndex][t][(i * 2) + 1] =\n              this.alphaSeq[t][i] *\n              this.params.transition[(i * 2) + 1] *\n              this.betaSeq[t + 1][i + 1];\n            this.epsilonSequence[phraseIndex][t][(i * 2) + 1] *=\n              observationProbabilities[t + 1][i + 1];\n          }\n        }\n      }\n    }\n\n    return logProb;\n  },\n\n  /**\n   * Sums the Gamma variables used for parameter estimation during training\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchGammaSum(trainingSet) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.gammaSum[i] = 0;\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.gammaSumPerMixture[(i * this.params.gaussians) + c] = 0;\n      }\n    }\n\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          this.gammaSum[i] +=\n            this.gammaSequence[phraseIndex][t][i];\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.gammaSumPerMixture[(i * this.params.gaussians) + c] +=\n              this.gammaSequenceperMixture[phraseIndex][c][t][i];\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n  },\n\n  /**\n   * Estimate the mixture coefficients of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateMixtureCoefficients(trainingSet) {\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.params.xStates[i].params.mixtureCoeffs[c] +=\n              this.gammaSequenceperMixture[phraseIndex][c][t][i];\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale mixture coefficients\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.params.xStates[i].normalizeMixtureCoeffs();\n    }\n  },\n\n  /**\n   * Estimate the means of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateMeans(trainingSet) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.xStates[i].params.components[c].mean.fill(0);\n      }\n    }\n\n    // Re-estimate Mean\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            for (let d = 0; d < this.params.dimension; d += 1) {\n              this.params.xStates[i].params.components[c].mean[d] +=\n                this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                phrase.get(t, d);\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Normalize mean\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          if (this.gammaSumPerMixture[(i * this.params.gaussians) + c] > 0) {\n            this.params.xStates[i].params.components[c].mean[d] /=\n              this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n          }\n          if (Number.isNaN(this.params.xStates[i].params.components[c].mean[d])) {\n            throw new Error('Convergence Error');\n          }\n        }\n      }\n    }\n  },\n\n  /**\n   * Estimate the covariances of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateCovariances(trainingSet) {\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n              if (this.params.covarianceMode === 'full') {\n                for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n                  this.params.xStates[i].params.components[c]\n                    .covariance[(d1 * this.params.dimension) + d2] +=\n                    this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                    (phrase.get(t, d1) -\n                      this.params.xStates[i].params.components[c].mean[d1]) *\n                    (phrase.get(t, d2) -\n                      this.params.xStates[i].params.components[c].mean[d2]);\n                }\n              } else {\n                const value = phrase.get(t, d1) -\n                  this.params.xStates[i].params.components[c].mean[d1];\n                this.params.xStates[i].params.components[c].covariance[d1] +=\n                  this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                  (value ** 2);\n              }\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale covariance\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        if (this.gammaSumPerMixture[(i * this.params.gaussians) + c] > 0) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n                this.params.xStates[i].params.components[c]\n                  .covariance[(d1 * this.params.dimension) + d2] /=\n                  this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n                if (d1 !== d2) {\n                  this.params.xStates[i].params.components[c]\n                    .covariance[(d2 * this.params.dimension) + d1] =\n                    this.params.xStates[i].params.components[c]\n                      .covariance[(d1 * this.params.dimension) + d2];\n                }\n              }\n            } else {\n              this.params.xStates[i].params.components[c].covariance[d1] /=\n                this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n            }\n          }\n        }\n      }\n      this.params.xStates[i].regularize();\n      this.params.xStates[i].updateInverseCovariances();\n    }\n  },\n\n  /**\n   * Estimate the prior probabilities of the model\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimatePrior(trainingSet) {\n    this.params.prior.fill(0);\n\n    // Re-estimate Prior probabilities\n    let sumprior = 0;\n    for (let phraseIndex = 0;\n      phraseIndex < trainingSet.size();\n      phraseIndex += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] += this.gammaSequence[phraseIndex][0][i];\n        sumprior += this.params.prior[i];\n      }\n    }\n\n    // Scale Prior vector\n    if (sumprior > 0) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] /= sumprior;\n      }\n    } else {\n      throw new Error('The Prior is all ZERO.....');\n    }\n  },\n\n  /**\n   * Estimate the transition probabilities of the model\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateTransitions(trainingSet) {\n    // Set transition matrix to 0\n    this.params.transition = this.params.transitionMode === 'ergodic' ?\n      Array.from(\n        new Array(this.params.states),\n        () => new Array(this.params.states).fill(0),\n      ) :\n      new Array(this.params.states * 2).fill(0);\n\n    // Re-estimate Transition probabilities\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      if (phrase.length > 0) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          // Experimental: A bit of regularization (sometimes avoids\n          // numerical errors)\n          if (this.params.transitionMode === 'leftright') {\n            this.params.transition[i * 2] += TRANSITION_REGULARIZATION;\n            if (i < this.params.states - 1) {\n              this.params.transition[(i * 2) + 1] += TRANSITION_REGULARIZATION;\n            } else {\n              this.params.transition[i * 2] += TRANSITION_REGULARIZATION;\n            }\n          }\n          // End Regularization\n          if (this.params.transitionMode === 'ergodic') {\n            for (let j = 0; j < this.params.states; j += 1) {\n              for (let t = 0; t < phrase.length - 1; t += 1) {\n                this.params.transition[i][j] +=\n                  this.epsilonSequence[phraseIndex][t][i][j];\n              }\n            }\n          } else {\n            for (let t = 0; t < phrase.length - 1; t += 1) {\n              this.params.transition[i * 2] +=\n                this.epsilonSequence[phraseIndex][t][i * 2];\n            }\n            if (i < this.params.states - 1) {\n              for (let t = 0; t < phrase.length - 1; t += 1) {\n                this.params.transition[(i * 2) + 1] +=\n                  this.epsilonSequence[phraseIndex][t][(i * 2) + 1];\n              }\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale transition matrix\n    if (this.params.transitionMode === 'ergodic') {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.params.transition[i][j] /=\n            (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n          if (Number.isNaN(this.params.transition[i][j])) {\n            throw new Error('Convergence Error. Check your training data or increase the variance offset');\n          }\n        }\n      }\n    } else {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.transition[i * 2] /=\n          (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n        if (Number.isNaN(this.params.transition[i * 2])) {\n          throw new Error('Convergence Error. Check your training data or increase the variance offset');\n        }\n        if (i < this.params.states - 1) {\n          this.params.transition[(i * 2) + 1] /=\n            (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n          if (Number.isNaN(this.params.transition[(i * 2) + 1])) {\n            throw new Error('Convergence Error. Check your training data or increase the variance offset');\n          }\n        }\n      }\n    }\n  },\n};\n\n/**\n * Add HMM Training capabilities to a HMM Model\n * @param  {HMMBase} o               Source HMM Model\n * @param  {Number} [states=1]       Number of hidden states\n * @param  {Number} [gaussians=1]    Number of Gaussian components\n * @param  {Object} [regularization] Regularization parameters\n * @param  {Number} [regularization.absolute=1e-3] Absolute regularization\n * @param  {Number} [regularization.relative=1e-2] Relative Regularization\n (relative to the training set's variance along each dimension)\n * @param  {String} [transitionMode='ergodic'] Structure of the transition\n * matrix ('ergodic' or 'left-right').\n * @param  {String} [covarianceMode='full'] Covariance mode ('full' or diagonal)\n * @return {BMMBase}\n */\nexport default function withHMMTraining(\n  o,\n  states = 1,\n  gaussians = 1,\n  regularization = { absolute: 1e-3, relative: 1e-2 },\n  transitionMode = 'leftright',\n  covarianceMode = 'full',\n) {\n  if (!Object.keys(o).includes('params')) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    hmmTrainerPrototype,\n    {\n      params: {\n        ...o.params,\n        states,\n        gaussians,\n        regularization,\n        transitionMode,\n        covarianceMode,\n      },\n    },\n  );\n}\n","import validateParameters from '../common/validation';\nimport { isBaseModel } from '../core/model_base_mixin';\nimport { GMMPredictor } from '../gmm';\n\nconst hmmParameterSpec = (states, transitionMode) => ({\n  states: {\n    required: true,\n    check: { min: 1 },\n  },\n  gaussians: {\n    required: true,\n    check: { min: 1 },\n  },\n  regularization: {\n    required: true,\n    check: ({ absolute, relative }) =>\n      (absolute && relative && absolute > 0 && relative > 0),\n  },\n  transitionMode: {\n    required: true,\n    check: ['ergodic', 'leftright'],\n  },\n  covarianceMode: {\n    required: true,\n    check: ['full', 'diagonal'],\n  },\n  prior: {\n    required: true,\n    check: m => transitionMode === 'leftright' || m.length === states,\n  },\n  transition: {\n    required: true,\n    check: m => (transitionMode === 'leftright' ?\n      m.length === 2 * states :\n      m.length === states),\n  },\n  xStates: {\n    required: true,\n    check: m => m.length === states,\n  },\n});\n\n\n/**\n * HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hmmPredictionPrototype = /** @lends withHMMPrediction */ {\n  forwardInitialized: false,\n  isHierarchical: false,\n\n  /**\n   * Setup the Model by allocating GMM predictors to each of the hidden states\n   * @return {HMMBaseModel} the model\n   * @private\n   */\n  setup() {\n    this.params.xStates = this.params.xStates.map(s => GMMPredictor(s).reset());\n    return this;\n  },\n\n  /**\n   * Reset the prediction process\n   * @return {HMMBaseModel} the model\n   */\n  reset() {\n    this.likelihoodBuffer.clear();\n    this.params.xStates.forEach((s) => { s.reset(); });\n    return this;\n  },\n\n  /**\n   * Compute the likelihood of an observation given the HMM's parameters\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}\n   */\n  likelihood(observation) {\n    const ct = (this.forwardInitialized) ?\n      this.updateForwardAlgorithm(observation) :\n      this.initializeForwardAlgorithm(observation);\n    this.updateAlphaWindow();\n    this.updateProgress();\n    return 1 / ct;\n  },\n\n  updateProgress() {\n    this.results.progress = 0.0;\n    for (let i = this.windowMinindex; i < this.windowMaxindex; i += 1) {\n      if (this.isHierarchical) {\n        this.results.progress += (this.alpha[i] + this.alpha1[i] + this.alpha2[i]) *\n          (i / this.windowNormalizationConstant);\n      } else {\n        this.results.progress += (this.alpha[i] * i) /\n          this.windowNormalizationConstant;\n      }\n    }\n    this.results.progress /= this.params.states - 1;\n  },\n\n  /**\n   * Update the state probabilities filtering window (for multiclass\n   * hierarchical HMM I think...)\n   * @private\n   */\n  updateAlphaWindow() {\n    this.results.likeliestState = 0;\n    // Get likeliest State\n    let bestAlpha = this.isHierarchical ?\n      (this.alpha[0] + this.alpha1[0]) :\n      this.alpha[0];\n    for (let i = 1; i < this.params.states; i += 1) {\n      if (this.isHierarchical) {\n        if ((this.alpha[i] + this.alpha1[i]) > bestAlpha) {\n          bestAlpha = this.alpha[i] + this.alpha1[i];\n          this.results.likeliestState = i;\n        }\n      } else if (this.alpha[i] > bestAlpha) {\n        bestAlpha = this.alpha[i];\n        this.results.likeliestState = i;\n      }\n    }\n\n    // Compute Window\n    this.windowMinindex = this.results.likeliestState - Math.floor(this.params.states / 2);\n    this.windowMaxindex = this.results.likeliestState + Math.floor(this.params.states / 2);\n    this.windowMinindex = (this.windowMinindex >= 0) ? this.windowMinindex : 0;\n    this.windowMaxindex = (this.windowMaxindex <= this.params.states) ?\n      this.windowMaxindex : this.params.states;\n    this.windowNormalizationConstant = 0.0;\n    for (let i = this.windowMinindex; i < this.windowMaxindex; i += 1) {\n      this.windowNormalizationConstant += this.isHierarchical ?\n        (this.alpha[i] + this.alpha1[i]) :\n        this.alpha[i];\n    }\n  },\n};\n\n/**\n * Bimodal (regression) HMM Prototype\n * @type {Object}\n * @ignore\n */\nconst hmmBimodalPredictionPrototype = /** @lends withHMMPrediction */ {\n  /**\n   * Estimate the output values corresponding to the input observation, by\n   * regression given the HMM's parameters. This method is called Hidden\n   * Mixture Regression (GMR).\n   *\n   * @param  {Array<Number>} inputObservation Observation on the input modality\n   * @return {Array<Number>} Output values (length = outputDimension)\n   */\n  regression(inputObservation) {\n    this.results.outputValues = Array(this.params.outputDimension).fill(0);\n    this.results.outputCovariance = Array(this.params.covarianceMode === 'full' ? this.params.outputDimension ** 2 : this.params.outputDimension).fill(0);\n\n    if (this.params.regressionEstimator === 'likeliest') {\n      this.params.xStates[this.results.likeliestState].predict(inputObservation);\n      this.results.outputValues =\n        this.params.xStates[this.results.likeliestState].results.outputValues;\n      return this.results.outputValues;\n    }\n\n    const clipMinState = (this.params.regressionEstimator === 'full') ?\n      0 : this.windowMinindex;\n    const clipMaxState = (this.params.regressionEstimator === 'full') ?\n      this.params.states : this.windowMaxindex;\n    let normalizationConstant = (this.params.regressionEstimator === 'full') ?\n      1 : this.windowNormalizationConstant;\n\n    if (normalizationConstant <= 0.0) normalizationConstant = 1;\n\n    // Compute Regression\n    for (let i = clipMinState; i < clipMaxState; i += 1) {\n      this.params.xStates[i].likelihood(inputObservation);\n      this.params.xStates[i].regression(inputObservation);\n      const tmpPredictedOutput = this.params.xStates[i].results.outputValues;\n      for (let d = 0; d < this.params.outputDimension; d += 1) {\n        if (this.isHierarchical) {\n          this.results.outputValues[d] +=\n            (this.alpha[i] + this.alpha1[i]) *\n            (tmpPredictedOutput[d] / normalizationConstant);\n          if (this.params.covarianceMode === 'full') {\n            for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n              this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n                (this.alpha[i] + this.alpha1[i]) *\n                (this.alpha[i] + this.alpha1[i]) *\n                (this.params.xStates[i].results\n                  .outputCovariance[(d * this.params.outputDimension) + d2] /\n                normalizationConstant);\n            }\n          } else {\n            this.results.outputCovariance[d] +=\n              (this.alpha[i] + this.alpha1[i]) *\n              (this.alpha[i] + this.alpha1[i]) *\n              (this.params.xStates[i].results.outputCovariance[d] /\n              normalizationConstant);\n          }\n        } else {\n          this.results.outputValues[d] += this.alpha[i] *\n            (tmpPredictedOutput[d] / normalizationConstant);\n          if (this.params.covarianceMode === 'full') {\n            for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n              this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n                (this.alpha[i] ** 2) *\n                (this.params.xStates[i].results\n                  .outputCovariance[(d * this.params.outputDimension) + d2] /\n                normalizationConstant);\n            }\n          } else {\n            this.results.outputCovariance[d] +=\n              ((this.alpha[i] ** 2) *\n              this.params.xStates[i].results.outputCovariance[d]) /\n              normalizationConstant;\n          }\n        }\n      }\n    }\n    return this.results.outputValues;\n  },\n};\n\n/**\n * Add HMM prediction capabilities to a single-class model. Mostly, this checks\n * the validity of the model parameters\n *\n * @todo validate gaussian components\n *\n * @param  {HMMBaseModel} o Source Model\n * @return {HMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  validateParameters('HMM', hmmParameterSpec(o.params.states, o.params.transitionMode), o.params);\n  return Object.assign(\n    o,\n    hmmPredictionPrototype,\n    o.params.bimodal ? hmmBimodalPredictionPrototype : {},\n    {\n      alpha: new Array(o.params.states).fill(0),\n      previous_alpha_: new Array(o.params.states).fill(0),\n    },\n  ).setup();\n}\n","import { isBaseModel } from '../core/model_base_mixin';\n\nconst DEFAULT_EXITPROBABILITY_LAST_STATE = 0.1;\n\n/**\n * Hierarchical HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hierarchicalHmmPredictionPrototype =\n/** @lends withHierarchicalHMMPrediction */\n{\n  /**\n   * Specificies if the forward algorithm has been initialized\n   * @type {Boolean}\n   * @private\n   */\n  forwardInitialized: false,\n\n  /**\n   * Setup the model (allocate transition parameters)\n   * @return {HierarchicalHMM} [description]\n   * @private\n   */\n  setup() {\n    const numClasses = this.size();\n    this.params.prior = new Array(numClasses).fill(1 / numClasses);\n    this.params.transition = Array.from(\n      new Array(numClasses),\n      () => new Array(numClasses).fill(1 / numClasses),\n    );\n    this.params.exitTransition = new Array(numClasses).fill(0.1);\n    Object.values(this.models).forEach((model) => {\n      const m = model;\n      m.isHierarchical = true;\n    });\n    this.updateExitProbabilities();\n    return this;\n  },\n\n  /**\n   * Update the exit probabilities of each sub-Markov model\n   * @param  {Array<Number>|undefined} [exitProbabilities=undefined] Vector of\n   * exit probabilities (optional)\n   * @private\n   */\n  updateExitProbabilities(exitProbabilities = undefined) {\n    const exitProb = (exitProbabilities !== undefined) ?\n      exitProbabilities :\n      new Array(this.params.states - 1).fill(0)\n        .concat([DEFAULT_EXITPROBABILITY_LAST_STATE]);\n    Object.keys(this.models).forEach((label) => {\n      this.models[label].params.exitProbabilities = exitProb.slice();\n    });\n  },\n\n  /**\n   * Reset the prediction process. This is particularly important for temporal\n   * models such as HMMs, that depends on previous observations.\n   */\n  reset() {\n    Object.values(this.models).forEach(m => m.reset());\n    this.results = {\n      labels: [],\n      instantLikelihoods: [],\n      smoothedLikelihoods: [],\n      smoothedLogLikelihoods: [],\n      smoothedNormalizedLikelihoods: [],\n      exitLikelihood: [],\n      likeliest: null,\n      classes: {},\n    };\n    if (this.params.bimodal) {\n      this.resetBimodal();\n    }\n    this.forwardInitialized = false;\n  },\n\n  /**\n   * Make a prediction from a new observation (updates the results member)\n   * @param  {Array<Number>} observation Observation vector\n   */\n  predict(observation) {\n    if (this.forwardInitialized) {\n      this.updateForwardAlgorithm(observation);\n    } else {\n      this.initializeForwardAlgorithm(observation);\n    }\n    Object.keys(this.models).sort().forEach((label) => {\n      const model = this.models[label];\n      model.updateAlphaWindow();\n      model.updateProgress();\n      model.updateResults(model.results.instantLikelihood);\n    });\n    this.updateResults();\n\n    if (this.params.bimodal) {\n      Object.values(this.models).forEach(m => m.regression(observation));\n\n      if (this.params.multiClassRegressionEstimator === 'likeliest') {\n        this.results.outputValues =\n          this.models[this.results.likeliest].results.outputValues;\n        this.results.outputCovariance =\n          this.models[this.results.likeliest].results.outputCovariance;\n      } else {\n        this.results.outputValues = new Array(this.outputDimension).fill(0);\n        this.results.outputCovariance =\n          new Array(this.params.covarianceMode === 'full' ?\n            this.outputDimension ** 2 :\n            this.outputDimension).fill(0);\n\n        let modelIndex = 0;\n        Object.values(this.models).forEach((model) => {\n          for (let d = 0; d < this.outputDimension; d += 1) {\n            this.results.outputValues[d] +=\n              this.results.smoothedNormalizedLikelihoods[modelIndex] *\n              model.second.results.outputValues[d];\n\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n                this.results.outputCovariance[(d * this.outputDimension) + d2] +=\n                  this.results.smoothedNormalizedLikelihoods[modelIndex] *\n                  model.results.outputCovariance[(d * this.outputDimension) + d2];\n              }\n            } else {\n              this.results.outputCovariance[d] +=\n                this.results.smoothedNormalizedLikelihoods[modelIndex] *\n                model.second.results.outputCovariance[d];\n            }\n          }\n          modelIndex += 1;\n        });\n      }\n    }\n  },\n\n  /**\n   * Initialize the forward algorithm of the hierarchical HMM\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  initializeForwardAlgorithm(observation) {\n    let normConst = 0;\n    let modelIndex = 0;\n    const classes = Object.keys(this.models).sort();\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      model.alpha1 = new Array(N).fill(0);\n      model.alpha2 = new Array(N).fill(0);\n\n      // Compute Emission probability and initialize on the first state of\n      // the primitive\n      if (model.params.transitionMode === 'ergodic') {\n        model.results.instantLikelihood = 0;\n        for (let i = 0; i < N; i += 1) {\n          model.alpha[i] = this.params.prior[modelIndex] *\n            model.params.prior[i] *\n            model.params.xStates[i].likelihood(observation);\n          model.results.instantLikelihood += model.alpha[i];\n        }\n      } else {\n        model.alpha[0] = this.params.prior[modelIndex] *\n          model.params.xStates[0].likelihood(observation);\n        [model.results.instantLikelihood] = model.alpha;\n      }\n      normConst += model.results.instantLikelihood;\n      modelIndex += 1;\n    });\n\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      for (let i = 0; i < N; i += 1) {\n        model.alpha[i] /= normConst;\n      }\n    });\n\n\n    this.frontierV1 = new Array(this.size).fill(0);\n    this.frontierV2 = new Array(this.size).fill(0);\n    this.forwardInitialized = true;\n  },\n\n  /**\n   * Update the forward algorithm of the hierarchical HMM\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  updateForwardAlgorithm(observation) {\n    let normConst = 0;\n\n    // Frontier Algorithm: variables\n    let tmp = 0;\n\n    // Intermediate variables: compute the sum of probabilities of making a\n    // transition to a new primitive\n    this.frontierV1 = this.likelihoodAlpha(1);\n    this.frontierV2 = this.likelihoodAlpha(2);\n\n    // FORWARD UPDATE\n    // --------------------------------------\n    let dstModelIndex = 0;\n    const classes = Object.keys(this.models).sort();\n    classes.forEach((label) => {\n      const dstModel = this.models[label];\n      const N = dstModel.params.states;\n\n      // 1) COMPUTE FRONTIER VARIABLE\n      //    --------------------------------------\n      // frontier variable : intermediate computation variable\n      const front = new Array(N).fill(0);\n\n      if (dstModel.params.transitionMode === 'ergodic') {\n        for (let k = 0; k < N; k += 1) {\n          for (let j = 0; j < N; j += 1) {\n            front[k] += (dstModel.params.transition[j][k] /\n              (1 - dstModel.params.exitProbabilities[j]))\n              * dstModel.alpha[j];\n          }\n\n          for (\n            let srcModelIndex = 0;\n            srcModelIndex < this.size();\n            srcModelIndex += 1\n          ) {\n            front[k] += dstModel.params.prior[k] * (\n              (this.frontierV1[srcModelIndex] *\n              this.params.transition[srcModelIndex][dstModelIndex]) +\n              (this.params.prior[dstModelIndex] *\n              this.frontierV2[srcModelIndex])\n            );\n          }\n        }\n      } else {\n        // k=0: first state of the primitive\n        front[0] = dstModel.params.transition[0] * dstModel.alpha[0];\n\n        for (\n          let srcModelIndex = 0;\n          srcModelIndex < this.size();\n          srcModelIndex += 1\n        ) {\n          front[0] += (this.frontierV1[srcModelIndex] *\n            this.params.transition[srcModelIndex][dstModelIndex]) +\n            (this.params.prior[dstModelIndex] *\n              this.frontierV2[srcModelIndex]);\n        }\n\n        // k>0: rest of the primitive\n        for (let k = 1; k < N; k += 1) {\n          front[k] += (dstModel.params.transition[k * 2] /\n            (1 - dstModel.params.exitProbabilities[k])) *\n            dstModel.alpha[k];\n          front[k] += (dstModel.params.transition[((k - 1) * 2) + 1] /\n            (1 - dstModel.params.exitProbabilities[k - 1])) *\n            dstModel.alpha[k - 1];\n        }\n\n        for (let k = 0; k < N; k += 1) {\n          dstModel.alpha[k] = 0;\n          dstModel.alpha1[k] = 0;\n          dstModel.alpha2[k] = 0;\n        }\n      }\n\n      // 2) UPDATE FORWARD VARIABLE\n      //    --------------------------------------\n      dstModel.results.exitLikelihood = 0.0;\n      dstModel.results.instantLikelihood = 0.0;\n\n      // end of the primitive: handle exit states\n      for (let k = 0; k < N; k += 1) {\n        tmp = dstModel.params.xStates[k].likelihood(observation) * front[k];\n        dstModel.alpha2[k] = this.params.exitTransition[dstModelIndex] *\n          dstModel.params.exitProbabilities[k] * tmp;\n        dstModel.alpha1[k] = (1 - this.params.exitTransition[dstModelIndex]) *\n          dstModel.params.exitProbabilities[k] * tmp;\n        dstModel.alpha[k] = (1 - dstModel.params.exitProbabilities[k]) * tmp;\n\n        dstModel.results.exitLikelihood += dstModel.alpha1[k] + dstModel.alpha2[k];\n        dstModel.results.instantLikelihood += dstModel.alpha[k] +\n          dstModel.alpha1[k] + dstModel.alpha2[k];\n        normConst += tmp;\n      }\n\n      dstModel.results.exitRatio = dstModel.results.exitLikelihood /\n        dstModel.results.instantLikelihood;\n\n      dstModelIndex += 1;\n    });\n\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      for (let k = 0; k < N; k += 1) {\n        model.alpha[k] /= normConst;\n        model.alpha1[k] /= normConst;\n        model.alpha2[k] /= normConst;\n      }\n    });\n  },\n\n  /**\n   * Compute the likelihood of a given probability.\n   * @param  {Number} exitNum Exit level number\n   * @return {Array<Number>}\n   */\n  likelihoodAlpha(exitNum) {\n    const likelihoodVector = new Array(this.size()).fill(0);\n    if (exitNum < 0) {\n      // Likelihood over all exit states\n      let modelIndex = 0;\n      Object.keys(this.models).sort().forEach((label) => {\n        const model = this.models[label];\n        likelihoodVector[modelIndex] = 0.0;\n        for (let k = 0; k < model.params.states; k += 1) {\n          likelihoodVector[modelIndex] += model.second.alpha[k] +\n            model.second.alpha1[k] +\n            model.second.alpha2[k];\n        }\n        modelIndex += 1;\n      });\n    } else {\n      // Likelihood for exit state \"exitNum\"\n      let modelIndex = 0;\n      Object.keys(this.models).sort().forEach((label) => {\n        const model = this.models[label];\n        likelihoodVector[modelIndex] = 0;\n        let { alpha } = model;\n        if (exitNum === 1) {\n          alpha = model.alpha1;\n        }\n        if (exitNum === 2) {\n          alpha = model.alpha2;\n        }\n        for (let k = 0; k < model.params.states; k += 1) {\n          likelihoodVector[modelIndex] += alpha[k];\n        }\n        modelIndex += 1;\n      });\n    }\n    return likelihoodVector;\n  },\n};\n\n/**\n * Add Hierarchical HMM prediction capabilities to a multi-class model.\n *\n * @todo algorithmic details\n * @todo validate parameters\n * @todo validate gaussian components\n *\n * @param  {MulticlassBaseModel} o Source Model\n * @return {HierarchicalHMM}\n *\n * @extends withMulticlassPrediction\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHierarchicalHMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  // validateParameters(\n  //   'Hierarchical HMM',\n  //   hierarchicalHmmParameterSpec(o.params.states, o.params.transitionMode),\n  //   o.params,\n  // );\n  return Object.assign(\n    o,\n    hierarchicalHmmPredictionPrototype,\n    {\n      // alpha: new Array(o.params.states).fill(0),\n      // previous_alpha_: new Array(o.params.states).fill(0),\n    },\n  ).setup();\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withEMTraining from '../core/em_training_mixin';\nimport withHMMBase from './hmm_base_mixin';\nimport withHMMTraining from './hmm_training_mixin';\nimport MulticlassModelBase from '../core/multiclass_mixin';\nimport withMulticlassTraining from '../core/multiclass_training_mixin';\nimport withAbtractPrediction from '../core/prediction_mixin';\nimport withHMMPrediction from './hmm_prediction_mixin';\nimport withMulticlassPrediction from '../core/multiclass_prediction_mixin';\nimport withHierarchicalHMMPrediction from './hierarchical_hmm_prediction_mixin';\n\n/**\n * HMM training configuration\n *\n * @typedef {Object} HMMConfiguration\n * @property {Number} states Number of Hidden States\n * @property {Number} gaussians Number of Gaussian components\n * @property {{ absolute: 1e-3, relative: 1e-2 }} regularization An object containing the\n * relative and absolute regularization values. Regularization is an offset value added to the\n * diagonal of covariance matrices for convergence and generalization. The two values represent:\n * - `relative`: the offset relative to the variance of the training data\n * - `absolute`: an absolute lower threshold for the offset\n * @property {String} covarianceMode Type of covariance matrix ('full' or 'diagonal')\n */\n\n/**\n * @typedef {Object} HMMParameters\n * @property {Boolean} bimodal Specifies if the model is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} states Number of hidden states in the Markov model\n * @property {Number} gaussians Number of components in the Gaussian mixture\n * observation distribution of each state\n * @property {String} transitionMode Transition matrix mode ('ergodic' or 'leftright')\n * @property {String} covarianceMode Covariance mode ('full' or 'diagonal')\n * @property {Array<Number>} mixtureCoeffs mixture coefficients ('weight' of\n * each gaussian component)\n * @property {Array<GaussianDistribution>} components Gaussian components\n */\n\n/**\n * Train a single-class HMM Model.\n *\n * @todo HMM details\n *\n * @param  {TrainingSet} trainingSet training set\n * @param  {HMMConfiguration} configuration Training configuration\n * @param  {ConvergenceCriteria} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {HMMParameters} Parameters of the trained HMM\n */\nexport function trainHMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const {\n    states,\n    gaussians,\n    regularization,\n    transitionMode,\n    covarianceMode,\n  } = configuration;\n  const model = withHMMTraining(\n    withEMTraining(\n      withHMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        ...configuration,\n      })),\n      convergenceCriteria,\n    ),\n    states,\n    gaussians,\n    regularization,\n    transitionMode,\n    covarianceMode,\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Train a multi-class HMM Model.\n *\n * @todo HMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {HMMConfiguration} configuration                   Training configuration\n * @param  {ConvergenceCriteria} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {HMMParameters} Parameters of the trained HMM\n */\nexport function trainMulticlassHMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withMulticlassTraining(\n    MulticlassModelBase({ inputDimension, outputDimension, ...configuration }),\n    ts => trainHMM(ts, configuration, convergenceCriteria),\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Create a HMM Predictor from a full set of parameters (generated by trainHMM).\n * @param {HMMParameters} params                       Model parameters\n * @param {number} [likelihoodWindow=1] Likelihoow window size\n * @function\n */\nexport function HMMPredictor(\n  params,\n  likelihoodWindow = 1,\n) {\n  const model = withHMMPrediction(withAbtractPrediction(\n    withHMMBase(ModelBase(params)),\n    likelihoodWindow,\n  ));\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass HMM Predictor from a full set of parameters\n * (generated by trainMulticlassHMM).\n * @param {HMMParameters} params                       Model parameters\n * @param {number} [likelihoodWindow=1] Likelihoow window size\n * @function\n */\nexport function MulticlassHMMPredictor(\n  params,\n  likelihoodWindow = 1,\n) {\n  const model = withMulticlassPrediction(MulticlassModelBase(params));\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = HMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass HMM Predictor from a full set of parameters\n * (generated by trainMulticlassHMM).\n * @param {HMMParameters} params Model parameters\n * @param {number} [likelihoodWindow=1] Likelihoow window size\n * @function\n */\nexport function HierarchicalHMMPredictor(\n  params,\n  likelihoodWindow = 1,\n) {\n  let model = MulticlassModelBase(params);\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = HMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model = withHierarchicalHMMPrediction(withMulticlassPrediction(model));\n  model.reset();\n  return model;\n}\n"],"names":["phrasePrototype","index","dim","Math","floor","Error","this","dimension","bimodal","inputDimension","inputData","length","outputData","concat","observation","push","slice","trim","outputDimension","mean","Array","fill","d","t","get","stddev","sqrt","minmax","from","min","Infinity","max","Phrase","columnNames","label","Object","assign","create","trainingSetPrototype","keys","phrases","phraseIndex","includes","toString","callback","forEach","phrase","p","undefined","filter","i","map","reduce","x","ts","TrainingSet","[object Object]","ll","sum","totalLength","ModelBase","isBaseModel","o","key","params","a","b","euclidean","v1","v2","x1","kMeansTrainingPrototype","trainingSet","empty","centers","clusters","trainingConfig","initialization","initializeClustersRandom","initializeClustersForgy","initClustersWithFirstPhrase","trainingNbIterations","maxIterations","previousCenters","updateCenters","meanClusterDistance","maxRelativeCenterVariation","k","l","relativeDistanceThreshold","getPhrase","indices","step","offset","c","random","pointsPerCluster","ppc","clustIdx","_","getFrame","numFramesPerCluster","frame","minDistance","clusterMembership","distance","withKMeansTraining","trainingConfiguration","model","trainKmeans","train","kEpsilonPseudoInverse","matrixPrototype","data","out","Matrix","ncols","nrows","j","mat","gaussJordanInverse","transp","transpose","prod","product","determinant","matrix","dst","newMat","n","abs","swapLines","ii","tmp","nc","baseGaussianPrototype","covarianceMode","covariance","inverseCovariance","allocateBimodal","covarianceDeterminant","inputLikelihood","euclideanDistance","exp","PI","Number","isNaN","regularization","covMatrix","inv","pinv","updateInverseCovarianceBimodal","dimension1","dimension2","gaussianEllipse","y","trace","eigenVal1","eigenVal2","width","height","angle","atan","tantheta","tan","updateInverseCovariance","bimodalGaussianPrototype","inverseCovarianceInput","inputObservation","covarianceDeterminantInput","prediction","e","f","covMatrixInput","d1","d2","invInput","updateOutputCovariance","outputCovariance","covarianceGS","covarianceSG","tmptmptmp","covarianceMod","GaussianDistribution","proto","dist","allocate","trainerPrototype","initTraining","logLikelihood","iterations","previousLogLikelihood","converged","updateTraining","pctChg","terminateTraining","iteration","logProb","previousLogProb","convergenceCriteria","minIterations","percentChange","withEMTraining","gmmBasePrototype","components","gaussians","mixtureCoeffs","beta","likelihood","componentLikelihood","mixtureComponent","normConst","regularize","currentRegularization","gmmBimodalPrototype","tmpOutputValues","results","outputValues","regression","withGMMBase","gmmTrainerPrototype","initParametersToDefault","standardDeviation","initMeansWithKMeans","initCovariances","updateInverseCovariances","dataStddev","normCoeffs","std","absolute","relative","kmeansParams","gmeans","factor","phraseIndices","E","tbase","log","pix","value","withGMMTraining","MulticlassBasePrototype","models","MulticlassModelBase","parameters","withMulticlassTraining","trainingFunction","labels","classes","getPhrasesOfClass","circularBufferPrototype","full","buffer","capacity","idx","CircularBuffer","clear","predictionBasePrototype","lw","likelihoodWindow","likelihoodBuffer","updateResults","instantLikelihood","bufSize","withAbtractPrediction","checkSpec","parameter","specification","constructor","validateParameters","values","attr","spec","required","check","transform","gmmParameterSpec","m","withGMMPrediction","MulticlassPredictionBasePrototype","setLikelihoodWindow","reset","resetBimodal","predict","labs","sort","normInstant","normSmoothed","maxLogLikelihood","lab","instantLikelihoods","smoothedLogLikelihoods","smoothedLikelihoods","likeliest","smoothedNormalizedLikelihoods","instantNormalizedLikelihoods","updateRegressionResults","MulticlassPredictionBimodalPrototype","multiClassRegressionEstimator","configuration","withMulticlassPrediction","trainGMM","trainMulticlassGMM","GMMPredictor","MulticlassGMMPredictor","hmmBasePrototype","transitionMode","states","alpha","prior","xStates","forwardInitialized","previousAlpha","transition","withHMMBase","TRANSITION_REGULARIZATION","hmmTrainerPrototype","initMeansCovariancesWithGMMEM","initMeansWithAllPhrases","initCovariancesFullyObserved","s","previousBeta","nbPhrases","size","gammaSequence","epsilonSequence","gammaSequenceperMixture","T","gammaSum","gammaSumPerMixture","baumWelchForwardBackward","baumWelchGammaSum","baumWelchEstimateMixtureCoefficients","baumWelchEstimateMeans","baumWelchEstimateCovariances","baumWelchEstimatePrior","baumWelchEstimateTransitions","normalizeTransitions","alphaSeq","betaSeq","setErgodic","setLeftRight","initCovariance","othermeans","gmmParams","normPrior","transitionNorm","ct","observationLikelihoods","currentPhrase","observationProbabilities","initializeForwardAlgorithm","baumWelchForwardUpdate","initializeBackwardAlgorithm","baumWelchBackwardUpdate","reverse","oo","normalizeMixtureCoeffs","sumprior","withHMMTraining","hmmParameterSpec","hmmPredictionPrototype","updateForwardAlgorithm","updateAlphaWindow","updateProgress","progress","windowMinindex","windowMaxindex","isHierarchical","alpha1","alpha2","windowNormalizationConstant","likeliestState","bestAlpha","hmmBimodalPredictionPrototype","regressionEstimator","clipMinState","clipMaxState","normalizationConstant","tmpPredictedOutput","withHMMPrediction","setup","DEFAULT_EXITPROBABILITY_LAST_STATE","hierarchicalHmmPredictionPrototype","numClasses","exitTransition","updateExitProbabilities","exitProbabilities","exitProb","modelIndex","second","N","frontierV1","frontierV2","likelihoodAlpha","dstModelIndex","dstModel","front","srcModelIndex","exitLikelihood","exitRatio","exitNum","likelihoodVector","withHierarchicalHMMPrediction","trainHMM","trainMulticlassHMM","HMMPredictor","MulticlassHMMPredictor","HierarchicalHMMPredictor"],"mappings":"AAIA,MAAMA,qBAOAC,EAAOC,MACY,iBAAVD,GAAsBE,KAAKC,MAAMH,KAAWA,QAC/C,IAAII,MAAM,mCAEdH,GAAOI,KAAKC,gBACR,IAAIF,MAAM,sCAEdC,KAAKE,QAAS,IACZN,EAAMI,KAAKG,eAAgB,IACzBR,GAASK,KAAKI,UAAUC,aACpB,IAAIN,MAAM,sCAEXC,KAAKI,UAAUT,GAAOC,MAE3BD,GAASK,KAAKM,WAAWD,aACrB,IAAIN,MAAM,sCAEXC,KAAKM,WAAWX,GAAOC,EAAMI,KAAKG,mBAEvCR,GAASK,KAAKK,aACV,IAAIN,MAAM,mCAEbC,KAAKI,UAAUT,SACZ,IAAII,MAAM,eAEXC,KAAKI,UAAUT,GAAOC,aAStBD,MACHA,GAASK,KAAKK,aACV,IAAIN,MAAM,sCAEdC,KAAKE,QACAF,KAAKI,UAAUT,GAAOY,OAAOP,KAAKM,WAAWX,IAE/CK,KAAKI,UAAUT,SASnBa,MAECA,EAAYH,SAAWL,KAAKC,gBACxB,IAAIF,MAAM,mCAGdC,KAAKE,cACFE,UAAUK,KAAKD,EAAYE,MAAM,EAAGV,KAAKG,sBACzCG,WAAWG,KAAKD,EAAYE,MAAMV,KAAKG,eAAgBH,KAAKC,kBAE5DG,UAAUK,KAAKD,QAGjBH,QAAU,aAUPG,OACHR,KAAKE,cACF,IAAIH,MAAM,0CAEdS,EAAYH,SAAWL,KAAKG,qBACxB,IAAIJ,MAAM,wCAGbK,UAAUK,KAAKD,QACfG,mBAUIH,OACJR,KAAKE,cACF,IAAIH,MAAM,0CAEdS,EAAYH,SAAWL,KAAKY,sBACxB,IAAIb,MAAM,wCAGbO,WAAWG,KAAKD,QAChBG,qBAOAN,OAAS,OACTD,kBACAE,iCAOAF,kBACAO,2BAOAL,mBACAK,qBASCE,EAAOC,MAAMd,KAAKC,WAAWc,KAAK,OACnC,IAAIC,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,KACrC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC/BD,IAAMhB,KAAKkB,IAAID,EAAGD,KAEpBA,IAAMhB,KAAKK,cAEXQ,6BASDM,EAASL,MAAMd,KAAKC,WAAWc,KAAK,GACpCF,EAAOb,KAAKa,WACb,IAAIG,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,KACrC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC7BD,KAAOhB,KAAKkB,IAAID,EAAGD,GAAKH,EAAKG,KAAOhB,KAAKkB,IAAID,EAAGD,GAAKH,EAAKG,MAE5DA,IAAMhB,KAAKK,SACXW,GAAKnB,KAAKuB,KAAKD,EAAOH,WAExBG,kBASDE,EAASP,MAAMQ,KACnBR,MAAMd,KAAKC,WACX,MAASsB,IAAMC,EAAAA,EAAUC,KAAMD,EAAAA,SAE5B,IAAIR,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC7BD,GAAGO,IAAM1B,KAAK0B,IAAIvB,KAAKkB,IAAID,EAAGD,GAAIK,EAAOL,GAAGO,OAC5CP,GAAGS,IAAM5B,KAAK4B,IAAIzB,KAAKkB,IAAID,EAAGD,GAAIK,EAAOL,GAAGS,YAGhDJ,UAQHrB,KAAKE,eACFG,OAASR,KAAK0B,IAAIvB,KAAKI,UAAUC,OAAQL,KAAKM,WAAWD,WA2BpE,SAAwBqB,QAAOvB,iBACZ,EADYS,kBAEX,EAFWe,cAGf,KAHeC,QAIrB,cAEF3B,EAAYE,EAAiBS,SAC5BiB,OAAOC,OACZD,OAAOE,OAAOrC,0BAEHkB,EAAkB,wDAInB,iDAIKe,GAAeb,MAAMb,GAAWc,KAAK,qUC9OxD,MAAMiB,oCAMKH,OAAOI,KAAKjC,KAAKkC,SAAS7B,uBAQV,IAAhBL,KAAKK,kBAQJ8B,UACJN,OAAOI,KAAKjC,KAAKkC,SAASE,SAASD,EAAYE,YAC1CrC,KAAKkC,QAAQC,EAAYE,YAE3B,cAUDC,UACCL,KAAKjC,KAAKkC,SAASK,QAASJ,MACxBnC,KAAKkC,QAAQC,GAAcA,EAAanC,KAAKkC,iBAYrDC,EAAaP,EAAmBY,SAC7BC,OAAgBC,IAAXF,EAAwBA,EAASd,uBAC1B1B,KAAKG,+BACJH,KAAKY,4BACTZ,KAAK2B,uBACAe,IAAVd,EAAuBA,EAAQO,EAAYE,yBAEhDH,QAAQC,GAAeM,EACrBA,UAOFN,UACEnC,KAAKkC,QAAQC,gBAOVP,QACLM,QAAUL,OAAOI,KAAKjC,KAAKkC,SAC7BS,OAAOC,GAAK5C,KAAKkC,QAAQU,GAAGhB,QAAUA,GACtCiB,IAAID,KAAQA,EAAG5C,KAAKkC,QAAQU,MAC5BE,OAAO,CAACC,EAAGN,gBAAYM,EAAMN,qBAO3BP,8BAQWN,SACVoB,EAAKC,YAAYjD,eACpBkC,QAAUL,OAAOI,KAAKjC,KAAKkC,SAC3BS,OAAOC,GAAK5C,KAAKkC,QAAQU,GAAGhB,QAAUA,GACtCiB,IAAID,KAAQM,CAACN,GAAI5C,KAAKkC,QAAQU,MAC9BE,OAAO,CAACC,EAAGN,gBAAYM,EAAMN,OACzBO,mBAQAnB,OAAOI,KAAKjC,KAAKkC,SACrBW,IAAID,GAAK5C,KAAKkC,QAAQU,GAAGhB,OACzBkB,OAAO,CAACK,EAAIJ,IAAOI,EAAGf,SAASW,GAAKI,EAAKA,EAAG5C,QAAQwC,0BAQhDlB,OAAOI,KAAKjC,KAAKkC,uBAQlBkB,EAAMtC,MAAMd,KAAKC,WAAWc,KAAK,OACnCsC,EAAc,gBACXpB,KAAKjC,KAAKkC,SAASK,QAASK,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKkC,QAAQU,GAAGvC,OAAQY,GAAK,IAC3CD,IAAMhB,KAAKkC,QAAQU,GAAG1B,IAAID,EAAGD,MAGtBhB,KAAKkC,QAAQU,GAAGvC,SAG1B+C,EAAIP,IAAIE,GAAKA,EAAIM,8BAQlBlC,EAASL,MAAMd,KAAKC,WAAWc,KAAK,GACpCF,EAAOb,KAAKa,WACdwC,EAAc,gBACXpB,KAAKjC,KAAKkC,SAASK,QAASK,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKkC,QAAQU,GAAGvC,OAAQY,GAAK,IACxCD,KAAOhB,KAAKkC,QAAQU,GAAG1B,IAAID,EAAGD,GAAKH,EAAKG,KAAO,KAG3ChB,KAAKkC,QAAQU,GAAGvC,SAG1Bc,EAAO0B,IAAIE,GAAKlD,KAAKuB,KAAK2B,EAAIM,oBAQ/BhC,EAASP,MAAMQ,KACnBR,MAAMd,KAAKC,WACX,MAASsB,IAAMC,EAAAA,EAAUC,KAAMD,EAAAA,mBAE1BS,KAAKjC,KAAKkC,SAASK,QAASK,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKkC,QAAQU,GAAGvC,OAAQY,GAAK,IACxCD,GAAGO,KAAO1B,KAAK0B,IAAIF,EAAOL,GAAGO,IAAKvB,KAAKkC,QAAQU,GAAG1B,IAAID,EAAGD,MACzDA,GAAGS,KAAO5B,KAAK4B,IAAIJ,EAAOL,GAAGS,IAAKzB,KAAKkC,QAAQU,GAAG1B,IAAID,EAAGD,MAI/DK,IAkCX,SAAwB4B,aAAY9C,iBACjB,EADiBS,kBAEhB,EAFgBe,cAGpB,gBAER1B,EAAYE,EAAiBS,SAC5BiB,OAAOC,OACZD,OAAOE,OAAOC,+BAEHpB,EAAkB,6DAIde,GAAeb,MAAMb,GAAWc,KAAK,iBC3NzC,SAASuC,iBAAUnD,iBAAAS,2BAK1B6B,gFACCA,EAAEvC,eACFuC,EAAEtC,sBACFsC,EAAE7B,uBACF6B,EAAExC,8BAGFwC,wBAEM7B,EAAkB,+BAGlBT,gCAGAS,0BAGAT,EAAiBS,MAWzB,SAAS2C,YAAYC,OACrB3B,OAAOI,KAAKuB,GAAGpB,SAAS,UAAW,OAAO,SACjC,UAAW,iBAAkB,kBAAmB,aAClDS,IAAIY,GAAO5B,OAAOI,KAAKuB,EAAEE,QAAQtB,SAASqB,IACnDX,OAAO,CAACa,EAAGC,IAAMD,GAAKC,GAAG,GCzCf,SAASC,UAAUC,EAAIC,UAC7BlE,KAAKuB,KAAK0C,EACdjB,IAAI,CAACmB,EAAIpB,KAAOoB,EAAKD,EAAGnB,KAAO,GAC/BE,OAAO,CAACa,EAAGZ,IAAOY,EAAIZ,EAAI,UCNzBkB,+BACEC,OACCA,GAAeA,EAAYC,cACxB,IAAIpE,MAAM,qCAGb2D,OAAOU,QAAUtD,MAAMQ,KAC1BR,MAAMd,KAAK0D,OAAOW,UAClB,IAAM,IAAIvD,MAAMd,KAAK0D,OAAOzD,WAAWc,KAAK,IAMH,WAAvCf,KAAKsE,eAAeC,oBACjBC,yBAAyBN,QACzB,GAA2C,UAAvClE,KAAKsE,eAAeC,oBACxBE,wBAAwBP,OACxB,CAAA,GAA2C,SAAvClE,KAAKsE,eAAeC,qBAGvB,IAAIxE,MAAM,4EAFX2E,4BAA4BR,OAMjC,IAAIS,EAAuB,EAC3BA,EAAuB3E,KAAKsE,eAAeM,cAC3CD,GAAwB,EACxB,OACME,EAAkB7E,KAAK0D,OAAOU,aAE/BU,cAAcD,EAAiBX,OAEhCa,EAAsB,EACtBC,EAA6B,MAC5B,IAAIC,EAAI,EAAGA,EAAIjF,KAAK0D,OAAOW,SAAUY,GAAK,EAAG,KAC3C,IAAIC,EAAI,EAAGA,EAAIlF,KAAK0D,OAAOW,SAAUa,GAAK,EACzCD,IAAMC,OACerB,UACrB7D,KAAK0D,OAAOU,QAAQa,GACpBjF,KAAK0D,OAAOU,QAAQc,OAIGrF,KAAK4B,IAChCoC,UACEgB,EAAgBI,GAChBjF,KAAK0D,OAAOU,QAAQa,IAEtBD,SAGmBhF,KAAK0D,OAAOW,UAAYrE,KAAK0D,OAAOW,SAAW,MACxCrE,KAAK0D,OAAOW,aACZU,GACG/E,KAAKsE,eAAea,0BAA2B,aAE3EnF,KAAK0D,oCAGcQ,SACpB1B,EAAS0B,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDC,EAAOzF,KAAKC,MAAM0C,EAAOnC,OAASL,KAAK0D,OAAOW,cAEhDkB,EAAS,MACR,IAAIC,EAAI,EAAGA,EAAIxF,KAAK0D,OAAOW,SAAUmB,GAAK,EAAG,MAC3C9B,OAAOU,QAAQoB,GAAK,IAAI1E,MAAMd,KAAK0D,OAAOzD,WAAWc,KAAK,OAC1D,IAAIE,EAAI,EAAGA,EAAIqE,EAAMrE,GAAK,MACxB,IAAID,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOU,QAAQoB,GAAGxE,IAAMwB,EAAOtB,IAAIqE,EAAStE,EAAGD,GAAKsE,KAGnDA,6BAIWpB,SACjB1B,EAAS0B,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDA,EAAUvE,MAAMQ,KACpBR,MAAM0B,EAAOnC,QACb,IAAMR,KAAKC,MAAMD,KAAK4F,SAAWzF,KAAK0D,OAAOW,WAEzCqB,EAAmBL,EAAQvC,OAC/B,CAAC6C,EAAK/C,WACEH,EAAIkD,WACR/C,IAAM,EACDH,GAET3B,MAAMd,KAAK0D,OAAOW,UAAUtD,KAAK,QAE9B,IAAI6B,EAAI,EAAGA,EAAIyC,EAAQhF,OAAQuC,GAAK,EAAG,OACpCgD,EAAWP,EAAQzC,OACpB,IAAI5B,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOU,QAAQwB,GAAU5E,IAAMwB,EAAOtB,IAAI0B,EAAG5B,QAGjD0C,OAAOU,QAAQ7B,QAAQ,CAACsD,EAAGL,UACzB9B,OAAOU,QAAQoB,GAAKxF,KAAK0D,OAAOU,QAAQoB,GAC1C3C,IAAIE,GAAKA,EAAI2C,EAAiBF,+BAIbtB,SAChB1B,EAAS0B,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDA,EAAUvE,MAAMQ,KACpBR,MAAMd,KAAK0D,OAAOW,UAClB,IAAMxE,KAAKC,MAAMD,KAAK4F,SAAWjD,EAAOnC,cAErCqD,OAAOU,QAAUiB,EAAQxC,IAAID,GAAKJ,EAAOsD,SAASlD,mBAG3CiC,EAAiBX,QACxBR,OAAOU,QAAUtD,MAAMQ,KAAKR,MAAMd,KAAK0D,OAAOW,UAAW,IAC5D,IAAIvD,MAAMd,KAAK0D,OAAOzD,WAAWc,KAAK,UAClCgF,EAAsBjF,MAAMd,KAAK0D,OAAOW,UAAUtD,KAAK,KACjDwB,QAASC,QACd,IAAIvB,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,EAAG,OACnC+E,EAAQxD,EAAOsD,SAAS7E,OAC1BgF,EAAcpC,UAAUmC,EAAOnB,EAAgB,IAC/CqB,EAAoB,MACnB,IAAIjB,EAAI,EAAGA,EAAIjF,KAAK0D,OAAOW,SAAUY,GAAK,EAAG,OAC1CkB,EAAWtC,UACfmC,EACAnB,EAAgBI,GAChBjF,KAAK0D,OAAOzD,WAEVkG,EAAWF,MACOhB,IACNkB,KAGED,IAAsB,MACrC,IAAIlF,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOU,QAAQ8B,GAAmBlF,IAAMwB,EAAOtB,IAAID,EAAGD,UAI5D,IAAIiE,EAAI,EAAGA,EAAIjF,KAAK0D,OAAOW,SAAUY,GAAK,KACzCc,EAAoBd,GAAK,MACtB,IAAIjE,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOU,QAAQa,GAAGjE,IAAM+E,EAAoBd,KAO3D,SAAwBmB,mBACtB5C,EACAa,EACAgC,UAEK9C,YAAYC,SACT,IAAIzD,MAAM,qGAEZuE,EAAiBzC,OAAOC,uBACZ,mCACW,mBACZ,gBACA,KACduE,GACGC,EAAQzE,OAAOC,OAAO0B,EAAGS,qDAGzBP,OAAOW,SAAWA,EACjBiC,EC3JT,SAAwBC,YACtBrC,EACAG,EACAC,SAEMnE,eAAEA,EAAFS,gBAAkBA,GAAoBsD,SAC9BkC,mBACZ9C,gDAIAe,EACAC,GAEWkC,MAAMtC,GC1BrB,MAAMuC,sBAAwB,KAWxBC,8BAMK1G,KAAK2G,KAAK7D,OAAO,CAACa,EAAGC,IAAMD,EAAIC,EAAG,sBAQnCgD,EAAMC,OAAO7G,KAAK8G,MAAO9G,KAAK+G,WAC/B,IAAInE,EAAI,EAAGA,EAAI5C,KAAK8G,MAAOlE,GAAK,MAC9B,IAAIoE,EAAI,EAAGA,EAAIhH,KAAK+G,MAAOC,GAAK,IAC/BL,KAAM/D,EAAI5C,KAAK+G,MAASC,GAAKhH,KAAK2G,KAAMK,EAAIhH,KAAK8G,MAASlE,UAG3DgE,WAQDK,MACFjH,KAAK8G,QAAUG,EAAIF,YACf,IAAIhH,MAAM,6CAEZ6G,EAAMC,OAAO7G,KAAK+G,MAAOE,EAAIH,WAC9B,IAAIlE,EAAI,EAAGA,EAAI5C,KAAK+G,MAAOnE,GAAK,MAC9B,IAAIoE,EAAI,EAAGA,EAAIC,EAAIH,MAAOE,GAAK,EAAG,GACjCL,KAAM/D,EAAIqE,EAAIH,MAASE,GAAK,MAC3B,IAAI/B,EAAI,EAAGA,EAAIjF,KAAK8G,MAAO7B,GAAK,IAC/B0B,KAAM/D,EAAIqE,EAAIH,MAASE,IACzBhH,KAAK2G,KAAM/D,EAAI5C,KAAK8G,MAAS7B,GAAKgC,EAAIN,KAAM1B,EAAIgC,EAAIH,MAASE,UAI9DJ,aASH5G,KAAK+G,QAAU/G,KAAK8G,aACf9G,KAAKkH,2BAGRC,EAASnH,KAAKoH,eAChBpH,KAAK+G,OAAS/G,KAAK8G,MAAO,OACtBO,EAAOF,EAAOG,QAAQtH,OACtBuH,YAAEA,EAAaC,OAAQC,GAAQJ,EAAKH,4BACjCK,YAAAA,EAAaC,OAAQC,EAAIH,QAAQH,UAEtCE,EAAOrH,KAAKsH,QAAQH,IACpBI,YAAEA,EAAaC,OAAQC,GAAQJ,EAAKH,4BACjCK,YAAAA,EAAaC,OAAQL,EAAOG,QAAQG,6BASzCzH,KAAK+G,QAAU/G,KAAK8G,YAChB,IAAI/G,MAAM,+DAEdwH,EAAc,QACZN,EAAMJ,OAAO7G,KAAK+G,MAAoB,EAAb/G,KAAK8G,OAC9BY,EAASb,OAAO7G,KAAK+G,MAAoB,EAAb/G,KAAK8G,OACjCa,EAAI3H,KAAK+G,UAGV,IAAInE,EAAI,EAAGA,EAAI+E,EAAG/E,GAAK,EAAG,KACxB,IAAIoE,EAAI,EAAGA,EAAIW,EAAGX,GAAK,IACtBL,KAAU,EAAJ/D,EAAQ+E,EAAKX,GAAKhH,KAAK2G,KAAM/D,EAAI+E,EAAKX,KAE9CL,KAAU,EAAJ/D,EAAQ+E,EAAKA,EAAI/E,GAAK,MAG7B,IAAIqC,EAAI,EAAGA,EAAI0C,EAAG1C,GAAK,EAAG,KACzBrC,EAAIqC,OACDpF,KAAK+H,IAAIX,EAAIN,KAAU,EAAJ/D,EAAQ+E,EAAK1C,IArGf,aAsGjB,KACK0C,QACF,IAAI5H,MAAM,4BAGLkH,EAAIN,KAAU,EAAJ/D,EAAQ+E,EAAK1C,GAGlCrC,IAAMqC,KACJ4C,UAAUjF,EAAGqC,KAGZ0B,KAAOM,EAAIN,KAAKjG,YAElB,IAAIsG,EAAI,EAAGA,EAAI,EAAIW,EAAGX,GAAK,IACvBL,KAAU,EAAJ1B,EAAQ0C,EAAKX,IAAMC,EAAIN,KAAU,EAAJ1B,EAAQ0C,EAAK1C,OAEpD,IAAI6C,EAAK,EAAGA,EAAKH,EAAGG,GAAM,KACzBA,IAAO7C,MACJ,IAAI+B,EAAI,EAAGA,EAAI,EAAIW,EAAGX,GAAK,IACvBL,KAAW,EAALmB,EAASH,EAAKX,IACvBC,EAAIN,KAAW,EAALmB,EAASH,EAAK1C,GACxByC,EAAOf,KAAU,EAAJ1B,EAAQ0C,EAAKX,KAIhCL,KAAOe,EAAOf,KAAKjG,cAGnB+G,EAAMZ,OAAO7G,KAAK+G,MAAO/G,KAAK8G,WAC/B,IAAIlE,EAAI,EAAGA,EAAI+E,EAAG/E,GAAK,MACrB,IAAIoE,EAAI,EAAGA,EAAIW,EAAGX,GAAK,IACtBL,KAAM/D,EAAI+E,EAAKX,GAAKC,EAAIN,KAAU,EAAJ/D,EAAQ+E,EAAKA,EAAIX,UAG9CO,YAAAA,EAAaC,OAAQC,cAStB7E,EAAGoE,OACN,IAAI/B,EAAI,EAAGA,EAAIjF,KAAK8G,MAAO7B,GAAK,EAAG,OAChC8C,EAAM/H,KAAK2G,KAAM/D,EAAI5C,KAAK8G,MAAS7B,QACpC0B,KAAM/D,EAAI5C,KAAK8G,MAAS7B,GAAKjF,KAAK2G,KAAMK,EAAIhH,KAAK8G,MAAS7B,QAC1D0B,KAAMK,EAAIhH,KAAK8G,MAAS7B,GAAK8C,gBAU1BnF,EAAGoE,OACR,IAAI/B,EAAI,EAAGA,EAAIjF,KAAK+G,MAAO9B,GAAK,EAAG,OAChC8C,EAAM/H,KAAK2G,KAAM1B,EAAIjF,KAAK8G,MAASlE,QACpC+D,KAAM1B,EAAIjF,KAAK8G,MAASlE,GAAK5C,KAAK2G,KAAM1B,EAAIjF,KAAK8G,MAASE,QAC1DL,KAAM1B,EAAIjF,KAAK8G,MAASE,GAAKe,KAiBxC,SAAwBlB,OAAOE,EAAQ,EAAGD,GAAQ,SAC1CkB,EAAKlB,EAAQ,EAAIC,EAAQD,SACxBjF,OAAOC,OACZD,OAAOE,OAAO2E,gCAGLsB,OACDlH,MAAMiG,EAAQiB,GAAIjH,KAAK,KC5KnC,MAAMkH,uCAMGpH,KAAO,IAAIC,MAAMd,KAAKC,WAAWc,KAAK,GACf,SAAxBf,KAAKkI,qBACFC,WAAa,IAAIrH,MAAMd,KAAKC,WAAa,GAAGc,KAAK,QACjDqH,kBAAoB,IAAItH,MAAMd,KAAKC,WAAa,GAAGc,KAAK,UAExDoH,WAAa,IAAIrH,MAAMd,KAAKC,WAAWc,KAAK,QAC5CqH,kBAAoB,IAAItH,MAAMd,KAAKC,WAAWc,KAAK,IAEtDf,KAAKE,cACFmI,8BAcE7H,MAC0B,IAA/BR,KAAKsI,4BACD,IAAIvI,MAAM,0CAEdC,KAAKE,SAAWM,EAAYH,SAAWL,KAAKG,sBACvCH,KAAKuI,gBAAgB/H,MAE1BA,EAAYH,SAAWL,KAAKC,gBACxB,IAAIF,2EAA2EC,KAAKC,sBAAsBO,EAAYH,gBAG1HmI,EAAoB,KACI,SAAxBxI,KAAKkI,mBACF,IAAIhD,EAAI,EAAGA,EAAIlF,KAAKC,UAAWiF,GAAK,EAAG,KACtC6C,EAAM,MACL,IAAI9C,EAAI,EAAGA,EAAIjF,KAAKC,UAAWgF,GAAK,KAChCjF,KAAKoI,kBAAmBlD,EAAIlF,KAAKC,UAAagF,IAClDzE,EAAYyE,GAAKjF,KAAKa,KAAKoE,QAEVzE,EAAY0E,GAAKlF,KAAKa,KAAKqE,IAAM6C,WAGpD,IAAI7C,EAAI,EAAGA,EAAIlF,KAAKC,UAAWiF,GAAK,KAClBlF,KAAKoI,kBAAkBlD,IACzC1E,EAAY0E,GAAKlF,KAAKa,KAAKqE,KAC3B1E,EAAY0E,GAAKlF,KAAKa,KAAKqE,QAI9BzC,EAAI5C,KAAK4I,KAAK,GAAMD,GACtB3I,KAAKuB,KAAKpB,KAAKsI,uBAA0B,EAAIzI,KAAK6I,KAAO1I,KAAKC,kBAE5DwC,EAAI,QAAUkG,OAAOC,MAAMnG,IAAM5C,KAAK+H,IAAInF,KAAQjB,EAAAA,OAChD,QAGCiB,cAUEoG,MACmB,SAAxB7I,KAAKkI,mBACF,IAAIlH,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,OAClCmH,WAAYnH,EAAIhB,KAAKC,UAAae,IAAM6H,EAAe7H,YAGzD,IAAIA,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,OAClCmH,WAAWnH,IAAM6H,EAAe7H,iCAUb,SAAxBhB,KAAKkI,eAA2B,OAC5BY,EAAYjC,OAAO7G,KAAKC,UAAWD,KAAKC,aAEpC0G,KAAO3G,KAAKmI,WAAWzH,cAC3BqI,EAAMD,EAAUE,YACjBV,sBAAwBS,EAAIxB,iBAC5Ba,kBAAoBW,EAAIvB,OAAOb,SAC/B,MACA2B,sBAAwB,MACxB,IAAItH,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,IACtChB,KAAKmI,WAAWnH,IAAM,QAClB,IAAIjB,MAAM,8BAEbqI,kBAAkBpH,GAAK,EAAIhB,KAAKmI,WAAWnH,QAC3CsH,uBAAyBtI,KAAKmI,WAAWnH,IAG9ChB,KAAKE,cACF+I,4CAWCC,EAAYC,MAChBD,GAAclJ,KAAKC,WAAakJ,GAAcnJ,KAAKC,gBAC/C,IAAIF,MAAM,iCAGZqJ,KACD,IACA,QACI,SACC,QACD,OAQLzF,EACAC,EACA4B,IARYzC,EAAI/C,KAAKa,KAAKqI,KACdG,EAAIrJ,KAAKa,KAAKsI,GAQF,SAAxBnJ,KAAKkI,kBACHlI,KAAKmI,WAAYe,EAAalJ,KAAKC,UAAaiJ,KAChDlJ,KAAKmI,WAAYe,EAAalJ,KAAKC,UAAakJ,KAChDnJ,KAAKmI,WAAYgB,EAAanJ,KAAKC,UAAakJ,OAEhDnJ,KAAKmI,WAAWe,KAChB,IACAlJ,KAAKmI,WAAWgB,UAIhBG,EAAQ3F,EAAI6B,EACZ+B,EAAe5D,EAAI6B,EAAM5B,EAAIA,EAC7B2F,EAAY,IAAOD,EAAQzJ,KAAKuB,KAAMkI,GAAS,EAAM,EAAI/B,IACzDiC,EAAY,IAAOF,EAAQzJ,KAAKuB,KAAMkI,GAAS,EAAM,EAAI/B,aAC/CkC,MAAQ5J,KAAKuB,KAAK,MAAQmI,KAC1BG,OAAS7J,KAAKuB,KAAK,MAAQoI,KAC3BG,MAAQ9J,KAAK+J,KAAKhG,GAAK2F,EAAY/D,IAC/CmD,OAAOC,MAAMQ,EAAgBO,WACfA,MAAQ9J,KAAK6I,GAAK,GAG7BU,eAYGA,EAAiBF,EAAYC,MACnCD,GAAclJ,KAAKC,WAAakJ,GAAcnJ,KAAKC,gBAC/C,IAAIF,MAAM,gCAGbc,KAAKqI,GAAcE,EAAgBrG,OACnClC,KAAKsI,GAAcC,EAAgBC,QAElCE,EAAaH,EAAgBK,MAAQL,EAAgBK,MAAS,MAC9DD,EAAaJ,EAAgBM,OAASN,EAAgBM,OAAU,MAChEG,EAAWhK,KAAKiK,IAAIV,EAAgBO,OACpC/F,GAAM2F,EAAYC,GAAaK,GAAcA,GAAY,EAAK,GAC9DrE,EAAI+D,EAAa3F,EAAIiG,EACrBlG,EAAI6F,EAAa5F,EAAIiG,EAEC,SAAxB7J,KAAKkI,qBACFC,WAAYe,EAAalJ,KAAKC,UAAaiJ,GAAcvF,OACzDwE,WAAYe,EAAalJ,KAAKC,UAAakJ,GAAcvF,OACzDuE,WAAYgB,EAAanJ,KAAKC,UAAaiJ,GAActF,OACzDuE,WAAYgB,EAAanJ,KAAKC,UAAakJ,GAAc3D,SAEzD2C,WAAWe,GAAcvF,OACzBwE,WAAWgB,GAAc3D,QAE3BuE,4BAqBHC,4CAM0B,SAAxBhK,KAAKkI,oBACF+B,uBAAyB,IAAInJ,MAAMd,KAAKG,gBAAkB,GAAGY,KAAK,QAElEkJ,uBAAyB,IAAInJ,MAAMd,KAAKG,gBAAgBY,KAAK,oBAWtDmJ,MAC0B,IAApClK,KAAKmK,iCACD,IAAIpK,MAAM,6DAGdyI,EAAoB,KACI,SAAxBxI,KAAKkI,mBACF,IAAIhD,EAAI,EAAGA,EAAIlF,KAAKG,eAAgB+E,GAAK,EAAG,KAC3C6C,EAAM,MACL,IAAI9C,EAAI,EAAGA,EAAIjF,KAAKG,eAAgB8E,GAAK,KACrCjF,KAAKiK,uBAAwB/E,EAAIlF,KAAKG,eAAkB8E,IAC5DiF,EAAiBjF,GAAKjF,KAAKa,KAAKoE,QAEfiF,EAAiBhF,GAAKlF,KAAKa,KAAKqE,IAAM6C,WAGzD,IAAI7C,EAAI,EAAGA,EAAIlF,KAAKG,eAAgB+E,GAAK,KACvBlF,KAAKoI,kBAAkBlD,IACzCgF,EAAiBhF,GAAKlF,KAAKa,KAAKqE,KAChCgF,EAAiBhF,GAAKlF,KAAKa,KAAKqE,QAInCzC,EAAI5C,KAAK4I,KAAK,GAAMD,GACb3I,KAAKuB,KAAKpB,KAAKmK,4BACR,EAAItK,KAAK6I,KAAO1I,KAAKG,uBAEnCsC,EAAI,QAAUkG,OAAOC,MAAMnG,IAAM5C,KAAK+H,IAAInF,KAAQjB,EAAAA,KAAUiB,EAAI,QAE7DA,cAYEyH,SACHtJ,EAAkBZ,KAAKC,UAAYD,KAAKG,eACxCiK,EAAatJ,MAAMF,GAAiBG,KAAK,MAEnB,SAAxBf,KAAKkI,mBACF,IAAIlH,EAAI,EAAGA,EAAIJ,EAAiBI,GAAK,EAAG,GAChCA,GAAKhB,KAAKa,KAAKb,KAAKG,eAAiBa,OAC3C,IAAIqJ,EAAI,EAAGA,EAAIrK,KAAKG,eAAgBkK,GAAK,EAAG,KAC3CtC,EAAM,MACL,IAAIuC,EAAI,EAAGA,EAAItK,KAAKG,eAAgBmK,GAAK,KACrCtK,KAAKiK,uBAAwBI,EAAIrK,KAAKG,eAAkBmK,IAC5DJ,EAAiBI,GAAKtK,KAAKa,KAAKyJ,MAE1BtJ,IAAM+G,EACf/H,KAAKmI,YAAanH,EAAIhB,KAAKG,gBAAkBH,KAAKC,UAAaoK,aAIhE,IAAIrJ,EAAI,EAAGA,EAAIJ,EAAiBI,GAAK,IAC7BA,GAAKhB,KAAKa,KAAKb,KAAKG,eAAiBa,UAG7CoJ,uCAQqB,SAAxBpK,KAAKkI,eAA2B,OAC5BqC,EAAiB1D,OAAO7G,KAAKG,eAAgBH,KAAKG,oBACnD,IAAIqK,EAAK,EAAGA,EAAKxK,KAAKG,eAAgBqK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKzK,KAAKG,eAAgBsK,GAAM,IAChC9D,KAAM6D,EAAKxK,KAAKG,eAAkBsK,GAC/CzK,KAAKmI,WAAYqC,EAAKxK,KAAKC,UAAawK,SAGxCC,EAAWH,EAAevB,YAC3BmB,2BAA6BO,EAASnD,iBACtC0C,uBAAyBS,EAASlD,OAAOb,SACzC,MACAwD,2BAA6B,MAC7B,IAAInJ,EAAI,EAAGA,EAAIhB,KAAKG,eAAgBa,GAAK,EAAG,IAC3ChB,KAAKmI,WAAWnH,IAAM,QAClB,IAAIjB,MAAM,8BAEbkK,uBAAuBjJ,GAAK,EAAIhB,KAAKmI,WAAWnH,QAChDmJ,4BAA8BnK,KAAKmI,WAAWnH,SAGlD2J,sDAQuB,aAAxB3K,KAAKkI,gCACF0C,iBAAmB5K,KAAKmI,WAAWzH,MAAM,EAAGV,KAAKG,uBAKlDoK,EAAiB1D,OAAO7G,KAAKG,eAAgBH,KAAKG,oBACnD,IAAIqK,EAAK,EAAGA,EAAKxK,KAAKG,eAAgBqK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKzK,KAAKG,eAAgBsK,GAAM,IAChC9D,KAAM6D,EAAKxK,KAAKG,eAAkBsK,GAC/CzK,KAAKmI,WAAYqC,EAAKxK,KAAKC,UAAawK,SAGxC1B,EAAMwB,EAAevB,OACrB6B,EAAehE,OAAO7G,KAAKG,eAAgBH,KAAKY,qBACjD,IAAI4J,EAAK,EAAGA,EAAKxK,KAAKG,eAAgBqK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKzK,KAAKY,gBAAiB6J,GAAM,IACnC9D,KAAM6D,EAAKxK,KAAKY,gBAAmB6J,GAC9CzK,KAAKmI,WAAYqC,EAAKxK,KAAKC,UAAaD,KAAKG,eAAiBsK,SAG9DK,EAAejE,OAAO7G,KAAKY,gBAAiBZ,KAAKG,oBAClD,IAAIqK,EAAK,EAAGA,EAAKxK,KAAKY,gBAAiB4J,GAAM,MAC3C,IAAIC,EAAK,EAAGA,EAAKzK,KAAKG,eAAgBsK,GAAM,IAClC9D,KAAM6D,EAAKxK,KAAKG,eAAkBsK,GAC7CzK,KAAKmI,YAAanI,KAAKG,eAAiBqK,GAAMxK,KAAKC,UAAawK,SAGhEM,EAAYhC,EAAIvB,OAAOF,QAAQuD,GAC/BG,EAAgBF,EAAaxD,QAAQyD,QACtCH,iBAAmB9J,MAAMd,KAAKY,iBAAmB,GAAGG,KAAK,OACzD,IAAIyJ,EAAK,EAAGA,EAAKxK,KAAKY,gBAAiB4J,GAAM,MAC3C,IAAIC,EAAK,EAAGA,EAAKzK,KAAKY,gBAAiB6J,GAAM,OAC3CG,iBAAkBJ,EAAKxK,KAAKY,gBAAmB6J,GAClDzK,KAAKmI,YAAanI,KAAKG,eAAiBqK,GAAMxK,KAAKC,UACjDD,KAAKG,eAAiBsK,GACtBO,EAAcrE,KAAM6D,EAAKxK,KAAKY,gBAAmB6J,KA2B9C,SAASQ,qBACtB9K,EAAiB,EACjBS,EAAkB,EAClBsH,EAAiB,cAEXhI,EAAUU,EAAkB,EAC5BX,EAAYE,EAAiBS,EAC7BsK,EAAQhL,EACZ2B,OAAOC,UAAWmG,sBAAuB+B,0BACzC/B,sBACItB,EAAO9E,OAAOC,wGAOO,GAEzB5B,GAAYiK,2BAA4B,OAEpCgB,EAAOtJ,OAAOC,OAClBD,OAAOE,OAAOmJ,GACdvE,YAEGyE,WACED,EC/bT,MAAME,wBAQEnH,OACCA,GAAeA,EAAYC,cACxB,IAAIpE,MAAM,kCAGbuL,aAAapH,OAEdqH,GAAiB/J,EAAAA,EACjBgK,EAAa,EACbC,EAAwBF,QAEpBvL,KAAK0L,UAAUF,EAAYD,EAAeE,IAAwB,GAChDF,IACRvL,KAAK2L,eAAezH,SAE9B0H,EACJ,IAAM/L,KAAK+H,KAAK2D,EAAgBE,GAAyBA,MACvD9C,OAAOC,MAAMgD,IAAWJ,EAAa,QACjC,IAAIzL,MAAM,uCAGJ,cAGX8L,oBACE7L,KAAK0D,kBAeJoI,EAAWC,EAASC,MACxBF,GAAa9L,KAAKiM,oBAAoBrH,cAAe,OAAO,KAC5D5E,KAAKiM,oBAAoBrH,eAAiB5E,KAAKiM,oBAAoBC,qBAC9DJ,GAAa9L,KAAKiM,oBAAoBrH,iBAE3CkH,EAAY9L,KAAKiM,oBAAoBC,cAAe,OAAO,SACzC,IAAMrM,KAAK+H,KAAKmE,EAAUC,GAAmBD,IAC3C/L,KAAKiM,oBAAoBE,gBA2BtC,SAASC,eACtB5I,EACAyI,iBACiB,mBACA,gBACA,aAGVpK,OAAOC,OAAO0B,EAAG6H,kBAAoBY,oBAAAA,IClF9C,MAAMI,kCAMG3I,OAAO4I,WAAaxL,MAAMQ,KAC7BR,MAAMd,KAAK0D,OAAO6I,WAClB,IAAM,IAAItB,qBACRjL,KAAK0D,OAAOvD,eACZH,KAAK0D,OAAO9C,gBACZZ,KAAK0D,OAAOwE,sBAGXxE,OAAO8I,cAAgB1L,MAAMd,KAAK0D,OAAO6I,WAAWxL,KAAK,QACzD0L,KAAO,IAAI3L,MAAMd,KAAK0D,OAAO6I,WAAWxL,KAAK,eAQzCP,OACLkM,EAAa,MACZ,IAAIlH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzCiH,KAAKjH,GAAKxF,KAAK2M,oBAAoBnM,EAAagF,MACvCxF,KAAKyM,KAAKjH,OAErB,IAAIA,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzCiH,KAAKjH,IAAMkH,SAGXA,uBAUWlM,EAAaoM,MAC3BA,GAAoB5M,KAAK0D,OAAO6I,gBAC5B,IAAIxM,MAAM,uEAEXC,KAAK0D,OAAO8I,cAAcI,GAC7B5M,KAAK0D,OAAO4I,WAAWM,GAAkBF,WAAWlM,oCAQnDkD,OAAO4I,WAAW/J,QAASiD,MAC5BuE,qCAGGrG,OAAO4I,WAAW/J,QAASiD,MAC5BuE,4BAEJ,MAAOM,SACD,IAAItK,MAAM,2FASd8M,EAAY,MACX,IAAIrH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,KACjCxF,KAAK0D,OAAO8I,cAAchH,MAErCqH,EAAY,MACT,IAAIrH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAO8I,cAAchH,IAAMqH,WAG7B,IAAIrH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAO8I,cAAchH,GAAK,EAAIxF,KAAK0D,OAAO6I,6BAU9C7I,OAAO4I,WAAW/J,QAASiD,MAC5BsH,WAAW9M,KAAK+M,2BAUlBC,gCASO9C,OAGL+C,OAFCC,QAAQC,aAAerM,MAAMd,KAAK0D,OAAO9C,iBAAiBG,KAAK,QAC/DmM,QAAQtC,iBAAmB9J,MAAqC,SAA/Bd,KAAK0D,OAAOwE,eAA4BlI,KAAK0D,OAAO9C,iBAAmB,EAAIZ,KAAK0D,OAAO9C,iBAAiBG,KAAK,OAG9I,IAAIyE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,EAAG,GAC/BxF,KAAK0D,OAAO4I,WAAW9G,GAAG4H,WAAWlD,OAClD,IAAIlJ,EAAI,EAAGA,EAAIhB,KAAK0D,OAAO9C,gBAAiBI,GAAK,UAC/CkM,QAAQC,aAAanM,IAAMhB,KAAKyM,KAAKjH,GAAKyH,EAAgBjM,GAC5B,SAA/BhB,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKzK,KAAK0D,OAAO9C,gBAAiB6J,GAAM,OAClDyC,QAAQtC,iBAAkB5J,EAAIhB,KAAK0D,OAAO9C,gBAAmB6J,IAC/DzK,KAAKyM,KAAKjH,IAAM,EACjBxF,KAAK0D,OAAO4I,WAAW9G,GAAGoF,iBAAkB5J,EAAIhB,KAAK0D,OAAO9C,gBAAmB6J,aAG9EyC,QAAQtC,iBAAiB5J,IAC3BhB,KAAKyM,KAAKjH,IAAM,EAAKxF,KAAK0D,OAAO4I,WAAW9G,GAAGoF,iBAAiB5J,UAIlEhB,KAAKkN,QAAQC,eAiBT,SAASE,YAAY7J,OAC7BD,YAAYC,SACT,IAAIzD,MAAM,sGAEX8B,OAAOC,OACZ0B,EACA6I,iBACA7I,EAAEE,OAAOxD,QAAU8M,wBC9JvB,MAAMM,kCAKSpJ,QACNkH,gBACAmC,wBAAwBrJ,EAAYsJ,0BACpCC,oBAAoBvJ,QACpBwJ,gBAAgBxJ,QAChB4I,kBACAa,oDAQiBC,OAClBC,EAAa,OACZd,sBAAwBa,EAAW/K,IAAIiL,GAAOjO,KAAK4B,IACtDzB,KAAK0D,OAAOmF,eAAekF,SAC3B/N,KAAK0D,OAAOmF,eAAemF,SAAWF,QAEnC,IAAItI,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,EACX,SAA/BxF,KAAK0D,OAAOwE,oBACTxE,OAAO4I,WAAW9G,GAAG2C,WAAarH,MAAMd,KAAK0D,OAAOzD,WAAa,GACnEc,KAAKf,KAAK0D,OAAOmF,eAAekF,SAAW,QAEzCrK,OAAO4I,WAAW9G,GAAG2C,WAAarH,MAAMd,KAAK0D,OAAOzD,WAAWc,KAAK,QAEtE2C,OAAO4I,WAAW9G,GAAGsH,WAAW9M,KAAK+M,4BACrCrJ,OAAO8I,cAAchH,GAAK,EAAIxF,KAAK0D,OAAO6I,aACjCvM,KAAK0D,OAAO8I,cAAchH,OAErC,IAAIA,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAO8I,cAAchH,IAAMqI,uBAYhB3J,OACbA,GAAeA,EAAYC,QAAS,aASnC8J,EARS7H,mBACb9C,0BACkBtD,KAAK0D,OAAOvD,+BACXH,KAAK0D,OAAO9C,kBAE/BZ,KAAK0D,OAAO6I,WACVhI,eAAgB,SAEQiC,MAAMtC,OAC7B,IAAIsB,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAO4I,WAAW9G,GAAG3E,KAAOoN,EAAa7J,QAAQoB,oBAU1CtB,OAGTA,GAAeA,EAAYC,QAAS,WAEpC,IAAIwD,EAAI,EAAGA,EAAI3H,KAAK0D,OAAO6I,UAAW5E,GAAK,OACzCjE,OAAO4I,WAAW3E,GAAGQ,WAAarH,MAAsC,SAA/Bd,KAAK0D,OAAOwE,eAA6BlI,KAAK0D,OAAOzD,WAAa,EAAID,KAAK0D,OAAOzD,WAAWc,KAAK,SAG5ImN,EAASpN,MAAMd,KAAK0D,OAAO6I,UAAYvM,KAAK0D,OAAOzD,WAAWc,KAAK,GACnEoN,EAASrN,MAAMd,KAAK0D,OAAO6I,WAAWxL,KAAK,KACrCwB,QAASC,UACb8C,EAAOzF,KAAKC,MAAM0C,EAAOnC,OAASL,KAAK0D,OAAO6I,eAChDhH,EAAS,MACR,IAAIoC,EAAI,EAAGA,EAAI3H,KAAK0D,OAAO6I,UAAW5E,GAAK,EAAG,KAC5C,IAAI1G,EAAI,EAAGA,EAAIqE,EAAMrE,GAAK,MACxB,IAAIuJ,EAAK,EAAGA,EAAKxK,KAAK0D,OAAOzD,UAAWuK,GAAM,OACzC7C,EAAI3H,KAAK0D,OAAOzD,UAAauK,IAAOhI,EAAOtB,IAAIqE,EAAStE,EAAGuJ,GAChC,SAA/BxK,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKzK,KAAK0D,OAAOzD,UAAWwK,GAAM,OAC5C/G,OAAO4I,WAAW3E,GACpBQ,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,IAC3CjI,EAAOtB,IAAIqE,EAAStE,EAAGuJ,GAAMhI,EAAOtB,IAAIqE,EAAStE,EAAGwJ,aAGnD/G,OAAO4I,WAAW3E,GAAGQ,WAAWqC,IACnChI,EAAOtB,IAAIqE,EAAStE,EAAGuJ,IAAO,KAI5BlF,IACHqC,IAAMrC,SAIZ,IAAIqC,EAAI,EAAGA,EAAI3H,KAAK0D,OAAO6I,UAAW5E,GAAK,MACzC,IAAI6C,EAAK,EAAGA,EAAKxK,KAAK0D,OAAOzD,UAAWuK,GAAM,OACzC7C,EAAI3H,KAAK0D,OAAOzD,UAAauK,IAAO2D,EAAOxG,GAChB,SAA/B3H,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKzK,KAAK0D,OAAOzD,UAAWwK,GAAM,OAC5C/G,OAAO4I,WAAW3E,GAAGQ,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,IAAO0D,EAAOxG,aAG/EjE,OAAO4I,WAAW3E,GAAGQ,WAAWqC,IAAO2D,EAAOxG,OAKpD,IAAIA,EAAI,EAAGA,EAAI3H,KAAK0D,OAAO6I,UAAW5E,GAAK,MACzC,IAAI6C,EAAK,EAAGA,EAAKxK,KAAK0D,OAAOzD,UAAWuK,GAAM,KACd,SAA/BxK,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKzK,KAAK0D,OAAOzD,UAAWwK,GAAM,OAC5C/G,OAAO4I,WAAW3E,GAAGQ,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,IAClEyD,EAAQvG,EAAI3H,KAAK0D,OAAOzD,UAAauK,GACrC0D,EAAQvG,EAAI3H,KAAK0D,OAAOzD,UAAawK,aAGpC/G,OAAO4I,WAAW3E,GAAGQ,WAAWqC,IACnC0D,EAAQvG,EAAI3H,KAAK0D,OAAOzD,UAAauK,IAAO,kBAUvCtG,OACT6H,EAAU,EACV1I,EAAc,IACNd,QAASC,OACJA,EAAOnC,eAElB+N,EAAgBvM,OAAOI,KAAKiC,EAAYhC,SAExCO,EAAI3B,MAAMQ,KACdR,MAAMd,KAAK0D,OAAO6I,WAClB,IAAM,IAAIzL,MAAMuC,GAAatC,KAAK,IAE9BsN,EAAIvN,MAAMd,KAAK0D,OAAO6I,WAAWxL,KAAK,OACxCuN,EAAQ,IAEA/L,QAASC,QACd,IAAIvB,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,EAAG,KACrC4L,EAAY,MACX,IAAIrH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,IAC5CA,GAAG8I,EAAQrN,GAAKjB,KAAK2M,oBAAoBnK,EAAOsD,SAAS7E,GAAIuE,IAEvC,IAApB/C,EAAE+C,GAAG8I,EAAQrN,IACf0H,OAAOC,MAAMnG,EAAE+C,GAAG8I,EAAQrN,KAC1BwB,EAAE+C,GAAG8I,EAAQrN,KAAQO,EAAAA,OACnBgE,GAAG8I,EAAQrN,GAAK,WAEPwB,EAAE+C,GAAG8I,EAAQrN,OAEvB,IAAIuE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,IAC5CA,GAAG8I,EAAQrN,IAAM4L,IACjBrH,IAAM/C,EAAE+C,GAAG8I,EAAQrN,MAEZpB,KAAK0O,IAAI1B,MAEbrK,EAAOnC,aAIb,IAAImF,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAO8I,cAAchH,GAAK6I,EAAE7I,GAAKnC,MAInC,IAAImC,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,MACzC,IAAIxE,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,EAAG,MAC5C0C,OAAO4I,WAAW9G,GAAG3E,KAAKG,GAAK,IAC5B,MACH,IAAIwN,EAAM,EAAGA,EAAMJ,EAAc/N,OAAQmO,GAAO,EAAG,OAChDhM,EAAS0B,EAAYhC,QAAQkM,EAAcI,QAC5C,IAAIvN,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,OACjCyC,OAAO4I,WAAW9G,GAAG3E,KAAKG,IAC7ByB,EAAE+C,GAAG8I,EAAQrN,GAAKuB,EAAOtB,IAAID,EAAGD,MAE3BwB,EAAOnC,YAEbqD,OAAO4I,WAAW9G,GAAG3E,KAAKG,IAAMqN,EAAE7I,MAKR,SAA/BxF,KAAK0D,OAAOwE,mBACT,IAAI1C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,MACzC,IAAIgF,EAAK,EAAGA,EAAKxK,KAAK0D,OAAOzD,UAAWuK,GAAM,MAC5C,IAAIC,EAAKD,EAAIC,EAAKzK,KAAK0D,OAAOzD,UAAWwK,GAAM,EAAG,MAChD/G,OAAO4I,WAAW9G,GAAG2C,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,GAAM,IAClE,MACH,IAAI+D,EAAM,EAAGA,EAAMJ,EAAc/N,OAAQmO,GAAO,EAAG,OAChDhM,EAAS0B,EAAYhC,QAAQkM,EAAcI,QAC5C,IAAIvN,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,OACjCyC,OAAO4I,WAAW9G,GAAG2C,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,IAClEhI,EAAE+C,GAAG8I,EAAQrN,IACZuB,EAAOtB,IAAID,EAAGuJ,GAAMxK,KAAK0D,OAAO4I,WAAW9G,GAAG3E,KAAK2J,KACnDhI,EAAOtB,IAAID,EAAGwJ,GAAMzK,KAAK0D,OAAO4I,WAAW9G,GAAG3E,KAAK4J,OAE/CjI,EAAOnC,YAEbqD,OAAO4I,WAAW9G,GAAG2C,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,IAAO4D,EAAE7I,GACzEgF,IAAOC,SACJ/G,OAAO4I,WAAW9G,GAAG2C,WAAYsC,EAAKzK,KAAK0D,OAAOzD,UAAauK,GAClExK,KAAK0D,OAAO4I,WAAW9G,GAAG2C,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,aAMzE,IAAIjF,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,MACzC,IAAIgF,EAAK,EAAGA,EAAKxK,KAAK0D,OAAOzD,UAAWuK,GAAM,EAAG,MAC/C9G,OAAO4I,WAAW9G,GAAG2C,WAAWqC,GAAM,IACnC,MACH,IAAIgE,EAAM,EAAGA,EAAMJ,EAAc/N,OAAQmO,GAAO,EAAG,OAChDhM,EAAS0B,EAAYhC,QAAQkM,EAAcI,QAC5C,IAAIvN,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,EAAG,OACnCwN,EAASjM,EAAOtB,IAAID,EAAGuJ,GAAMxK,KAAK0D,OAAO4I,WAAW9G,GAAG3E,KAAK2J,QAC7D9G,OAAO4I,WAAW9G,GAAG2C,WAAWqC,IAC/B/H,EAAE+C,GAAG8I,EAAQrN,GAAKwN,EAAQA,KAEzBjM,EAAOnC,YAEbqD,OAAO4I,WAAW9G,GAAG2C,WAAWqC,IAAO6D,EAAE7I,eAK/CsH,kBACAa,2BAEE5B,0BAoBX,SAAwB2C,gBACtBlL,EACA+I,EAAY,EACZ1D,GAAmBkF,SAAU,KAAMC,SAAU,KAC7C9F,EAAiB,YAEZrG,OAAOI,KAAKuB,GAAGpB,SAAS,gBACrB,IAAIrC,MAAM,sGAEX8B,OAAOC,OACZ0B,EACA8J,wCAGO9J,EAAEE,0DCxRb,MAAMiL,uCAMK9M,OAAOI,KAAKjC,KAAK4O,QAAQvO,iBAQzBuB,UACAC,OAAOI,KAAKjC,KAAK4O,QAAQxM,SAASR,WAOpCA,GACD5B,KAAKoC,SAASR,WACT5B,KAAK4O,OAAOhN,KAYV,SAASiN,2BAAoB1O,iBAAAS,qBAGvCkO,yEAEIjN,OAAOC,OACZwB,oBAAYnD,eAAAA,EAAgBS,gBAAAA,GAAoBkO,IAChDH,yBC1CW,SAASI,uBACtBvL,EACAwL,UAEOnN,OAAOC,OACZ0B,SAaQU,EAAa+K,OACZ/K,GAAeA,EAAYC,cACxB,IAAIpE,MAAM,oCAEdkP,KACK1M,QAAS2C,QACTlF,KAAKoC,SAAS8C,SACX,IAAInF,uBAAuBmF,2BAKlCxB,OAAOwL,YACCD,GAAU/K,EAAY+K,UAC9B1M,QAASX,UACNoB,EAAKkB,EAAYiL,kBAAkBvN,QAEpC8B,OAAOwL,QAAQtN,GAASoN,EAAiBhM,KAEzChD,KAAK0D,UCpCpB,MAAM0L,sCAKG/O,OAAS,OACTV,MAAQ,OACR0P,MAAO,OACPC,gBAOFb,GACCzO,KAAKqP,WACFC,OAAOtP,KAAKL,OAAS8O,OACrB9O,OAASK,KAAKL,MAAQ,GAAKK,KAAKuP,gBAEhCD,OAAO7O,KAAKgO,QACZpO,QAAU,OACVgP,KAAQrP,KAAKK,SAAWL,KAAKuP,eASlCC,UACKxP,KAAKsP,QAAQE,EAAMxP,KAAKL,OAASK,KAAKuP,gBAO1Cd,QACEpO,OAASL,KAAKuP,cACd5P,MAAQ,OACR0P,MAAO,OACPC,OAASxO,MAAMd,KAAKuP,UAAUxO,KAAK0N,YAQlCnM,OACD,IAAIM,EAAI,EAAGA,EAAI5C,KAAKK,OAAQuC,GAAK,IAC3B5C,KAAKsP,QAAQ1M,EAAI5C,KAAKL,OAASK,KAAKuP,UAAW3M,oBASnD5C,KAAKsP,OAAO5O,MAAMV,KAAKL,OAC3BY,OAAOP,KAAKsP,OAAO5O,MAAM,EAAGV,KAAKL,UAczB,SAAS8P,eAAeF,SAC/BD,EAASzN,OAAOE,OAAOqN,kCACtBG,SAAWA,IACXG,QACAJ,ECjFT,MAAMK,wBAA0BzP,sBAMZuP,eAAe,uBAMbG,QACbC,iBAAmBD,OACnBE,iBAAmBL,eAAeG,wBAQlCE,iBAAiBJ,QACf1P,cAUDQ,SACAkM,EAAa1M,KAAK0M,WAAWlM,UAC/BN,QACGkN,WAAW5M,QAEbuP,cAAcrD,GACZ1M,KAAKkN,uBAQA8C,QACP9C,QAAQ8C,kBAAoBA,OAC5BF,iBAAiBrP,KAAKZ,KAAK0O,IAAIyB,SAC/B9C,QAAQ3B,cAAgB,QACvB0E,EAAUjQ,KAAK8P,iBAAiBzP,WACjC,IAAIuC,EAAI,EAAGA,EAAIqN,EAASrN,GAAK,OAC3BsK,QAAQ3B,eAAiBvL,KAAK8P,iBAAiB5O,IAAI0B,QAErDsK,QAAQ3B,eAAiB0E,KAUlC,SAAwBC,sBAAsB1M,EAAGqM,EAAmB,OAC7DtM,YAAYC,SACT,IAAIzD,MAAM,qGAEZmN,EAAUrL,OAAOC,QACnBkO,kBAAmB,EAAGzE,cAAe,GACvC/H,EAAEE,OAAOxD,SAAYiN,gBAAkBvC,gCAElC/I,OAAOC,OACZ0B,EACAmM,wBAAwBnM,EAAEE,OAAOxD,UAC/BgN,QAAAA,EAAS4C,iBAAkBL,eAAeI,KCzEhD,SAASM,UAAU7J,EAAO8J,EAAWC,EAAe5B,MAC7C4B,MACDA,EAAcC,cAAgBxP,QAAUuP,EAAcjO,SAASqM,SAC3D,IAAI1O,oBAAoBqQ,eAAuB3B,iCAAqCnI,iBAAqB+J,QAC1G,GAAIA,EAAcC,cAAgBzO,OAAQ,IAC3CA,OAAOI,KAAKoO,GAAejO,SAAS,QAAUqM,EAAQ4B,EAAc9O,UAChE,IAAIxB,oBAAoBqQ,cAAsB3B,mDAAuD4B,EAAc9O,kBAAkB+E,UAEzIzE,OAAOI,KAAKoO,GAAejO,SAAS,QAAUqM,EAAQ4B,EAAc5O,UAChE,IAAI1B,oBAAoBqQ,cAAsB3B,mDAAuD4B,EAAc9O,kBAAkB+E,YAExI,GAA6B,mBAAlB+J,IACXA,EAAc5B,SACX,IAAI1O,oBAAoBqQ,cAAsB3B,kCAAsCnI,QAqEhG,SAAwBiK,mBAAmBjK,EAAO+J,EAAeG,SACzD1B,EAAajN,OAAOC,UAAW0O,iBAC9BvO,KAAKoO,GAAe9N,QAASkO,UAC5BC,EAAOL,EAAcI,MAGvBC,EAAKC,WAAa9O,OAAOI,KAAKuO,GAAQpO,SAASqO,SAC3C,IAAI1Q,2BAA2B0Q,6BAAgCnK,iBAI7DA,EAAOmK,EAAMC,EAAKE,MAAOJ,EAAOC,MAE/BA,GAAQC,EAAKG,UACtBH,EAAKG,UAAUL,EAAOC,IACtBD,EAAOC,KAEJ3B,EC5GT,MAAMgC,iBAAmBvE,0BAEX,SACDhL,IAAK,8BAGJ,QACH,EAAGwM,SAAAA,EAAUC,SAAAA,KACjBD,GAAYC,GAAYD,EAAW,GAAKC,EAAW,6BAG5C,SACF,OAAQ,sCAGN,QACH+C,GAAKA,EAAE1Q,SAAWkM,yBAGf,QACH/G,GAAKA,EAAEnF,SAAWkM,KAed,SAASyE,kBAAkBxN,OACnCD,YAAYC,SACT,IAAIzD,MAAM,yHAEC,MAAO+Q,iBAAiBtN,EAAEE,OAAO6I,WAAY/I,EAAEE,QAC3D7B,OAAOC,OACZ0B,GACEiJ,KAAM,IAAI3L,MAAM0C,EAAEE,OAAO6I,WAAWxL,KAAK,KCtC/C,MAAMkQ,gEAMKjR,KAAK6P,sCAOMD,QACbC,iBAAmBD,SACjB3N,KAAKjC,KAAK4O,QAAQrM,QAASX,SAC3BgN,OAAOhN,GAAOsP,oBAAoBtB,qBASlCY,OAAOxQ,KAAK4O,QAAQrM,QAAQwO,GAAKA,EAAEI,cACrCjE,qIAMQ,iBAGTlN,KAAK0D,OAAOxD,cACTkR,wBAQD5Q,UACCgQ,OAAOxQ,KAAK4O,QAAQrM,QAAQwO,GAAKA,EAAEM,QAAQ7Q,SAC7CuP,uCAICuB,EAAOzP,OAAOI,KAAKjC,KAAK4O,QAAQ2C,YACjCrE,QAAQ+B,OAASqC,MAClBE,EAAc,EACdC,EAAe,EACfC,GAAoBlQ,EAAAA,OACnB0L,QAAQgC,QAAUoC,EACpBzO,IAAI,CAAC8O,EAAK/O,UACJsK,QAAQ0E,mBAAmBhP,GAC9B5C,KAAK4O,OAAO+C,GAAKzE,QAAQ8C,uBACtB9C,QAAQ2E,uBAAuBjP,GAClC5C,KAAK4O,OAAO+C,GAAKzE,QAAQ3B,mBACtB2B,QAAQ4E,oBAAoBlP,GAC/B/C,KAAK4I,IAAIzI,KAAKkN,QAAQ2E,uBAAuBjP,OAChC5C,KAAKkN,QAAQ0E,mBAAmBhP,MAC/B5C,KAAKkN,QAAQ4E,oBAAoBlP,GAC7C5C,KAAKkN,QAAQ2E,uBAAuBjP,GAAK8O,MACxB1R,KAAKkN,QAAQ2E,uBAAuBjP,QAClDsK,QAAQ6E,UAAYJ,IAElBzO,CAACyO,GAAM3R,KAAK4O,OAAO+C,GAAKzE,WAElCpK,OAAO,CAACU,EAAGT,gBAAYS,EAAMT,YAC3BmK,QAAQ8E,8BACXhS,KAAKkN,QAAQ4E,oBAAoBjP,IAAIE,GAAKA,EAAI0O,QAC3CvE,QAAQ+E,6BACXjS,KAAKkN,QAAQ0E,mBAAmB/O,IAAIE,GAAKA,EAAIyO,GAC3CxR,KAAK0D,OAAOxD,cACTgS,4BAKLC,0DAEGjF,QAAQC,qBACRD,QAAQtC,kDAIqC,cAA9C5K,KAAK0D,OAAO0O,mCACTlF,QAAQC,aACXnN,KAAK4O,OAAO5O,KAAKkN,QAAQ6E,WAAW7E,QAAQC,kBACzCD,QAAQtC,iBACX5K,KAAK4O,OAAO5O,KAAKkN,QAAQ6E,WAAW7E,QAAQtC,qBACzC,CAAA,GAAkD,YAA9C5K,KAAK0D,OAAO0O,oCAcf,IAAIrS,MAAM,mEAbXmN,QAAQC,aAAerM,MAAMd,KAAKY,iBAAiBG,KAAK,QACxDmM,QAAQtC,iBAAmB9J,MAAMd,KAAKY,kBAA0D,SAAtCZ,KAAKqS,cAAcnK,eAA4B,EAAI,IAAInH,KAAK,QACtHmM,QAAQ+B,OAAO1M,QAASoP,SACtBzE,QAAQC,aAAatK,IAAI,CAACE,EAAGH,IAAMG,EACtC/C,KAAKkN,QAAQ8E,8BAA8BpP,GAC3C5C,KAAK4O,OAAO+C,GAAKzE,QAAQC,aAAavK,SAEnCsK,QAAQtC,iBAAiB/H,IAAI,CAACE,EAAGH,IAAMG,EAC1C/C,KAAKkN,QAAQ8E,8BAA8BpP,GAC3C5C,KAAK4O,OAAO+C,GAAKzE,QAAQtC,iBAAiBhI,SAoBpD,SAAwB0P,yBAAyB9O,EAAG4O,EAAgC,iBAC7E7O,YAAYC,SACT,IAAIzD,MAAM,qGAEZgR,EAAIlP,OAAOC,OACf0B,EACAyN,kCACAzN,EAAEE,OAAOxD,QAAUiS,kDAEnBzO,OAAO0O,8BAAgCA,EAClCrB,EC7ET,SAAgBwB,SACdrO,EACAmO,EACApG,SAEM9L,eAAEA,EAAFS,gBAAkBA,GAAoBsD,GACtCqI,UAAEA,EAAF1D,eAAaA,EAAbX,eAA6BA,GAAmBmK,SACxC3D,gBACZtC,eACEiB,YAAY/J,wDAGP+O,KAELpG,GAEFM,EACA1D,EACAX,GAEW1B,MAAMtC,GAcrB,SAAgBsO,mBACdtO,EACAmO,EACApG,SAEM9L,eAAEA,EAAFS,gBAAkBA,GAAoBsD,SAC9B6K,uBACZF,8BAAsB1O,eAAAA,EAAgBS,gBAAAA,GAAoByR,IAC1DrP,GAAMuP,SAASvP,EAAIqP,EAAepG,IAEvBzF,MAAMtC,GASrB,SAAgBuO,aACd/O,EACAmM,EAAmB,SAEbvJ,EAAQ0K,kBAAkBd,sBAC9B7C,YAAY/J,UAAUI,IACtBmM,aAEKvD,WAAW/J,QAAQ,CAACiD,EAAG5C,OACtBc,OAAO4I,WAAW1J,GAAKf,OAAOC,OAAOmJ,qBACzCvH,EAAOvD,eACPuD,EAAO9C,gBACP8C,EAAOwE,gBACN1C,OAEC2L,QACC7K,EAUT,SAAgBoM,uBACdhP,EACAmM,EAAmB,SAEbvJ,EAAQgM,yBAAyBzD,oBAAoBnL,aACrDkL,iBACC3M,KAAKyB,EAAOwL,SAAS3M,QAASX,MAC7BgN,OAAOhN,GAAS6Q,aAAa/O,EAAOwL,QAAQtN,GAAQiO,OAEtDsB,QACC7K,EC9IT,MAAMqM,sCAMgB,kBAQJ,6BAOWnS,OACrBqM,EAAY,KACmB,YAA/B7M,KAAK0D,OAAOkP,mBACT,IAAIhQ,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,OACtCkQ,MAAMlQ,GAAK5C,KAAK0D,OAAOqP,MAAMnQ,GAChC5C,KAAK0D,OAAOsP,QAAQpQ,GAAG8J,WAAWlM,MACvBR,KAAK8S,MAAMlQ,aAGrBkQ,MAAQ,IAAIhS,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,QAC3C+R,MAAM,GAAK9S,KAAK0D,OAAOsP,QAAQ,GAAGtG,WAAWlM,MACrCR,KAAK8S,MAAM,WAErBG,oBAAqB,EACtBpG,EAAY,EAAG,KACZ,IAAIjK,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,OACtCkQ,MAAMlQ,IAAMiK,SAEZ,EAAIA,MAER,IAAI7F,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,OACtC8L,MAAM9L,GAAK,EAAIhH,KAAK0D,OAAOmP,cAE3B,0BAQcrS,OACjBqM,EAAY,OACXqG,cAAgBlT,KAAK8S,MAAMpS,YAC3B,IAAIsG,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,EAAG,SACzC8L,MAAM9L,GAAK,EACmB,YAA/BhH,KAAK0D,OAAOkP,mBACT,IAAIhQ,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,OACtCkQ,MAAM9L,IAAMhH,KAAKkT,cAActQ,GAClC5C,KAAK0D,OAAOyP,WAAWvQ,GAAGoE,aAGzB8L,MAAM9L,IAAMhH,KAAKkT,cAAclM,GAAKhH,KAAK0D,OAAOyP,WAAe,EAAJnM,GAC5DA,EAAI,OACD8L,MAAM9L,IAAMhH,KAAKkT,cAAclM,EAAI,GACtChH,KAAK0D,OAAOyP,WAAsB,GAATnM,EAAI,GAAU,QAEpC8L,MAAM,IAAM9S,KAAKkT,cAAclT,KAAK0D,OAAOmP,OAAS,GACvD7S,KAAK0D,OAAOyP,WAAiC,EAArBnT,KAAK0D,OAAOmP,OAAc,QAGnDC,MAAM9L,IAAMhH,KAAK0D,OAAOsP,QAAQhM,GAAG0F,WAAWlM,MACtCR,KAAK8S,MAAM9L,MAEtB6F,EAAY,OAAQ,KACjB,IAAI7F,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,OACtC8L,MAAM9L,IAAM6F,SAEZ,EAAIA,SAEN,IAiBI,SAASuG,YAAY5P,OAC7BD,YAAYC,SACT,IAAIzD,MAAM,sGAEX8B,OAAOC,OAAO0B,EAAGmP,kBC5G1B,MAAMU,0BAA4B,KAO5BC,kCAKSpP,GACNA,IAAeA,EAAYC,eAE3BiH,SAASlH,QACTqJ,wBAAwBrJ,EAAYsJ,qBACrCxN,KAAK0D,OAAO6I,UAAY,OACrBgH,8BAA8BrP,SAE9BsP,wBAAwBtP,QACxBuP,6BAA6BvP,eAS7BA,SACD/D,iBAAAS,kBAAA2L,YAAA1D,iBAAAX,kBAMFlI,KAAK0D,YACJA,OAAOsP,QAAUlS,MAAMQ,KAC1B,IAAIR,MAAMd,KAAK0D,OAAOmP,QACtB,IAAMxF,YAAY/J,qGAQfI,OAAOsP,QAAQzQ,QAAQmR,GAAKA,EAAEtI,iBAC9B0H,MAAQ,IAAIhS,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,QAC3CmS,cAAgB,IAAIpS,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,QACnD0L,KAAO,IAAI3L,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,QAC1C4S,aAAe,IAAI7S,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,SAIjD6S,EAAY1P,EAAY2P,YACzBC,cAAgB,IAAIhT,MAAM8S,GAAW7S,KAAK,WAC1CgT,gBAAkB,IAAIjT,MAAM8S,GAAW7S,KAAK,WAC5CiT,wBAA0B,IAAIlT,MAAM8S,GAAW7S,KAAK,UAErD6B,EAAI,IACIL,QAASC,UACbyR,EAAIzR,EAAOnC,YACZyT,cAAclR,GAAK9B,MAAMQ,KAC5B,IAAIR,MAAMmT,GACV,IAAM,IAAInT,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,IAER,YAA/Bf,KAAK0D,OAAOkP,oBACTmB,gBAAgBnR,GAAK9B,MAAMQ,KAC9B,IAAIR,MAAMmT,GACV,IAAMnT,MAAMQ,KACV,IAAIR,MAAMd,KAAK0D,OAAOmP,QACtB,IAAM,IAAI/R,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,UAIxCgT,gBAAgBnR,GAAK9B,MAAMQ,KAC9B,IAAIR,MAAMmT,GACV,IAAM,IAAInT,MAA2B,EAArBd,KAAK0D,OAAOmP,QAAY9R,KAAK,SAG5CiT,wBAAwBpR,GAC3B,IAAI9B,MAAMd,KAAK0D,OAAO6I,WAAWxL,KAAK,OACnC,IAAIyE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzCwO,wBAAwBpR,GAAG4C,GAC9B1E,MAAMQ,KACJ,IAAIR,MAAMmT,GACV,IAAM,IAAInT,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,OAM1C,SAGFmT,SAAW,IAAIpT,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,QAC9CoT,mBAAqB,IAAIrT,MAAMd,KAAK0D,OAAOmP,OAAS7S,KAAK0D,OAAO6I,WAAWxL,KAAK,mBAOxEmD,OACT6H,EAAU,EAIV5J,EAAc,IACNI,QAASC,IACfA,EAAOnC,OAAS,OACPL,KAAKoU,yBAAyB5R,EAAQL,OAEpC,SAEZkS,kBAAkBnQ,OAMlB,IAAItB,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,MACtC,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAOsP,QAAQpQ,GAAGc,OAAO8I,cAAchH,GAAK,EACd,SAA/BxF,KAAK0D,OAAOwE,oBACTxE,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GAAG2C,WAC1C,IAAIrH,MAAMd,KAAK0D,OAAOzD,WAAa,GAAGc,KAAK,QAExC2C,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GAAG2C,WAC1C,IAAIrH,MAAMd,KAAK0D,OAAOzD,WAAWc,KAAK,eAKzCuT,qCAAqCpQ,QACrCqQ,uBAAuBrQ,QACvBsQ,6BAA6BtQ,GACC,YAA/BlE,KAAK0D,OAAOkP,qBACT6B,uBAAuBvQ,QAEzBwQ,6BAA6BxQ,GAC3B6H,4BAQF4I,4BACAb,cAAgB,UAChBC,gBAAkB,UAClBC,wBAA0B,UAC1BY,SAAW,UACXC,QAAU,UACVX,SAAW,UACXC,mBAAqB,UACrBzQ,OAAOsP,QAAUhT,KAAK0D,OAAOsP,QAAQnQ,IAAI6Q,GAAKA,EAAEhQ,iCAQ/BkK,GACa,YAA/B5N,KAAK0D,OAAOkP,oBACTkC,kBAEAC,qBAEDhI,EAAwBa,EAAW/K,IAAIiL,GAAOjO,KAAK4B,IACvDzB,KAAK0D,OAAOmF,eAAekF,SAC3B/N,KAAK0D,OAAOmF,eAAemF,SAAWF,IAElCkH,EAAiD,SAA/BhV,KAAK0D,OAAOwE,eAClC,IAAM,IAAIpH,MAAMd,KAAK0D,OAAOzD,WAAa,GACtCc,KAAKf,KAAK0D,OAAOmF,eAAekF,SAAW,GAC9C,IAAM,IAAIjN,MAAMd,KAAK0D,OAAOzD,WACzBc,KAAK,OACL,IAAI6B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,EAAG,OAExC8Q,EAAI1T,KAAK0D,OAAOsP,QAAQpQ,KAC5BmK,sBAAwBA,MACrB,IAAIvH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,IAC5C9B,OAAO4I,WAAW9G,GAAG2C,WAAa6M,MAClCtR,OAAO4I,WAAW9G,GAAGsH,WAAWC,KAChCrJ,OAAO8I,cAAchH,GAAK,EAAIxF,KAAK0D,OAAO6I,oCAW1BrI,OACjBA,GAAeA,EAAYC,QAAS,WAEpC,IAAIwD,EAAI,EAAGA,EAAI3H,KAAK0D,OAAOmP,OAAQlL,GAAK,MACtC,IAAI3G,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW,GAAGzL,KAAKG,GAAK,QAIpDmN,EAAS,IAAIrN,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,KACtCwB,QAASC,UACb8C,EAAOzF,KAAKC,MAAM0C,EAAOnC,OAASL,KAAK0D,OAAOmP,YAChDtN,EAAS,MACR,IAAIoC,EAAI,EAAGA,EAAI3H,KAAK0D,OAAOmP,OAAQlL,GAAK,EAAG,KACzC,IAAI1G,EAAI,EAAGA,EAAIqE,EAAMrE,GAAK,MACxB,IAAID,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW,GAAGzL,KAAKG,IAC/CwB,EAAOtB,IAAIqE,EAAStE,EAAGD,MAGnBsE,IACHqC,IAAMrC,SAGZ,IAAIqC,EAAI,EAAGA,EAAI3H,KAAK0D,OAAOmP,OAAQlL,GAAK,MACtC,IAAI3G,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW,GAAGzL,KAAKG,IAAMmN,EAAOxG,iCAWvCzD,OACtBA,GAAeA,EAAYC,QAAS,WAEpC,IAAIwD,EAAI,EAAGA,EAAI3H,KAAK0D,OAAOmP,OAAQlL,GAAK,OACtCjE,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW,GAAGnE,WAC1C,IAAIrH,MAAMd,KAAK0D,OAAOzD,YAA6C,SAA/BD,KAAK0D,OAAOwE,eAA4B,EAAI,IAAInH,KAAK,SAGvFoN,EAAS,IAAIrN,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,GAC5CkU,EAAa,IAAInU,MAAMd,KAAK0D,OAAOmP,OAAS7S,KAAK0D,OAAOzD,WAC3Dc,KAAK,KACIwB,QAASC,UACb8C,EAAOzF,KAAKC,MAAM0C,EAAOnC,OAASL,KAAK0D,OAAOmP,YAChDtN,EAAS,MACR,IAAIoC,EAAI,EAAGA,EAAI3H,KAAK0D,OAAOmP,OAAQlL,GAAK,EAAG,KACzC,IAAI1G,EAAI,EAAGA,EAAIqE,EAAMrE,GAAK,MACxB,IAAIuJ,EAAK,EAAGA,EAAKxK,KAAK0D,OAAOzD,UAAWuK,GAAM,OACpC7C,EAAI3H,KAAK0D,OAAOzD,UAAcuK,IACvChI,EAAOtB,IAAIqE,EAAStE,EAAGuJ,GACQ,SAA/BxK,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKzK,KAAK0D,OAAOzD,UAAWwK,GAAM,OAC5C/G,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW,GACtCnE,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,IACzCjI,EAAOtB,IAAIqE,EAAStE,EAAGuJ,GACvBhI,EAAOtB,IAAIqE,EAAStE,EAAGwJ,aAGxB/G,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW,GAAGnE,WAAWqC,IACrDhI,EAAOtB,IAAIqE,EAAStE,EAAGuJ,IAAO,KAI5BlF,IACHqC,IAAMrC,SAIZ,IAAIqC,EAAI,EAAGA,EAAI3H,KAAK0D,OAAOmP,OAAQlL,GAAK,MACtC,IAAI6C,EAAK,EAAGA,EAAKxK,KAAK0D,OAAOzD,UAAWuK,GAAM,OACrC7C,EAAI3H,KAAK0D,OAAOzD,UAAauK,IAAO2D,EAAOxG,GACpB,SAA/B3H,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKzK,KAAK0D,OAAOzD,UAAWwK,GAAM,OAC5C/G,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW,GACtCnE,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,IACzC0D,EAAOxG,aAGRjE,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW,GAAGnE,WAAWqC,IAAO2D,EAAOxG,OAKtE,IAAIA,EAAI,EAAGA,EAAI3H,KAAK0D,OAAOmP,OAAQlL,GAAK,EAAG,KACzC,IAAI6C,EAAK,EAAGA,EAAKxK,KAAK0D,OAAOzD,UAAWuK,GAAM,KACd,SAA/BxK,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKzK,KAAK0D,OAAOzD,UAAWwK,GAAM,OAC5C/G,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW,GACtCnE,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,IACzCwK,EAAYtN,EAAI3H,KAAK0D,OAAOzD,UAAauK,GACzCyK,EAAYtN,EAAI3H,KAAK0D,OAAOzD,UAAawK,aAG1C/G,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW,GAAGnE,WAAWqC,IACrDyK,EAAYtN,EAAI3H,KAAK0D,OAAOzD,UAAauK,GACzCyK,EAAYtN,EAAI3H,KAAK0D,OAAOzD,UAAauK,QAG1C9G,OAAOsP,QAAQrL,GAAGmF,kBAClBpJ,OAAOsP,QAAQrL,GAAGgG,2DAUGzJ,OACvB,IAAIyD,EAAI,EAAGA,EAAI3H,KAAK0D,OAAOmP,OAAQlL,GAAK,EAAG,OACxC3E,EAAKC,YAAYjD,KAAK0D,aAEhBnB,QAAQ,CAACC,EAAQL,WACrBmD,EAAOzF,KAAKC,MAAM0C,EAAOnC,OAASL,KAAK0D,OAAOmP,WAChDvN,EAAO,EAAG,GACT7E,KAAK0B,EAAaK,EAAOZ,WACvB,IAAIX,EAAI0G,EAAIrC,EAAMrE,GAAK0G,EAAI,GAAKrC,EAAMrE,GAAK,IAC3CmE,UAAUjD,GAAa1B,KAAK+B,EAAOsD,SAAS7E,QAIhD+B,EAAGmB,QAAS,OACT+Q,EAAY3C,SAASvP,EAAIhD,KAAK0D,YAC/B,IAAI8B,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW9G,GAAG3E,KAC1CqU,EAAU5I,WAAW9G,GAAG3E,UACrB6C,OAAOsP,QAAQrL,GAAGjE,OAAO4I,WAAW9G,GAAG2C,WAC1C+M,EAAU5I,WAAW9G,GAAG2C,gBACrBzE,OAAOsP,QAAQrL,GAAGgG,iDAWvBlL,EAAI,EAAIzC,KAAK0D,OAAOmP,YACrBnP,OAAOqP,MAAQ,IAAIjS,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK0B,QAClDiB,OAAOyP,WAAarS,MAAMQ,KAC7B,IAAIR,MAAMd,KAAK0D,OAAOmP,QACtB,IAAM,IAAI/R,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK0B,yBAStCiB,OAAOqP,MAAQ,IAAIjS,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,QAClD2C,OAAOqP,MAAM,GAAK,OAClBrP,OAAOyP,WAAa,IAAIrS,MAA2B,EAArBd,KAAK0D,OAAOmP,QAAY9R,KAAK,SAC3D2C,OAAOyP,WAAsC,GAA1BnT,KAAK0D,OAAOmP,OAAS,IAAU,OAClDnP,OAAOyP,WAAuC,GAA1BnT,KAAK0D,OAAOmP,OAAS,GAAU,GAAK,6BAS1B,YAA/B7S,KAAK0D,OAAOkP,eAA8B,OACtCuC,EAAYnV,KAAK0D,OAAOqP,MAAMjQ,OAAO,CAACa,EAAGC,IAAMD,EAAIC,EAAG,OACvD,IAAIhB,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,EAAG,MACzCc,OAAOqP,MAAMnQ,IAAMuS,MACpBC,EAAiB,MAChB,IAAIpO,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,KACzBhH,KAAK0D,OAAOyP,WAAWvQ,GAAGoE,OAEzC,IAAIA,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,OACtCtD,OAAOyP,WAAWvQ,GAAGoE,IAAMoO,YAI/B,IAAIxS,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,EAAG,OACxCwS,EAAiBpV,KAAK0D,OAAOyP,WAAe,EAAJvQ,GAAS5C,KAAK0D,OAAOyP,WAAgB,EAAJvQ,EAAS,QACnFc,OAAOyP,WAAe,EAAJvQ,IAAUwS,OAC5B1R,OAAOyP,WAAgB,EAAJvQ,EAAS,IAAMwS,gCAWjBC,OACrB,IAAIzS,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,OACtC6J,KAAK7J,GAAKyS,2BAUKA,EAAI7U,QACrBmT,aAAe3T,KAAKyM,KAAK/L,YACzB,IAAIkC,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,EAAG,SACzC6J,KAAK7J,GAAK,EACoB,YAA/B5C,KAAK0D,OAAOkP,mBACT,IAAI5L,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,OACtCyF,KAAK7J,IAAM5C,KAAK0D,OAAOyP,WAAWvQ,GAAGoE,GACxChH,KAAK2T,aAAa3M,GAClBhH,KAAK0D,OAAOsP,QAAQhM,GAAG0F,WAAWlM,aAGjCiM,KAAK7J,IAAM5C,KAAK0D,OAAOyP,WAAe,EAAJvQ,GACrC5C,KAAK2T,aAAa/Q,GAClB5C,KAAK0D,OAAOsP,QAAQpQ,GAAG8J,WAAWlM,GAChCoC,EAAI5C,KAAK0D,OAAOmP,OAAS,SACtBpG,KAAK7J,IAAM5C,KAAK0D,OAAOyP,WAAgB,EAAJvQ,EAAS,GAC/C5C,KAAK2T,aAAa/Q,EAAI,GACtB5C,KAAK0D,OAAOsP,QAAQpQ,EAAI,GAAG8J,WAAWlM,SAGvCiM,KAAK7J,IAAMyS,GACZ1M,OAAOC,MAAM5I,KAAKyM,KAAK7J,KAAO/C,KAAK+H,IAAI5H,KAAKyM,KAAK7J,MAASpB,EAAAA,UACvDiL,KAAK7J,GAAK,gCAYE0S,OACjBzI,EAAY,OACXqG,cAAgBlT,KAAK8S,MAAMpS,YAC3B,IAAIsG,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,EAAG,SACzC8L,MAAM9L,GAAK,EACmB,YAA/BhH,KAAK0D,OAAOkP,mBACT,IAAIhQ,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,OACtCkQ,MAAM9L,IAAMhH,KAAKkT,cAActQ,GAClC5C,KAAK0D,OAAOyP,WAAWvQ,GAAGoE,aAGzB8L,MAAM9L,IAAMhH,KAAKkT,cAAclM,GAAKhH,KAAK0D,OAAOyP,WAAe,EAAJnM,GAC5DA,EAAI,OACD8L,MAAM9L,IAAMhH,KAAKkT,cAAclM,EAAI,GACtChH,KAAK0D,OAAOyP,WAAsB,GAATnM,EAAI,GAAU,QAEpC8L,MAAM,IAAM9S,KAAKkT,cAAclT,KAAK0D,OAAOmP,OAAS,GACvD7S,KAAK0D,OAAOyP,WAAiC,EAArBnT,KAAK0D,OAAOmP,OAAc,QAGnDC,MAAM9L,IAAMsO,EAAuBtO,MAC3BhH,KAAK8S,MAAM9L,MAEtB2B,OAAOC,MAAMiE,SACT,IAAI9M,MAAM,iBAEd8M,EAAY,OAAQ,KACjB,IAAI7F,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,OACtC8L,MAAM9L,IAAM6F,SAEZ,EAAIA,SAEN,2BAWewI,EAAIC,QACrB3B,aAAe3T,KAAKyM,KAAK/L,YACzB,IAAIkC,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,EAAG,SACzC6J,KAAK7J,GAAK,EACoB,YAA/B5C,KAAK0D,OAAOkP,mBACT,IAAI5L,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,OACtCyF,KAAK7J,IACR5C,KAAK0D,OAAOyP,WAAWvQ,GAAGoE,GAC1BhH,KAAK2T,aAAa3M,GAClBsO,EAAuBtO,aAGtByF,KAAK7J,IAAM5C,KAAK0D,OAAOyP,WAAe,EAAJvQ,GACrC5C,KAAK2T,aAAa/Q,GAClB0S,EAAuB1S,GACrBA,EAAI5C,KAAK0D,OAAOmP,OAAS,SACtBpG,KAAK7J,IAAM5C,KAAK0D,OAAOyP,WAAgB,EAAJvQ,EAAS,GAC/C5C,KAAK2T,aAAa/Q,EAAI,GACtB0S,EAAuB1S,EAAI,SAG5B6J,KAAK7J,IAAMyS,GACZ1M,OAAOC,MAAM5I,KAAKyM,KAAK7J,KAAO/C,KAAK+H,IAAI5H,KAAKyM,KAAK7J,MAASpB,EAAAA,UACvDiL,KAAK7J,GAAK,kCAYI2S,EAAepT,SAChC8R,EAAIsB,EAAclV,OAElBgV,EAAK,IAAIvU,MAAMmT,GAAGlT,KAAK,OACzBgL,OACC6I,iBACAC,iBAECW,EAA2B1U,MAAMQ,KACrC,IAAIR,MAAMmT,GACV,IAAM,IAAInT,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,QAEtC,IAAIE,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,IAClB3B,GAAG2B,GAC1B5C,KAAK0D,OAAOsP,QAAQpQ,GAAG8J,WAAW6I,EAAczP,SAAS7E,MAK5D,GAAKjB,KAAKyV,2BAA2BF,EAAczP,SAAS,OACpDjG,KAAK0O,IAAI8G,EAAG,SAClBT,SAASnU,KAAKT,KAAK8S,MAAMpS,aAEzB,IAAIO,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,IACvBA,GAAKjB,KAAK0V,uBAAuBF,EAAyBvU,OAClDpB,KAAK0O,IAAI8G,EAAGpU,SAClB2T,SAASnU,KAAKT,KAAK8S,MAAMpS,cAI3BiV,4BAA4BN,EAAGpB,EAAI,SACnCY,QAAQpU,KAAKT,KAAKyM,KAAK/L,aAEvB,IAAIO,EAAIgT,EAAI,EAAGhT,GAAK,EAAGA,GAAK,OAC1B2U,wBAAwBP,EAAGpU,GAAIuU,EAAyBvU,EAAI,SAC5D4T,QAAQpU,KAAKT,KAAKyM,KAAK/L,cAEzBmU,QAAQgB,cAGR,IAAI5U,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,OACtCkR,cAAc3R,GAAalB,GAAG2B,GAChC5C,KAAK4U,SAAS3T,GAAG2B,GAAK5C,KAAK6U,QAAQ5T,GAAG2B,GAAMyS,EAAGpU,OAKlD4L,MAEC,IAAI5L,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,EAAG,MAClC,EACkB,IAA1B5C,KAAK0D,OAAO6I,UAAiB,OACzBuJ,EAAKN,EAAyBvU,GAAG2B,QAClCoR,wBAAwB7R,GAAa,GAAGlB,GAAG2B,GAC9C5C,KAAK8T,cAAc3R,GAAalB,GAAG2B,GAAKkT,KAC7BA,WAER,IAAItQ,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,EAAG,OAC3CsQ,EAAK9V,KAAK0D,OAAOsP,QAAQpQ,GAC5B+J,oBAAoB4I,EAAczP,SAAS7E,GAAIuE,QAC7CwO,wBAAwB7R,GAAaqD,GAAGvE,GAAG2B,GAC9C5C,KAAK8T,cAAc3R,GAAalB,GAAG2B,GACnCkT,KACWA,KAGbjJ,EAAY,MACT,IAAIrH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzCwO,wBAAwB7R,GAAaqD,GAAGvE,GAAG2B,IAAMiK,KAO3B,YAA/B7M,KAAK0D,OAAOkP,mBACT,IAAI3R,EAAI,EAAGA,EAAIgT,EAAI,EAAGhT,GAAK,MACzB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,MACtC,IAAIoE,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,OACtC+M,gBAAgB5R,GAAalB,GAAG2B,GAAGoE,GACtChH,KAAK4U,SAAS3T,GAAG2B,GACjB5C,KAAK0D,OAAOyP,WAAWvQ,GAAGoE,GAC1BhH,KAAK6U,QAAQ5T,EAAI,GAAG+F,QACjB+M,gBAAgB5R,GAAalB,GAAG2B,GAAGoE,IACtCwO,EAAyBvU,EAAI,GAAG+F,YAKnC,IAAI/F,EAAI,EAAGA,EAAIgT,EAAI,EAAGhT,GAAK,MACzB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,OACtCmR,gBAAgB5R,GAAalB,GAAO,EAAJ2B,GACnC5C,KAAK4U,SAAS3T,GAAG2B,GACjB5C,KAAK0D,OAAOyP,WAAe,EAAJvQ,GACvB5C,KAAK6U,QAAQ5T,EAAI,GAAG2B,QACjBmR,gBAAgB5R,GAAalB,GAAO,EAAJ2B,IACnC4S,EAAyBvU,EAAI,GAAG2B,GAC9BA,EAAI5C,KAAK0D,OAAOmP,OAAS,SACtBkB,gBAAgB5R,GAAalB,GAAQ,EAAJ2B,EAAS,GAC7C5C,KAAK4U,SAAS3T,GAAG2B,GACjB5C,KAAK0D,OAAOyP,WAAgB,EAAJvQ,EAAS,GACjC5C,KAAK6U,QAAQ5T,EAAI,GAAG2B,EAAI,QACrBmR,gBAAgB5R,GAAalB,GAAQ,EAAJ2B,EAAS,IAC7C4S,EAAyBvU,EAAI,GAAG2B,EAAI,WAMvCmJ,qBAQS7H,OACX,IAAItB,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,EAAG,MACzCsR,SAAStR,GAAK,MACd,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzC2O,mBAAoBvR,EAAI5C,KAAK0D,OAAO6I,UAAa/G,GAAK,MAI3DrD,EAAc,IACNI,QAASC,QACd,IAAII,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,EAAG,MACpCiT,SAAStR,IACZ5C,KAAK8T,cAAc3R,GAAalB,GAAG2B,OAChC,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzC2O,mBAAoBvR,EAAI5C,KAAK0D,OAAO6I,UAAa/G,IACpDxF,KAAKgU,wBAAwB7R,GAAaqD,GAAGvE,GAAG2B,MAIzC,0CAUkBsB,OAC/B/B,EAAc,IACNI,QAASC,QACd,IAAII,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,MACjC,IAAIuE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAOsP,QAAQpQ,GAAGc,OAAO8I,cAAchH,IAC1CxF,KAAKgU,wBAAwB7R,GAAaqD,GAAGvE,GAAG2B,MAIzC,QAIZ,IAAIA,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,OACtCc,OAAOsP,QAAQpQ,GAAGmT,iDAUJ7R,OAChB,IAAItB,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,MACtC,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,OACzC9B,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GAAG3E,KAAKE,KAAK,OAKtDoB,EAAc,IACNI,QAASC,QACd,IAAII,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,MACjC,IAAIuE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,MACzC,IAAIxE,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GAAG3E,KAAKG,IAC/ChB,KAAKgU,wBAAwB7R,GAAaqD,GAAGvE,GAAG2B,GAChDJ,EAAOtB,IAAID,EAAGD,MAKT,QAIZ,IAAI4B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,MACtC,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,MACzC,IAAIxE,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,KAC1ChB,KAAKmU,mBAAoBvR,EAAI5C,KAAK0D,OAAO6I,UAAa/G,GAAK,SACxD9B,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GAAG3E,KAAKG,IAC/ChB,KAAKmU,mBAAoBvR,EAAI5C,KAAK0D,OAAO6I,UAAa/G,IAEtDmD,OAAOC,MAAM5I,KAAK0D,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GAAG3E,KAAKG,UAC1D,IAAIjB,MAAM,mDAaGmE,OACvB/B,EAAc,IACNI,QAASC,QACd,IAAII,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAIuB,EAAOnC,OAAQY,GAAK,MACjC,IAAIuE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,MACzC,IAAIgF,EAAK,EAAGA,EAAKxK,KAAK0D,OAAOzD,UAAWuK,GAAM,KACd,SAA/BxK,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAKD,EAAIC,EAAKzK,KAAK0D,OAAOzD,UAAWwK,GAAM,OAC7C/G,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GACtC2C,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,IAC3CzK,KAAKgU,wBAAwB7R,GAAaqD,GAAGvE,GAAG2B,IAC/CJ,EAAOtB,IAAID,EAAGuJ,GACbxK,KAAK0D,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GAAG3E,KAAK2J,KAClDhI,EAAOtB,IAAID,EAAGwJ,GACbzK,KAAK0D,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GAAG3E,KAAK4J,QAElD,OACCgE,EAAQjM,EAAOtB,IAAID,EAAGuJ,GAC1BxK,KAAK0D,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GAAG3E,KAAK2J,QAC9C9G,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GAAG2C,WAAWqC,IACrDxK,KAAKgU,wBAAwB7R,GAAaqD,GAAGvE,GAAG2B,GAC/C6L,GAAS,KAMP,QAIZ,IAAI7L,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,EAAG,KACzC,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO6I,UAAW/G,GAAK,KAC1CxF,KAAKmU,mBAAoBvR,EAAI5C,KAAK0D,OAAO6I,UAAa/G,GAAK,MACxD,IAAIgF,EAAK,EAAGA,EAAKxK,KAAK0D,OAAOzD,UAAWuK,GAAM,KACd,SAA/BxK,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAKD,EAAIC,EAAKzK,KAAK0D,OAAOzD,UAAWwK,GAAM,OAC7C/G,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GACtC2C,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,IAC3CzK,KAAKmU,mBAAoBvR,EAAI5C,KAAK0D,OAAO6I,UAAa/G,GACpDgF,IAAOC,SACJ/G,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GACtC2C,WAAYsC,EAAKzK,KAAK0D,OAAOzD,UAAauK,GAC3CxK,KAAK0D,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GACtC2C,WAAYqC,EAAKxK,KAAK0D,OAAOzD,UAAawK,cAI9C/G,OAAOsP,QAAQpQ,GAAGc,OAAO4I,WAAW9G,GAAG2C,WAAWqC,IACrDxK,KAAKmU,mBAAoBvR,EAAI5C,KAAK0D,OAAO6I,UAAa/G,QAK3D9B,OAAOsP,QAAQpQ,GAAGkK,kBAClBpJ,OAAOsP,QAAQpQ,GAAG+K,oDASJzJ,QAChBR,OAAOqP,MAAMhS,KAAK,OAGnBiV,EAAW,MACV,IAAI7T,EAAc,EACrBA,EAAc+B,EAAY2P,OAC1B1R,GAAe,MACV,IAAIS,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,OACtCc,OAAOqP,MAAMnQ,IAAM5C,KAAK8T,cAAc3R,GAAa,GAAGS,MAC/C5C,KAAK0D,OAAOqP,MAAMnQ,QAK9BoT,EAAW,SAKP,IAAIjW,MAAM,kCAJX,IAAI6C,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,OACtCc,OAAOqP,MAAMnQ,IAAMoT,gCAYD9R,QAEtBR,OAAOyP,WAA4C,YAA/BnT,KAAK0D,OAAOkP,eACnC9R,MAAMQ,KACJ,IAAIR,MAAMd,KAAK0D,OAAOmP,QACtB,IAAM,IAAI/R,MAAMd,KAAK0D,OAAOmP,QAAQ9R,KAAK,IAE3C,IAAID,MAA2B,EAArBd,KAAK0D,OAAOmP,QAAY9R,KAAK,OAGrCoB,EAAc,OACNI,QAASC,OACfA,EAAOnC,OAAS,MACb,IAAIuC,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,KAGR,cAA/B5C,KAAK0D,OAAOkP,sBACTlP,OAAOyP,WAAe,EAAJvQ,IAx1BD,KAy1BlBA,EAAI5C,KAAK0D,OAAOmP,OAAS,OACtBnP,OAAOyP,WAAgB,EAAJvQ,EAAS,IA11Bb,UA41Bfc,OAAOyP,WAAe,EAAJvQ,IA51BH,MAg2BW,YAA/B5C,KAAK0D,OAAOkP,mBACT,IAAI5L,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,MACtC,IAAI/F,EAAI,EAAGA,EAAIuB,EAAOnC,OAAS,EAAGY,GAAK,OACrCyC,OAAOyP,WAAWvQ,GAAGoE,IACxBhH,KAAK+T,gBAAgB5R,GAAalB,GAAG2B,GAAGoE,OAGzC,KACA,IAAI/F,EAAI,EAAGA,EAAIuB,EAAOnC,OAAS,EAAGY,GAAK,OACrCyC,OAAOyP,WAAe,EAAJvQ,IACrB5C,KAAK+T,gBAAgB5R,GAAalB,GAAO,EAAJ2B,MAErCA,EAAI5C,KAAK0D,OAAOmP,OAAS,MACtB,IAAI5R,EAAI,EAAGA,EAAIuB,EAAOnC,OAAS,EAAGY,GAAK,OACrCyC,OAAOyP,WAAgB,EAAJvQ,EAAS,IAC/B5C,KAAK+T,gBAAgB5R,GAAalB,GAAQ,EAAJ2B,EAAS,MAM5C,IAIkB,YAA/B5C,KAAK0D,OAAOkP,oBACT,IAAIhQ,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,MACtC,IAAIoE,EAAI,EAAGA,EAAIhH,KAAK0D,OAAOmP,OAAQ7L,GAAK,UACtCtD,OAAOyP,WAAWvQ,GAAGoE,IACvBhH,KAAKkU,SAAStR,GAAM,KACnB+F,OAAOC,MAAM5I,KAAK0D,OAAOyP,WAAWvQ,GAAGoE,UACnC,IAAIjH,MAAM,wFAKjB,IAAI6C,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,EAAG,SACzCc,OAAOyP,WAAe,EAAJvQ,IACpB5C,KAAKkU,SAAStR,GAAM,KACnB+F,OAAOC,MAAM5I,KAAK0D,OAAOyP,WAAe,EAAJvQ,UAChC,IAAI7C,MAAM,kFAEd6C,EAAI5C,KAAK0D,OAAOmP,OAAS,SACtBnP,OAAOyP,WAAgB,EAAJvQ,EAAS,IAC9B5C,KAAKkU,SAAStR,GAAM,KACnB+F,OAAOC,MAAM5I,KAAK0D,OAAOyP,WAAgB,EAAJvQ,EAAS,WAC1C,IAAI7C,MAAM,kFAsBb,SAASkW,gBACtBzS,EACAqP,EAAS,EACTtG,EAAY,EACZ1D,GAAmBkF,SAAU,KAAMC,SAAU,KAC7C4E,EAAiB,YACjB1K,EAAiB,YAEZrG,OAAOI,KAAKuB,GAAGpB,SAAS,gBACrB,IAAIrC,MAAM,sGAEX8B,OAAOC,OACZ0B,EACA8P,wCAGO9P,EAAEE,oFCr7Bb,MAAMwS,iBAAmB,CAACrD,EAAQD,wBAEpB,SACDrR,IAAK,yBAGJ,SACDA,IAAK,8BAGJ,QACH,EAAGwM,SAAAA,EAAUC,SAAAA,KACjBD,GAAYC,GAAYD,EAAW,GAAKC,EAAW,6BAG5C,SACF,UAAW,wCAGT,SACF,OAAQ,8BAGN,QACH+C,GAAwB,cAAnB6B,GAAkC7B,EAAE1Q,SAAWwS,yBAGjD,QACH9B,GAAyB,cAAnB6B,EACX7B,EAAE1Q,SAAW,EAAIwS,EACjB9B,EAAE1Q,SAAWwS,sBAGL,QACH9B,GAAKA,EAAE1Q,SAAWwS,KAUvBsD,4CACgB,kBACJ,sBAQTzS,OAAOsP,QAAUhT,KAAK0D,OAAOsP,QAAQnQ,IAAI6Q,GAAKjB,aAAaiB,GAAGvC,SAC5DnR,0BAQF8P,iBAAiBJ,aACjBhM,OAAOsP,QAAQzQ,QAASmR,MAAUvC,UAChCnR,iBAQEQ,SACH6U,EAAMrV,KAAKiT,mBACfjT,KAAKoW,uBAAuB5V,GAC5BR,KAAKyV,2BAA2BjV,eAC7B6V,yBACAC,iBACE,EAAIjB,yBAINnI,QAAQqJ,SAAW,MACnB,IAAI3T,EAAI5C,KAAKwW,eAAgB5T,EAAI5C,KAAKyW,eAAgB7T,GAAK,EAC1D5C,KAAK0W,oBACFxJ,QAAQqJ,WAAavW,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,GAAK5C,KAAK4W,OAAOhU,KACpEA,EAAI5C,KAAK6W,kCAEP3J,QAAQqJ,UAAavW,KAAK8S,MAAMlQ,GAAKA,EACxC5C,KAAK6W,iCAGN3J,QAAQqJ,UAAYvW,KAAK0D,OAAOmP,OAAS,4BASzC3F,QAAQ4J,eAAiB,MAE1BC,EAAY/W,KAAK0W,eAClB1W,KAAK8S,MAAM,GAAK9S,KAAK2W,OAAO,GAC7B3W,KAAK8S,MAAM,OACR,IAAIlQ,EAAI,EAAGA,EAAI5C,KAAK0D,OAAOmP,OAAQjQ,GAAK,EACvC5C,KAAK0W,eACF1W,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,GAAMmU,MACzB/W,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,QACnCsK,QAAQ4J,eAAiBlU,GAEvB5C,KAAK8S,MAAMlQ,GAAKmU,MACb/W,KAAK8S,MAAMlQ,QAClBsK,QAAQ4J,eAAiBlU,QAK7B4T,eAAiBxW,KAAKkN,QAAQ4J,eAAiBjX,KAAKC,MAAME,KAAK0D,OAAOmP,OAAS,QAC/E4D,eAAiBzW,KAAKkN,QAAQ4J,eAAiBjX,KAAKC,MAAME,KAAK0D,OAAOmP,OAAS,QAC/E2D,eAAkBxW,KAAKwW,gBAAkB,EAAKxW,KAAKwW,eAAiB,OACpEC,eAAkBzW,KAAKyW,gBAAkBzW,KAAK0D,OAAOmP,OACxD7S,KAAKyW,eAAiBzW,KAAK0D,OAAOmP,YAC/BgE,4BAA8B,MAC9B,IAAIjU,EAAI5C,KAAKwW,eAAgB5T,EAAI5C,KAAKyW,eAAgB7T,GAAK,OACzDiU,6BAA+B7W,KAAK0W,eACtC1W,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,GAC7B5C,KAAK8S,MAAMlQ,KAUboU,0CASO9M,WACJgD,QAAQC,aAAerM,MAAMd,KAAK0D,OAAO9C,iBAAiBG,KAAK,QAC/DmM,QAAQtC,iBAAmB9J,MAAqC,SAA/Bd,KAAK0D,OAAOwE,eAA4BlI,KAAK0D,OAAO9C,iBAAmB,EAAIZ,KAAK0D,OAAO9C,iBAAiBG,KAAK,GAE3G,cAApCf,KAAK0D,OAAOuT,gCACTvT,OAAOsP,QAAQhT,KAAKkN,QAAQ4J,gBAAgBzF,QAAQnH,QACpDgD,QAAQC,aACXnN,KAAK0D,OAAOsP,QAAQhT,KAAKkN,QAAQ4J,gBAAgB5J,QAAQC,aACpDnN,KAAKkN,QAAQC,mBAGhB+J,EAAoD,SAApClX,KAAK0D,OAAOuT,oBAChC,EAAIjX,KAAKwW,eACLW,EAAoD,SAApCnX,KAAK0D,OAAOuT,oBAChCjX,KAAK0D,OAAOmP,OAAS7S,KAAKyW,mBACxBW,EAA6D,SAApCpX,KAAK0D,OAAOuT,oBACvC,EAAIjX,KAAK6W,4BAEPO,GAAyB,IAAKA,EAAwB,OAGrD,IAAIxU,EAAIsU,EAActU,EAAIuU,EAAcvU,GAAK,EAAG,MAC9Cc,OAAOsP,QAAQpQ,GAAG8J,WAAWxC,QAC7BxG,OAAOsP,QAAQpQ,GAAGwK,WAAWlD,SAC5BmN,EAAqBrX,KAAK0D,OAAOsP,QAAQpQ,GAAGsK,QAAQC,iBACrD,IAAInM,EAAI,EAAGA,EAAIhB,KAAK0D,OAAO9C,gBAAiBI,GAAK,KAChDhB,KAAK0W,uBACFxJ,QAAQC,aAAanM,KACvBhB,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,KAC5ByU,EAAmBrW,GAAKoW,GACQ,SAA/BpX,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKzK,KAAK0D,OAAO9C,gBAAiB6J,GAAM,OAClDyC,QAAQtC,iBAAkB5J,EAAIhB,KAAK0D,OAAO9C,gBAAmB6J,KAC/DzK,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,KAC5B5C,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,KAC5B5C,KAAK0D,OAAOsP,QAAQpQ,GAAGsK,QACrBtC,iBAAkB5J,EAAIhB,KAAK0D,OAAO9C,gBAAmB6J,GACxD2M,aAGClK,QAAQtC,iBAAiB5J,KAC3BhB,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,KAC5B5C,KAAK8S,MAAMlQ,GAAK5C,KAAK2W,OAAO/T,KAC5B5C,KAAK0D,OAAOsP,QAAQpQ,GAAGsK,QAAQtC,iBAAiB5J,GACjDoW,gBAGClK,QAAQC,aAAanM,IAAMhB,KAAK8S,MAAMlQ,IACxCyU,EAAmBrW,GAAKoW,GACQ,SAA/BpX,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKzK,KAAK0D,OAAO9C,gBAAiB6J,GAAM,OAClDyC,QAAQtC,iBAAkB5J,EAAIhB,KAAK0D,OAAO9C,gBAAmB6J,IAC/DzK,KAAK8S,MAAMlQ,IAAM,GACjB5C,KAAK0D,OAAOsP,QAAQpQ,GAAGsK,QACrBtC,iBAAkB5J,EAAIhB,KAAK0D,OAAO9C,gBAAmB6J,GACxD2M,aAGClK,QAAQtC,iBAAiB5J,IAC1BhB,KAAK8S,MAAMlQ,IAAM,EACnB5C,KAAK0D,OAAOsP,QAAQpQ,GAAGsK,QAAQtC,iBAAiB5J,GAChDoW,SAKHpX,KAAKkN,QAAQC,eAeT,SAASmK,kBAAkB9T,OACnCD,YAAYC,SACT,IAAIzD,MAAM,yHAEC,MAAOmW,iBAAiB1S,EAAEE,OAAOmP,OAAQrP,EAAEE,OAAOkP,gBAAiBpP,EAAEE,QACjF7B,OAAOC,OACZ0B,EACA2S,uBACA3S,EAAEE,OAAOxD,QAAU8W,wCAEV,IAAIlW,MAAM0C,EAAEE,OAAOmP,QAAQ9R,KAAK,mBACtB,IAAID,MAAM0C,EAAEE,OAAOmP,QAAQ9R,KAAK,KAEnDwW,QCpPJ,MAAMC,mCAAqC,GAOrCC,wDAQgB,gBAQZC,EAAa1X,KAAK6T,mBACnBnQ,OAAOqP,MAAQ,IAAIjS,MAAM4W,GAAY3W,KAAK,EAAI2W,QAC9ChU,OAAOyP,WAAarS,MAAMQ,KAC7B,IAAIR,MAAM4W,GACV,IAAM,IAAI5W,MAAM4W,GAAY3W,KAAK,EAAI2W,SAElChU,OAAOiU,eAAiB,IAAI7W,MAAM4W,GAAY3W,KAAK,WACjDyP,OAAOxQ,KAAK4O,QAAQrM,QAAS+D,IACxBA,EACRoQ,gBAAiB,SAEhBkB,0BACE5X,8BASe6X,SAChBC,OAAkCpV,IAAtBmV,EAChBA,EACA,IAAI/W,MAAMd,KAAK0D,OAAOmP,OAAS,GAAG9R,KAAK,GACpCR,QAhDkC,YAiDhC0B,KAAKjC,KAAK4O,QAAQrM,QAASX,SAC3BgN,OAAOhN,GAAO8B,OAAOmU,kBAAoBC,EAASpX,0BASlD8P,OAAOxQ,KAAK4O,QAAQrM,QAAQwO,GAAKA,EAAEI,cACrCjE,uJAOQ,iBAGTlN,KAAK0D,OAAOxD,cACTkR,oBAEF6B,oBAAqB,WAOpBzS,MACFR,KAAKiT,wBACFmD,uBAAuB5V,QAEvBiV,2BAA2BjV,UAE3ByB,KAAKjC,KAAK4O,QAAQ2C,OAAOhP,QAASX,UACjC0E,EAAQtG,KAAK4O,OAAOhN,KACpByU,sBACAC,mBACAvG,cAAczJ,EAAM4G,QAAQ8C,0BAE/BD,gBAED/P,KAAK0D,OAAOxD,kBACPsQ,OAAOxQ,KAAK4O,QAAQrM,QAAQwO,GAAKA,EAAE3D,WAAW5M,IAEH,cAA9CR,KAAK0D,OAAO0O,mCACTlF,QAAQC,aACXnN,KAAK4O,OAAO5O,KAAKkN,QAAQ6E,WAAW7E,QAAQC,kBACzCD,QAAQtC,iBACX5K,KAAK4O,OAAO5O,KAAKkN,QAAQ6E,WAAW7E,QAAQtC,qBACzC,MACAsC,QAAQC,aAAe,IAAIrM,MAAMd,KAAKY,iBAAiBG,KAAK,QAC5DmM,QAAQtC,iBACX,IAAI9J,MAAqC,SAA/Bd,KAAK0D,OAAOwE,eACpBlI,KAAKY,iBAAmB,EACxBZ,KAAKY,iBAAiBG,KAAK,OAE3BgX,EAAa,SACVvH,OAAOxQ,KAAK4O,QAAQrM,QAAS+D,QAC7B,IAAItF,EAAI,EAAGA,EAAIhB,KAAKY,gBAAiBI,GAAK,UACxCkM,QAAQC,aAAanM,IACxBhB,KAAKkN,QAAQ8E,8BAA8B+F,GAC3CzR,EAAM0R,OAAO9K,QAAQC,aAAanM,GAED,SAA/BhB,KAAK0D,OAAOwE,mBACT,IAAIuC,EAAK,EAAGA,EAAKzK,KAAKY,gBAAiB6J,GAAM,OAC3CyC,QAAQtC,iBAAkB5J,EAAIhB,KAAKY,gBAAmB6J,IACzDzK,KAAKkN,QAAQ8E,8BAA8B+F,GAC3CzR,EAAM4G,QAAQtC,iBAAkB5J,EAAIhB,KAAKY,gBAAmB6J,aAG3DyC,QAAQtC,iBAAiB5J,IAC5BhB,KAAKkN,QAAQ8E,8BAA8B+F,GAC3CzR,EAAM0R,OAAO9K,QAAQtC,iBAAiB5J,MAG9B,iCAWKR,OACrBqM,EAAY,EACZkL,EAAa,QACX7I,EAAUrN,OAAOI,KAAKjC,KAAK4O,QAAQ2C,SACjChP,QAASX,UACT0E,EAAQtG,KAAK4O,OAAOhN,GACpBqW,EAAI3R,EAAM5C,OAAOmP,YACjB8D,OAAS,IAAI7V,MAAMmX,GAAGlX,KAAK,KAC3B6V,OAAS,IAAI9V,MAAMmX,GAAGlX,KAAK,GAIG,YAAhCuF,EAAM5C,OAAOkP,eAA8B,GACvC1F,QAAQ8C,kBAAoB,MAC7B,IAAIpN,EAAI,EAAGA,EAAIqV,EAAGrV,GAAK,IACpBkQ,MAAMlQ,GAAK5C,KAAK0D,OAAOqP,MAAMgF,GACjCzR,EAAM5C,OAAOqP,MAAMnQ,GACnB0D,EAAM5C,OAAOsP,QAAQpQ,GAAG8J,WAAWlM,KAC/B0M,QAAQ8C,mBAAqB1J,EAAMwM,MAAMlQ,UAG3CkQ,MAAM,GAAK9S,KAAK0D,OAAOqP,MAAMgF,GACjCzR,EAAM5C,OAAOsP,QAAQ,GAAGtG,WAAWlM,IACpC8F,EAAM4G,QAAQ8C,mBAAqB1J,EAAMwM,SAE/BxM,EAAM4G,QAAQ8C,qBACb,MAGRzN,QAASX,UACT0E,EAAQtG,KAAK4O,OAAOhN,GACpBqW,EAAI3R,EAAM5C,OAAOmP,WAClB,IAAIjQ,EAAI,EAAGA,EAAIqV,EAAGrV,GAAK,IACpBkQ,MAAMlQ,IAAMiK,SAKjBqL,WAAa,IAAIpX,MAAMd,KAAK6T,MAAM9S,KAAK,QACvCoX,WAAa,IAAIrX,MAAMd,KAAK6T,MAAM9S,KAAK,QACvCkS,oBAAqB,0BAQLzS,OACjBqM,EAAY,EAGZ9E,EAAM,OAILmQ,WAAalY,KAAKoY,gBAAgB,QAClCD,WAAanY,KAAKoY,gBAAgB,OAInCC,EAAgB,QACdnJ,EAAUrN,OAAOI,KAAKjC,KAAK4O,QAAQ2C,SACjChP,QAASX,UACT0W,EAAWtY,KAAK4O,OAAOhN,GACvBqW,EAAIK,EAAS5U,OAAOmP,OAKpB0F,EAAQ,IAAIzX,MAAMmX,GAAGlX,KAAK,MAEO,YAAnCuX,EAAS5U,OAAOkP,mBACb,IAAI3N,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,EAAG,KACxB,IAAI+B,EAAI,EAAGA,EAAIiR,EAAGjR,GAAK,IACpB/B,IAAOqT,EAAS5U,OAAOyP,WAAWnM,GAAG/B,IACxC,EAAIqT,EAAS5U,OAAOmU,kBAAkB7Q,IACrCsR,EAASxF,MAAM9L,OAInB,IAAIwR,EAAgB,EACpBA,EAAgBxY,KAAK6T,OACrB2E,GAAiB,IAEXvT,IAAMqT,EAAS5U,OAAOqP,MAAM9N,IAC/BjF,KAAKkY,WAAWM,GACjBxY,KAAK0D,OAAOyP,WAAWqF,GAAeH,GACrCrY,KAAK0D,OAAOqP,MAAMsF,GACnBrY,KAAKmY,WAAWK,QAIjB,GAEC,GAAKF,EAAS5U,OAAOyP,WAAW,GAAKmF,EAASxF,MAAM,OAGxD,IAAI0F,EAAgB,EACpBA,EAAgBxY,KAAK6T,OACrB2E,GAAiB,IAEX,IAAOxY,KAAKkY,WAAWM,GAC3BxY,KAAK0D,OAAOyP,WAAWqF,GAAeH,GACrCrY,KAAK0D,OAAOqP,MAAMsF,GACjBrY,KAAKmY,WAAWK,OAIjB,IAAIvT,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,IACpBA,IAAOqT,EAAS5U,OAAOyP,WAAe,EAAJlO,IACrC,EAAIqT,EAAS5U,OAAOmU,kBAAkB5S,IACvCqT,EAASxF,MAAM7N,KACXA,IAAOqT,EAAS5U,OAAOyP,WAAsB,GAATlO,EAAI,GAAU,IACrD,EAAIqT,EAAS5U,OAAOmU,kBAAkB5S,EAAI,IAC3CqT,EAASxF,MAAM7N,EAAI,OAGlB,IAAIA,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,IACjB6N,MAAM7N,GAAK,IACX0R,OAAO1R,GAAK,IACZ2R,OAAO3R,GAAK,IAMhBiI,QAAQuL,eAAiB,IACzBvL,QAAQ8C,kBAAoB,MAGhC,IAAI/K,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,IACpBqT,EAAS5U,OAAOsP,QAAQ/N,GAAGyH,WAAWlM,GAAe+X,EAAMtT,KACxD2R,OAAO3R,GAAKjF,KAAK0D,OAAOiU,eAAeU,GAC9CC,EAAS5U,OAAOmU,kBAAkB5S,GAAK8C,IAChC4O,OAAO1R,IAAM,EAAIjF,KAAK0D,OAAOiU,eAAeU,IACnDC,EAAS5U,OAAOmU,kBAAkB5S,GAAK8C,IAChC+K,MAAM7N,IAAM,EAAIqT,EAAS5U,OAAOmU,kBAAkB5S,IAAM8C,IAExDmF,QAAQuL,gBAAkBH,EAAS3B,OAAO1R,GAAKqT,EAAS1B,OAAO3R,KAC/DiI,QAAQ8C,mBAAqBsI,EAASxF,MAAM7N,GACnDqT,EAAS3B,OAAO1R,GAAKqT,EAAS1B,OAAO3R,MAC1B8C,IAGNmF,QAAQwL,UAAYJ,EAASpL,QAAQuL,eAC5CH,EAASpL,QAAQ8C,qBAEF,MAGXzN,QAASX,UACT0E,EAAQtG,KAAK4O,OAAOhN,GACpBqW,EAAI3R,EAAM5C,OAAOmP,WAClB,IAAI5N,EAAI,EAAGA,EAAIgT,EAAGhT,GAAK,IACpB6N,MAAM7N,IAAM4H,IACZ8J,OAAO1R,IAAM4H,IACb+J,OAAO3R,IAAM4H,qBAUT8L,SACRC,EAAmB,IAAI9X,MAAMd,KAAK6T,QAAQ9S,KAAK,MACjD4X,EAAU,EAAG,KAEXZ,EAAa,SACV9V,KAAKjC,KAAK4O,QAAQ2C,OAAOhP,QAASX,UACjC0E,EAAQtG,KAAK4O,OAAOhN,KACTmW,GAAc,MAC1B,IAAI9S,EAAI,EAAGA,EAAIqB,EAAM5C,OAAOmP,OAAQ5N,GAAK,IAC3B8S,IAAezR,EAAM0R,OAAOlF,MAAM7N,GACjDqB,EAAM0R,OAAOrB,OAAO1R,GACpBqB,EAAM0R,OAAOpB,OAAO3R,MAEV,QAEX,KAED8S,EAAa,SACV9V,KAAKjC,KAAK4O,QAAQ2C,OAAOhP,QAASX,UACjC0E,EAAQtG,KAAK4O,OAAOhN,KACTmW,GAAc,MAC3BjF,MAAEA,GAAUxM,EACA,IAAZqS,MACMrS,EAAMqQ,QAEA,IAAZgC,MACMrS,EAAMsQ,YAEX,IAAI3R,EAAI,EAAGA,EAAIqB,EAAM5C,OAAOmP,OAAQ5N,GAAK,IAC3B8S,IAAejF,EAAM7N,MAE1B,WAGX2T,IAkBI,SAASC,8BAA8BrV,OAC/CD,YAAYC,SACT,IAAIzD,MAAM,sGAOX8B,OAAOC,OACZ0B,EACAiU,uCAKAF,QCpUJ,SAAgBuB,SACd5U,EACAmO,EACApG,SAEM9L,eAAEA,EAAFS,gBAAkBA,GAAoBsD,GACtC2O,SAAAtG,YAAA1D,iBAAA+J,iBAAA1K,kBAMFmK,SACU4D,gBACZ7J,eACEgH,YAAY9P,wDAGP+O,KAELpG,GAEF4G,EACAtG,EACA1D,EACA+J,EACA1K,GAEW1B,MAAMtC,GAcrB,SAAgB6U,mBACd7U,EACAmO,EACApG,SAEM9L,eAAEA,EAAFS,gBAAkBA,GAAoBsD,SAC9B6K,uBACZF,8BAAsB1O,eAAAA,EAAgBS,gBAAAA,GAAoByR,IAC1DrP,GAAM8V,SAAS9V,EAAIqP,EAAepG,IAEvBzF,MAAMtC,GASrB,SAAgB8U,aACdtV,EACAmM,EAAmB,SAEbvJ,EAAQgR,kBAAkBpH,sBAC9BkD,YAAY9P,UAAUI,IACtBmM,aAEIsB,QACC7K,EAUT,SAAgB2S,uBACdvV,EACAmM,EAAmB,SAEbvJ,EAAQgM,yBAAyBzD,oBAAoBnL,aACrDkL,iBACC3M,KAAKyB,EAAOwL,SAAS3M,QAASX,MAC7BgN,OAAOhN,GAASoX,aAAatV,EAAOwL,QAAQtN,GAAQiO,OAEtDsB,QACC7K,EAUT,SAAgB4S,yBACdxV,EACAmM,EAAmB,OAEfvJ,EAAQuI,oBAAoBnL,YAC1BkL,iBACC3M,KAAKyB,EAAOwL,SAAS3M,QAASX,MAC7BgN,OAAOhN,GAASoX,aAAatV,EAAOwL,QAAQtN,GAAQiO,QAEpDgJ,8BAA8BvG,yBAAyBhM,KACzD6K,QACC7K"}