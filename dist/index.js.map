{"version":3,"file":"index.js","sources":["../src/training_set/phrase.js","../src/training_set/index.js","../src/core/model_base_mixin.js","../src/common/euclidean.js","../src/kmeans/kmeans_training_mixin.js","../src/common/matrix.js","../src/common/gaussian_distribution.js","../src/core/em_training_mixin.js","../src/gmm/gmm_base_mixin.js","../src/gmm/gmm_training_mixin.js","../src/core/multiclass_mixin.js","../src/core/multiclass_training_mixin.js","../src/common/circular_buffer.js","../src/core/prediction_mixin.js","../src/common/validation.js","../src/gmm/gmm_prediction_mixin.js","../src/core/multiclass_prediction_mixin.js","../src/gmm/index.js","../src/hmm/hmm_base_mixin.js","../src/hmm/hmm_training_mixin.js","../src/hmm/hmm_prediction_mixin.js","../src/hmm/hierarchical_hmm_prediction_mixin.js","../src/hmm/index.js","../src/kmeans/index.js"],"sourcesContent":["/**\n * Data Phrase Prototype\n * @ignore\n */\nconst phrasePrototype = /** @lends Phrase */ {\n  /**\n   * Get the value at a given index and dimension\n   * @param  {Number} index index\n   * @param  {Number} dim   dimension\n   * @return {Number}\n   */\n  get(index, dim) {\n    if (typeof index !== 'number' || Math.floor(index) !== index) {\n      throw new Error('The index must be an integer');\n    }\n    if (dim >= this.dimension) {\n      throw new Error('Phrase: dimension out of bounds');\n    }\n    if (this.bimodal) {\n      if (dim < this.inputDimension) {\n        if (index >= this.inputData.length) {\n          throw new Error('Phrase: index out of bounds');\n        }\n        return this.inputData[index][dim];\n      }\n      if (index >= this.outputData.length) {\n        throw new Error('Phrase: index out of bounds');\n      }\n      return this.outputData[index][dim - this.inputDimension];\n    }\n    if (index >= this.length) {\n      throw new Error('Phrase: index out of bounds');\n    }\n    if (!this.inputData[index]) {\n      throw new Error('WTF?');\n    }\n    return this.inputData[index][dim];\n  },\n\n  /**\n   * Get the data frame at a given index\n   * @param  {Number} index index\n   * @return {Array<number>}\n   * @throws {Error} if the index is out of bounds\n   */\n  getFrame(index) {\n    if (index >= this.length) {\n      throw new Error('Phrase: index out of bounds');\n    }\n    if (this.bimodal) {\n      return this.inputData[index].concat(this.outputData[index]);\n    }\n    return this.inputData[index];\n  },\n\n  /**\n   * Push an observation vector to the phrase\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the observation's dimension does not match the\n   * dimension of the training set\n   */\n  push(observation) {\n    // console.log('push:', observation);\n    if (observation.length !== this.dimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    if (this.bimodal) {\n      this.inputData.push(observation.slice(0, this.inputDimension));\n      this.outputData.push(observation.slice(this.inputDimension, this.dimension));\n    } else {\n      this.inputData.push(observation);\n    }\n\n    this.length += 1;\n  },\n\n  /**\n   * Push an observation to the input modality only\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the phrase is not bimodal\n   * @throws {Error} if the observation's dimension does not match the\n   * input dimension of the training set\n   */\n  pushInput(observation) {\n    if (!this.bimodal) {\n      throw new Error('this phrase is unimodal, use `push`');\n    }\n    if (observation.length !== this.inputDimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    this.inputData.push(observation);\n    this.trim();\n  },\n\n  /**\n   * Push an observation to the output modality only\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the phrase is not bimodal\n   * @throws {Error} if the observation's dimension does not match the\n   * output dimension of the training set\n   */\n  pushOutput(observation) {\n    if (!this.bimodal) {\n      throw new Error('this phrase is unimodal, use `push`');\n    }\n    if (observation.length !== this.outputDimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    this.outputData.push(observation);\n    this.trim();\n  },\n\n  /**\n   * Clear the phrase's data\n   */\n  clear() {\n    this.length = 0;\n    this.inputData = [];\n    this.outputData = [];\n  },\n\n  /**\n   * Clear the phrase's input data\n   */\n  clearInput() {\n    this.inputData = [];\n    this.trim();\n  },\n\n  /**\n   * Clear the phrase's output data\n   */\n  clearOutput() {\n    this.outputData = [];\n    this.trim();\n  },\n\n  /**\n   * Compute the mean of the phrase (across time)\n   * @return {Array<number>} The mean vector (same dimension as the\n   * training set)\n   */\n  mean() {\n    const mean = Array(this.dimension).fill(0);\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        mean[d] += this.get(t, d);\n      }\n      mean[d] /= this.length;\n    }\n    return mean;\n  },\n\n  /**\n   * Compute the standard deviation of the phrase (across time)\n   * @return {Array<number>} The standard deviation vector (same dimension as\n   * the training set)\n   */\n  standardDeviation() {\n    const stddev = Array(this.dimension).fill(0);\n    const mean = this.mean();\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        stddev[d] += (this.get(t, d) - mean[d]) * (this.get(t, d) - mean[d]);\n      }\n      stddev[d] /= this.length;\n      stddev[d] = Math.sqrt(stddev[d]);\n    }\n    return stddev;\n  },\n\n  /**\n   * Compute the minimum and maximum of the phrase (across time)\n   * @return {Array<{ min: number, max: number }>} The min/max vector (same\n   * dimension as the training set)\n   */\n  minmax() {\n    const minmax = Array.from(\n      Array(this.dimension),\n      () => ({ min: +Infinity, max: -Infinity }),\n    );\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        minmax[d].min = Math.min(this.get(t, d), minmax[d].min);\n        minmax[d].max = Math.max(this.get(t, d), minmax[d].max);\n      }\n    }\n    return minmax;\n  },\n\n  /**\n   * Trim the phrase length to the minimum of the input and output lengths\n   * @private\n   */\n  trim() {\n    if (this.bimodal) {\n      this.length = Math.min(this.inputData.length, this.outputData.length);\n    }\n  },\n};\n\n/**\n * Create a data phrase, potentially bimodal. Phrases are data structures for\n * temporal data (e.g. gestures), used to constitute training sets.\n *\n * @param {Object} [params]                   Phrase parameters\n * @param {Number} [params.inputDimension=1]  Dimension of the input modality\n * @param {Number} [params.outputDimension=0] Dimension of the output modality\n * (optional)\n * @param {Array<String>} [params.columnNames=null] Data column names, e.g.\n * \\['accX', 'accY', 'accZ'\\] (optional)\n * @param {String} [params.label='']          Phrase label\n * @return {Phrase}\n * @function\n *\n * @property {Boolean} bimodal Specifies if the phrase is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} length Phrase length (number of frames)\n * @property {String} label Phrase label\n * @property {Array<String>} columnNames Columns names\n */\nexport default function Phrase({\n  inputDimension = 1,\n  outputDimension = 0,\n  columnNames = null,\n  label = '',\n} = {}) {\n  const dimension = inputDimension + outputDimension;\n  return Object.assign(\n    Object.create(phrasePrototype),\n    {\n      bimodal: outputDimension > 0,\n      inputDimension,\n      outputDimension,\n      dimension,\n      length: 0,\n      label,\n      inputData: [],\n      outputData: [],\n      columnNames: columnNames || Array(dimension).fill(''),\n    },\n  );\n}\n","import Phrase from './phrase';\n\n/**\n * Training Set Prototype\n * @ignore\n */\nconst trainingSetPrototype = /** @lends TrainingSet */ {\n  /**\n   * Get the training set size (number of phrases)\n   * @return {number}\n   */\n  size() {\n    return Object.keys(this.phrases).length;\n  },\n\n  /**\n   * Checks if the training set is empty\n   * @return {boolean}\n   */\n  empty() {\n    return this.length === 0;\n  },\n\n  /**\n   * Get a reference to a phrase by index\n   * @param  {number} phraseIndex phrase index\n   * @return {Phrase}\n   */\n  getPhrase(phraseIndex) {\n    if (Object.keys(this.phrases).includes(phraseIndex.toString())) {\n      return this.phrases[phraseIndex.toString()];\n    }\n    return null;\n  },\n\n  /**\n   * Iterate over all phrases in the training set. The callback function\n   * should take 3 arguments: the phrase, its index in the training set,\n   * and the phrases structure.\n   *\n   * @param  {Function} callback Callback function\n   */\n  forEach(callback) {\n    Object.keys(this.phrases).forEach((phraseIndex) => {\n      callback(this.phrases[phraseIndex], phraseIndex, this.phrases);\n    });\n  },\n\n  /**\n   * Add a phrase to the training set and return it.\n   * @param  {number} phraseIndex        phrase index\n   * @param  {string} [label=undefined]  phrase label (its index if undefined)\n   * @param  {Phrase} [phrase=undefined] Phrase data. If unspecified, an empty\n   * phrase is created.\n   * @return {Phrase}\n   */\n  push(phraseIndex, label = undefined, phrase = undefined) {\n    const p = (phrase !== undefined) ? phrase : Phrase({\n      inputDimension: this.inputDimension,\n      outputDimension: this.outputDimension,\n      columnNames: this.columnNames,\n      label: (label !== undefined) ? label : phraseIndex.toString(),\n    });\n    this.phrases[phraseIndex] = p;\n    return p;\n  },\n\n  /**\n   * Remove a phrase\n   * @param  {number} phraseIndex phrase index\n   */\n  remove(phraseIndex) {\n    delete this.phrases[phraseIndex];\n  },\n\n  /**\n   * Remove all phrases with a given label\n   * @param  {string} label class label\n   */\n  removeClass(label) {\n    this.phrases = Object.keys(this.phrases)\n      .filter(i => this.phrases[i].label !== label)\n      .map(i => ({ i: this.phrases[i] }))\n      .reduce((x, p) => ({ ...x, ...p }), {});\n  },\n\n  /**\n   * Clear the training set (delete all phrases)\n   */\n  clear() {\n    this.phrases = {};\n  },\n\n  /**\n   * Get the sub-training set composed of all phrases of a given class\n   * @param  {string} label class label\n   * @return {TrainingSet}\n   */\n  getPhrasesOfClass(label) {\n    const ts = TrainingSet(this); // eslint-disable-line no-use-before-define\n    ts.phrases = Object.keys(this.phrases)\n      .filter(i => this.phrases[i].label === label)\n      .map(i => ({ [i]: this.phrases[i] }))\n      .reduce((x, p) => ({ ...x, ...p }), {});\n    return ts;\n  },\n\n  /**\n   * Get the list of unique labels in the training set\n   * @return {Array<string>}\n   */\n  labels() {\n    return Object.keys(this.phrases)\n      .map(i => this.phrases[i].label)\n      .reduce((ll, x) => (ll.includes(x) ? ll : ll.concat([x])), []);\n  },\n\n  /**\n   * Get the list of phrase indices\n   * @return {Array<number>}\n   */\n  indices() {\n    return Object.keys(this.phrases);\n  },\n\n  /**\n   * Get the mean of the training set over all phrases\n   * @return {Array<number>} mean (same dimension as the training set)\n   */\n  mean() {\n    const sum = Array(this.dimension).fill(0);\n    let totalLength = 0;\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          sum[d] += this.phrases[i].get(t, d);\n        }\n      }\n      totalLength += this.phrases[i].length;\n    });\n\n    return sum.map(x => x / totalLength);\n  },\n\n  /**\n   * Get the standard deviation of the training set over all phrases\n   * @return {Array<number>} standard deviation (same dimension as the training set)\n   */\n  standardDeviation() {\n    const stddev = Array(this.dimension).fill(0);\n    const mean = this.mean();\n    let totalLength = 0;\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          stddev[d] += (this.phrases[i].get(t, d) - mean[d]) ** 2;\n        }\n      }\n      totalLength += this.phrases[i].length;\n    });\n\n    return stddev.map(x => Math.sqrt(x / totalLength));\n  },\n\n  /**\n   * Get the min and max of the training set over all phrases\n   * @return {Array<{ min: number, max: number }>} min/max (same dimension as the training set)\n   */\n  minmax() {\n    const minmax = Array.from(\n      Array(this.dimension),\n      () => ({ min: +Infinity, max: -Infinity }),\n    );\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          minmax[d].min += Math.min(minmax[d].min, this.phrases[i].get(t, d));\n          minmax[d].max += Math.max(minmax[d].max, this.phrases[i].get(t, d));\n        }\n      }\n    });\n    return minmax;\n  },\n};\n\n/**\n * Create a Training set, composed of a set of indexed data phrases\n * @param {Object} [params]                   Training set parameters\n * @param {Number} [params.inputDimension=1]  Dimension of the input modality\n * @param {Number} [params.outputDimension=0] Dimension of the output modality\n * (optional)\n * @param {Array<String>} [params.columnNames=null] Data column names, e.g.\n * \\['accX', 'accY', 'accZ'\\] (optional)\n * @return {TrainingSet}\n * @function\n *\n * @property {Boolean} bimodal Specifies if the training set is bimodal\n * @property {Number}  inputDimension Dimension of the input modality\n * @property {Number}  outputDimension Dimension of the output modality\n * @property {Number}  dimension Total dimension\n * @property {Array<String>} columnNames Columns names\n *\n * @example\n * // Create a training dataset for data with 3 channels\n * const ts = TrainingSet({ inputDimension: 2 });\n *\n * // Add a new phrase to the training set, and record data frames\n * const phrase = ts.push(0, 'default');\n * for (let i = 0; i < 1000; i += 1) {\n *   const frame = ...; // get data from somewhere\n *   phrase.push(frame);\n * }\n *\n * console.log(ts);\n */\nexport default function TrainingSet({\n  inputDimension = 1,\n  outputDimension = 0,\n  columnNames = null,\n} = {}) {\n  const dimension = inputDimension + outputDimension;\n  return Object.assign(\n    Object.create(trainingSetPrototype),\n    {\n      bimodal: outputDimension > 0,\n      inputDimension,\n      outputDimension,\n      dimension,\n      columnNames: columnNames || Array(dimension).fill(''),\n      phrases: {},\n    },\n  );\n}\n","/**\n * Create the skeleton of a model\n *\n * @function\n * @param       {Number} inputDimension  input dimension\n * @param       {Number} outputDimension output dimension\n * @param       {Object} parameters      additional parameters to be copied\n * @constructor\n */\nexport default function ModelBase({\n  inputDimension,\n  outputDimension,\n  ...parameters\n}) {\n  const p = parameters;\n  delete p.bimodal;\n  delete p.inputDimension;\n  delete p.outputDimension;\n  delete p.dimension;\n  return /** @lends ModelBase */{\n    params: {\n      ...p,\n      get bimodal() {\n        return outputDimension > 0;\n      },\n      get inputDimension() {\n        return inputDimension;\n      },\n      get outputDimension() {\n        return outputDimension;\n      },\n      get dimension() {\n        return inputDimension + outputDimension;\n      },\n    },\n  };\n}\n\n/**\n * Check if an object is a base model (check for attribute existence)\n * @param  {Object}  o Source object\n * @return {Boolean}\n */\nexport function isBaseModel(o) {\n  if (!Object.keys(o).includes('params')) return false;\n  const keys = ['bimodal', 'inputDimension', 'outputDimension', 'dimension'];\n  return keys.map(key => Object.keys(o.params).includes(key))\n    .reduce((a, b) => a && b, true);\n}\n","/**\n * Compute the euclidean distance between to vectors\n * @param  {Array} v1\n * @param  {Array} v2\n * @return {number}\n */\nexport default function euclidean(v1, v2) {\n  return Math.sqrt(v1\n    .map((x1, i) => (x1 - v2[i]) ** 2)\n    .reduce((a, x) => (a + x), 0));\n}\n","import { isBaseModel } from '../core/model_base_mixin';\nimport euclidean from '../common/euclidean';\n\nconst kMeansTrainingPrototype = {\n  train(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) {\n      throw new Error('The training set is empty');\n    }\n\n    this.params.centers = Array.from(\n      Array(this.params.clusters),\n      () => new Array(this.params.dimension).fill(0),\n    );\n\n    // TODO: improve initialization =>\n    // https://www.slideshare.net/djempol/kmeans-initialization-15041920\n    //\n    if (this.trainingConfig.initialization === 'random') {\n      this.initializeClustersRandom(trainingSet);\n    } else if (this.trainingConfig.initialization === 'forgy') {\n      this.initializeClustersForgy(trainingSet);\n    } else if (this.trainingConfig.initialization === 'data') {\n      this.initClustersWithFirstPhrase(trainingSet);\n    } else {\n      throw new Error('Unknown K-Means initialization, must be `random`, `forgy` or `data`');\n    }\n\n    for (\n      let trainingNbIterations = 0;\n      trainingNbIterations < this.trainingConfig.maxIterations;\n      trainingNbIterations += 1\n    ) {\n      const previousCenters = this.params.centers;\n\n      this.updateCenters(previousCenters, trainingSet);\n\n      let meanClusterDistance = 0;\n      let maxRelativeCenterVariation = 0;\n      for (let k = 0; k < this.params.clusters; k += 1) {\n        for (let l = 0; l < this.params.clusters; l += 1) {\n          if (k !== l) {\n            meanClusterDistance += euclidean(\n              this.params.centers[k],\n              this.params.centers[l],\n            );\n          }\n        }\n        maxRelativeCenterVariation = Math.max(\n          euclidean(\n            previousCenters[k],\n            this.params.centers[k],\n          ),\n          maxRelativeCenterVariation,\n        );\n      }\n      meanClusterDistance /= this.params.clusters * (this.params.clusters - 1);\n      maxRelativeCenterVariation /= this.params.clusters;\n      maxRelativeCenterVariation /= meanClusterDistance;\n      if (maxRelativeCenterVariation < this.trainingConfig.relativeDistanceThreshold) break;\n    }\n    return this.params;\n  },\n\n  initClustersWithFirstPhrase(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const step = Math.floor(phrase.length / this.params.clusters);\n\n    let offset = 0;\n    for (let c = 0; c < this.params.clusters; c += 1) {\n      this.params.centers[c] = new Array(this.params.dimension).fill(0);\n      for (let t = 0; t < step; t += 1) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[c][d] += phrase.get(offset + t, d) / step;\n        }\n      }\n      offset += step;\n    }\n  },\n\n  initializeClustersRandom(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const indices = Array.from(\n      Array(phrase.length),\n      () => Math.floor(Math.random() * this.params.clusters),\n    );\n    const pointsPerCluster = indices.reduce(\n      (ppc, i) => {\n        const p = ppc;\n        p[i] += 1;\n        return p;\n      },\n      Array(this.params.clusters).fill(0),\n    );\n    for (let i = 0; i < indices.length; i += 1) {\n      const clustIdx = indices[i];\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.centers[clustIdx][d] += phrase.get(i, d);\n      }\n    }\n    this.params.centers.forEach((_, c) => {\n      this.params.centers[c] = this.params.centers[c]\n        .map(x => x / pointsPerCluster[c]);\n    });\n  },\n\n  initializeClustersForgy(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const indices = Array.from(\n      Array(this.params.clusters),\n      () => Math.floor(Math.random() * phrase.length),\n    );\n    this.params.centers = indices.map(i => phrase.getFrame(i));\n  },\n\n  updateCenters(previousCenters, trainingSet) {\n    this.params.centers = Array.from(Array(this.params.clusters), () =>\n      new Array(this.params.dimension).fill(0));\n    const numFramesPerCluster = Array(this.params.clusters).fill(0);\n    trainingSet.forEach((phrase) => {\n      for (let t = 0; t < phrase.length; t += 1) {\n        const frame = phrase.getFrame(t);\n        let minDistance = euclidean(frame, previousCenters[0]);\n        let clusterMembership = 0;\n        for (let k = 1; k < this.params.clusters; k += 1) {\n          const distance = euclidean(\n            frame,\n            previousCenters[k],\n            this.params.dimension,\n          );\n          if (distance < minDistance) {\n            clusterMembership = k;\n            minDistance = distance;\n          }\n        }\n        numFramesPerCluster[clusterMembership] += 1;\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[clusterMembership][d] += phrase.get(t, d);\n        }\n      }\n    });\n    for (let k = 0; k < this.params.clusters; k += 1) {\n      if (numFramesPerCluster[k] > 0) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[k][d] /= numFramesPerCluster[k];\n        }\n      }\n    }\n  },\n};\n\nexport default function withKMeansTraining(\n  o,\n  clusters,\n  trainingConfiguration = {},\n) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const trainingConfig = Object.assign({\n    initialization: 'random',\n    relativeDistanceThreshold: 1e-3,\n    minIterations: 5,\n    maxIterations: 100,\n  }, trainingConfiguration);\n  const model = Object.assign(o, kMeansTrainingPrototype, {\n    trainingConfig,\n  });\n  model.params.clusters = clusters;\n  return model;\n}\n","/* eslint-disable no-use-before-define */\nconst kEpsilonPseudoInverse = 1.0e-9;\n\n/**\n * Matrix Prototype\n * @type {Object}\n * @property {Array} data Matrix data\n * @property {Number} ncols Number of columns\n * @property {Number} nrows Number of rows\n *\n * @ignore\n */\nconst matrixPrototype = /** @lends Matrix */ {\n  /**\n   * Compute the Sum of the matrix\n   * @return {Number} Sum of all elements in the matrix\n   */\n  sum() {\n    return this.data.reduce((a, b) => a + b, 0);\n  },\n\n  /**\n   * Compute the transpose matrix\n   * @return {Matrix}\n   */\n  transpose() {\n    const out = Matrix(this.ncols, this.nrows);\n    for (let i = 0; i < this.ncols; i += 1) {\n      for (let j = 0; j < this.nrows; j += 1) {\n        out.data[(i * this.nrows) + j] = this.data[(j * this.ncols) + i];\n      }\n    }\n    return out;\n  },\n\n  /**\n   * Compute the product of matrices\n   * @param  {Matrix} mat Second matrix\n   * @return {Matrix}     Product of the current matrix by `mat`\n   */\n  product(mat) {\n    if (this.ncols !== mat.nrows) {\n      throw new Error('Wrong dimensions for matrix product');\n    }\n    const out = Matrix(this.nrows, mat.ncols);\n    for (let i = 0; i < this.nrows; i += 1) {\n      for (let j = 0; j < mat.ncols; j += 1) {\n        out.data[(i * mat.ncols) + j] = 0;\n        for (let k = 0; k < this.ncols; k += 1) {\n          out.data[(i * mat.ncols) + j] +=\n            this.data[(i * this.ncols) + k] * mat.data[(k * mat.ncols) + j];\n        }\n      }\n    }\n    return out;\n  },\n\n  /**\n   * Compute the Pseudo-Inverse of a Matrix\n   * @param  {Number} determinant Determinant (computed with the inversion)\n   * @return {Matrix}             Pseudo-inverse of the matrix\n   */\n  pinv() {\n    if (this.nrows === this.ncols) {\n      return this.gaussJordanInverse();\n    }\n\n    const transp = this.transpose();\n    if (this.nrows >= this.ncols) {\n      const prod = transp.product(this);\n      const { determinant, matrix: dst } = prod.gaussJordanInverse();\n      return { determinant, matrix: dst.product(transp) };\n    }\n    const prod = this.product(transp);\n    const { determinant, matrix: dst } = prod.gaussJordanInverse();\n    return { determinant, matrix: transp.product(dst) };\n  },\n\n  /**\n   * Compute the Gauss-Jordan Inverse of a Square Matrix\n   * !!! Determinant (computed with the inversion\n   * @private\n   */\n  gaussJordanInverse() {\n    if (this.nrows !== this.ncols) {\n      throw new Error('Gauss-Jordan inversion: Cannot invert Non-square matrix');\n    }\n    let determinant = 1;\n    const mat = Matrix(this.nrows, this.ncols * 2);\n    const newMat = Matrix(this.nrows, this.ncols * 2);\n    const n = this.nrows;\n\n    // Create matrix\n    for (let i = 0; i < n; i += 1) {\n      for (let j = 0; j < n; j += 1) {\n        mat.data[(i * 2 * n) + j] = this.data[(i * n) + j];\n      }\n      mat.data[(i * 2 * n) + n + i] = 1;\n    }\n\n    for (let k = 0; k < n; k += 1) {\n      let i = k;\n      while (Math.abs(mat.data[(i * 2 * n) + k]) < kEpsilonPseudoInverse) {\n        i += 1;\n        if (i === n) {\n          throw new Error('Non-invertible matrix');\n        }\n      }\n      determinant *= mat.data[(i * 2 * n) + k];\n\n      // if found > Exchange lines\n      if (i !== k) {\n        mat.swapLines(i, k);\n      }\n\n      newMat.data = mat.data.slice();\n\n      for (let j = 0; j < 2 * n; j += 1) {\n        newMat.data[(k * 2 * n) + j] /= mat.data[(k * 2 * n) + k];\n      }\n      for (let ii = 0; ii < n; ii += 1) {\n        if (ii !== k) {\n          for (let j = 0; j < 2 * n; j += 1) {\n            newMat.data[(ii * 2 * n) + j] -=\n                mat.data[(ii * 2 * n) + k] *\n                newMat.data[(k * 2 * n) + j];\n          }\n        }\n      }\n      mat.data = newMat.data.slice();\n    }\n\n    const dst = Matrix(this.nrows, this.ncols);\n    for (let i = 0; i < n; i += 1) {\n      for (let j = 0; j < n; j += 1) {\n        dst.data[(i * n) + j] = mat.data[(i * 2 * n) + n + j];\n      }\n    }\n    return { determinant, matrix: dst };\n  },\n\n  /**\n   * Swap 2 lines of the matrix\n   * @param  {[type]} i index of the first line\n   * @param  {[type]} j index of the second line\n   * @private\n   */\n  swapLines(i, j) {\n    for (let k = 0; k < this.ncols; k += 1) {\n      const tmp = this.data[(i * this.ncols) + k];\n      this.data[(i * this.ncols) + k] = this.data[(j * this.ncols) + k];\n      this.data[(j * this.ncols) + k] = tmp;\n    }\n  },\n\n  /**\n   * Swap 2 columns of the matrix\n   * @param  {[type]} i index of the first column\n   * @param  {[type]} j index of the second column\n   * @private\n   */\n  swapColumns(i, j) {\n    for (let k = 0; k < this.nrows; k += 1) {\n      const tmp = this.data[(k * this.ncols) + i];\n      this.data[(k * this.ncols) + i] = this.data[(k * this.ncols) + j];\n      this.data[(k * this.ncols) + j] = tmp;\n    }\n  },\n};\n\n/**\n * Create a matrix\n *\n * @function\n * @param       {Number} [nrows=0]  Number of rows\n * @param       {Number} [ncols=-1] Number of columns\n * @return {matrixPrototype}\n *\n * @property {Array} data Matrix data\n * @property {Number} ncols Number of columns\n * @property {Number} nrows Number of rows\n */\nexport default function Matrix(nrows = 0, ncols = -1) {\n  const nc = ncols < 0 ? nrows : ncols;\n  return Object.assign(\n    Object.create(matrixPrototype), //\n    {\n      nrows,\n      ncols: nc,\n      data: Array(nrows * nc).fill(0),\n    },\n  );\n}\n","import Matrix from './matrix';\n\n/**\n * Gaussian Distribution Prototype\n *\n * @type {Object}\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n *\n * @ignore\n */\nconst baseGaussianPrototype = /** @lends GaussianDistribution */ {\n  /**\n   * Allocate the distribution\n   * @private\n   */\n  allocate() {\n    this.mean = new Array(this.dimension).fill(0);\n    if (this.covarianceMode === 'full') {\n      this.covariance = new Array(this.dimension ** 2).fill(0);\n      this.inverseCovariance = new Array(this.dimension ** 2).fill(0);\n    } else {\n      this.covariance = new Array(this.dimension).fill(0);\n      this.inverseCovariance = new Array(this.dimension).fill(0);\n    }\n    if (this.bimodal) {\n      this.allocateBimodal();\n    }\n  },\n\n  /**\n   * @brief Estimate the likelihood of an observation vector.\n   *\n   * If the distribution is bimodal an the observation is a vector of the size\n   * of the input modality, the likelihood is computed only on the\n   * distribution for the input modality\n   *\n   * @param  {array} observation data observation\n   * @return {number}\n   */\n  likelihood(observation) {\n    if (this.covarianceDeterminant === 0) {\n      throw new Error('Covariance Matrix is not invertible');\n    }\n    if (this.bimodal && observation.length === this.inputDimension) {\n      return this.inputLikelihood(observation);\n    }\n    if (observation.length !== this.dimension) {\n      throw new Error(`GaussianDistribution: observation has wrong dimension. Expected \\`${this.dimension}\\`, got \\`${observation.length}\\``);\n    }\n\n    let euclideanDistance = 0;\n    if (this.covarianceMode === 'full') {\n      for (let l = 0; l < this.dimension; l += 1) {\n        let tmp = 0;\n        for (let k = 0; k < this.dimension; k += 1) {\n          tmp += this.inverseCovariance[(l * this.dimension) + k] *\n            (observation[k] - this.mean[k]);\n        }\n        euclideanDistance += (observation[l] - this.mean[l]) * tmp;\n      }\n    } else {\n      for (let l = 0; l < this.dimension; l += 1) {\n        euclideanDistance += this.inverseCovariance[l] *\n          (observation[l] - this.mean[l]) *\n          (observation[l] - this.mean[l]);\n      }\n    }\n\n    let p = Math.exp(-0.5 * euclideanDistance) /\n      Math.sqrt(this.covarianceDeterminant * ((2 * Math.PI) ** this.dimension));\n\n    if (p < 1e-180 || Number.isNaN(p) || Math.abs(p) === +Infinity) {\n      p = 1e-180;\n    }\n\n    return p;\n  },\n\n  /**\n   * Regularize the distribution, given a regularization vector of the same\n   * dimension. Regularization adds the vector to the variance of the\n   * distribution.\n   *\n   * @param  {Array} regularization regularization vector\n   */\n  regularize(regularization) {\n    if (this.covarianceMode === 'full') {\n      for (let d = 0; d < this.dimension; d += 1) {\n        this.covariance[(d * this.dimension) + d] += regularization[d];\n      }\n    } else {\n      for (let d = 0; d < this.dimension; d += 1) {\n        this.covariance[d] += regularization[d];\n      }\n    }\n  },\n\n  /**\n   * Update the inverse covariance of the distribution\n   * @private\n   */\n  updateInverseCovariance() {\n    if (this.covarianceMode === 'full') {\n      const covMatrix = Matrix(this.dimension, this.dimension);\n\n      covMatrix.data = this.covariance.slice();\n      const inv = covMatrix.pinv();\n      this.covarianceDeterminant = inv.determinant;\n      this.inverseCovariance = inv.matrix.data;\n    } else { // DIAGONAL COVARIANCE\n      this.covarianceDeterminant = 1;\n      for (let d = 0; d < this.dimension; d += 1) {\n        if (this.covariance[d] <= 0) {\n          throw new Error('Non-invertible matrix');\n        }\n        this.inverseCovariance[d] = 1 / this.covariance[d];\n        this.covarianceDeterminant *= this.covariance[d];\n      }\n    }\n    if (this.bimodal) {\n      this.updateInverseCovarianceBimodal();\n    }\n  },\n\n  /**\n   * Convert to an ellipse allong two dimensions\n   *\n   * @param  {number} dimension1 first dimension\n   * @param  {number} dimension2 second dimension\n   * @return {Ellipse}\n   */\n  toEllipse(dimension1, dimension2) {\n    if (dimension1 >= this.dimension || dimension2 >= this.dimension) {\n      throw new Error('dimensions out of range');\n    }\n\n    const gaussianEllipse = {\n      x: 0,\n      y: 0,\n      width: 0,\n      height: 0,\n      angle: 0,\n    };\n    gaussianEllipse.x = this.mean[dimension1];\n    gaussianEllipse.y = this.mean[dimension2];\n\n    // Represent 2D covariance with square matrix\n    // |a b|\n    // |b c|\n    let a;\n    let b;\n    let c;\n    if (this.covarianceMode === 'full') {\n      a = this.covariance[(dimension1 * this.dimension) + dimension1];\n      b = this.covariance[(dimension1 * this.dimension) + dimension2];\n      c = this.covariance[(dimension2 * this.dimension) + dimension2];\n    } else {\n      a = this.covariance[dimension1];\n      b = 0;\n      c = this.covariance[dimension2];\n    }\n\n    // Compute Eigen Values to get width, height and angle\n    const trace = a + c;\n    const determinant = (a * c) - (b * b);\n    const eigenVal1 = 0.5 * (trace + Math.sqrt((trace ** 2) - (4 * determinant)));\n    const eigenVal2 = 0.5 * (trace - Math.sqrt((trace ** 2) - (4 * determinant)));\n    gaussianEllipse.width = Math.sqrt(5.991 * eigenVal1);\n    gaussianEllipse.height = Math.sqrt(5.991 * eigenVal2);\n    gaussianEllipse.angle = Math.atan(b / (eigenVal1 - c));\n    if (Number.isNaN(gaussianEllipse.angle)) {\n      gaussianEllipse.angle = Math.PI / 2;\n    }\n\n    return gaussianEllipse;\n  },\n\n  /**\n   * Modify the distribution along two dimensions given the equivalent values\n   * as an Ellipse representation.\n   *\n   * @param  {Ellipse} gaussianEllipse The Ellipse corresponding to the 2D\n   * covariance along the two target dimensions\n   * @param  {number} dimension1      first dimension\n   * @param  {number} dimension2      second dimension\n   */\n  fromEllipse(gaussianEllipse, dimension1, dimension2) {\n    if (dimension1 >= this.dimension || dimension2 >= this.dimension) {\n      throw new Error('dimensions out of range');\n    }\n\n    this.mean[dimension1] = gaussianEllipse.x;\n    this.mean[dimension2] = gaussianEllipse.y;\n\n    const eigenVal1 = (gaussianEllipse.width * gaussianEllipse.width) / 5.991;\n    const eigenVal2 = (gaussianEllipse.height * gaussianEllipse.height) / 5.991;\n    const tantheta = Math.tan(gaussianEllipse.angle);\n    const b = ((eigenVal1 - eigenVal2) * tantheta) / ((tantheta ** 2) + 1);\n    const c = eigenVal1 - (b / tantheta);\n    const a = eigenVal2 + (b / tantheta);\n\n    if (this.covarianceMode === 'full') {\n      this.covariance[(dimension1 * this.dimension) + dimension1] = a;\n      this.covariance[(dimension1 * this.dimension) + dimension2] = b;\n      this.covariance[(dimension2 * this.dimension) + dimension1] = b;\n      this.covariance[(dimension2 * this.dimension) + dimension2] = c;\n    } else {\n      this.covariance[dimension1] = a;\n      this.covariance[dimension2] = c;\n    }\n    this.updateInverseCovariance();\n  },\n};\n\n/**\n * Bimodal Gaussian Distribution Prototype, for Regression purposes\n *\n * @type {Object}\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n * @property {Array}   inverseCovarianceInput Inverse covariance of the input\n * modality\n *\n * @ignore\n */\nconst bimodalGaussianPrototype = /** @lends GaussianDistribution */ {\n  /**\n   * Allocate the distribution\n   * @private\n   */\n  allocateBimodal() {\n    if (this.covarianceMode === 'full') {\n      this.inverseCovarianceInput = new Array(this.inputDimension ** 2).fill(0);\n    } else {\n      this.inverseCovarianceInput = new Array(this.inputDimension).fill(0);\n    }\n  },\n\n  /**\n   * Estimate the likelihood of an observation for the input modality only.\n   * Called by `likelihood` when relevant.\n   * @param  {Array} inputObservation observation (input modality only)\n   * @return {number}\n   * @private\n   */\n  inputLikelihood(inputObservation) {\n    if (this.covarianceDeterminantInput === 0) {\n      throw new Error('Covariance Matrix of input modality is not invertible');\n    }\n\n    let euclideanDistance = 0;\n    if (this.covarianceMode === 'full') {\n      for (let l = 0; l < this.inputDimension; l += 1) {\n        let tmp = 0;\n        for (let k = 0; k < this.inputDimension; k += 1) {\n          tmp += this.inverseCovarianceInput[(l * this.inputDimension) + k] *\n            (inputObservation[k] - this.mean[k]);\n        }\n        euclideanDistance += (inputObservation[l] - this.mean[l]) * tmp;\n      }\n    } else {\n      for (let l = 0; l < this.inputDimension; l += 1) {\n        euclideanDistance += this.inverseCovariance[l] *\n          (inputObservation[l] - this.mean[l]) *\n          (inputObservation[l] - this.mean[l]);\n      }\n    }\n\n    let p = Math.exp(-0.5 * euclideanDistance) /\n               Math.sqrt(this.covarianceDeterminantInput *\n                    ((2 * Math.PI) ** this.inputDimension));\n\n    if (p < 1e-180 || Number.isNaN(p) || Math.abs(p) === +Infinity) p = 1e-180;\n\n    return p;\n  },\n\n  /**\n   * Estimate the output values associated with an input observation by\n   * regression, given the distribution parameters.\n   *\n   * @todo Clarify the maths here.\n   *\n   * @param  {Array} inputObservation observation (input modality only)\n   * @return {Array} Output values\n   */\n  regression(inputObservation) {\n    const outputDimension = this.dimension - this.inputDimension;\n    const prediction = Array(outputDimension).fill(0);\n\n    if (this.covarianceMode === 'full') {\n      for (let d = 0; d < outputDimension; d += 1) {\n        prediction[d] = this.mean[this.inputDimension + d];\n        for (let e = 0; e < this.inputDimension; e += 1) {\n          let tmp = 0;\n          for (let f = 0; f < this.inputDimension; f += 1) {\n            tmp += this.inverseCovarianceInput[(e * this.inputDimension) + f] *\n              (inputObservation[f] - this.mean[f]);\n          }\n          prediction[d] += tmp *\n            this.covariance[((d + this.inputDimension) * this.dimension) + e];\n        }\n      }\n    } else {\n      for (let d = 0; d < outputDimension; d += 1) {\n        prediction[d] = this.mean[this.inputDimension + d];\n      }\n    }\n    return prediction;\n  },\n\n  /**\n   * Update the inverse covariance\n   * @private\n   */\n  updateInverseCovarianceBimodal() {\n    if (this.covarianceMode === 'full') {\n      const covMatrixInput = Matrix(this.inputDimension, this.inputDimension);\n      for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n        for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n          covMatrixInput.data[(d1 * this.inputDimension) + d2] =\n            this.covariance[(d1 * this.dimension) + d2];\n        }\n      }\n      const invInput = covMatrixInput.pinv();\n      this.covarianceDeterminantInput = invInput.determinant;\n      this.inverseCovarianceInput = invInput.matrix.data;\n    } else { // DIAGONAL COVARIANCE\n      this.covarianceDeterminantInput = 1;\n      for (let d = 0; d < this.inputDimension; d += 1) {\n        if (this.covariance[d] <= 0) {\n          throw new Error('Non-invertible matrix');\n        }\n        this.inverseCovarianceInput[d] = 1 / this.covariance[d];\n        this.covarianceDeterminantInput *= this.covariance[d];\n      }\n    }\n    this.updateOutputCovariance();\n  },\n\n  /**\n   * Update the output covariance\n   * @private\n   */\n  updateOutputCovariance() {\n    if (this.covarianceMode === 'diagonal') {\n      this.outputCovariance = this.covariance.slice(0, this.inputDimension);\n      return;\n    }\n\n    // CASE: FULL COVARIANCE\n    const covMatrixInput = Matrix(this.inputDimension, this.inputDimension);\n    for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n        covMatrixInput.data[(d1 * this.inputDimension) + d2] =\n          this.covariance[(d1 * this.dimension) + d2];\n      }\n    }\n    const inv = covMatrixInput.pinv();\n    const covarianceGS = Matrix(this.inputDimension, this.outputDimension);\n    for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n        covarianceGS.data[(d1 * this.outputDimension) + d2] =\n          this.covariance[(d1 * this.dimension) + this.inputDimension + d2];\n      }\n    }\n    const covarianceSG = Matrix(this.outputDimension, this.inputDimension);\n    for (let d1 = 0; d1 < this.outputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n        covarianceSG.data[(d1 * this.inputDimension) + d2] =\n          this.covariance[((this.inputDimension + d1) * this.dimension) + d2];\n      }\n    }\n    const tmptmptmp = inv.matrix.product(covarianceGS);\n    const covarianceMod = covarianceSG.product(tmptmptmp);\n    this.outputCovariance = Array(this.outputDimension ** 2).fill(0);\n    for (let d1 = 0; d1 < this.outputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n        this.outputCovariance[(d1 * this.outputDimension) + d2] =\n          this.covariance[((this.inputDimension + d1) * this.dimension) +\n            this.inputDimension + d2] -\n            covarianceMod.data[(d1 * this.outputDimension) + d2];\n      }\n    }\n  },\n};\n\n/**\n * Multivariate Gaussian Distribution factory function.\n * Full covariance, optionally multimodal with support for regression.\n *\n * @function\n * @param {Number} [inputDimension=1]      Dimension of the input modality\n * @param {Number} [outputDimension=0]     Dimension of the output\n * modality (positive for regression, otherwise 0 for recognition).\n * @param {String} [covarianceMode='full'] covariance mode (full vs\n * diagonal)\n * @return {baseGaussianPrototype|bimodalGaussianPrototype}\n *\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n */\nexport default function GaussianDistribution(\n  inputDimension = 1,\n  outputDimension = 0,\n  covarianceMode = 'full',\n) {\n  const bimodal = outputDimension > 0;\n  const dimension = inputDimension + outputDimension;\n  const proto = bimodal ?\n    Object.assign({}, baseGaussianPrototype, bimodalGaussianPrototype) :\n    baseGaussianPrototype;\n  const data = Object.assign(\n    {\n      bimodal,\n      dimension,\n      inputDimension,\n      outputDimension,\n      covarianceMode,\n      covarianceDeterminant: 0,\n    },\n    bimodal ? { covarianceDeterminantInput: 0 } : {},\n  );\n  const dist = Object.assign(\n    Object.create(proto),\n    data,\n  );\n  dist.allocate();\n  return dist;\n}\n","const trainerPrototype = /** @lends withEMTraining */ {\n  /**\n   * Train the model from the given training set, using the\n   * Expectation-Maximisation algorithm.\n   *\n   * @param  {TrainingSet} trainingSet Training Set\n   * @return {Object} Parameters of the trained model\n   */\n  train(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) {\n      throw new Error('The training set is empty');\n    }\n\n    this.initTraining(trainingSet);\n\n    let logLikelihood = -Infinity;\n    let iterations = 0;\n    let previousLogLikelihood = logLikelihood;\n\n    while (!this.converged(iterations, logLikelihood, previousLogLikelihood)) {\n      previousLogLikelihood = logLikelihood;\n      logLikelihood = this.updateTraining(trainingSet);\n\n      const pctChg =\n        100 * Math.abs((logLikelihood - previousLogLikelihood) / previousLogLikelihood);\n      if (Number.isNaN(pctChg) && iterations > 1) {\n        throw new Error('An error occured during training');\n      }\n\n      iterations += 1;\n    }\n\n    this.terminateTraining();\n    return this.params;\n  },\n\n  /**\n   * Return `true` if the training has converged according to the criteria\n   * specified at the creation\n   *\n   * @param  {number} iteration       Current iteration\n   * @param  {number} logProb         Current log-likelihood of the training set\n   * @param  {number} previousLogProb Previous log-likelihood of the training\n   * set\n   * @return {boolean}\n   *\n   * @private\n   */\n  converged(iteration, logProb, previousLogProb) {\n    if (iteration >= this.convergenceCriteria.maxIterations) return true;\n    if (this.convergenceCriteria.maxIterations >= this.convergenceCriteria.minIterations) {\n      return iteration >= this.convergenceCriteria.maxIterations;\n    }\n    if (iteration < this.convergenceCriteria.minIterations) return false;\n    const percentChange = 100 * Math.abs((logProb - previousLogProb) / logProb);\n    return percentChange <= this.convergenceCriteria.percentChange;\n  },\n};\n\n/**\n * Add ABSTRACT training capabilities to a model for which the training process\n * use the Expectation-Maximisation (EM) algorithm. This is used in particular\n * for training GMMs and HMMs.\n *\n * The final instance needs to implement `initTraining`, `updateTraining` and\n * `terminateTraining` methods. `updateTraining` will be called until the\n * convergence criteria are met. Convergence depends on\n * - A minimum number of iterations\n * - A maximum number of iterations\n * - A threshold on the relative change of the log-likelihood of the training\n * data between successive iterations.\n *\n * @todo details\n *\n * @param  {Object} [o]                   Source object\n * @param  {Object} [convergenceCriteria] Set of convergence criteria\n * @param  {number} [convergenceCriteria.percentChange=1e-3] Threshold in % of\n * the relative change of the log-likelihood, under which the training stops.\n * @param  {number} [convergenceCriteria.minIterations=5]    minimum number of iterations\n * @param  {number} [convergenceCriteria.maxIterations=100]  maximum number of iterations\n * @return {Object}\n */\nexport default function withEMTraining(\n  o,\n  convergenceCriteria = {\n    percentChange: 1e-3,\n    minIterations: 5,\n    maxIterations: 100,\n  },\n) {\n  return Object.assign(o, trainerPrototype, { convergenceCriteria });\n}\n","import { isBaseModel } from '../core/model_base_mixin';\nimport GaussianDistribution from '../common/gaussian_distribution';\n\n/**\n * GMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst gmmBasePrototype = /** @lends withGMMBase */ {\n  /**\n   * Allocate the training variables\n   * @private\n   */\n  allocate() {\n    this.params.components = Array.from(\n      Array(this.params.gaussians),\n      () => new GaussianDistribution(\n        this.params.inputDimension,\n        this.params.outputDimension,\n        this.params.covarianceMode,\n      ),\n    );\n    this.params.mixtureCoeffs = Array(this.params.gaussians).fill(0);\n    this.beta = new Array(this.params.gaussians).fill(0);\n  },\n\n  /**\n   * Compute the likelihood of an observation given the GMM's parameters\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}\n   */\n  likelihood(observation) {\n    let likelihood = 0;\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.beta[c] = this.componentLikelihood(observation, c);\n      likelihood += this.beta[c];\n    }\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.beta[c] /= likelihood;\n    }\n\n    return likelihood;\n  },\n\n  /**\n   * Compute the likelihood of an observation for a single component\n   * @param  {Array<Number>} observation Observation vector\n   * @param  {Number} mixtureComponent Component index\n   * @return {Number}\n   * @private\n   */\n  componentLikelihood(observation, mixtureComponent) {\n    if (mixtureComponent >= this.params.gaussians) {\n      throw new Error('The index of the Gaussian Mixture Component is out of bounds');\n    }\n    return this.params.mixtureCoeffs[mixtureComponent] *\n        this.params.components[mixtureComponent].likelihood(observation);\n  },\n\n  /**\n   * Update the inverse covariance of each Gaussian component\n   * @private\n   */\n  updateInverseCovariances() {\n    this.params.components.forEach((c) => {\n      c.updateInverseCovariance();\n    });\n    try {\n      this.params.components.forEach((c) => {\n        c.updateInverseCovariance();\n      });\n    } catch (e) {\n      throw new Error('Matrix inversion error: varianceoffset must be too small');\n    }\n  },\n\n  /**\n   * Normalize the mixing coefficients of the Gaussian mixture\n   * @private\n   */\n  normalizeMixtureCoeffs() {\n    let normConst = 0;\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      normConst += this.params.mixtureCoeffs[c];\n    }\n    if (normConst > 0) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.mixtureCoeffs[c] /= normConst;\n      }\n    } else {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      }\n    }\n  },\n\n  /**\n   * Regularize the covariances\n   * @private\n   */\n  regularize() {\n    this.params.components.forEach((c) => {\n      c.regularize(this.currentRegularization);\n    });\n  },\n};\n\n/**\n * Bimodal (regression) GMM Prototype\n * @type {Object}\n * @ignore\n */\nconst gmmBimodalPrototype = /** @lends withGMMBase */ {\n  /**\n   * Estimate the output values corresponding to the input observation, by\n   * regression given the GMM's parameters. This method is called Gaussian\n   * Mixture Regression (GMR).\n   *\n   * @param  {Array<Number>} inputObservation Observation on the input modality\n   * @return {Array<Number>} Output values (length = outputDimension)\n   */\n  regression(inputObservation) {\n    this.results.outputValues = Array(this.params.outputDimension).fill(0);\n    this.results.outputCovariance = Array(this.params.covarianceMode === 'full' ? this.params.outputDimension ** 2 : this.params.outputDimension).fill(0);\n    let tmpOutputValues;\n\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      tmpOutputValues = this.params.components[c].regression(inputObservation);\n      for (let d = 0; d < this.params.outputDimension; d += 1) {\n        this.results.outputValues[d] += this.beta[c] * tmpOutputValues[d];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n            this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n              (this.beta[c] ** 2) *\n              this.params.components[c].outputCovariance[(d * this.params.outputDimension) + d2];\n          }\n        } else {\n          this.results.outputCovariance[d] +=\n            (this.beta[c] ** 2) * this.params.components[c].outputCovariance[d];\n        }\n      }\n    }\n    return this.results.outputValues;\n  },\n};\n\n/**\n * Add basic GMM capabilities to a single-class model. This enables the\n * computation of the likelihoods and regression operations common to\n * training and prediction\n *\n * @see withGMMTraining\n * @see withGMMPrediction\n *\n * @param  {ModelBase} o Source Model\n * @return {GMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withGMMBase(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    gmmBasePrototype,\n    o.params.bimodal ? gmmBimodalPrototype : {},\n  );\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withKMeansTraining from '../kmeans/kmeans_training_mixin';\n\n/**\n * GMM Training Prototype\n * @type {Object}\n * @ignore\n */\nconst gmmTrainerPrototype = /** @lends withGMMTraining */ {\n  /**\n   * Initialize the EM Training process\n   * @param  {TrainingSet} trainingSet Training set\n   */\n  initTraining(trainingSet) {\n    this.allocate();\n    this.initParametersToDefault(trainingSet.standardDeviation());\n    this.initMeansWithKMeans(trainingSet);\n    this.initCovariances(trainingSet);\n    this.regularize();\n    this.updateInverseCovariances();\n  },\n\n  /**\n   * Initialize the model parameters to their default values\n   * @param  {Array<Number>} dataStddev Standard deviation of the training data\n   * @private\n   */\n  initParametersToDefault(dataStddev) {\n    let normCoeffs = 0;\n    this.currentRegularization = dataStddev.map(std => Math.max(\n      this.params.regularization.absolute,\n      this.params.regularization.relative * std,\n    ));\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      if (this.params.covarianceMode === 'full') {\n        this.params.components[c].covariance = Array(this.params.dimension ** 2)\n          .fill(this.params.regularization.absolute / 2);\n      } else {\n        this.params.components[c].covariance = Array(this.params.dimension).fill(0);\n      }\n      this.params.components[c].regularize(this.currentRegularization);\n      this.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      normCoeffs += this.params.mixtureCoeffs[c];\n    }\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.mixtureCoeffs[c] /= normCoeffs;\n    }\n  },\n\n  /**\n   * Initialize the means of the model using a K-Means algorithm\n   *\n   * @see withKMeansTraining\n   *\n   * @param  {TrainingSet} trainingSet training set\n   * @private\n   */\n  initMeansWithKMeans(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n    const kmeans = withKMeansTraining(\n      ModelBase({\n        inputDimension: this.params.inputDimension,\n        outputDimension: this.params.outputDimension,\n      }),\n      this.params.gaussians,\n      { initialization: 'data' },\n    );\n    const kmeansParams = kmeans.train(trainingSet);\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.components[c].mean = kmeansParams.centers[c];\n    }\n  },\n\n  /**\n   * Initialize the covariances of the model from the training set\n   *\n   * @param  {TrainingSet} trainingSet training set\n   * @private\n   */\n  initCovariances(trainingSet) {\n    // TODO: simplify with covariance symmetricity\n    // TODO: If Kmeans, covariances from cluster members\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      this.params.components[n].covariance = Array((this.params.covarianceMode === 'full') ? this.params.dimension ** 2 : this.params.dimension).fill(0);\n    }\n\n    const gmeans = Array(this.params.gaussians * this.params.dimension).fill(0);\n    const factor = Array(this.params.gaussians).fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.gaussians);\n      let offset = 0;\n      for (let n = 0; n < this.params.gaussians; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            gmeans[(n * this.params.dimension) + d1] += phrase.get(offset + t, d1);\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n                this.params.components[n]\n                  .covariance[(d1 * this.params.dimension) + d2] +=\n                  phrase.get(offset + t, d1) * phrase.get(offset + t, d2);\n              }\n            } else {\n              this.params.components[n].covariance[d1] +=\n                phrase.get(offset + t, d1) ** 2;\n            }\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        gmeans[(n * this.params.dimension) + d1] /= factor[n];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[n].covariance[(d1 * this.params.dimension) + d2] /= factor[n];\n          }\n        } else {\n          this.params.components[n].covariance[d1] /= factor[n];\n        }\n      }\n    }\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[n].covariance[(d1 * this.params.dimension) + d2] -=\n              gmeans[(n * this.params.dimension) + d1] *\n              gmeans[(n * this.params.dimension) + d2];\n          }\n        } else {\n          this.params.components[n].covariance[d1] -=\n            gmeans[(n * this.params.dimension) + d1] ** 2;\n        }\n      }\n    }\n  },\n\n  /**\n   * Update the EM Training process (1 EM iteration).\n   * @param  TrainingSet trainingSet training set\n   */\n  updateTraining(trainingSet) {\n    let logProb = 0;\n    let totalLength = 0;\n    trainingSet.forEach((phrase) => {\n      totalLength += phrase.length;\n    });\n    const phraseIndices = Object.keys(trainingSet.phrases);\n\n    const p = Array.from(\n      Array(this.params.gaussians),\n      () => new Array(totalLength).fill(0),\n    );\n    const E = Array(this.params.gaussians).fill(0);\n    let tbase = 0;\n\n    trainingSet.forEach((phrase) => {\n      for (let t = 0; t < phrase.length; t += 1) {\n        let normConst = 0;\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          p[c][tbase + t] = this.componentLikelihood(phrase.getFrame(t), c);\n\n          if (p[c][tbase + t] === 0 ||\n            Number.isNaN(p[c][tbase + t]) ||\n            p[c][tbase + t] === +Infinity) {\n            p[c][tbase + t] = 1e-100;\n          }\n          normConst += p[c][tbase + t];\n        }\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          p[c][tbase + t] /= normConst;\n          E[c] += p[c][tbase + t];\n        }\n        logProb += Math.log(normConst);\n      }\n      tbase += phrase.length;\n    });\n\n    // Estimate Mixture coefficients\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.mixtureCoeffs[c] = E[c] / totalLength;\n    }\n\n    // Estimate means\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.components[c].mean[d] = 0;\n        tbase = 0;\n        for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n          const phrase = trainingSet.phrases[phraseIndices[pix]];\n          for (let t = 0; t < phrase.length; t += 1) {\n            this.params.components[c].mean[d] +=\n              p[c][tbase + t] * phrase.get(t, d);\n          }\n          tbase += phrase.length;\n        }\n        this.params.components[c].mean[d] /= E[c];\n      }\n    }\n\n    // estimate covariances\n    if (this.params.covarianceMode === 'full') {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n          for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[c].covariance[(d1 * this.params.dimension) + d2] = 0;\n            tbase = 0;\n            for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n              const phrase = trainingSet.phrases[phraseIndices[pix]];\n              for (let t = 0; t < phrase.length; t += 1) {\n                this.params.components[c].covariance[(d1 * this.params.dimension) + d2] +=\n                  p[c][tbase + t] *\n                  (phrase.get(t, d1) - this.params.components[c].mean[d1]) *\n                  (phrase.get(t, d2) - this.params.components[c].mean[d2]);\n              }\n              tbase += phrase.length;\n            }\n            this.params.components[c].covariance[(d1 * this.params.dimension) + d2] /= E[c];\n            if (d1 !== d2) {\n              this.params.components[c].covariance[(d2 * this.params.dimension) + d1] =\n                this.params.components[c].covariance[(d1 * this.params.dimension) + d2];\n            }\n          }\n        }\n      }\n    } else {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n          this.params.components[c].covariance[d1] = 0;\n          tbase = 0;\n          for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n            const phrase = trainingSet.phrases[phraseIndices[pix]];\n            for (let t = 0; t < phrase.length; t += 1) {\n              const value = (phrase.get(t, d1) - this.params.components[c].mean[d1]);\n              this.params.components[c].covariance[d1] +=\n                    p[c][tbase + t] * value * value;\n            }\n            tbase += phrase.length;\n          }\n          this.params.components[c].covariance[d1] /= E[c];\n        }\n      }\n    }\n\n    this.regularize();\n    this.updateInverseCovariances();\n\n    return logProb;\n  },\n\n  /**\n   * Terminate the EM Training process\n   */\n  terminateTraining() {},\n};\n\n/**\n * Add GMM Training capabilities to a GMM Model\n * @param  {GMMBase} o               Source GMM Model\n * @param  {Number} [gaussians=1]    Number of Gaussian components\n * @param  {Object} [regularization] Regularization parameters\n * @param  {Number} [regularization.absolute=1e-3] Absolute regularization\n * @param  {Number} [regularization.relative=1e-2] Relative Regularization\n (relative to the training set's variance along each dimension)\n * @param  {String} [covarianceMode='full'] Covariance mode ('full' or diagonal)\n * @return {BMMBase}\n */\nexport default function withGMMTraining(\n  o,\n  gaussians = 1,\n  regularization = { absolute: 1e-3, relative: 1e-2 },\n  covarianceMode = 'full',\n) {\n  if (!Object.keys(o).includes('params')) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    gmmTrainerPrototype,\n    {\n      params: {\n        ...o.params,\n        gaussians,\n        regularization,\n        covarianceMode,\n      },\n    },\n  );\n}\n","import ModelBase from './model_base_mixin';\n\n/**\n * Multiclass Models Mixin\n * @type {Object}\n * @ignore\n */\nconst MulticlassBasePrototype = /** @lends MulticlassModelBase */{\n  /**\n   * Get the number of classes in the model\n   * @return {number} number of classes\n   */\n  size() {\n    return Object.keys(this.models).length;\n  },\n\n  /**\n   * Check if a class with the given label exists\n   * @param  {string} label Class label\n   * @return {boolean}\n   */\n  includes(label) {\n    return Object.keys(this.models).includes(label);\n  },\n\n  /**\n   * Remove a class by label\n   * @param  {string} label Class label\n   */\n  remove(label) {\n    if (this.includes(label)) {\n      delete this.models[label];\n    }\n  },\n};\n\n/**\n * Create an abstract Multiclass Model\n * @param       {number]} inputDimension  input dimension\n * @param       {number]} outputDimension output dimension\n * @param       {Object} parameters       additional parameters to copy\n * @function\n */\nexport default function MulticlassModelBase({\n  inputDimension,\n  outputDimension,\n  ...parameters\n}) {\n  return Object.assign(\n    ModelBase({ inputDimension, outputDimension, ...parameters }),\n    MulticlassBasePrototype,\n  );\n}\n","/**\n * Add multiclass training capabilities to a model. It takes as argument\n * the training function called to train each class of the training set.\n *\n * @param  {MulticlassModelBase} o Source model\n * @param  {Function}  trainingFunction Training function for a single class\n * @return {MulticlassModelBase}\n */\nexport default function withMulticlassTraining(\n  o,\n  trainingFunction,\n) {\n  return Object.assign(\n    o,\n    /** @lends withMulticlassTraining */ {\n      /**\n       * Train the model, optionally specifying a set of classes to train\n       *\n       * @param  {TrainingSet} trainingSet   Training data set\n       * @param  {undefined|Array<String>} [labels=undefined] Labels\n       * corresponding to the classes to be trained (all if unspecified)\n       * @return {Object} the parameters of the trained model\n       *\n       * @throws {Error} if the training set is empty\n       * @throws {Error} if one of the specified class does not exist\n       */\n      train(trainingSet, labels = undefined) {\n        if (!trainingSet || trainingSet.empty()) {\n          throw new Error('The training set is empty');\n        }\n        if (labels) {\n          labels.forEach((l) => {\n            if (!this.includes(l)) {\n              throw new Error(`Class labeled ${l} does not exist`);\n            }\n          });\n        }\n\n        this.params.classes = {};\n        const labs = labels || trainingSet.labels();\n        labs.forEach((label) => {\n          const ts = trainingSet.getPhrasesOfClass(label);\n          // console.log(ts);\n          this.params.classes[label] = trainingFunction(ts);\n        });\n        return this.params;\n      },\n    },\n  );\n}\n","/**\n * Circular Buffer prototype\n *\n * @property {number}  capacity Buffer capacity\n * @property {number}  length Current buffer length\n * @property {boolean} full Specifies if the buffer is full\n *\n * @ignore\n */\nconst circularBufferPrototype = /** @lends CircularBuffer */ {\n  /**\n   * Clear the buffer contents\n   */\n  clear() {\n    this.length = 0;\n    this.index = 0;\n    this.full = false;\n    this.buffer = [];\n  },\n\n  /**\n   * Push a value to the buffer\n   * @param  {*} value data value (any type)\n   */\n  push(value) {\n    if (this.full) {\n      this.buffer[this.index] = value;\n      this.index = (this.index + 1) % this.capacity;\n    } else {\n      this.buffer.push(value);\n      this.length += 1;\n      this.full = (this.length === this.capacity);\n    }\n  },\n\n  /**\n   * Get the value at a given index\n   * @param  {number} idx data index\n   * @return {anything}   value at index\n   */\n  get(idx) {\n    return this.buffer[(idx + this.index) % this.capacity];\n  },\n\n  /**\n   * Fill the buffer with a constant value\n   * @param  {*} value data value (any type)\n   */\n  fill(value) {\n    this.length = this.capacity;\n    this.index = 0;\n    this.full = true;\n    this.buffer = Array(this.capacity).fill(value);\n  },\n\n  /**\n   * Iterate over the buffer's data\n   * @param  {Function} callback Callback function\n   * (@see Array.prototype.forEach).\n   */\n  forEach(callback) {\n    for (let i = 0; i < this.length; i += 1) {\n      callback(this.buffer[(i + this.index) % this.capacity], i);\n    }\n  },\n\n  /**\n   * Get an array of the buffer current values (ordered)\n   * @return {Array} Buffer contents\n   */\n  values() {\n    return this.buffer.slice(this.index)\n      .concat(this.buffer.slice(0, this.index));\n  },\n};\n\n/**\n * Circular Buffer Data Structure (any data type)\n * @param  {number} capacity Buffer capacity\n * @return {circularBufferPrototype}\n * @function\n *\n * @property {number}  capacity Buffer capacity\n * @property {number}  length Current buffer length\n * @property {boolean} full Specifies if the buffer is full\n */\nexport default function CircularBuffer(capacity) {\n  const buffer = Object.create(circularBufferPrototype);\n  buffer.capacity = capacity;\n  buffer.clear();\n  return buffer;\n}\n","import { isBaseModel } from './model_base_mixin';\nimport CircularBuffer from '../common/circular_buffer';\n\n/**\n * Prototype for models with prediction capabilities\n * @param  {Boolean} bimodal Specifies whether the model is bimodal\n * @return {Object}\n * @ignore\n */\nconst predictionBasePrototype = bimodal => (/** @lends withAbtractPrediction */{\n  /**\n   * Likelihood Buffer\n   * @type {CircularBuffer}\n   * @private\n   */\n  likelihoodBuffer: CircularBuffer(1),\n\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @param {Number} [lw] Size (in frames) of the likelihood smoothing window\n   */\n  setLikelihoodWindow(lw) {\n    this.likelihoodWindow = lw;\n    this.likelihoodBuffer = CircularBuffer(lw);\n  },\n\n  /**\n   * Reset the prediction process\n   * @return {Modelbase} the model\n   */\n  reset() {\n    this.likelihoodBuffer.clear();\n    return this;\n  },\n\n  /**\n   * Update the predictions with a new observation\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Object} Prediction results\n   *\n   * @todo document results data structure\n   */\n  predict(observation) {\n    const likelihood = this.likelihood(observation);\n    if (bimodal) {\n      this.regression(observation);\n    }\n    this.updateResults(likelihood);\n    return this.results;\n  },\n\n  /**\n   * Update the prediction results\n   * @param  {Number} instantLikelihood Instantaneous likelihood\n   * @private\n   */\n  updateResults(instantLikelihood) {\n    this.results.instantLikelihood = instantLikelihood;\n    this.likelihoodBuffer.push(Math.log(instantLikelihood));\n    this.results.logLikelihood = 0;\n    const bufSize = this.likelihoodBuffer.length;\n    for (let i = 0; i < bufSize; i += 1) {\n      this.results.logLikelihood += this.likelihoodBuffer.get(i);\n    }\n    this.results.logLikelihood /= bufSize;\n  },\n});\n\n/**\n * Add ABSTRACT prediction capabilities to an existing model\n * @param  {Modelbase} o                 Source model\n * @param  {Number} [likelihoodWindow=1] Size of the likelihood smoothing window\n * @return {Modelbase}\n */\nexport default function withAbtractPrediction(o, likelihoodWindow = 1) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const results = Object.assign(\n    { instantLikelihood: 0, logLikelihood: 0 },\n    o.params.bimodal ? { outputValues: [], outputCovariance: [] } : {},\n  );\n  return Object.assign(\n    o,\n    predictionBasePrototype(o.params.bimodal),\n    { results, likelihoodBuffer: CircularBuffer(likelihoodWindow) },\n  );\n}\n","/**\n * Check if the specification is respected for a given parameter and value,\n * and clip if relevant.\n *\n * @ignore\n *\n * @param  {String}        model      Stream Operator Name (for logging)\n * @param  {String}        parameter     Attribute name\n * @param  {Specification} specification Attribute specification\n * @param  {*}             value         Attribute value\n * @return {*}                           Type-checked parameter value\n */\nfunction checkSpec(model, parameter, specification, value) {\n  if (!specification) return;\n  if (specification.constructor === Array && !specification.includes(value)) {\n    throw new Error(`Attribute '${parameter}' (value: '${value}') is not allowed for model '${model}' (options: [${specification}]).`);\n  } else if (specification.constructor === Object) {\n    if (Object.keys(specification).includes('min') && value < specification.min) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is inferior to the minimum required value of ${specification.min} for model '${model}'.`);\n    }\n    if (Object.keys(specification).includes('max') && value > specification.max) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is superior to the maximum required value of ${specification.min} for model '${model}'.`);\n    }\n  } else if (typeof specification === 'function') {\n    if (!specification(value)) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is incompatible with model '${model}'.`);\n    }\n  }\n}\n\n/**\n * Check the parameters of a model and return the parameters of the\n * output stream.\n *\n * The specification should be a structure of the form:\n * ```\n * const streamSpecification = {\n *   <parameter name>: {\n *     required: <boolean>,\n *     check: <null || Array || { min: <minimum value>, max: <maximum value>} || Function >,\n *     transform: Function,\n *   },\n * };\n * ```\n *\n * @param  {String} model      Name of the model for logging\n * @param  {Object} specification I/O Stream Specification\n * @param  {Object} values        Attributes of the input stream\n * @return {Object}               Attributes of the output stream\n *\n * @example\n * import setupStreamAttributes from 'stream';\n *\n * const specification = {\n *   type: {\n *     required: false,\n *     check: null,\n *     transform: x => x || null,\n *   },\n *   format: {\n *     required: true,\n *     check: ['scalar', 'vector'],\n *     transform: x => x,\n *   },\n *   size: {\n *     required: true,\n *     check: { min: 1 },\n *     transform: x => 2 * x,\n *   },\n *   stuff: {\n *     required: true,\n *     check: x => Math.log2(x) === Math.floor(Math.log2(x)),\n *     transform: x => Math.log2(x),\n *   },\n * };\n *\n * const values = {\n *   type: 'anything',\n *   format: 'vector',\n *   size: 3,\n *   stuff: 8,\n *   another: 'one',\n * };\n *\n * setupStreamAttributes('module name', specification, values);\n * // Returns:\n * // {\n * //   type: 'anything',\n * //   format: 'vector',\n * //   size: 6,\n * //   stuff: 3,\n * //   another: 'one',\n * // }\n */\nexport default function validateParameters(model, specification, values) {\n  const parameters = Object.assign({}, values);\n  Object.keys(specification).forEach((attr) => {\n    const spec = specification[attr];\n\n    // Check for required parameters\n    if (spec.required && !Object.keys(values).includes(attr)) {\n      throw new Error(`Stream parameter '${attr}' is required for model '${model}'.`);\n    }\n\n    // Check the validity of the input parameters\n    checkSpec(model, attr, spec.check, values[attr]);\n\n    parameters[attr] = spec.transform ?\n      spec.transform(values[attr]) :\n      values[attr];\n  });\n  return parameters;\n}\n","import validateParameters from '../common/validation';\nimport { isBaseModel } from '../core/model_base_mixin';\n\nconst gmmParameterSpec = gaussians => ({\n  gaussians: {\n    required: true,\n    check: { min: 1 },\n  },\n  regularization: {\n    required: true,\n    check: ({ absolute, relative }) =>\n      (absolute && relative && absolute > 0 && relative > 0),\n  },\n  covarianceMode: {\n    required: true,\n    check: ['full', 'diagonal'],\n  },\n  mixtureCoeffs: {\n    required: true,\n    check: m => m.length === gaussians,\n  },\n  components: {\n    required: true,\n    check: c => c.length === gaussians,\n  },\n});\n\n/**\n * Add GMM prediction capabilities to a single-class model. Mostly, this checks\n * the validity of the model parameters\n *\n * @todo validate gaussian components\n *\n * @param  {GMMBaseModel} o Source Model\n * @return {GMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withGMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  validateParameters('GMM', gmmParameterSpec(o.params.gaussians), o.params);\n  return Object.assign(\n    o,\n    { beta: new Array(o.params.gaussians).fill(0) },\n  );\n}\n","import { isBaseModel } from './model_base_mixin';\n\n/**\n * Multiclass prediction mixin\n * @type {Object}\n * @ignore\n */\nconst MulticlassPredictionBasePrototype = /** @lends withMulticlassPrediction */ {\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @return {Number}\n   */\n  getLikelihoodWindow() {\n    return this.likelihoodWindow;\n  },\n\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @param {Number} [lw] Size (in frames) of the likelihood smoothing window\n   */\n  setLikelihoodWindow(lw) {\n    this.likelihoodWindow = lw;\n    Object.keys(this.models).forEach((label) => {\n      this.models[label].setLikelihoodWindow(lw);\n    });\n  },\n\n  /**\n   * Reset the prediction process. This is particularly important for temporal\n   * models such as HMMs, that depends on previous observations.\n   */\n  reset() {\n    Object.values(this.models).forEach(m => m.reset());\n    this.results = {\n      labels: [],\n      instantLikelihoods: [],\n      smoothedLikelihoods: [],\n      smoothedLogLikelihoods: [],\n      smoothedNormalizedLikelihoods: [],\n      likeliest: null,\n      classes: {},\n    };\n    if (this.params.bimodal) {\n      this.resetBimodal();\n    }\n  },\n\n  /**\n   * Make a prediction from a new observation (updates the results member)\n   * @param  {Array<Number>} observation Observation vector\n   */\n  predict(observation) {\n    Object.values(this.models).forEach(m => m.predict(observation));\n    this.updateResults();\n  },\n\n  updateResults() {\n    const labs = Object.keys(this.models).sort();\n    this.results.labels = labs;\n    let normInstant = 0;\n    let normSmoothed = 0;\n    let maxLogLikelihood = -Infinity;\n    this.results.classes = labs\n      .map((lab, i) => {\n        this.results.instantLikelihoods[i] =\n          this.models[lab].results.instantLikelihood;\n        this.results.smoothedLogLikelihoods[i] =\n          this.models[lab].results.logLikelihood;\n        this.results.smoothedLikelihoods[i] =\n          Math.exp(this.results.smoothedLogLikelihoods[i]);\n        normInstant += this.results.instantLikelihoods[i];\n        normSmoothed += this.results.smoothedLikelihoods[i];\n        if (this.results.smoothedLogLikelihoods[i] > maxLogLikelihood) {\n          maxLogLikelihood = this.results.smoothedLogLikelihoods[i];\n          this.results.likeliest = lab;\n        }\n        return { [lab]: this.models[lab].results };\n      })\n      .reduce((o, x) => ({ ...o, ...x }), {});\n    this.results.smoothedNormalizedLikelihoods =\n      this.results.smoothedLikelihoods.map(x => x / normSmoothed);\n    this.results.instantNormalizedLikelihoods =\n      this.results.instantLikelihoods.map(x => x / normInstant);\n    if (this.params.bimodal) {\n      this.updateRegressionResults();\n    }\n  },\n};\n\nconst MulticlassPredictionBimodalPrototype = {\n  resetBimodal() {\n    this.results.outputValues = [];\n    this.results.outputCovariance = [];\n  },\n\n  updateRegressionResults() {\n    if (this.params.multiClassRegressionEstimator === 'likeliest') {\n      this.results.outputValues =\n        this.models[this.results.likeliest].results.outputValues;\n      this.results.outputCovariance =\n        this.models[this.results.likeliest].results.outputCovariance;\n    } else if (this.params.multiClassRegressionEstimator === 'mixture') {\n      this.results.outputValues = Array(this.outputDimension).fill(0);\n      this.results.outputCovariance = Array(this.outputDimension ** (this.configuration.covarianceMode === 'full' ? 2 : 1)).fill(0);\n      this.results.labels.forEach((lab) => {\n        this.results.outputValues.map((x, i) => x + (\n          this.results.smoothedNormalizedLikelihoods[i] *\n          this.models[lab].results.outputValues[i]\n        ));\n        this.results.outputCovariance.map((x, i) => x + (\n          this.results.smoothedNormalizedLikelihoods[i] *\n          this.models[lab].results.outputCovariance[i]\n        ));\n      });\n    } else {\n      throw new Error('Unknown regression estimator, use `likeliest` or `mixture`');\n    }\n  },\n};\n\n/**\n * Add multiclass prediction capabilities to a multiclass model\n * @param  {MulticlassModelBase} o Source model\n * @param  {String} [multiClassRegressionEstimator='likeliest'] Type of\n * regression estimator:\n * - `likeliest` selects the output values from the likeliest class\n * - `mixture` computes the output values as the weighted sum of the\n * contributions of each class, weighed by their normalized likelihood\n * @return {MulticlassPredictionBasePrototype}\n * @function\n */\nexport default function withMulticlassPrediction(o, multiClassRegressionEstimator = 'likeliest') {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const m = Object.assign(\n    o,\n    MulticlassPredictionBasePrototype,\n    o.params.bimodal ? MulticlassPredictionBimodalPrototype : {},\n  );\n  m.params.multiClassRegressionEstimator = multiClassRegressionEstimator;\n  return m;\n}\n","import GaussianDistribution from '../common/gaussian_distribution';\nimport ModelBase from '../core/model_base_mixin';\nimport withEMTraining from '../core/em_training_mixin';\nimport withGMMBase from './gmm_base_mixin';\nimport withGMMTraining from './gmm_training_mixin';\nimport MulticlassModelBase from '../core/multiclass_mixin';\nimport withMulticlassTraining from '../core/multiclass_training_mixin';\nimport withAbtractPrediction from '../core/prediction_mixin';\nimport withGMMPrediction from './gmm_prediction_mixin';\nimport withMulticlassPrediction from '../core/multiclass_prediction_mixin';\n\n/**\n * Set of criteria that define when the EM algorithm (for either GMMs or HMMs) has converged.\n * Convergence depends on\n * - A minimum number of iterations\n * - A maximum number of iterations\n * - A threshold on the relative change of the log-likelihood of the training\n * data between successive iterations.\n *\n * @typedef {Object} ConvergenceCriteria\n *\n * @property {number} [percentChange=1e-3] Threshold in % of\n * the relative change of the log-likelihood, under which the training stops.\n * @property {number} [minIterations=5]    minimum number of iterations\n * @property {number} [maxIterations=100]  maximum number of iterations\n */\n\n/**\n * GMM training configuration\n *\n * @typedef {Object} GMMConfiguration\n * @property {Number} gaussians Number of Gaussian components\n * @property {{ absolute: 1e-3, relative: 1e-2 }} regularization An object containing the\n * relative and absolute regularization values. Regularization is an offset value added to the\n * diagonal of covariance matrices for convergence and generalization. The two values represent:\n * - `relative`: the offset relative to the variance of the training data\n * - `absolute`: an absolute lower threshold for the offset\n * @property {String} covarianceMode Type of covariance matrix ('full' or 'diagonal')\n */\n\n/**\n * @typedef {Object} GMMParameters\n * @property {Boolean} bimodal Specifies if the model is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} gaussians Number of gaussian components in the mixture\n * @property {String} covarianceMode Covariance mode ('full' or 'diagonal')\n * @property {Array<Number>} mixtureCoeffs mixture coefficients ('weight' of\n * each gaussian component)\n * @property {Array<GaussianDistribution>} components Gaussian components\n */\n\n/**\n * Train a single-class GMM Model.\n *\n * @todo GMM details\n *\n * @param  {TrainingSet} trainingSet Training set\n * @param  {GMMConfiguration} configuration Training configuration\n * @param  {ConvergenceCriteria} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {GMMParameters} Parameters of the trained GMM\n */\nexport function trainGMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const { gaussians, regularization, covarianceMode } = configuration;\n  const model = withGMMTraining(\n    withEMTraining(\n      withGMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        ...configuration,\n      })),\n      convergenceCriteria,\n    ),\n    gaussians,\n    regularization,\n    covarianceMode,\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Train a multi-class GMM Model.\n *\n * @todo GMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {GMMConfiguration} configuration                   Training configuration\n * @param  {ConvergenceCriteria} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {GMMParameters} Parameters of the trained GMM\n */\nexport function trainMulticlassGMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withMulticlassTraining(\n    MulticlassModelBase({ inputDimension, outputDimension, ...configuration }),\n    ts => trainGMM(ts, configuration, convergenceCriteria),\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Create a GMM Predictor from a full set of parameters (generated by trainGMM).\n * @param {GMMParameters} params Model parameters\n * @param {number} [likelihoodWindow=1] Likelihoow window size\n * @function\n */\nexport function GMMPredictor(\n  params,\n  likelihoodWindow = 1,\n) {\n  const model = withGMMPrediction(withAbtractPrediction(\n    withGMMBase(ModelBase(params)),\n    likelihoodWindow,\n  ));\n  params.components.forEach((c, i) => {\n    model.params.components[i] = Object.assign(GaussianDistribution(\n      params.inputDimension,\n      params.outputDimension,\n      params.covarianceMode,\n    ), c);\n  });\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass GMM Predictor from a full set of parameters\n * (generated by trainMulticlassGMM).\n * @param {GMMParameters} params Model parameters\n * @param {number} [likelihoodWindow=1] Likelihoow window size\n * @function\n */\nexport function MulticlassGMMPredictor(\n  params,\n  likelihoodWindow = 1,\n) {\n  const model = withMulticlassPrediction(MulticlassModelBase(params));\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = GMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model.reset();\n  return model;\n}\n","import { isBaseModel } from '../core/model_base_mixin';\n\n//\n// TODO: hierarchical + exit probabilities methods.\n//\n\n/**\n * HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hmmBasePrototype = /** @lends withHMMBase */ {\n  /**\n   * Specifies if the forward algorithm has been initialized\n   * @type {Boolean}\n   * @private\n   */\n  forwardInitialized: false,\n\n  /**\n   * Specifies if the containing multiclass model is isHierarchical\n   * @todo check that\n   * @type {Boolean}\n   * @private\n   */\n  isHierarchical: false,\n\n  /**\n   * Initialize the forward algorithm (See rabiner, 1989)\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}                    `ct` (inverse likelihood)\n   */\n  initializeForwardAlgorithm(observation) {\n    let normConst = 0;\n    if (this.params.transitionMode === 'ergodic') {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.alpha[i] = this.params.prior[i] *\n          this.params.xStates[i].likelihood(observation);\n        normConst += this.alpha[i];\n      }\n    } else {\n      this.alpha = new Array(this.params.states).fill(0);\n      this.alpha[0] = this.params.xStates[0].likelihood(observation);\n      normConst += this.alpha[0];\n    }\n    this.forwardInitialized = true;\n    if (normConst > 0) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.alpha[i] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 1 / this.params.states;\n    }\n    return 1;\n  },\n\n  /**\n   * Update the forward algorithm (See rabiner, 1989)\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}                    `ct` (inverse likelihood)\n   */\n  updateForwardAlgorithm(observation) {\n    let normConst = 0;\n    this.previousAlpha = this.alpha.slice();\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.alpha[j] += this.previousAlpha[i] *\n            this.params.transition[i][j];\n        }\n      } else {\n        this.alpha[j] += this.previousAlpha[j] * this.params.transition[j * 2];\n        if (j > 0) {\n          this.alpha[j] += this.previousAlpha[j - 1] *\n            this.params.transition[((j - 1) * 2) + 1];\n        } else {\n          this.alpha[0] += this.previousAlpha[this.params.states - 1] *\n            this.params.transition[(this.params.states * 2) - 1];\n        }\n      }\n      this.alpha[j] *= this.params.xStates[j].likelihood(observation);\n      normConst += this.alpha[j];\n    }\n    if (normConst > 1e-300) {\n      for (let j = 0; j < this.params.states; j += 1) {\n        this.alpha[j] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    return 0;\n  },\n};\n\n/**\n * Add basic HMM capabilities to a single-class model. This enables the\n * computation of the likelihoods and regression operations common to\n * training and prediction\n *\n * @see withHMMTraining\n * @see withHMMPrediction\n *\n * @param  {ModelBase} o Source Model\n * @return {HMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHMMBase(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(o, hmmBasePrototype);\n}\n","import TrainingSet from '../training_set';\nimport ModelBase from '../core/model_base_mixin';\nimport withGMMBase from '../gmm/gmm_base_mixin';\nimport { trainGMM } from '../gmm';\n\nconst TRANSITION_REGULARIZATION = 1e-5;\n\n/**\n * HMM Training Prototype\n * @type {Object}\n * @ignore\n */\nconst hmmTrainerPrototype = /** @lends withHMMTraining */ {\n  /**\n   * Initialize the EM Training process\n   * @param  {TrainingSet} trainingSet Training set\n   */\n  initTraining(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    this.allocate(trainingSet);\n    this.initParametersToDefault(trainingSet.standardDeviation());\n    if (this.params.gaussians > 1) {\n      this.initMeansCovariancesWithGMMEM(trainingSet);\n    } else {\n      this.initMeansWithAllPhrases(trainingSet);\n      this.initCovariancesFullyObserved(trainingSet);\n    }\n  },\n\n  /**\n   * Allocate the model's parameters and training variables\n   * @param  {TrainingSet} trainingSet The training set\n   * @private\n   */\n  allocate(trainingSet) {\n    const {\n      inputDimension,\n      outputDimension,\n      gaussians,\n      regularization,\n      covarianceMode,\n    } = this.params;\n    this.params.xStates = Array.from(\n      new Array(this.params.states),\n      () => withGMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        gaussians,\n        regularization,\n        covarianceMode,\n      })),\n    );\n    this.params.xStates.forEach(s => s.allocate());\n    this.alpha = new Array(this.params.states).fill(0);\n    this.previousAlpha = new Array(this.params.states).fill(0);\n    this.beta = new Array(this.params.states).fill(0);\n    this.previousBeta = new Array(this.params.states).fill(0);\n\n    // Initialize Algorithm variables\n    // ---------------------------------------\n    const nbPhrases = trainingSet.size();\n    this.gammaSequence = new Array(nbPhrases).fill(null);\n    this.epsilonSequence = new Array(nbPhrases).fill(null);\n    this.gammaSequenceperMixture = new Array(nbPhrases).fill(null);\n    let maxT = 0;\n    let i = 0;\n    trainingSet.forEach((phrase) => {\n      const T = phrase.length;\n      this.gammaSequence[i] = Array.from(\n        new Array(T),\n        () => new Array(this.params.states).fill(0),\n      );\n      if (this.params.transitionMode === 'ergodic') {\n        this.epsilonSequence[i] = Array.from(\n          new Array(T),\n          () => Array.from(\n            new Array(this.params.states),\n            () => new Array(this.params.states).fill(0),\n          ),\n        );\n      } else {\n        this.epsilonSequence[i] = Array.from(\n          new Array(T),\n          () => new Array(this.params.states * 2).fill(0),\n        );\n      }\n      this.gammaSequenceperMixture[i] =\n        new Array(this.params.gaussians).fill(0);\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.gammaSequenceperMixture[i][c] =\n          Array.from(\n            new Array(T),\n            () => new Array(this.params.states).fill(0),\n          );\n      }\n      if (T > maxT) {\n        maxT = T;\n      }\n      i += 1;\n    });\n\n    this.gammaSum = new Array(this.params.states).fill(0);\n    this.gammaSumPerMixture = new Array(this.params.states * this.params.gaussians).fill(0);\n  },\n\n  /**\n   * Update the EM Training process (1 EM iteration).\n   * @param  TrainingSet trainingSet training set\n   */\n  updateTraining(trainingSet) {\n    let logProb = 0;\n\n    // Forward-backward for each phrase\n    // =================================================\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      if (phrase.length > 0) {\n        logProb += this.baumWelchForwardBackward(phrase, phraseIndex);\n      }\n      phraseIndex += 1;\n    });\n    this.baumWelchGammaSum(trainingSet);\n\n    // Re-estimate model parameters\n    // =================================================\n\n    // set covariance and mixture coefficients to zero for each state\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.xStates[i].params.mixtureCoeffs[c] = 0;\n        if (this.params.covarianceMode === 'full') {\n          this.params.xStates[i].params.components[c].covariance =\n            new Array(this.params.dimension ** 2).fill(0);\n        } else {\n          this.params.xStates[i].params.components[c].covariance =\n            new Array(this.params.dimension).fill(0);\n        }\n      }\n    }\n\n    this.baumWelchEstimateMixtureCoefficients(trainingSet);\n    this.baumWelchEstimateMeans(trainingSet);\n    this.baumWelchEstimateCovariances(trainingSet);\n    if (this.params.transitionMode === 'ergodic') {\n      this.baumWelchEstimatePrior(trainingSet);\n    }\n    this.baumWelchEstimateTransitions(trainingSet);\n    return logProb;\n  },\n\n  /**\n   * terminate the EM Training process\n   * @param  TrainingSet trainingSet training set\n   */\n  terminateTraining() {\n    this.normalizeTransitions();\n    this.gammaSequence = null;\n    this.epsilonSequence = null;\n    this.gammaSequenceperMixture = null;\n    this.alphaSeq = null;\n    this.betaSeq = null;\n    this.gammaSum = null;\n    this.gammaSumPerMixture = null;\n    this.params.xStates = this.params.xStates.map(s => s.params);\n  },\n\n  /**\n   * Initialize the model parameters to their default values\n   * @param  {Array<Number>} dataStddev Standard deviation of the training data\n   * @private\n   */\n  initParametersToDefault(dataStddev) {\n    if (this.params.transitionMode === 'ergodic') {\n      this.setErgodic();\n    } else {\n      this.setLeftRight();\n    }\n    const currentRegularization = dataStddev.map(std => Math.max(\n      this.params.regularization.absolute,\n      this.params.regularization.relative * std,\n    ));\n    const initCovariance = (this.params.covarianceMode === 'full') ?\n      () => new Array(this.params.dimension ** 2)\n        .fill(this.params.regularization.absolute / 2) :\n      () => new Array(this.params.dimension)\n        .fill(0);\n    for (let i = 0; i < this.params.states; i += 1) {\n      // this.params.xStates[i].initParametersToDefault(dataStddev);\n      const s = this.params.xStates[i];\n      s.currentRegularization = currentRegularization;\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        s.params.components[c].covariance = initCovariance();\n        s.params.components[c].regularize(currentRegularization);\n        s.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      }\n    }\n  },\n\n  /**\n   * Initialize the means of each state using all available phrases in the\n   * training set\n   * @param  {TrainingSet} trainingSet Training set\n   * @private\n   */\n  initMeansWithAllPhrases(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.xStates[n].params.components[0].mean[d] = 0.0;\n      }\n    }\n\n    const factor = new Array(this.params.states).fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.states);\n      let offset = 0;\n      for (let n = 0; n < this.params.states; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d = 0; d < this.params.dimension; d += 1) {\n            this.params.xStates[n].params.components[0].mean[d] +=\n              phrase.get(offset + t, d);\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.xStates[n].params.components[0].mean[d] /= factor[n];\n      }\n    }\n  },\n\n  /**\n   * Initialize the covariance by direct (fully-observed) estimation from the\n   * training data.\n   * @param  {[type]} trainingSet [description]\n   * @private\n   */\n  initCovariancesFullyObserved(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      this.params.xStates[n].params.components[0].covariance =\n        new Array(this.params.dimension ** (this.params.covarianceMode === 'full' ? 2 : 1)).fill(0);\n    }\n\n    const factor = new Array(this.params.states).fill(0);\n    const othermeans = new Array(this.params.states * this.params.dimension)\n      .fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.states);\n      let offset = 0;\n      for (let n = 0; n < this.params.states; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            othermeans[((n * this.params.dimension)) + d1] +=\n                phrase.get(offset + t, d1);\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n                this.params.xStates[n].params.components[0]\n                  .covariance[(d1 * this.params.dimension) + d2] +=\n                    phrase.get(offset + t, d1) *\n                    phrase.get(offset + t, d2);\n              }\n            } else {\n              this.params.xStates[n].params.components[0].covariance[d1] +=\n                phrase.get(offset + t, d1) ** 2;\n            }\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        othermeans[(n * this.params.dimension) + d1] /= factor[n];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.xStates[n].params.components[0]\n              .covariance[(d1 * this.params.dimension) + d2] /=\n                factor[n];\n          }\n        } else {\n          this.params.xStates[n].params.components[0].covariance[d1] /= factor[n];\n        }\n      }\n    }\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.xStates[n].params.components[0]\n              .covariance[(d1 * this.params.dimension) + d2] -=\n                othermeans[(n * this.params.dimension) + d1] *\n                othermeans[(n * this.params.dimension) + d2];\n          }\n        } else {\n          this.params.xStates[n].params.components[0].covariance[d1] -=\n            othermeans[(n * this.params.dimension) + d1] *\n            othermeans[(n * this.params.dimension) + d1];\n        }\n      }\n      this.params.xStates[n].regularize();\n      this.params.xStates[n].updateInverseCovariances();\n    }\n  },\n\n  /**\n   * Initialize the means and covariance of each state's observation probability\n   * distribution using the Expectation-Maximization algorithm for GMMs\n   * @param  {[type]} trainingSet [description]\n   * @private\n   */\n  initMeansCovariancesWithGMMEM(trainingSet) {\n    for (let n = 0; n < this.params.states; n += 1) {\n      const ts = TrainingSet(this.params);\n      // eslint-disable-next-line no-loop-func\n      trainingSet.forEach((phrase, phraseIndex) => {\n        const step = Math.floor(phrase.length / this.params.states);\n        if (step > 0) {\n          ts.push(phraseIndex, phrase.label);\n          for (let t = n * step; t < (n + 1) * step; t += 1) {\n            ts.getPhrase(phraseIndex).push(phrase.getFrame(t));\n          }\n        }\n      });\n      if (!ts.empty()) {\n        const gmmParams = trainGMM(ts, this.params);\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          this.params.xStates[n].params.components[c].mean =\n            gmmParams.components[c].mean;\n          this.params.xStates[n].params.components[c].covariance =\n            gmmParams.components[c].covariance;\n          this.params.xStates[n].updateInverseCovariances();\n        }\n      }\n    }\n  },\n\n  /**\n   * Initialize the transition matrix to an ergodic transition matrix\n   * @private\n   */\n  setErgodic() {\n    const p = 1 / this.params.states;\n    this.params.prior = new Array(this.params.states).fill(p);\n    this.params.transition = Array.from(\n      new Array(this.params.states),\n      () => new Array(this.params.states).fill(p),\n    );\n  },\n\n  /**\n   * Initialize the transition matrix to a left-right transition matrix\n   * @private\n   */\n  setLeftRight() {\n    this.params.prior = new Array(this.params.states).fill(0);\n    this.params.prior[0] = 1;\n    this.params.transition = new Array(this.params.states * 2).fill(0.5);\n    this.params.transition[(this.params.states - 1) * 2] = 1;\n    this.params.transition[((this.params.states - 1) * 2) + 1] = 0;\n  },\n\n  /**\n   * Normalize the hidden state transition parameters\n   * (prior + transition matrix)\n   * @private\n   */\n  normalizeTransitions() {\n    if (this.params.transitionMode === 'ergodic') {\n      const normPrior = this.params.prior.reduce((a, b) => a + b, 0);\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] /= normPrior;\n        let transitionNorm = 0;\n        for (let j = 0; j < this.params.states; j += 1) {\n          transitionNorm += this.params.transition[i][j];\n        }\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.params.transition[i][j] /= transitionNorm;\n        }\n      }\n    } else {\n      for (let i = 0; i < this.params.states; i += 1) {\n        const transitionNorm = this.params.transition[i * 2] + this.params.transition[(i * 2) + 1];\n        this.params.transition[i * 2] /= transitionNorm;\n        this.params.transition[(i * 2) + 1] /= transitionNorm;\n      }\n    }\n  },\n\n  /**\n   * Initialize the backward algorithm (see rabiner, 1989)\n   * @param  {Number} ct Inverse probability at time T - 1 (last observation of\n   * the sequence)\n   * @private\n   */\n  initializeBackwardAlgorithm(ct) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = ct;\n    }\n  },\n\n  /**\n   * Initialize the backward algorithm (see rabiner, 1989)\n   * @param  {Number} ct Inverse probability at time t\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  updateBackwardAlgorithm(ct, observation) {\n    this.previousBeta = this.beta.slice();\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.beta[i] += this.params.transition[i][j] *\n            this.previousBeta[j] *\n            this.params.xStates[j].likelihood(observation);\n        }\n      } else {\n        this.beta[i] += this.params.transition[i * 2] *\n          this.previousBeta[i] *\n          this.params.xStates[i].likelihood(observation);\n        if (i < this.params.states - 1) {\n          this.beta[i] += this.params.transition[(i * 2) + 1] *\n            this.previousBeta[i + 1] *\n            this.params.xStates[i + 1].likelihood(observation);\n        }\n      }\n      this.beta[i] *= ct;\n      if (Number.isNaN(this.beta[i]) || Math.abs(this.beta[i]) === +Infinity) {\n        this.beta[i] = 1e100;\n      }\n    }\n  },\n\n  /**\n   * Forward algorithm update step for the Baum-Welch algorithms. It is similar\n   * to `updateForwardAlgorithm` except it takes precomputed observation\n   * likelihoods as argument.\n   * @param  {Array<Number>} observationLikelihoods observation likelihoods\n   * @private\n   */\n  baumWelchForwardUpdate(observationLikelihoods) {\n    let normConst = 0;\n    this.previousAlpha = this.alpha.slice();\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.alpha[j] += this.previousAlpha[i] *\n            this.params.transition[i][j];\n        }\n      } else {\n        this.alpha[j] += this.previousAlpha[j] * this.params.transition[j * 2];\n        if (j > 0) {\n          this.alpha[j] += this.previousAlpha[j - 1] *\n            this.params.transition[((j - 1) * 2) + 1];\n        } else {\n          this.alpha[0] += this.previousAlpha[this.params.states - 1] *\n            this.params.transition[(this.params.states * 2) - 1];\n        }\n      }\n      this.alpha[j] *= observationLikelihoods[j];\n      normConst += this.alpha[j];\n    }\n    if (Number.isNaN(normConst)) {\n      throw new Error('Holy molly');\n    }\n    if (normConst > 1e-300) {\n      for (let j = 0; j < this.params.states; j += 1) {\n        this.alpha[j] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    return 0;\n  },\n\n  /**\n   * Backward algorithm update step for the Baum-Welch algorithms. It is similar\n   * to `updatebackwardAlgorithm` except it takes precomputed observation\n   * likelihoods as argument.\n   * @param  {Number} ct Inverse probability at time t\n   * @param  {Array<Number>} observationLikelihoods observation likelihoods\n   * @private\n   */\n  baumWelchBackwardUpdate(ct, observationLikelihoods) {\n    this.previousBeta = this.beta.slice();\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.beta[i] +=\n            this.params.transition[i][j] *\n            this.previousBeta[j] *\n            observationLikelihoods[j];\n        }\n      } else {\n        this.beta[i] += this.params.transition[i * 2] *\n          this.previousBeta[i] *\n          observationLikelihoods[i];\n        if (i < this.params.states - 1) {\n          this.beta[i] += this.params.transition[(i * 2) + 1] *\n            this.previousBeta[i + 1] *\n            observationLikelihoods[i + 1];\n        }\n      }\n      this.beta[i] *= ct;\n      if (Number.isNaN(this.beta[i]) || Math.abs(this.beta[i]) === +Infinity) {\n        this.beta[i] = 1e100;\n      }\n    }\n  },\n\n  /**\n   * Forward-Backward algorithm for the Baum-Welch training algorithm\n   * @param  {Phrase} currentPhrase Current data phrase\n   * @param  {Number} phraseIndex   Current phrase index\n   * @return {Number} Log-likelihood\n   * @private\n   */\n  baumWelchForwardBackward(currentPhrase, phraseIndex) {\n    const T = currentPhrase.length;\n\n    const ct = new Array(T).fill(0);\n    let logProb;\n    this.alphaSeq = [];\n    this.betaSeq = [];\n\n    const observationProbabilities = Array.from(\n      new Array(T),\n      () => new Array(this.params.states).fill(0),\n    );\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        observationProbabilities[t][i] =\n          this.params.xStates[i].likelihood(currentPhrase.getFrame(t));\n      }\n    }\n\n    // Forward algorithm\n    ct[0] = this.initializeForwardAlgorithm(currentPhrase.getFrame(0));\n    logProb = -Math.log(ct[0]);\n    this.alphaSeq.push(this.alpha.slice());\n\n    for (let t = 1; t < T; t += 1) {\n      ct[t] = this.baumWelchForwardUpdate(observationProbabilities[t]);\n      logProb -= Math.log(ct[t]);\n      this.alphaSeq.push(this.alpha.slice());\n    }\n\n    // Backward algorithm\n    this.initializeBackwardAlgorithm(ct[T - 1]);\n    this.betaSeq.push(this.beta.slice());\n\n    for (let t = T - 2; t >= 0; t -= 1) {\n      this.baumWelchBackwardUpdate(ct[t], observationProbabilities[t + 1]);\n      this.betaSeq.push(this.beta.slice());\n    }\n    this.betaSeq.reverse();\n\n    // Compute Gamma Variable\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.gammaSequence[phraseIndex][t][i] =\n          (this.alphaSeq[t][i] * this.betaSeq[t][i]) / ct[t];\n      }\n    }\n\n    // Compute Gamma variable for each mixture component\n    let normConst;\n\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        normConst = 0;\n        if (this.params.gaussians === 1) {\n          const oo = observationProbabilities[t][i];\n          this.gammaSequenceperMixture[phraseIndex][0][t][i] =\n            this.gammaSequence[phraseIndex][t][i] * oo;\n          normConst += oo;\n        } else {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            const oo = this.params.xStates[i]\n              .componentLikelihood(currentPhrase.getFrame(t), c);\n            this.gammaSequenceperMixture[phraseIndex][c][t][i] =\n              this.gammaSequence[phraseIndex][t][i] *\n              oo;\n            normConst += oo;\n          }\n        }\n        if (normConst > 0) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.gammaSequenceperMixture[phraseIndex][c][t][i] /= normConst;\n          }\n        }\n      }\n    }\n\n    // Compute Epsilon Variable\n    if (this.params.transitionMode === 'ergodic') {\n      for (let t = 0; t < T - 1; t += 1) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          for (let j = 0; j < this.params.states; j += 1) {\n            this.epsilonSequence[phraseIndex][t][i][j] =\n              this.alphaSeq[t][i] *\n              this.params.transition[i][j] *\n              this.betaSeq[t + 1][j];\n            this.epsilonSequence[phraseIndex][t][i][j] *=\n              observationProbabilities[t + 1][j];\n          }\n        }\n      }\n    } else {\n      for (let t = 0; t < T - 1; t += 1) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.epsilonSequence[phraseIndex][t][i * 2] =\n            this.alphaSeq[t][i] *\n            this.params.transition[i * 2] *\n            this.betaSeq[t + 1][i];\n          this.epsilonSequence[phraseIndex][t][i * 2] *=\n            observationProbabilities[t + 1][i];\n          if (i < this.params.states - 1) {\n            this.epsilonSequence[phraseIndex][t][(i * 2) + 1] =\n              this.alphaSeq[t][i] *\n              this.params.transition[(i * 2) + 1] *\n              this.betaSeq[t + 1][i + 1];\n            this.epsilonSequence[phraseIndex][t][(i * 2) + 1] *=\n              observationProbabilities[t + 1][i + 1];\n          }\n        }\n      }\n    }\n\n    return logProb;\n  },\n\n  /**\n   * Sums the Gamma variables used for parameter estimation during training\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchGammaSum(trainingSet) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.gammaSum[i] = 0;\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.gammaSumPerMixture[(i * this.params.gaussians) + c] = 0;\n      }\n    }\n\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          this.gammaSum[i] +=\n            this.gammaSequence[phraseIndex][t][i];\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.gammaSumPerMixture[(i * this.params.gaussians) + c] +=\n              this.gammaSequenceperMixture[phraseIndex][c][t][i];\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n  },\n\n  /**\n   * Estimate the mixture coefficients of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateMixtureCoefficients(trainingSet) {\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.params.xStates[i].params.mixtureCoeffs[c] +=\n              this.gammaSequenceperMixture[phraseIndex][c][t][i];\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale mixture coefficients\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.params.xStates[i].normalizeMixtureCoeffs();\n    }\n  },\n\n  /**\n   * Estimate the means of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateMeans(trainingSet) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.xStates[i].params.components[c].mean.fill(0);\n      }\n    }\n\n    // Re-estimate Mean\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            for (let d = 0; d < this.params.dimension; d += 1) {\n              this.params.xStates[i].params.components[c].mean[d] +=\n                this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                phrase.get(t, d);\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Normalize mean\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          if (this.gammaSumPerMixture[(i * this.params.gaussians) + c] > 0) {\n            this.params.xStates[i].params.components[c].mean[d] /=\n              this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n          }\n          if (Number.isNaN(this.params.xStates[i].params.components[c].mean[d])) {\n            throw new Error('Convergence Error');\n          }\n        }\n      }\n    }\n  },\n\n  /**\n   * Estimate the covariances of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateCovariances(trainingSet) {\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n              if (this.params.covarianceMode === 'full') {\n                for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n                  this.params.xStates[i].params.components[c]\n                    .covariance[(d1 * this.params.dimension) + d2] +=\n                    this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                    (phrase.get(t, d1) -\n                      this.params.xStates[i].params.components[c].mean[d1]) *\n                    (phrase.get(t, d2) -\n                      this.params.xStates[i].params.components[c].mean[d2]);\n                }\n              } else {\n                const value = phrase.get(t, d1) -\n                  this.params.xStates[i].params.components[c].mean[d1];\n                this.params.xStates[i].params.components[c].covariance[d1] +=\n                  this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                  (value ** 2);\n              }\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale covariance\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        if (this.gammaSumPerMixture[(i * this.params.gaussians) + c] > 0) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n                this.params.xStates[i].params.components[c]\n                  .covariance[(d1 * this.params.dimension) + d2] /=\n                  this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n                if (d1 !== d2) {\n                  this.params.xStates[i].params.components[c]\n                    .covariance[(d2 * this.params.dimension) + d1] =\n                    this.params.xStates[i].params.components[c]\n                      .covariance[(d1 * this.params.dimension) + d2];\n                }\n              }\n            } else {\n              this.params.xStates[i].params.components[c].covariance[d1] /=\n                this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n            }\n          }\n        }\n      }\n      this.params.xStates[i].regularize();\n      this.params.xStates[i].updateInverseCovariances();\n    }\n  },\n\n  /**\n   * Estimate the prior probabilities of the model\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimatePrior(trainingSet) {\n    this.params.prior.fill(0);\n\n    // Re-estimate Prior probabilities\n    let sumprior = 0;\n    for (let phraseIndex = 0;\n      phraseIndex < trainingSet.size();\n      phraseIndex += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] += this.gammaSequence[phraseIndex][0][i];\n        sumprior += this.params.prior[i];\n      }\n    }\n\n    // Scale Prior vector\n    if (sumprior > 0) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] /= sumprior;\n      }\n    } else {\n      throw new Error('The Prior is all ZERO.....');\n    }\n  },\n\n  /**\n   * Estimate the transition probabilities of the model\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateTransitions(trainingSet) {\n    // Set transition matrix to 0\n    this.params.transition = this.params.transitionMode === 'ergodic' ?\n      Array.from(\n        new Array(this.params.states),\n        () => new Array(this.params.states).fill(0),\n      ) :\n      new Array(this.params.states * 2).fill(0);\n\n    // Re-estimate Transition probabilities\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      if (phrase.length > 0) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          // Experimental: A bit of regularization (sometimes avoids\n          // numerical errors)\n          if (this.params.transitionMode === 'leftright') {\n            this.params.transition[i * 2] += TRANSITION_REGULARIZATION;\n            if (i < this.params.states - 1) {\n              this.params.transition[(i * 2) + 1] += TRANSITION_REGULARIZATION;\n            } else {\n              this.params.transition[i * 2] += TRANSITION_REGULARIZATION;\n            }\n          }\n          // End Regularization\n          if (this.params.transitionMode === 'ergodic') {\n            for (let j = 0; j < this.params.states; j += 1) {\n              for (let t = 0; t < phrase.length - 1; t += 1) {\n                this.params.transition[i][j] +=\n                  this.epsilonSequence[phraseIndex][t][i][j];\n              }\n            }\n          } else {\n            for (let t = 0; t < phrase.length - 1; t += 1) {\n              this.params.transition[i * 2] +=\n                this.epsilonSequence[phraseIndex][t][i * 2];\n            }\n            if (i < this.params.states - 1) {\n              for (let t = 0; t < phrase.length - 1; t += 1) {\n                this.params.transition[(i * 2) + 1] +=\n                  this.epsilonSequence[phraseIndex][t][(i * 2) + 1];\n              }\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale transition matrix\n    if (this.params.transitionMode === 'ergodic') {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.params.transition[i][j] /=\n            (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n          if (Number.isNaN(this.params.transition[i][j])) {\n            throw new Error('Convergence Error. Check your training data or increase the variance offset');\n          }\n        }\n      }\n    } else {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.transition[i * 2] /=\n          (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n        if (Number.isNaN(this.params.transition[i * 2])) {\n          throw new Error('Convergence Error. Check your training data or increase the variance offset');\n        }\n        if (i < this.params.states - 1) {\n          this.params.transition[(i * 2) + 1] /=\n            (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n          if (Number.isNaN(this.params.transition[(i * 2) + 1])) {\n            throw new Error('Convergence Error. Check your training data or increase the variance offset');\n          }\n        }\n      }\n    }\n  },\n};\n\n/**\n * Add HMM Training capabilities to a HMM Model\n * @param  {HMMBase} o               Source HMM Model\n * @param  {Number} [states=1]       Number of hidden states\n * @param  {Number} [gaussians=1]    Number of Gaussian components\n * @param  {Object} [regularization] Regularization parameters\n * @param  {Number} [regularization.absolute=1e-3] Absolute regularization\n * @param  {Number} [regularization.relative=1e-2] Relative Regularization\n (relative to the training set's variance along each dimension)\n * @param  {String} [transitionMode='ergodic'] Structure of the transition\n * matrix ('ergodic' or 'left-right').\n * @param  {String} [covarianceMode='full'] Covariance mode ('full' or diagonal)\n * @return {BMMBase}\n */\nexport default function withHMMTraining(\n  o,\n  states = 1,\n  gaussians = 1,\n  regularization = { absolute: 1e-3, relative: 1e-2 },\n  transitionMode = 'leftright',\n  covarianceMode = 'full',\n) {\n  if (!Object.keys(o).includes('params')) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    hmmTrainerPrototype,\n    {\n      params: {\n        ...o.params,\n        states,\n        gaussians,\n        regularization,\n        transitionMode,\n        covarianceMode,\n      },\n    },\n  );\n}\n","import validateParameters from '../common/validation';\nimport { isBaseModel } from '../core/model_base_mixin';\nimport { GMMPredictor } from '../gmm';\n\nconst hmmParameterSpec = (states, transitionMode) => ({\n  states: {\n    required: true,\n    check: { min: 1 },\n  },\n  gaussians: {\n    required: true,\n    check: { min: 1 },\n  },\n  regularization: {\n    required: true,\n    check: ({ absolute, relative }) =>\n      (absolute && relative && absolute > 0 && relative > 0),\n  },\n  transitionMode: {\n    required: true,\n    check: ['ergodic', 'leftright'],\n  },\n  covarianceMode: {\n    required: true,\n    check: ['full', 'diagonal'],\n  },\n  prior: {\n    required: true,\n    check: m => transitionMode === 'leftright' || m.length === states,\n  },\n  transition: {\n    required: true,\n    check: m => (transitionMode === 'leftright' ?\n      m.length === 2 * states :\n      m.length === states),\n  },\n  xStates: {\n    required: true,\n    check: m => m.length === states,\n  },\n});\n\n\n/**\n * HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hmmPredictionPrototype = /** @lends withHMMPrediction */ {\n  forwardInitialized: false,\n  isHierarchical: false,\n\n  /**\n   * Setup the Model by allocating GMM predictors to each of the hidden states\n   * @return {HMMBaseModel} the model\n   * @private\n   */\n  setup() {\n    this.params.xStates = this.params.xStates.map(s => GMMPredictor(s).reset());\n    return this;\n  },\n\n  /**\n   * Reset the prediction process\n   * @return {HMMBaseModel} the model\n   */\n  reset() {\n    this.likelihoodBuffer.clear();\n    this.params.xStates.forEach((s) => { s.reset(); });\n    return this;\n  },\n\n  /**\n   * Compute the likelihood of an observation given the HMM's parameters\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}\n   */\n  likelihood(observation) {\n    const ct = (this.forwardInitialized) ?\n      this.updateForwardAlgorithm(observation) :\n      this.initializeForwardAlgorithm(observation);\n    this.updateAlphaWindow();\n    this.updateProgress();\n    return 1 / ct;\n  },\n\n  updateProgress() {\n    this.results.progress = 0.0;\n    for (let i = this.windowMinindex; i < this.windowMaxindex; i += 1) {\n      if (this.isHierarchical) {\n        this.results.progress += (this.alpha[i] + this.alpha1[i] + this.alpha2[i]) *\n          (i / this.windowNormalizationConstant);\n      } else {\n        this.results.progress += (this.alpha[i] * i) /\n          this.windowNormalizationConstant;\n      }\n    }\n    this.results.progress /= this.params.states - 1;\n  },\n\n  /**\n   * Update the state probabilities filtering window (for multiclass\n   * hierarchical HMM I think...)\n   * @private\n   */\n  updateAlphaWindow() {\n    this.results.likeliestState = 0;\n    // Get likeliest State\n    let bestAlpha = this.isHierarchical ?\n      (this.alpha[0] + this.alpha1[0]) :\n      this.alpha[0];\n    for (let i = 1; i < this.params.states; i += 1) {\n      if (this.isHierarchical) {\n        if ((this.alpha[i] + this.alpha1[i]) > bestAlpha) {\n          bestAlpha = this.alpha[i] + this.alpha1[i];\n          this.results.likeliestState = i;\n        }\n      } else if (this.alpha[i] > bestAlpha) {\n        bestAlpha = this.alpha[i];\n        this.results.likeliestState = i;\n      }\n    }\n\n    // Compute Window\n    this.windowMinindex = this.results.likeliestState - Math.floor(this.params.states / 2);\n    this.windowMaxindex = this.results.likeliestState + Math.floor(this.params.states / 2);\n    this.windowMinindex = (this.windowMinindex >= 0) ? this.windowMinindex : 0;\n    this.windowMaxindex = (this.windowMaxindex <= this.params.states) ?\n      this.windowMaxindex : this.params.states;\n    this.windowNormalizationConstant = 0.0;\n    for (let i = this.windowMinindex; i < this.windowMaxindex; i += 1) {\n      this.windowNormalizationConstant += this.isHierarchical ?\n        (this.alpha[i] + this.alpha1[i]) :\n        this.alpha[i];\n    }\n  },\n};\n\n/**\n * Bimodal (regression) HMM Prototype\n * @type {Object}\n * @ignore\n */\nconst hmmBimodalPredictionPrototype = /** @lends withHMMPrediction */ {\n  /**\n   * Estimate the output values corresponding to the input observation, by\n   * regression given the HMM's parameters. This method is called Hidden\n   * Mixture Regression (GMR).\n   *\n   * @param  {Array<Number>} inputObservation Observation on the input modality\n   * @return {Array<Number>} Output values (length = outputDimension)\n   */\n  regression(inputObservation) {\n    this.results.outputValues = Array(this.params.outputDimension).fill(0);\n    this.results.outputCovariance = Array(this.params.covarianceMode === 'full' ? this.params.outputDimension ** 2 : this.params.outputDimension).fill(0);\n\n    if (this.params.regressionEstimator === 'likeliest') {\n      this.params.xStates[this.results.likeliestState].predict(inputObservation);\n      this.results.outputValues =\n        this.params.xStates[this.results.likeliestState].results.outputValues;\n      return this.results.outputValues;\n    }\n\n    const clipMinState = (this.params.regressionEstimator === 'full') ?\n      0 : this.windowMinindex;\n    const clipMaxState = (this.params.regressionEstimator === 'full') ?\n      this.params.states : this.windowMaxindex;\n    let normalizationConstant = (this.params.regressionEstimator === 'full') ?\n      1 : this.windowNormalizationConstant;\n\n    if (normalizationConstant <= 0.0) normalizationConstant = 1;\n\n    // Compute Regression\n    for (let i = clipMinState; i < clipMaxState; i += 1) {\n      this.params.xStates[i].likelihood(inputObservation);\n      this.params.xStates[i].regression(inputObservation);\n      const tmpPredictedOutput = this.params.xStates[i].results.outputValues;\n      for (let d = 0; d < this.params.outputDimension; d += 1) {\n        if (this.isHierarchical) {\n          this.results.outputValues[d] +=\n            (this.alpha[i] + this.alpha1[i]) *\n            (tmpPredictedOutput[d] / normalizationConstant);\n          if (this.params.covarianceMode === 'full') {\n            for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n              this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n                (this.alpha[i] + this.alpha1[i]) *\n                (this.alpha[i] + this.alpha1[i]) *\n                (this.params.xStates[i].results\n                  .outputCovariance[(d * this.params.outputDimension) + d2] /\n                normalizationConstant);\n            }\n          } else {\n            this.results.outputCovariance[d] +=\n              (this.alpha[i] + this.alpha1[i]) *\n              (this.alpha[i] + this.alpha1[i]) *\n              (this.params.xStates[i].results.outputCovariance[d] /\n              normalizationConstant);\n          }\n        } else {\n          this.results.outputValues[d] += this.alpha[i] *\n            (tmpPredictedOutput[d] / normalizationConstant);\n          if (this.params.covarianceMode === 'full') {\n            for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n              this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n                (this.alpha[i] ** 2) *\n                (this.params.xStates[i].results\n                  .outputCovariance[(d * this.params.outputDimension) + d2] /\n                normalizationConstant);\n            }\n          } else {\n            this.results.outputCovariance[d] +=\n              ((this.alpha[i] ** 2) *\n              this.params.xStates[i].results.outputCovariance[d]) /\n              normalizationConstant;\n          }\n        }\n      }\n    }\n    return this.results.outputValues;\n  },\n};\n\n/**\n * Add HMM prediction capabilities to a single-class model. Mostly, this checks\n * the validity of the model parameters\n *\n * @todo validate gaussian components\n *\n * @param  {HMMBaseModel} o Source Model\n * @return {HMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  validateParameters('HMM', hmmParameterSpec(o.params.states, o.params.transitionMode), o.params);\n  return Object.assign(\n    o,\n    hmmPredictionPrototype,\n    o.params.bimodal ? hmmBimodalPredictionPrototype : {},\n    {\n      alpha: new Array(o.params.states).fill(0),\n      previous_alpha_: new Array(o.params.states).fill(0),\n    },\n  ).setup();\n}\n","import { isBaseModel } from '../core/model_base_mixin';\n\nconst DEFAULT_EXITPROBABILITY_LAST_STATE = 0.1;\n\n/**\n * Hierarchical HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hierarchicalHmmPredictionPrototype =\n/** @lends withHierarchicalHMMPrediction */\n{\n  /**\n   * Specificies if the forward algorithm has been initialized\n   * @type {Boolean}\n   * @private\n   */\n  forwardInitialized: false,\n\n  /**\n   * Setup the model (allocate transition parameters)\n   * @return {HierarchicalHMM} [description]\n   * @private\n   */\n  setup() {\n    const numClasses = this.size();\n    this.params.prior = new Array(numClasses).fill(1 / numClasses);\n    this.params.transition = Array.from(\n      new Array(numClasses),\n      () => new Array(numClasses).fill(1 / numClasses),\n    );\n    this.params.exitTransition = new Array(numClasses).fill(0.1);\n    Object.values(this.models).forEach((model) => {\n      const m = model;\n      m.isHierarchical = true;\n    });\n    this.updateExitProbabilities();\n    return this;\n  },\n\n  /**\n   * Update the exit probabilities of each sub-Markov model\n   * @param  {Array<Number>|undefined} [exitProbabilities=undefined] Vector of\n   * exit probabilities (optional)\n   * @private\n   */\n  updateExitProbabilities(exitProbabilities = undefined) {\n    const exitProb = (exitProbabilities !== undefined) ?\n      exitProbabilities :\n      new Array(this.params.states - 1).fill(0)\n        .concat([DEFAULT_EXITPROBABILITY_LAST_STATE]);\n    Object.keys(this.models).forEach((label) => {\n      this.models[label].params.exitProbabilities = exitProb.slice();\n    });\n  },\n\n  /**\n   * Reset the prediction process. This is particularly important for temporal\n   * models such as HMMs, that depends on previous observations.\n   */\n  reset() {\n    Object.values(this.models).forEach(m => m.reset());\n    this.results = {\n      labels: [],\n      instantLikelihoods: [],\n      smoothedLikelihoods: [],\n      smoothedLogLikelihoods: [],\n      smoothedNormalizedLikelihoods: [],\n      exitLikelihood: [],\n      likeliest: null,\n      classes: {},\n    };\n    if (this.params.bimodal) {\n      this.resetBimodal();\n    }\n    this.forwardInitialized = false;\n  },\n\n  /**\n   * Make a prediction from a new observation (updates the results member)\n   * @param  {Array<Number>} observation Observation vector\n   */\n  predict(observation) {\n    if (this.forwardInitialized) {\n      this.updateForwardAlgorithm(observation);\n    } else {\n      this.initializeForwardAlgorithm(observation);\n    }\n    Object.keys(this.models).sort().forEach((label) => {\n      const model = this.models[label];\n      model.updateAlphaWindow();\n      model.updateProgress();\n      model.updateResults(model.results.instantLikelihood);\n    });\n    this.updateResults();\n\n    if (this.params.bimodal) {\n      Object.values(this.models).forEach(m => m.regression(observation));\n\n      if (this.params.multiClassRegressionEstimator === 'likeliest') {\n        this.results.outputValues =\n          this.models[this.results.likeliest].results.outputValues;\n        this.results.outputCovariance =\n          this.models[this.results.likeliest].results.outputCovariance;\n      } else {\n        this.results.outputValues = new Array(this.outputDimension).fill(0);\n        this.results.outputCovariance =\n          new Array(this.params.covarianceMode === 'full' ?\n            this.outputDimension ** 2 :\n            this.outputDimension).fill(0);\n\n        let modelIndex = 0;\n        Object.values(this.models).forEach((model) => {\n          for (let d = 0; d < this.outputDimension; d += 1) {\n            this.results.outputValues[d] +=\n              this.results.smoothedNormalizedLikelihoods[modelIndex] *\n              model.second.results.outputValues[d];\n\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n                this.results.outputCovariance[(d * this.outputDimension) + d2] +=\n                  this.results.smoothedNormalizedLikelihoods[modelIndex] *\n                  model.results.outputCovariance[(d * this.outputDimension) + d2];\n              }\n            } else {\n              this.results.outputCovariance[d] +=\n                this.results.smoothedNormalizedLikelihoods[modelIndex] *\n                model.second.results.outputCovariance[d];\n            }\n          }\n          modelIndex += 1;\n        });\n      }\n    }\n  },\n\n  /**\n   * Initialize the forward algorithm of the hierarchical HMM\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  initializeForwardAlgorithm(observation) {\n    let normConst = 0;\n    let modelIndex = 0;\n    const classes = Object.keys(this.models).sort();\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      model.alpha1 = new Array(N).fill(0);\n      model.alpha2 = new Array(N).fill(0);\n\n      // Compute Emission probability and initialize on the first state of\n      // the primitive\n      if (model.params.transitionMode === 'ergodic') {\n        model.results.instantLikelihood = 0;\n        for (let i = 0; i < N; i += 1) {\n          model.alpha[i] = this.params.prior[modelIndex] *\n            model.params.prior[i] *\n            model.params.xStates[i].likelihood(observation);\n          model.results.instantLikelihood += model.alpha[i];\n        }\n      } else {\n        model.alpha[0] = this.params.prior[modelIndex] *\n          model.params.xStates[0].likelihood(observation);\n        [model.results.instantLikelihood] = model.alpha;\n      }\n      normConst += model.results.instantLikelihood;\n      modelIndex += 1;\n    });\n\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      for (let i = 0; i < N; i += 1) {\n        model.alpha[i] /= normConst;\n      }\n    });\n\n\n    this.frontierV1 = new Array(this.size).fill(0);\n    this.frontierV2 = new Array(this.size).fill(0);\n    this.forwardInitialized = true;\n  },\n\n  /**\n   * Update the forward algorithm of the hierarchical HMM\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  updateForwardAlgorithm(observation) {\n    let normConst = 0;\n\n    // Frontier Algorithm: variables\n    let tmp = 0;\n\n    // Intermediate variables: compute the sum of probabilities of making a\n    // transition to a new primitive\n    this.frontierV1 = this.likelihoodAlpha(1);\n    this.frontierV2 = this.likelihoodAlpha(2);\n\n    // FORWARD UPDATE\n    // --------------------------------------\n    let dstModelIndex = 0;\n    const classes = Object.keys(this.models).sort();\n    classes.forEach((label) => {\n      const dstModel = this.models[label];\n      const N = dstModel.params.states;\n\n      // 1) COMPUTE FRONTIER VARIABLE\n      //    --------------------------------------\n      // frontier variable : intermediate computation variable\n      const front = new Array(N).fill(0);\n\n      if (dstModel.params.transitionMode === 'ergodic') {\n        for (let k = 0; k < N; k += 1) {\n          for (let j = 0; j < N; j += 1) {\n            front[k] += (dstModel.params.transition[j][k] /\n              (1 - dstModel.params.exitProbabilities[j]))\n              * dstModel.alpha[j];\n          }\n\n          for (\n            let srcModelIndex = 0;\n            srcModelIndex < this.size();\n            srcModelIndex += 1\n          ) {\n            front[k] += dstModel.params.prior[k] * (\n              (this.frontierV1[srcModelIndex] *\n              this.params.transition[srcModelIndex][dstModelIndex]) +\n              (this.params.prior[dstModelIndex] *\n              this.frontierV2[srcModelIndex])\n            );\n          }\n        }\n      } else {\n        // k=0: first state of the primitive\n        front[0] = dstModel.params.transition[0] * dstModel.alpha[0];\n\n        for (\n          let srcModelIndex = 0;\n          srcModelIndex < this.size();\n          srcModelIndex += 1\n        ) {\n          front[0] += (this.frontierV1[srcModelIndex] *\n            this.params.transition[srcModelIndex][dstModelIndex]) +\n            (this.params.prior[dstModelIndex] *\n              this.frontierV2[srcModelIndex]);\n        }\n\n        // k>0: rest of the primitive\n        for (let k = 1; k < N; k += 1) {\n          front[k] += (dstModel.params.transition[k * 2] /\n            (1 - dstModel.params.exitProbabilities[k])) *\n            dstModel.alpha[k];\n          front[k] += (dstModel.params.transition[((k - 1) * 2) + 1] /\n            (1 - dstModel.params.exitProbabilities[k - 1])) *\n            dstModel.alpha[k - 1];\n        }\n\n        for (let k = 0; k < N; k += 1) {\n          dstModel.alpha[k] = 0;\n          dstModel.alpha1[k] = 0;\n          dstModel.alpha2[k] = 0;\n        }\n      }\n\n      // 2) UPDATE FORWARD VARIABLE\n      //    --------------------------------------\n      dstModel.results.exitLikelihood = 0.0;\n      dstModel.results.instantLikelihood = 0.0;\n\n      // end of the primitive: handle exit states\n      for (let k = 0; k < N; k += 1) {\n        tmp = dstModel.params.xStates[k].likelihood(observation) * front[k];\n        dstModel.alpha2[k] = this.params.exitTransition[dstModelIndex] *\n          dstModel.params.exitProbabilities[k] * tmp;\n        dstModel.alpha1[k] = (1 - this.params.exitTransition[dstModelIndex]) *\n          dstModel.params.exitProbabilities[k] * tmp;\n        dstModel.alpha[k] = (1 - dstModel.params.exitProbabilities[k]) * tmp;\n\n        dstModel.results.exitLikelihood += dstModel.alpha1[k] + dstModel.alpha2[k];\n        dstModel.results.instantLikelihood += dstModel.alpha[k] +\n          dstModel.alpha1[k] + dstModel.alpha2[k];\n        normConst += tmp;\n      }\n\n      dstModel.results.exitRatio = dstModel.results.exitLikelihood /\n        dstModel.results.instantLikelihood;\n\n      dstModelIndex += 1;\n    });\n\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      for (let k = 0; k < N; k += 1) {\n        model.alpha[k] /= normConst;\n        model.alpha1[k] /= normConst;\n        model.alpha2[k] /= normConst;\n      }\n    });\n  },\n\n  /**\n   * Compute the likelihood of a given probability.\n   * @param  {Number} exitNum Exit level number\n   * @return {Array<Number>}\n   */\n  likelihoodAlpha(exitNum) {\n    const likelihoodVector = new Array(this.size()).fill(0);\n    if (exitNum < 0) {\n      // Likelihood over all exit states\n      let modelIndex = 0;\n      Object.keys(this.models).sort().forEach((label) => {\n        const model = this.models[label];\n        likelihoodVector[modelIndex] = 0.0;\n        for (let k = 0; k < model.params.states; k += 1) {\n          likelihoodVector[modelIndex] += model.second.alpha[k] +\n            model.second.alpha1[k] +\n            model.second.alpha2[k];\n        }\n        modelIndex += 1;\n      });\n    } else {\n      // Likelihood for exit state \"exitNum\"\n      let modelIndex = 0;\n      Object.keys(this.models).sort().forEach((label) => {\n        const model = this.models[label];\n        likelihoodVector[modelIndex] = 0;\n        let { alpha } = model;\n        if (exitNum === 1) {\n          alpha = model.alpha1;\n        }\n        if (exitNum === 2) {\n          alpha = model.alpha2;\n        }\n        for (let k = 0; k < model.params.states; k += 1) {\n          likelihoodVector[modelIndex] += alpha[k];\n        }\n        modelIndex += 1;\n      });\n    }\n    return likelihoodVector;\n  },\n};\n\n/**\n * Add Hierarchical HMM prediction capabilities to a multi-class model.\n *\n * @todo algorithmic details\n * @todo validate parameters\n * @todo validate gaussian components\n *\n * @param  {MulticlassBaseModel} o Source Model\n * @return {HierarchicalHMM}\n *\n * @extends withMulticlassPrediction\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHierarchicalHMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  // validateParameters(\n  //   'Hierarchical HMM',\n  //   hierarchicalHmmParameterSpec(o.params.states, o.params.transitionMode),\n  //   o.params,\n  // );\n  return Object.assign(\n    o,\n    hierarchicalHmmPredictionPrototype,\n    {\n      // alpha: new Array(o.params.states).fill(0),\n      // previous_alpha_: new Array(o.params.states).fill(0),\n    },\n  ).setup();\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withEMTraining from '../core/em_training_mixin';\nimport withHMMBase from './hmm_base_mixin';\nimport withHMMTraining from './hmm_training_mixin';\nimport MulticlassModelBase from '../core/multiclass_mixin';\nimport withMulticlassTraining from '../core/multiclass_training_mixin';\nimport withAbtractPrediction from '../core/prediction_mixin';\nimport withHMMPrediction from './hmm_prediction_mixin';\nimport withMulticlassPrediction from '../core/multiclass_prediction_mixin';\nimport withHierarchicalHMMPrediction from './hierarchical_hmm_prediction_mixin';\n\n/**\n * HMM training configuration\n *\n * @typedef {Object} HMMConfiguration\n * @property {Number} states Number of Hidden States\n * @property {Number} gaussians Number of Gaussian components\n * @property {{ absolute: 1e-3, relative: 1e-2 }} regularization An object containing the\n * relative and absolute regularization values. Regularization is an offset value added to the\n * diagonal of covariance matrices for convergence and generalization. The two values represent:\n * - `relative`: the offset relative to the variance of the training data\n * - `absolute`: an absolute lower threshold for the offset\n * @property {String} covarianceMode Type of covariance matrix ('full' or 'diagonal')\n */\n\n/**\n * @typedef {Object} HMMParameters\n * @property {Boolean} bimodal Specifies if the model is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} states Number of hidden states in the Markov model\n * @property {Number} gaussians Number of components in the Gaussian mixture\n * observation distribution of each state\n * @property {String} transitionMode Transition matrix mode ('ergodic' or 'leftright')\n * @property {String} covarianceMode Covariance mode ('full' or 'diagonal')\n * @property {Array<Number>} mixtureCoeffs mixture coefficients ('weight' of\n * each gaussian component)\n * @property {Array<GaussianDistribution>} components Gaussian components\n */\n\n/**\n * Train a single-class HMM Model.\n *\n * @todo HMM details\n *\n * @param  {TrainingSet} trainingSet training set\n * @param  {HMMConfiguration} configuration Training configuration\n * @param  {ConvergenceCriteria} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {HMMParameters} Parameters of the trained HMM\n */\nexport function trainHMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const {\n    states,\n    gaussians,\n    regularization,\n    transitionMode,\n    covarianceMode,\n  } = configuration;\n  const model = withHMMTraining(\n    withEMTraining(\n      withHMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        ...configuration,\n      })),\n      convergenceCriteria,\n    ),\n    states,\n    gaussians,\n    regularization,\n    transitionMode,\n    covarianceMode,\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Train a multi-class HMM Model.\n *\n * @todo HMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {HMMConfiguration} configuration                   Training configuration\n * @param  {ConvergenceCriteria} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {HMMParameters} Parameters of the trained HMM\n */\nexport function trainMulticlassHMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withMulticlassTraining(\n    MulticlassModelBase({ inputDimension, outputDimension, ...configuration }),\n    ts => trainHMM(ts, configuration, convergenceCriteria),\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Create a HMM Predictor from a full set of parameters (generated by trainHMM).\n * @param {HMMParameters} params                       Model parameters\n * @param {number} [likelihoodWindow=1] Likelihoow window size\n * @function\n */\nexport function HMMPredictor(\n  params,\n  likelihoodWindow = 1,\n) {\n  const model = withHMMPrediction(withAbtractPrediction(\n    withHMMBase(ModelBase(params)),\n    likelihoodWindow,\n  ));\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass HMM Predictor from a full set of parameters\n * (generated by trainMulticlassHMM).\n * @param {HMMParameters} params                       Model parameters\n * @param {number} [likelihoodWindow=1] Likelihoow window size\n * @function\n */\nexport function MulticlassHMMPredictor(\n  params,\n  likelihoodWindow = 1,\n) {\n  const model = withMulticlassPrediction(MulticlassModelBase(params));\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = HMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass HMM Predictor from a full set of parameters\n * (generated by trainMulticlassHMM).\n * @param {HMMParameters} params Model parameters\n * @param {number} [likelihoodWindow=1] Likelihoow window size\n * @function\n */\nexport function HierarchicalHMMPredictor(\n  params,\n  likelihoodWindow = 1,\n) {\n  let model = MulticlassModelBase(params);\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = HMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model = withHierarchicalHMMPrediction(withMulticlassPrediction(model));\n  model.reset();\n  return model;\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withKMeansTraining from './kmeans_training_mixin';\n\n/**\n * Train a K-Means model.\n *\n * @todo K-Means details\n *\n * @param  {TrainingSet} trainingSet           training set\n * @param  {number} clusters                   Number of clusters\n * @param  {Object} [trainingConfig=undefined] Training configuration\n * @return {Object}                            K-Means parameters\n */\nexport default function trainKmeans(\n  trainingSet,\n  clusters,\n  trainingConfig = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withKMeansTraining(\n    ModelBase({\n      inputDimension,\n      outputDimension,\n    }),\n    clusters,\n    trainingConfig,\n  );\n  return model.train(trainingSet);\n}\n"],"names":["phrasePrototype","index","dim","Math","floor","Error","this","dimension","bimodal","inputDimension","inputData","length","outputData","concat","observation","push","slice","trim","outputDimension","mean","Array","fill","d","t","get","stddev","sqrt","minmax","from","min","Infinity","max","trainingSetPrototype","Object","keys","phrases","phraseIndex","includes","toString","callback","forEach","label","phrase","p","undefined","columnNames","assign","create","Phrase","filter","i","map","reduce","x","ts","TrainingSet","[object Object]","ll","sum","totalLength","ModelBase","isBaseModel","o","key","params","a","b","euclidean","v1","v2","x1","kMeansTrainingPrototype","trainingSet","empty","centers","clusters","trainingConfig","initialization","initializeClustersRandom","initializeClustersForgy","initClustersWithFirstPhrase","trainingNbIterations","maxIterations","previousCenters","updateCenters","meanClusterDistance","maxRelativeCenterVariation","k","l","relativeDistanceThreshold","getPhrase","indices","step","offset","c","random","pointsPerCluster","ppc","clustIdx","_","getFrame","numFramesPerCluster","frame","minDistance","clusterMembership","distance","withKMeansTraining","trainingConfiguration","model","matrixPrototype","data","out","Matrix","ncols","nrows","j","mat","gaussJordanInverse","transp","transpose","prod","product","determinant","matrix","dst","newMat","n","abs","swapLines","ii","tmp","nc","baseGaussianPrototype","covarianceMode","covariance","inverseCovariance","allocateBimodal","covarianceDeterminant","inputLikelihood","euclideanDistance","exp","PI","Number","isNaN","regularization","covMatrix","inv","pinv","updateInverseCovarianceBimodal","dimension1","dimension2","gaussianEllipse","y","trace","eigenVal1","eigenVal2","width","height","angle","atan","tantheta","tan","updateInverseCovariance","bimodalGaussianPrototype","inverseCovarianceInput","inputObservation","covarianceDeterminantInput","prediction","e","f","covMatrixInput","d1","d2","invInput","updateOutputCovariance","outputCovariance","covarianceGS","covarianceSG","tmptmptmp","covarianceMod","GaussianDistribution","proto","dist","allocate","trainerPrototype","initTraining","logLikelihood","iterations","previousLogLikelihood","converged","updateTraining","pctChg","terminateTraining","iteration","logProb","previousLogProb","convergenceCriteria","minIterations","percentChange","withEMTraining","gmmBasePrototype","components","gaussians","mixtureCoeffs","beta","likelihood","componentLikelihood","mixtureComponent","normConst","regularize","currentRegularization","gmmBimodalPrototype","tmpOutputValues","results","outputValues","regression","withGMMBase","gmmTrainerPrototype","initParametersToDefault","standardDeviation","initMeansWithKMeans","initCovariances","updateInverseCovariances","dataStddev","normCoeffs","std","absolute","relative","kmeansParams","train","gmeans","factor","phraseIndices","E","tbase","log","pix","value","MulticlassBasePrototype","models","MulticlassModelBase","parameters","withMulticlassTraining","trainingFunction","labels","classes","getPhrasesOfClass","circularBufferPrototype","full","buffer","capacity","idx","CircularBuffer","clear","predictionBasePrototype","lw","likelihoodWindow","likelihoodBuffer","updateResults","instantLikelihood","bufSize","withAbtractPrediction","validateParameters","specification","values","attr","spec","required","parameter","constructor","check","transform","gmmParameterSpec","m","MulticlassPredictionBasePrototype","setLikelihoodWindow","reset","resetBimodal","predict","labs","sort","normInstant","normSmoothed","maxLogLikelihood","lab","instantLikelihoods","smoothedLogLikelihoods","smoothedLikelihoods","likeliest","smoothedNormalizedLikelihoods","instantNormalizedLikelihoods","updateRegressionResults","MulticlassPredictionBimodalPrototype","multiClassRegressionEstimator","configuration","withMulticlassPrediction","trainGMM","withGMMTraining","GMMPredictor","withGMMPrediction","hmmBasePrototype","transitionMode","states","alpha","prior","xStates","forwardInitialized","previousAlpha","transition","withHMMBase","hmmTrainerPrototype","initMeansCovariancesWithGMMEM","initMeansWithAllPhrases","initCovariancesFullyObserved","s","previousBeta","nbPhrases","size","gammaSequence","epsilonSequence","gammaSequenceperMixture","T","gammaSum","gammaSumPerMixture","baumWelchForwardBackward","baumWelchGammaSum","baumWelchEstimateMixtureCoefficients","baumWelchEstimateMeans","baumWelchEstimateCovariances","baumWelchEstimatePrior","baumWelchEstimateTransitions","normalizeTransitions","alphaSeq","betaSeq","setErgodic","setLeftRight","initCovariance","othermeans","gmmParams","normPrior","transitionNorm","ct","observationLikelihoods","currentPhrase","observationProbabilities","initializeForwardAlgorithm","baumWelchForwardUpdate","initializeBackwardAlgorithm","baumWelchBackwardUpdate","reverse","oo","normalizeMixtureCoeffs","sumprior","hmmParameterSpec","hmmPredictionPrototype","updateForwardAlgorithm","updateAlphaWindow","updateProgress","progress","windowMinindex","windowMaxindex","isHierarchical","alpha1","alpha2","windowNormalizationConstant","likeliestState","bestAlpha","hmmBimodalPredictionPrototype","regressionEstimator","clipMinState","clipMaxState","normalizationConstant","tmpPredictedOutput","hierarchicalHmmPredictionPrototype","numClasses","exitTransition","updateExitProbabilities","exitProbabilities","exitProb","modelIndex","second","N","frontierV1","frontierV2","likelihoodAlpha","dstModelIndex","dstModel","front","srcModelIndex","exitLikelihood","exitRatio","exitNum","likelihoodVector","trainHMM","withHMMTraining","HMMPredictor","setup","withHMMPrediction","withHierarchicalHMMPrediction"],"mappings":"sLAIA,MAAMA,OAOAC,EAAOC,MACY,iBAAVD,GAAsBE,KAAKC,MAAMH,KAAWA,QAC/C,IAAII,MAAM,mCAEdH,GAAOI,KAAKC,gBACR,IAAIF,MAAM,sCAEdC,KAAKE,QAAS,IACZN,EAAMI,KAAKG,eAAgB,IACzBR,GAASK,KAAKI,UAAUC,aACpB,IAAIN,MAAM,sCAEXC,KAAKI,UAAUT,GAAOC,MAE3BD,GAASK,KAAKM,WAAWD,aACrB,IAAIN,MAAM,sCAEXC,KAAKM,WAAWX,GAAOC,EAAMI,KAAKG,mBAEvCR,GAASK,KAAKK,aACV,IAAIN,MAAM,mCAEbC,KAAKI,UAAUT,SACZ,IAAII,MAAM,eAEXC,KAAKI,UAAUT,GAAOC,aAStBD,MACHA,GAASK,KAAKK,aACV,IAAIN,MAAM,sCAEdC,KAAKE,QACAF,KAAKI,UAAUT,GAAOY,OAAOP,KAAKM,WAAWX,IAE/CK,KAAKI,UAAUT,SASnBa,MAECA,EAAYH,SAAWL,KAAKC,gBACxB,IAAIF,MAAM,mCAGdC,KAAKE,cACFE,UAAUK,KAAKD,EAAYE,MAAM,EAAGV,KAAKG,sBACzCG,WAAWG,KAAKD,EAAYE,MAAMV,KAAKG,eAAgBH,KAAKC,kBAE5DG,UAAUK,KAAKD,QAGjBH,QAAU,aAUPG,OACHR,KAAKE,cACF,IAAIH,MAAM,0CAEdS,EAAYH,SAAWL,KAAKG,qBACxB,IAAIJ,MAAM,wCAGbK,UAAUK,KAAKD,QACfG,mBAUIH,OACJR,KAAKE,cACF,IAAIH,MAAM,0CAEdS,EAAYH,SAAWL,KAAKY,sBACxB,IAAIb,MAAM,wCAGbO,WAAWG,KAAKD,QAChBG,qBAOAN,OAAS,OACTD,kBACAE,iCAOAF,kBACAO,2BAOAL,mBACAK,qBASCE,EAAOC,MAAMd,KAAKC,WAAWc,KAAK,OACnC,IAAIC,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,KACrC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC/BD,IAAMhB,KAAKkB,IAAID,EAAGD,KAEpBA,IAAMhB,KAAKK,cAEXQ,6BASDM,EAASL,MAAMd,KAAKC,WAAWc,KAAK,GACpCF,EAAOb,KAAKa,WACb,IAAIG,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,KACrC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC7BD,KAAOhB,KAAKkB,IAAID,EAAGD,GAAKH,EAAKG,KAAOhB,KAAKkB,IAAID,EAAGD,GAAKH,EAAKG,MAE5DA,IAAMhB,KAAKK,SACXW,GAAKnB,KAAKuB,KAAKD,EAAOH,WAExBG,kBASDE,EAASP,MAAMQ,KACnBR,MAAMd,KAAKC,WACX,MAASsB,IAAMC,EAAAA,EAAUC,KAAMD,EAAAA,SAE5B,IAAIR,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC7BD,GAAGO,IAAM1B,KAAK0B,IAAIvB,KAAKkB,IAAID,EAAGD,GAAIK,EAAOL,GAAGO,OAC5CP,GAAGS,IAAM5B,KAAK4B,IAAIzB,KAAKkB,IAAID,EAAGD,GAAIK,EAAOL,GAAGS,YAGhDJ,UAQHrB,KAAKE,eACFG,OAASR,KAAK0B,IAAIvB,KAAKI,UAAUC,OAAQL,KAAKM,WAAWD,6SCjMpE,MAAMqB,iBAMKC,OAAOC,KAAK5B,KAAK6B,SAASxB,uBAQV,IAAhBL,KAAKK,kBAQJyB,UACJH,OAAOC,KAAK5B,KAAK6B,SAASE,SAASD,EAAYE,YAC1ChC,KAAK6B,QAAQC,EAAYE,YAE3B,cAUDC,UACCL,KAAK5B,KAAK6B,SAASK,QAASJ,MACxB9B,KAAK6B,QAAQC,GAAcA,EAAa9B,KAAK6B,iBAYrDC,EAAaK,EAAmBC,SAC7BC,OAAgBC,IAAXF,EAAwBA,EDyKxB,UAAgBjC,iBACZ,EADYS,kBAEX,EAFW2B,cAGf,KAHeJ,QAIrB,cAEFlC,EAAYE,EAAiBS,SAC5Be,OAAOa,OACZb,OAAOc,OAAO/C,YAEHkB,EAAkB,wDAInB,iDAIK2B,GAAezB,MAAMb,GAAWc,KAAK,MC3LR2B,iBAC1B1C,KAAKG,+BACJH,KAAKY,4BACTZ,KAAKuC,uBACAD,IAAVH,EAAuBA,EAAQL,EAAYE,yBAEhDH,QAAQC,GAAeO,EACrBA,UAOFP,UACE9B,KAAK6B,QAAQC,gBAOVK,QACLN,QAAUF,OAAOC,KAAK5B,KAAK6B,SAC7Bc,OAAOC,GAAK5C,KAAK6B,QAAQe,GAAGT,QAAUA,GACtCU,IAAID,KAAQA,EAAG5C,KAAK6B,QAAQe,MAC5BE,OAAO,CAACC,EAAGV,SAAYU,EAAMV,qBAO3BR,8BAQWM,SACVa,EAAKC,EAAYjD,eACpB6B,QAAUF,OAAOC,KAAK5B,KAAK6B,SAC3Bc,OAAOC,GAAK5C,KAAK6B,QAAQe,GAAGT,QAAUA,GACtCU,IAAID,KAAQM,CAACN,GAAI5C,KAAK6B,QAAQe,MAC9BE,OAAO,CAACC,EAAGV,SAAYU,EAAMV,OACzBW,mBAQArB,OAAOC,KAAK5B,KAAK6B,SACrBgB,IAAID,GAAK5C,KAAK6B,QAAQe,GAAGT,OACzBW,OAAO,CAACK,EAAIJ,IAAOI,EAAGpB,SAASgB,GAAKI,EAAKA,EAAG5C,QAAQwC,0BAQhDpB,OAAOC,KAAK5B,KAAK6B,uBAQlBuB,EAAMtC,MAAMd,KAAKC,WAAWc,KAAK,OACnCsC,EAAc,gBACXzB,KAAK5B,KAAK6B,SAASK,QAASU,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAK6B,QAAQe,GAAGvC,OAAQY,GAAK,IAC3CD,IAAMhB,KAAK6B,QAAQe,GAAG1B,IAAID,EAAGD,MAGtBhB,KAAK6B,QAAQe,GAAGvC,SAG1B+C,EAAIP,IAAIE,GAAKA,EAAIM,8BAQlBlC,EAASL,MAAMd,KAAKC,WAAWc,KAAK,GACpCF,EAAOb,KAAKa,WACdwC,EAAc,gBACXzB,KAAK5B,KAAK6B,SAASK,QAASU,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAK6B,QAAQe,GAAGvC,OAAQY,GAAK,IACxCD,KAAOhB,KAAK6B,QAAQe,GAAG1B,IAAID,EAAGD,GAAKH,EAAKG,KAAO,KAG3ChB,KAAK6B,QAAQe,GAAGvC,SAG1Bc,EAAO0B,IAAIE,GAAKlD,KAAKuB,KAAK2B,EAAIM,oBAQ/BhC,EAASP,MAAMQ,KACnBR,MAAMd,KAAKC,WACX,MAASsB,IAAMC,EAAAA,EAAUC,KAAMD,EAAAA,mBAE1BI,KAAK5B,KAAK6B,SAASK,QAASU,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAK6B,QAAQe,GAAGvC,OAAQY,GAAK,IACxCD,GAAGO,KAAO1B,KAAK0B,IAAIF,EAAOL,GAAGO,IAAKvB,KAAK6B,QAAQe,GAAG1B,IAAID,EAAGD,MACzDA,GAAGS,KAAO5B,KAAK4B,IAAIJ,EAAOL,GAAGS,IAAKzB,KAAK6B,QAAQe,GAAG1B,IAAID,EAAGD,MAI/DK,IAkCI,SAAS4B,GAAY9C,iBACjB,EADiBS,kBAEhB,EAFgB2B,cAGpB,gBAERtC,EAAYE,EAAiBS,SAC5Be,OAAOa,OACZb,OAAOc,OAAOf,YAEHd,EAAkB,6DAId2B,GAAezB,MAAMb,GAAWc,KAAK,iBC3NzC,SAASuC,SAAUnD,iBAAAS,2BAK1ByB,0DACCA,EAAEnC,eACFmC,EAAElC,sBACFkC,EAAEzB,uBACFyB,EAAEpC,uBAGFoC,wBAEMzB,EAAkB,+BAGlBT,gCAGAS,0BAGAT,EAAiBS,MAWzB,SAAS2C,EAAYC,OACrB7B,OAAOC,KAAK4B,GAAGzB,SAAS,UAAW,OAAO,SACjC,UAAW,iBAAkB,kBAAmB,aAClDc,IAAIY,GAAO9B,OAAOC,KAAK4B,EAAEE,QAAQ3B,SAAS0B,IACnDX,OAAO,CAACa,EAAGC,IAAMD,GAAKC,GAAG,GCzCf,SAASC,EAAUC,EAAIC,UAC7BlE,KAAKuB,KAAK0C,EACdjB,IAAI,CAACmB,EAAIpB,KAAOoB,EAAKD,EAAGnB,KAAO,GAC/BE,OAAO,CAACa,EAAGZ,IAAOY,EAAIZ,EAAI,UCNzBkB,SACEC,OACCA,GAAeA,EAAYC,cACxB,IAAIpE,MAAM,qCAGb2D,OAAOU,QAAUtD,MAAMQ,KAC1BR,MAAMd,KAAK0D,OAAOW,UAClB,IAAM,IAAIvD,MAAMd,KAAK0D,OAAOzD,WAAWc,KAAK,IAMH,WAAvCf,KAAKsE,eAAeC,oBACjBC,yBAAyBN,QACzB,GAA2C,UAAvClE,KAAKsE,eAAeC,oBACxBE,wBAAwBP,OACxB,CAAA,GAA2C,SAAvClE,KAAKsE,eAAeC,qBAGvB,IAAIxE,MAAM,4EAFX2E,4BAA4BR,OAMjC,IAAIS,EAAuB,EAC3BA,EAAuB3E,KAAKsE,eAAeM,cAC3CD,GAAwB,EACxB,OACME,EAAkB7E,KAAK0D,OAAOU,aAE/BU,cAAcD,EAAiBX,OAEhCa,EAAsB,EACtBC,EAA6B,MAC5B,IAAIC,EAAI,EAAGA,EAAIjF,KAAK0D,OAAOW,SAAUY,GAAK,EAAG,KAC3C,IAAIC,EAAI,EAAGA,EAAIlF,KAAK0D,OAAOW,SAAUa,GAAK,EACzCD,IAAMC,OACerB,EACrB7D,KAAK0D,OAAOU,QAAQa,GACpBjF,KAAK0D,OAAOU,QAAQc,OAIGrF,KAAK4B,IAChCoC,EACEgB,EAAgBI,GAChBjF,KAAK0D,OAAOU,QAAQa,IAEtBD,SAGmBhF,KAAK0D,OAAOW,UAAYrE,KAAK0D,OAAOW,SAAW,MACxCrE,KAAK0D,OAAOW,aACZU,GACG/E,KAAKsE,eAAea,0BAA2B,aAE3EnF,KAAK0D,oCAGcQ,SACpB9B,EAAS8B,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDC,EAAOzF,KAAKC,MAAMsC,EAAO/B,OAASL,KAAK0D,OAAOW,cAEhDkB,EAAS,MACR,IAAIC,EAAI,EAAGA,EAAIxF,KAAK0D,OAAOW,SAAUmB,GAAK,EAAG,MAC3C9B,OAAOU,QAAQoB,GAAK,IAAI1E,MAAMd,KAAK0D,OAAOzD,WAAWc,KAAK,OAC1D,IAAIE,EAAI,EAAGA,EAAIqE,EAAMrE,GAAK,MACxB,IAAID,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOU,QAAQoB,GAAGxE,IAAMoB,EAAOlB,IAAIqE,EAAStE,EAAGD,GAAKsE,KAGnDA,6BAIWpB,SACjB9B,EAAS8B,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDA,EAAUvE,MAAMQ,KACpBR,MAAMsB,EAAO/B,QACb,IAAMR,KAAKC,MAAMD,KAAK4F,SAAWzF,KAAK0D,OAAOW,WAEzCqB,EAAmBL,EAAQvC,OAC/B,CAAC6C,EAAK/C,WACEP,EAAIsD,WACR/C,IAAM,EACDP,GAETvB,MAAMd,KAAK0D,OAAOW,UAAUtD,KAAK,QAE9B,IAAI6B,EAAI,EAAGA,EAAIyC,EAAQhF,OAAQuC,GAAK,EAAG,OACpCgD,EAAWP,EAAQzC,OACpB,IAAI5B,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOU,QAAQwB,GAAU5E,IAAMoB,EAAOlB,IAAI0B,EAAG5B,QAGjD0C,OAAOU,QAAQlC,QAAQ,CAAC2D,EAAGL,UACzB9B,OAAOU,QAAQoB,GAAKxF,KAAK0D,OAAOU,QAAQoB,GAC1C3C,IAAIE,GAAKA,EAAI2C,EAAiBF,+BAIbtB,SAChB9B,EAAS8B,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDA,EAAUvE,MAAMQ,KACpBR,MAAMd,KAAK0D,OAAOW,UAClB,IAAMxE,KAAKC,MAAMD,KAAK4F,SAAWrD,EAAO/B,cAErCqD,OAAOU,QAAUiB,EAAQxC,IAAID,GAAKR,EAAO0D,SAASlD,mBAG3CiC,EAAiBX,QACxBR,OAAOU,QAAUtD,MAAMQ,KAAKR,MAAMd,KAAK0D,OAAOW,UAAW,IAC5D,IAAIvD,MAAMd,KAAK0D,OAAOzD,WAAWc,KAAK,UAClCgF,EAAsBjF,MAAMd,KAAK0D,OAAOW,UAAUtD,KAAK,KACjDmB,QAASE,QACd,IAAInB,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,EAAG,OACnC+E,EAAQ5D,EAAO0D,SAAS7E,OAC1BgF,EAAcpC,EAAUmC,EAAOnB,EAAgB,IAC/CqB,EAAoB,MACnB,IAAIjB,EAAI,EAAGA,EAAIjF,KAAK0D,OAAOW,SAAUY,GAAK,EAAG,OAC1CkB,EAAWtC,EACfmC,EACAnB,EAAgBI,GAChBjF,KAAK0D,OAAOzD,WAEVkG,EAAWF,MACOhB,IACNkB,KAGED,IAAsB,MACrC,IAAIlF,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOU,QAAQ8B,GAAmBlF,IAAMoB,EAAOlB,IAAID,EAAGD,UAI5D,IAAIiE,EAAI,EAAGA,EAAIjF,KAAK0D,OAAOW,SAAUY,GAAK,KACzCc,EAAoBd,GAAK,MACtB,IAAIjE,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOU,QAAQa,GAAGjE,IAAM+E,EAAoBd,KAO5C,SAASmB,EACtB5C,EACAa,EACAgC,UAEK9C,EAAYC,SACT,IAAIzD,MAAM,qGAEZuE,EAAiB3C,OAAOa,uBACZ,mCACW,mBACZ,gBACA,KACd6D,GACGC,EAAQ3E,OAAOa,OAAOgB,EAAGS,+BAGzBP,OAAOW,SAAWA,EACjBiC,ECvKT,MAWMC,gBAMKvG,KAAKwG,KAAK1D,OAAO,CAACa,EAAGC,IAAMD,EAAIC,EAAG,sBAQnC6C,EAAMC,EAAO1G,KAAK2G,MAAO3G,KAAK4G,WAC/B,IAAIhE,EAAI,EAAGA,EAAI5C,KAAK2G,MAAO/D,GAAK,MAC9B,IAAIiE,EAAI,EAAGA,EAAI7G,KAAK4G,MAAOC,GAAK,IAC/BL,KAAM5D,EAAI5C,KAAK4G,MAASC,GAAK7G,KAAKwG,KAAMK,EAAI7G,KAAK2G,MAAS/D,UAG3D6D,WAQDK,MACF9G,KAAK2G,QAAUG,EAAIF,YACf,IAAI7G,MAAM,6CAEZ0G,EAAMC,EAAO1G,KAAK4G,MAAOE,EAAIH,WAC9B,IAAI/D,EAAI,EAAGA,EAAI5C,KAAK4G,MAAOhE,GAAK,MAC9B,IAAIiE,EAAI,EAAGA,EAAIC,EAAIH,MAAOE,GAAK,EAAG,GACjCL,KAAM5D,EAAIkE,EAAIH,MAASE,GAAK,MAC3B,IAAI5B,EAAI,EAAGA,EAAIjF,KAAK2G,MAAO1B,GAAK,IAC/BuB,KAAM5D,EAAIkE,EAAIH,MAASE,IACzB7G,KAAKwG,KAAM5D,EAAI5C,KAAK2G,MAAS1B,GAAK6B,EAAIN,KAAMvB,EAAI6B,EAAIH,MAASE,UAI9DJ,aASHzG,KAAK4G,QAAU5G,KAAK2G,aACf3G,KAAK+G,2BAGRC,EAAShH,KAAKiH,eAChBjH,KAAK4G,OAAS5G,KAAK2G,MAAO,OACtBO,EAAOF,EAAOG,QAAQnH,OACtBoH,YAAEA,EAAaC,OAAQC,GAAQJ,EAAKH,4BACjCK,YAAAA,EAAaC,OAAQC,EAAIH,QAAQH,UAEtCE,EAAOlH,KAAKmH,QAAQH,IACpBI,YAAEA,EAAaC,OAAQC,GAAQJ,EAAKH,4BACjCK,YAAAA,EAAaC,OAAQL,EAAOG,QAAQG,6BASzCtH,KAAK4G,QAAU5G,KAAK2G,YAChB,IAAI5G,MAAM,+DAEdqH,EAAc,QACZN,EAAMJ,EAAO1G,KAAK4G,MAAoB,EAAb5G,KAAK2G,OAC9BY,EAASb,EAAO1G,KAAK4G,MAAoB,EAAb5G,KAAK2G,OACjCa,EAAIxH,KAAK4G,UAGV,IAAIhE,EAAI,EAAGA,EAAI4E,EAAG5E,GAAK,EAAG,KACxB,IAAIiE,EAAI,EAAGA,EAAIW,EAAGX,GAAK,IACtBL,KAAU,EAAJ5D,EAAQ4E,EAAKX,GAAK7G,KAAKwG,KAAM5D,EAAI4E,EAAKX,KAE9CL,KAAU,EAAJ5D,EAAQ4E,EAAKA,EAAI5E,GAAK,MAG7B,IAAIqC,EAAI,EAAGA,EAAIuC,EAAGvC,GAAK,EAAG,KACzBrC,EAAIqC,OACDpF,KAAK4H,IAAIX,EAAIN,KAAU,EAAJ5D,EAAQ4E,EAAKvC,IArGf,aAsGjB,KACKuC,QACF,IAAIzH,MAAM,4BAGL+G,EAAIN,KAAU,EAAJ5D,EAAQ4E,EAAKvC,GAGlCrC,IAAMqC,KACJyC,UAAU9E,EAAGqC,KAGZuB,KAAOM,EAAIN,KAAK9F,YAElB,IAAImG,EAAI,EAAGA,EAAI,EAAIW,EAAGX,GAAK,IACvBL,KAAU,EAAJvB,EAAQuC,EAAKX,IAAMC,EAAIN,KAAU,EAAJvB,EAAQuC,EAAKvC,OAEpD,IAAI0C,EAAK,EAAGA,EAAKH,EAAGG,GAAM,KACzBA,IAAO1C,MACJ,IAAI4B,EAAI,EAAGA,EAAI,EAAIW,EAAGX,GAAK,IACvBL,KAAW,EAALmB,EAASH,EAAKX,IACvBC,EAAIN,KAAW,EAALmB,EAASH,EAAKvC,GACxBsC,EAAOf,KAAU,EAAJvB,EAAQuC,EAAKX,KAIhCL,KAAOe,EAAOf,KAAK9F,cAGnB4G,EAAMZ,EAAO1G,KAAK4G,MAAO5G,KAAK2G,WAC/B,IAAI/D,EAAI,EAAGA,EAAI4E,EAAG5E,GAAK,MACrB,IAAIiE,EAAI,EAAGA,EAAIW,EAAGX,GAAK,IACtBL,KAAM5D,EAAI4E,EAAKX,GAAKC,EAAIN,KAAU,EAAJ5D,EAAQ4E,EAAKA,EAAIX,UAG9CO,YAAAA,EAAaC,OAAQC,cAStB1E,EAAGiE,OACN,IAAI5B,EAAI,EAAGA,EAAIjF,KAAK2G,MAAO1B,GAAK,EAAG,OAChC2C,EAAM5H,KAAKwG,KAAM5D,EAAI5C,KAAK2G,MAAS1B,QACpCuB,KAAM5D,EAAI5C,KAAK2G,MAAS1B,GAAKjF,KAAKwG,KAAMK,EAAI7G,KAAK2G,MAAS1B,QAC1DuB,KAAMK,EAAI7G,KAAK2G,MAAS1B,GAAK2C,gBAU1BhF,EAAGiE,OACR,IAAI5B,EAAI,EAAGA,EAAIjF,KAAK4G,MAAO3B,GAAK,EAAG,OAChC2C,EAAM5H,KAAKwG,KAAMvB,EAAIjF,KAAK2G,MAAS/D,QACpC4D,KAAMvB,EAAIjF,KAAK2G,MAAS/D,GAAK5C,KAAKwG,KAAMvB,EAAIjF,KAAK2G,MAASE,QAC1DL,KAAMvB,EAAIjF,KAAK2G,MAASE,GAAKe,KAiBzB,SAASlB,EAAOE,EAAQ,EAAGD,GAAQ,SAC1CkB,EAAKlB,EAAQ,EAAIC,EAAQD,SACxBhF,OAAOa,OACZb,OAAOc,OAAO8D,kBAGLsB,OACD/G,MAAM8F,EAAQiB,GAAI9G,KAAK,KC5KnC,MAAM+G,mBAMGjH,KAAO,IAAIC,MAAMd,KAAKC,WAAWc,KAAK,GACf,SAAxBf,KAAK+H,qBACFC,WAAa,IAAIlH,MAAMd,KAAKC,WAAa,GAAGc,KAAK,QACjDkH,kBAAoB,IAAInH,MAAMd,KAAKC,WAAa,GAAGc,KAAK,UAExDiH,WAAa,IAAIlH,MAAMd,KAAKC,WAAWc,KAAK,QAC5CkH,kBAAoB,IAAInH,MAAMd,KAAKC,WAAWc,KAAK,IAEtDf,KAAKE,cACFgI,8BAcE1H,MAC0B,IAA/BR,KAAKmI,4BACD,IAAIpI,MAAM,0CAEdC,KAAKE,SAAWM,EAAYH,SAAWL,KAAKG,sBACvCH,KAAKoI,gBAAgB5H,MAE1BA,EAAYH,SAAWL,KAAKC,gBACxB,IAAIF,2EAA2EC,KAAKC,sBAAsBO,EAAYH,gBAG1HgI,EAAoB,KACI,SAAxBrI,KAAK+H,mBACF,IAAI7C,EAAI,EAAGA,EAAIlF,KAAKC,UAAWiF,GAAK,EAAG,KACtC0C,EAAM,MACL,IAAI3C,EAAI,EAAGA,EAAIjF,KAAKC,UAAWgF,GAAK,KAChCjF,KAAKiI,kBAAmB/C,EAAIlF,KAAKC,UAAagF,IAClDzE,EAAYyE,GAAKjF,KAAKa,KAAKoE,QAEVzE,EAAY0E,GAAKlF,KAAKa,KAAKqE,IAAM0C,WAGpD,IAAI1C,EAAI,EAAGA,EAAIlF,KAAKC,UAAWiF,GAAK,KAClBlF,KAAKiI,kBAAkB/C,IACzC1E,EAAY0E,GAAKlF,KAAKa,KAAKqE,KAC3B1E,EAAY0E,GAAKlF,KAAKa,KAAKqE,QAI9B7C,EAAIxC,KAAKyI,KAAK,GAAMD,GACtBxI,KAAKuB,KAAKpB,KAAKmI,uBAA0B,EAAItI,KAAK0I,KAAOvI,KAAKC,kBAE5DoC,EAAI,QAAUmG,OAAOC,MAAMpG,IAAMxC,KAAK4H,IAAIpF,KAAQb,EAAAA,OAChD,QAGCa,cAUEqG,MACmB,SAAxB1I,KAAK+H,mBACF,IAAI/G,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,OAClCgH,WAAYhH,EAAIhB,KAAKC,UAAae,IAAM0H,EAAe1H,YAGzD,IAAIA,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,OAClCgH,WAAWhH,IAAM0H,EAAe1H,iCAUb,SAAxBhB,KAAK+H,eAA2B,OAC5BY,EAAYjC,EAAO1G,KAAKC,UAAWD,KAAKC,aAEpCuG,KAAOxG,KAAKgI,WAAWtH,cAC3BkI,EAAMD,EAAUE,YACjBV,sBAAwBS,EAAIxB,iBAC5Ba,kBAAoBW,EAAIvB,OAAOb,SAC/B,MACA2B,sBAAwB,MACxB,IAAInH,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,IACtChB,KAAKgI,WAAWhH,IAAM,QAClB,IAAIjB,MAAM,8BAEbkI,kBAAkBjH,GAAK,EAAIhB,KAAKgI,WAAWhH,QAC3CmH,uBAAyBnI,KAAKgI,WAAWhH,IAG9ChB,KAAKE,cACF4I,4CAWCC,EAAYC,MAChBD,GAAc/I,KAAKC,WAAa+I,GAAchJ,KAAKC,gBAC/C,IAAIF,MAAM,iCAGZkJ,KACD,IACA,QACI,SACC,QACD,OAQLtF,EACAC,EACA4B,IARYzC,EAAI/C,KAAKa,KAAKkI,KACdG,EAAIlJ,KAAKa,KAAKmI,GAQF,SAAxBhJ,KAAK+H,kBACH/H,KAAKgI,WAAYe,EAAa/I,KAAKC,UAAa8I,KAChD/I,KAAKgI,WAAYe,EAAa/I,KAAKC,UAAa+I,KAChDhJ,KAAKgI,WAAYgB,EAAahJ,KAAKC,UAAa+I,OAEhDhJ,KAAKgI,WAAWe,KAChB,IACA/I,KAAKgI,WAAWgB,UAIhBG,EAAQxF,EAAI6B,EACZ4B,EAAezD,EAAI6B,EAAM5B,EAAIA,EAC7BwF,EAAY,IAAOD,EAAQtJ,KAAKuB,KAAM+H,GAAS,EAAM,EAAI/B,IACzDiC,EAAY,IAAOF,EAAQtJ,KAAKuB,KAAM+H,GAAS,EAAM,EAAI/B,aAC/CkC,MAAQzJ,KAAKuB,KAAK,MAAQgI,KAC1BG,OAAS1J,KAAKuB,KAAK,MAAQiI,KAC3BG,MAAQ3J,KAAK4J,KAAK7F,GAAKwF,EAAY5D,IAC/CgD,OAAOC,MAAMQ,EAAgBO,WACfA,MAAQ3J,KAAK0I,GAAK,GAG7BU,eAYGA,EAAiBF,EAAYC,MACnCD,GAAc/I,KAAKC,WAAa+I,GAAchJ,KAAKC,gBAC/C,IAAIF,MAAM,gCAGbc,KAAKkI,GAAcE,EAAgBlG,OACnClC,KAAKmI,GAAcC,EAAgBC,QAElCE,EAAaH,EAAgBK,MAAQL,EAAgBK,MAAS,MAC9DD,EAAaJ,EAAgBM,OAASN,EAAgBM,OAAU,MAChEG,EAAW7J,KAAK8J,IAAIV,EAAgBO,OACpC5F,GAAMwF,EAAYC,GAAaK,GAAcA,GAAY,EAAK,GAC9DlE,EAAI4D,EAAaxF,EAAI8F,EACrB/F,EAAI0F,EAAazF,EAAI8F,EAEC,SAAxB1J,KAAK+H,qBACFC,WAAYe,EAAa/I,KAAKC,UAAa8I,GAAcpF,OACzDqE,WAAYe,EAAa/I,KAAKC,UAAa+I,GAAcpF,OACzDoE,WAAYgB,EAAahJ,KAAKC,UAAa8I,GAAcnF,OACzDoE,WAAYgB,EAAahJ,KAAKC,UAAa+I,GAAcxD,SAEzDwC,WAAWe,GAAcpF,OACzBqE,WAAWgB,GAAcxD,QAE3BoE,4BAqBHC,qBAM0B,SAAxB7J,KAAK+H,oBACF+B,uBAAyB,IAAIhJ,MAAMd,KAAKG,gBAAkB,GAAGY,KAAK,QAElE+I,uBAAyB,IAAIhJ,MAAMd,KAAKG,gBAAgBY,KAAK,oBAWtDgJ,MAC0B,IAApC/J,KAAKgK,iCACD,IAAIjK,MAAM,6DAGdsI,EAAoB,KACI,SAAxBrI,KAAK+H,mBACF,IAAI7C,EAAI,EAAGA,EAAIlF,KAAKG,eAAgB+E,GAAK,EAAG,KAC3C0C,EAAM,MACL,IAAI3C,EAAI,EAAGA,EAAIjF,KAAKG,eAAgB8E,GAAK,KACrCjF,KAAK8J,uBAAwB5E,EAAIlF,KAAKG,eAAkB8E,IAC5D8E,EAAiB9E,GAAKjF,KAAKa,KAAKoE,QAEf8E,EAAiB7E,GAAKlF,KAAKa,KAAKqE,IAAM0C,WAGzD,IAAI1C,EAAI,EAAGA,EAAIlF,KAAKG,eAAgB+E,GAAK,KACvBlF,KAAKiI,kBAAkB/C,IACzC6E,EAAiB7E,GAAKlF,KAAKa,KAAKqE,KAChC6E,EAAiB7E,GAAKlF,KAAKa,KAAKqE,QAInC7C,EAAIxC,KAAKyI,KAAK,GAAMD,GACbxI,KAAKuB,KAAKpB,KAAKgK,4BACR,EAAInK,KAAK0I,KAAOvI,KAAKG,uBAEnCkC,EAAI,QAAUmG,OAAOC,MAAMpG,IAAMxC,KAAK4H,IAAIpF,KAAQb,EAAAA,KAAUa,EAAI,QAE7DA,cAYE0H,SACHnJ,EAAkBZ,KAAKC,UAAYD,KAAKG,eACxC8J,EAAanJ,MAAMF,GAAiBG,KAAK,MAEnB,SAAxBf,KAAK+H,mBACF,IAAI/G,EAAI,EAAGA,EAAIJ,EAAiBI,GAAK,EAAG,GAChCA,GAAKhB,KAAKa,KAAKb,KAAKG,eAAiBa,OAC3C,IAAIkJ,EAAI,EAAGA,EAAIlK,KAAKG,eAAgB+J,GAAK,EAAG,KAC3CtC,EAAM,MACL,IAAIuC,EAAI,EAAGA,EAAInK,KAAKG,eAAgBgK,GAAK,KACrCnK,KAAK8J,uBAAwBI,EAAIlK,KAAKG,eAAkBgK,IAC5DJ,EAAiBI,GAAKnK,KAAKa,KAAKsJ,MAE1BnJ,IAAM4G,EACf5H,KAAKgI,YAAahH,EAAIhB,KAAKG,gBAAkBH,KAAKC,UAAaiK,aAIhE,IAAIlJ,EAAI,EAAGA,EAAIJ,EAAiBI,GAAK,IAC7BA,GAAKhB,KAAKa,KAAKb,KAAKG,eAAiBa,UAG7CiJ,uCAQqB,SAAxBjK,KAAK+H,eAA2B,OAC5BqC,EAAiB1D,EAAO1G,KAAKG,eAAgBH,KAAKG,oBACnD,IAAIkK,EAAK,EAAGA,EAAKrK,KAAKG,eAAgBkK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKtK,KAAKG,eAAgBmK,GAAM,IAChC9D,KAAM6D,EAAKrK,KAAKG,eAAkBmK,GAC/CtK,KAAKgI,WAAYqC,EAAKrK,KAAKC,UAAaqK,SAGxCC,EAAWH,EAAevB,YAC3BmB,2BAA6BO,EAASnD,iBACtC0C,uBAAyBS,EAASlD,OAAOb,SACzC,MACAwD,2BAA6B,MAC7B,IAAIhJ,EAAI,EAAGA,EAAIhB,KAAKG,eAAgBa,GAAK,EAAG,IAC3ChB,KAAKgI,WAAWhH,IAAM,QAClB,IAAIjB,MAAM,8BAEb+J,uBAAuB9I,GAAK,EAAIhB,KAAKgI,WAAWhH,QAChDgJ,4BAA8BhK,KAAKgI,WAAWhH,SAGlDwJ,sDAQuB,aAAxBxK,KAAK+H,gCACF0C,iBAAmBzK,KAAKgI,WAAWtH,MAAM,EAAGV,KAAKG,uBAKlDiK,EAAiB1D,EAAO1G,KAAKG,eAAgBH,KAAKG,oBACnD,IAAIkK,EAAK,EAAGA,EAAKrK,KAAKG,eAAgBkK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKtK,KAAKG,eAAgBmK,GAAM,IAChC9D,KAAM6D,EAAKrK,KAAKG,eAAkBmK,GAC/CtK,KAAKgI,WAAYqC,EAAKrK,KAAKC,UAAaqK,SAGxC1B,EAAMwB,EAAevB,OACrB6B,EAAehE,EAAO1G,KAAKG,eAAgBH,KAAKY,qBACjD,IAAIyJ,EAAK,EAAGA,EAAKrK,KAAKG,eAAgBkK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKtK,KAAKY,gBAAiB0J,GAAM,IACnC9D,KAAM6D,EAAKrK,KAAKY,gBAAmB0J,GAC9CtK,KAAKgI,WAAYqC,EAAKrK,KAAKC,UAAaD,KAAKG,eAAiBmK,SAG9DK,EAAejE,EAAO1G,KAAKY,gBAAiBZ,KAAKG,oBAClD,IAAIkK,EAAK,EAAGA,EAAKrK,KAAKY,gBAAiByJ,GAAM,MAC3C,IAAIC,EAAK,EAAGA,EAAKtK,KAAKG,eAAgBmK,GAAM,IAClC9D,KAAM6D,EAAKrK,KAAKG,eAAkBmK,GAC7CtK,KAAKgI,YAAahI,KAAKG,eAAiBkK,GAAMrK,KAAKC,UAAaqK,SAGhEM,EAAYhC,EAAIvB,OAAOF,QAAQuD,GAC/BG,EAAgBF,EAAaxD,QAAQyD,QACtCH,iBAAmB3J,MAAMd,KAAKY,iBAAmB,GAAGG,KAAK,OACzD,IAAIsJ,EAAK,EAAGA,EAAKrK,KAAKY,gBAAiByJ,GAAM,MAC3C,IAAIC,EAAK,EAAGA,EAAKtK,KAAKY,gBAAiB0J,GAAM,OAC3CG,iBAAkBJ,EAAKrK,KAAKY,gBAAmB0J,GAClDtK,KAAKgI,YAAahI,KAAKG,eAAiBkK,GAAMrK,KAAKC,UACjDD,KAAKG,eAAiBmK,GACtBO,EAAcrE,KAAM6D,EAAKrK,KAAKY,gBAAmB0J,KA2B9C,SAASQ,EACtB3K,EAAiB,EACjBS,EAAkB,EAClBmH,EAAiB,cAEX7H,EAAUU,EAAkB,EAC5BX,EAAYE,EAAiBS,EAC7BmK,EAAQ7K,EACZyB,OAAOa,UAAWsF,EAAuB+B,GACzC/B,EACItB,EAAO7E,OAAOa,wGAOO,GAEzBtC,GAAY8J,2BAA4B,OAEpCgB,EAAOrJ,OAAOa,OAClBb,OAAOc,OAAOsI,GACdvE,YAEGyE,WACED,EC/bT,MAAME,SAQEhH,OACCA,GAAeA,EAAYC,cACxB,IAAIpE,MAAM,kCAGboL,aAAajH,OAEdkH,GAAiB5J,EAAAA,EACjB6J,EAAa,EACbC,EAAwBF,QAEpBpL,KAAKuL,UAAUF,EAAYD,EAAeE,IAAwB,GAChDF,IACRpL,KAAKwL,eAAetH,SAE9BuH,EACJ,IAAM5L,KAAK4H,KAAK2D,EAAgBE,GAAyBA,MACvD9C,OAAOC,MAAMgD,IAAWJ,EAAa,QACjC,IAAItL,MAAM,uCAGJ,cAGX2L,oBACE1L,KAAK0D,kBAeJiI,EAAWC,EAASC,MACxBF,GAAa3L,KAAK8L,oBAAoBlH,cAAe,OAAO,KAC5D5E,KAAK8L,oBAAoBlH,eAAiB5E,KAAK8L,oBAAoBC,qBAC9DJ,GAAa3L,KAAK8L,oBAAoBlH,iBAE3C+G,EAAY3L,KAAK8L,oBAAoBC,cAAe,OAAO,SACzC,IAAMlM,KAAK4H,KAAKmE,EAAUC,GAAmBD,IAC3C5L,KAAK8L,oBAAoBE,gBA2BtC,SAASC,EACtBzI,EACAsI,iBACiB,mBACA,gBACA,aAGVnK,OAAOa,OAAOgB,EAAG0H,GAAoBY,oBAAAA,IClF9C,MAAMI,mBAMGxI,OAAOyI,WAAarL,MAAMQ,KAC7BR,MAAMd,KAAK0D,OAAO0I,WAClB,IAAM,IAAItB,EACR9K,KAAK0D,OAAOvD,eACZH,KAAK0D,OAAO9C,gBACZZ,KAAK0D,OAAOqE,sBAGXrE,OAAO2I,cAAgBvL,MAAMd,KAAK0D,OAAO0I,WAAWrL,KAAK,QACzDuL,KAAO,IAAIxL,MAAMd,KAAK0D,OAAO0I,WAAWrL,KAAK,eAQzCP,OACL+L,EAAa,MACZ,IAAI/G,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzC8G,KAAK9G,GAAKxF,KAAKwM,oBAAoBhM,EAAagF,MACvCxF,KAAKsM,KAAK9G,OAErB,IAAIA,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzC8G,KAAK9G,IAAM+G,SAGXA,uBAUW/L,EAAaiM,MAC3BA,GAAoBzM,KAAK0D,OAAO0I,gBAC5B,IAAIrM,MAAM,uEAEXC,KAAK0D,OAAO2I,cAAcI,GAC7BzM,KAAK0D,OAAOyI,WAAWM,GAAkBF,WAAW/L,oCAQnDkD,OAAOyI,WAAWjK,QAASsD,MAC5BoE,qCAGGlG,OAAOyI,WAAWjK,QAASsD,MAC5BoE,4BAEJ,MAAOM,SACD,IAAInK,MAAM,2FASd2M,EAAY,MACX,IAAIlH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,KACjCxF,KAAK0D,OAAO2I,cAAc7G,MAErCkH,EAAY,MACT,IAAIlH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAO2I,cAAc7G,IAAMkH,WAG7B,IAAIlH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAO2I,cAAc7G,GAAK,EAAIxF,KAAK0D,OAAO0I,6BAU9C1I,OAAOyI,WAAWjK,QAASsD,MAC5BmH,WAAW3M,KAAK4M,2BAUlBC,cASO9C,OAGL+C,OAFCC,QAAQC,aAAelM,MAAMd,KAAK0D,OAAO9C,iBAAiBG,KAAK,QAC/DgM,QAAQtC,iBAAmB3J,MAAqC,SAA/Bd,KAAK0D,OAAOqE,eAA4B/H,KAAK0D,OAAO9C,iBAAmB,EAAIZ,KAAK0D,OAAO9C,iBAAiBG,KAAK,OAG9I,IAAIyE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,EAAG,GAC/BxF,KAAK0D,OAAOyI,WAAW3G,GAAGyH,WAAWlD,OAClD,IAAI/I,EAAI,EAAGA,EAAIhB,KAAK0D,OAAO9C,gBAAiBI,GAAK,UAC/C+L,QAAQC,aAAahM,IAAMhB,KAAKsM,KAAK9G,GAAKsH,EAAgB9L,GAC5B,SAA/BhB,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKtK,KAAK0D,OAAO9C,gBAAiB0J,GAAM,OAClDyC,QAAQtC,iBAAkBzJ,EAAIhB,KAAK0D,OAAO9C,gBAAmB0J,IAC/DtK,KAAKsM,KAAK9G,IAAM,EACjBxF,KAAK0D,OAAOyI,WAAW3G,GAAGiF,iBAAkBzJ,EAAIhB,KAAK0D,OAAO9C,gBAAmB0J,aAG9EyC,QAAQtC,iBAAiBzJ,IAC3BhB,KAAKsM,KAAK9G,IAAM,EAAKxF,KAAK0D,OAAOyI,WAAW3G,GAAGiF,iBAAiBzJ,UAIlEhB,KAAK+M,QAAQC,eAiBT,SAASE,EAAY1J,OAC7BD,EAAYC,SACT,IAAIzD,MAAM,sGAEX4B,OAAOa,OACZgB,EACA0I,EACA1I,EAAEE,OAAOxD,QAAU2M,MC9JvB,MAAMM,gBAKSjJ,QACN+G,gBACAmC,wBAAwBlJ,EAAYmJ,0BACpCC,oBAAoBpJ,QACpBqJ,gBAAgBrJ,QAChByI,kBACAa,oDAQiBC,OAClBC,EAAa,OACZd,sBAAwBa,EAAW5K,IAAI8K,GAAO9N,KAAK4B,IACtDzB,KAAK0D,OAAOgF,eAAekF,SAC3B5N,KAAK0D,OAAOgF,eAAemF,SAAWF,QAEnC,IAAInI,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,EACX,SAA/BxF,KAAK0D,OAAOqE,oBACTrE,OAAOyI,WAAW3G,GAAGwC,WAAalH,MAAMd,KAAK0D,OAAOzD,WAAa,GACnEc,KAAKf,KAAK0D,OAAOgF,eAAekF,SAAW,QAEzClK,OAAOyI,WAAW3G,GAAGwC,WAAalH,MAAMd,KAAK0D,OAAOzD,WAAWc,KAAK,QAEtE2C,OAAOyI,WAAW3G,GAAGmH,WAAW3M,KAAK4M,4BACrClJ,OAAO2I,cAAc7G,GAAK,EAAIxF,KAAK0D,OAAO0I,aACjCpM,KAAK0D,OAAO2I,cAAc7G,OAErC,IAAIA,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAO2I,cAAc7G,IAAMkI,uBAYhBxJ,OACbA,GAAeA,EAAYC,QAAS,aASnC2J,EARS1H,EACb9C,kBACkBtD,KAAK0D,OAAOvD,+BACXH,KAAK0D,OAAO9C,kBAE/BZ,KAAK0D,OAAO0I,WACV7H,eAAgB,SAEQwJ,MAAM7J,OAC7B,IAAIsB,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAOyI,WAAW3G,GAAG3E,KAAOiN,EAAa1J,QAAQoB,oBAU1CtB,OAGTA,GAAeA,EAAYC,QAAS,WAEpC,IAAIqD,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO0I,UAAW5E,GAAK,OACzC9D,OAAOyI,WAAW3E,GAAGQ,WAAalH,MAAsC,SAA/Bd,KAAK0D,OAAOqE,eAA6B/H,KAAK0D,OAAOzD,WAAa,EAAID,KAAK0D,OAAOzD,WAAWc,KAAK,SAG5IiN,EAASlN,MAAMd,KAAK0D,OAAO0I,UAAYpM,KAAK0D,OAAOzD,WAAWc,KAAK,GACnEkN,EAASnN,MAAMd,KAAK0D,OAAO0I,WAAWrL,KAAK,KACrCmB,QAASE,UACbkD,EAAOzF,KAAKC,MAAMsC,EAAO/B,OAASL,KAAK0D,OAAO0I,eAChD7G,EAAS,MACR,IAAIiC,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO0I,UAAW5E,GAAK,EAAG,KAC5C,IAAIvG,EAAI,EAAGA,EAAIqE,EAAMrE,GAAK,MACxB,IAAIoJ,EAAK,EAAGA,EAAKrK,KAAK0D,OAAOzD,UAAWoK,GAAM,OACzC7C,EAAIxH,KAAK0D,OAAOzD,UAAaoK,IAAOjI,EAAOlB,IAAIqE,EAAStE,EAAGoJ,GAChC,SAA/BrK,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKtK,KAAK0D,OAAOzD,UAAWqK,GAAM,OAC5C5G,OAAOyI,WAAW3E,GACpBQ,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,IAC3ClI,EAAOlB,IAAIqE,EAAStE,EAAGoJ,GAAMjI,EAAOlB,IAAIqE,EAAStE,EAAGqJ,aAGnD5G,OAAOyI,WAAW3E,GAAGQ,WAAWqC,IACnCjI,EAAOlB,IAAIqE,EAAStE,EAAGoJ,IAAO,KAI5B/E,IACHkC,IAAMlC,SAIZ,IAAIkC,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO0I,UAAW5E,GAAK,MACzC,IAAI6C,EAAK,EAAGA,EAAKrK,KAAK0D,OAAOzD,UAAWoK,GAAM,OACzC7C,EAAIxH,KAAK0D,OAAOzD,UAAaoK,IAAO4D,EAAOzG,GAChB,SAA/BxH,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKtK,KAAK0D,OAAOzD,UAAWqK,GAAM,OAC5C5G,OAAOyI,WAAW3E,GAAGQ,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,IAAO2D,EAAOzG,aAG/E9D,OAAOyI,WAAW3E,GAAGQ,WAAWqC,IAAO4D,EAAOzG,OAKpD,IAAIA,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO0I,UAAW5E,GAAK,MACzC,IAAI6C,EAAK,EAAGA,EAAKrK,KAAK0D,OAAOzD,UAAWoK,GAAM,KACd,SAA/BrK,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKtK,KAAK0D,OAAOzD,UAAWqK,GAAM,OAC5C5G,OAAOyI,WAAW3E,GAAGQ,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,IAClE0D,EAAQxG,EAAIxH,KAAK0D,OAAOzD,UAAaoK,GACrC2D,EAAQxG,EAAIxH,KAAK0D,OAAOzD,UAAaqK,aAGpC5G,OAAOyI,WAAW3E,GAAGQ,WAAWqC,IACnC2D,EAAQxG,EAAIxH,KAAK0D,OAAOzD,UAAaoK,IAAO,kBAUvCnG,OACT0H,EAAU,EACVvI,EAAc,IACNnB,QAASE,OACJA,EAAO/B,eAElB6N,EAAgBvM,OAAOC,KAAKsC,EAAYrC,SAExCQ,EAAIvB,MAAMQ,KACdR,MAAMd,KAAK0D,OAAO0I,WAClB,IAAM,IAAItL,MAAMuC,GAAatC,KAAK,IAE9BoN,EAAIrN,MAAMd,KAAK0D,OAAO0I,WAAWrL,KAAK,OACxCqN,EAAQ,IAEAlM,QAASE,QACd,IAAInB,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,EAAG,KACrCyL,EAAY,MACX,IAAIlH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,IAC5CA,GAAG4I,EAAQnN,GAAKjB,KAAKwM,oBAAoBpK,EAAO0D,SAAS7E,GAAIuE,IAEvC,IAApBnD,EAAEmD,GAAG4I,EAAQnN,IACfuH,OAAOC,MAAMpG,EAAEmD,GAAG4I,EAAQnN,KAC1BoB,EAAEmD,GAAG4I,EAAQnN,KAAQO,EAAAA,OACnBgE,GAAG4I,EAAQnN,GAAK,WAEPoB,EAAEmD,GAAG4I,EAAQnN,OAEvB,IAAIuE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,IAC5CA,GAAG4I,EAAQnN,IAAMyL,IACjBlH,IAAMnD,EAAEmD,GAAG4I,EAAQnN,MAEZpB,KAAKwO,IAAI3B,MAEbtK,EAAO/B,aAIb,IAAImF,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAO2I,cAAc7G,GAAK2I,EAAE3I,GAAKnC,MAInC,IAAImC,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,MACzC,IAAIxE,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,EAAG,MAC5C0C,OAAOyI,WAAW3G,GAAG3E,KAAKG,GAAK,IAC5B,MACH,IAAIsN,EAAM,EAAGA,EAAMJ,EAAc7N,OAAQiO,GAAO,EAAG,OAChDlM,EAAS8B,EAAYrC,QAAQqM,EAAcI,QAC5C,IAAIrN,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,OACjCyC,OAAOyI,WAAW3G,GAAG3E,KAAKG,IAC7BqB,EAAEmD,GAAG4I,EAAQnN,GAAKmB,EAAOlB,IAAID,EAAGD,MAE3BoB,EAAO/B,YAEbqD,OAAOyI,WAAW3G,GAAG3E,KAAKG,IAAMmN,EAAE3I,MAKR,SAA/BxF,KAAK0D,OAAOqE,mBACT,IAAIvC,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,MACzC,IAAI6E,EAAK,EAAGA,EAAKrK,KAAK0D,OAAOzD,UAAWoK,GAAM,MAC5C,IAAIC,EAAKD,EAAIC,EAAKtK,KAAK0D,OAAOzD,UAAWqK,GAAM,EAAG,MAChD5G,OAAOyI,WAAW3G,GAAGwC,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,GAAM,IAClE,MACH,IAAIgE,EAAM,EAAGA,EAAMJ,EAAc7N,OAAQiO,GAAO,EAAG,OAChDlM,EAAS8B,EAAYrC,QAAQqM,EAAcI,QAC5C,IAAIrN,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,OACjCyC,OAAOyI,WAAW3G,GAAGwC,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,IAClEjI,EAAEmD,GAAG4I,EAAQnN,IACZmB,EAAOlB,IAAID,EAAGoJ,GAAMrK,KAAK0D,OAAOyI,WAAW3G,GAAG3E,KAAKwJ,KACnDjI,EAAOlB,IAAID,EAAGqJ,GAAMtK,KAAK0D,OAAOyI,WAAW3G,GAAG3E,KAAKyJ,OAE/ClI,EAAO/B,YAEbqD,OAAOyI,WAAW3G,GAAGwC,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,IAAO6D,EAAE3I,GACzE6E,IAAOC,SACJ5G,OAAOyI,WAAW3G,GAAGwC,WAAYsC,EAAKtK,KAAK0D,OAAOzD,UAAaoK,GAClErK,KAAK0D,OAAOyI,WAAW3G,GAAGwC,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,aAMzE,IAAI9E,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,MACzC,IAAI6E,EAAK,EAAGA,EAAKrK,KAAK0D,OAAOzD,UAAWoK,GAAM,EAAG,MAC/C3G,OAAOyI,WAAW3G,GAAGwC,WAAWqC,GAAM,IACnC,MACH,IAAIiE,EAAM,EAAGA,EAAMJ,EAAc7N,OAAQiO,GAAO,EAAG,OAChDlM,EAAS8B,EAAYrC,QAAQqM,EAAcI,QAC5C,IAAIrN,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,EAAG,OACnCsN,EAASnM,EAAOlB,IAAID,EAAGoJ,GAAMrK,KAAK0D,OAAOyI,WAAW3G,GAAG3E,KAAKwJ,QAC7D3G,OAAOyI,WAAW3G,GAAGwC,WAAWqC,IAC/BhI,EAAEmD,GAAG4I,EAAQnN,GAAKsN,EAAQA,KAEzBnM,EAAO/B,YAEbqD,OAAOyI,WAAW3G,GAAGwC,WAAWqC,IAAO8D,EAAE3I,eAK/CmH,kBACAa,2BAEE5B,0BCtPX,MAAM4C,iBAMK7M,OAAOC,KAAK5B,KAAKyO,QAAQpO,iBAQzB8B,UACAR,OAAOC,KAAK5B,KAAKyO,QAAQ1M,SAASI,WAOpCA,GACDnC,KAAK+B,SAASI,WACTnC,KAAKyO,OAAOtM,KAYV,SAASuM,SAAoBvO,iBAAAS,qBAGvC+N,mDAEIhN,OAAOa,OACZc,KAAYnD,eAAAA,EAAgBS,gBAAAA,GAAoB+N,IAChDH,GC1CW,SAASI,EACtBpL,EACAqL,UAEOlN,OAAOa,OACZgB,SAaQU,EAAa4K,OACZ5K,GAAeA,EAAYC,cACxB,IAAIpE,MAAM,oCAEd+O,KACK5M,QAASgD,QACTlF,KAAK+B,SAASmD,SACX,IAAInF,uBAAuBmF,2BAKlCxB,OAAOqL,YACCD,GAAU5K,EAAY4K,UAC9B5M,QAASC,UACNa,EAAKkB,EAAY8K,kBAAkB7M,QAEpCuB,OAAOqL,QAAQ5M,GAAS0M,EAAiB7L,KAEzChD,KAAK0D,UCpCpB,MAAMuL,gBAKG5O,OAAS,OACTV,MAAQ,OACRuP,MAAO,OACPC,gBAOFZ,GACCvO,KAAKkP,WACFC,OAAOnP,KAAKL,OAAS4O,OACrB5O,OAASK,KAAKL,MAAQ,GAAKK,KAAKoP,gBAEhCD,OAAO1O,KAAK8N,QACZlO,QAAU,OACV6O,KAAQlP,KAAKK,SAAWL,KAAKoP,eASlCC,UACKrP,KAAKmP,QAAQE,EAAMrP,KAAKL,OAASK,KAAKoP,gBAO1Cb,QACElO,OAASL,KAAKoP,cACdzP,MAAQ,OACRuP,MAAO,OACPC,OAASrO,MAAMd,KAAKoP,UAAUrO,KAAKwN,YAQlCtM,OACD,IAAIW,EAAI,EAAGA,EAAI5C,KAAKK,OAAQuC,GAAK,IAC3B5C,KAAKmP,QAAQvM,EAAI5C,KAAKL,OAASK,KAAKoP,UAAWxM,oBASnD5C,KAAKmP,OAAOzO,MAAMV,KAAKL,OAC3BY,OAAOP,KAAKmP,OAAOzO,MAAM,EAAGV,KAAKL,UAczB,SAAS2P,EAAeF,SAC/BD,EAASxN,OAAOc,OAAOwM,YACtBG,SAAWA,IACXG,QACAJ,ECjFT,MAAMK,EAA0BtP,sBAMZoP,EAAe,uBAMbG,QACbC,iBAAmBD,OACnBE,iBAAmBL,EAAeG,wBAQlCE,iBAAiBJ,QACfvP,cAUDQ,SACA+L,EAAavM,KAAKuM,WAAW/L,UAC/BN,QACG+M,WAAWzM,QAEboP,cAAcrD,GACZvM,KAAK+M,uBAQA8C,QACP9C,QAAQ8C,kBAAoBA,OAC5BF,iBAAiBlP,KAAKZ,KAAKwO,IAAIwB,SAC/B9C,QAAQ3B,cAAgB,QACvB0E,EAAU9P,KAAK2P,iBAAiBtP,WACjC,IAAIuC,EAAI,EAAGA,EAAIkN,EAASlN,GAAK,OAC3BmK,QAAQ3B,eAAiBpL,KAAK2P,iBAAiBzO,IAAI0B,QAErDmK,QAAQ3B,eAAiB0E,KAUnB,SAASC,EAAsBvM,EAAGkM,EAAmB,OAC7DnM,EAAYC,SACT,IAAIzD,MAAM,qGAEZgN,EAAUpL,OAAOa,QACnBqN,kBAAmB,EAAGzE,cAAe,GACvC5H,EAAEE,OAAOxD,SAAY8M,gBAAkBvC,gCAElC9I,OAAOa,OACZgB,EACAgM,EAAwBhM,EAAEE,OAAOxD,UAC/B6M,QAAAA,EAAS4C,iBAAkBL,EAAeI,KCSjC,SAASM,EAAmB1J,EAAO2J,EAAeC,SACzDvB,EAAahN,OAAOa,UAAW0N,iBAC9BtO,KAAKqO,GAAe/N,QAASiO,UAC5BC,EAAOH,EAAcE,MAGvBC,EAAKC,WAAa1O,OAAOC,KAAKsO,GAAQnO,SAASoO,SAC3C,IAAIpQ,2BAA2BoQ,6BAAgC7J,QAzF3E,SAAmBA,EAAOgK,EAAWL,EAAe1B,MAC7C0B,MACDA,EAAcM,cAAgBzP,QAAUmP,EAAclO,SAASwM,SAC3D,IAAIxO,oBAAoBuQ,eAAuB/B,iCAAqCjI,iBAAqB2J,QAC1G,GAAIA,EAAcM,cAAgB5O,OAAQ,IAC3CA,OAAOC,KAAKqO,GAAelO,SAAS,QAAUwM,EAAQ0B,EAAc1O,UAChE,IAAIxB,oBAAoBuQ,cAAsB/B,mDAAuD0B,EAAc1O,kBAAkB+E,UAEzI3E,OAAOC,KAAKqO,GAAelO,SAAS,QAAUwM,EAAQ0B,EAAcxO,UAChE,IAAI1B,oBAAoBuQ,cAAsB/B,mDAAuD0B,EAAc1O,kBAAkB+E,YAExI,GAA6B,mBAAlB2J,IACXA,EAAc1B,SACX,IAAIxO,oBAAoBuQ,cAAsB/B,kCAAsCjI,SAgFlFA,EAAO6J,EAAMC,EAAKI,MAAON,EAAOC,MAE/BA,GAAQC,EAAKK,UACtBL,EAAKK,UAAUP,EAAOC,IACtBD,EAAOC,KAEJxB,EC5GT,MAAM+B,EAAmBtE,0BAEX,SACD7K,IAAK,8BAGJ,QACH,EAAGqM,SAAAA,EAAUC,SAAAA,KACjBD,GAAYC,GAAYD,EAAW,GAAKC,EAAW,6BAG5C,SACF,OAAQ,sCAGN,QACH8C,GAAKA,EAAEtQ,SAAW+L,yBAGf,QACH5G,GAAKA,EAAEnF,SAAW+L,KChB7B,MAAMwE,gCAMK5Q,KAAK0P,sCAOMD,QACbC,iBAAmBD,SACjB7N,KAAK5B,KAAKyO,QAAQvM,QAASC,SAC3BsM,OAAOtM,GAAO0O,oBAAoBpB,qBASlCS,OAAOlQ,KAAKyO,QAAQvM,QAAQyO,GAAKA,EAAEG,cACrC/D,qIAMQ,iBAGT/M,KAAK0D,OAAOxD,cACT6Q,wBAQDvQ,UACC0P,OAAOlQ,KAAKyO,QAAQvM,QAAQyO,GAAKA,EAAEK,QAAQxQ,SAC7CoP,uCAICqB,EAAOtP,OAAOC,KAAK5B,KAAKyO,QAAQyC,YACjCnE,QAAQ+B,OAASmC,MAClBE,EAAc,EACdC,EAAe,EACfC,GAAoB7P,EAAAA,OACnBuL,QAAQgC,QAAUkC,EACpBpO,IAAI,CAACyO,EAAK1O,UACJmK,QAAQwE,mBAAmB3O,GAC9B5C,KAAKyO,OAAO6C,GAAKvE,QAAQ8C,uBACtB9C,QAAQyE,uBAAuB5O,GAClC5C,KAAKyO,OAAO6C,GAAKvE,QAAQ3B,mBACtB2B,QAAQ0E,oBAAoB7O,GAC/B/C,KAAKyI,IAAItI,KAAK+M,QAAQyE,uBAAuB5O,OAChC5C,KAAK+M,QAAQwE,mBAAmB3O,MAC/B5C,KAAK+M,QAAQ0E,oBAAoB7O,GAC7C5C,KAAK+M,QAAQyE,uBAAuB5O,GAAKyO,MACxBrR,KAAK+M,QAAQyE,uBAAuB5O,QAClDmK,QAAQ2E,UAAYJ,IAElBpO,CAACoO,GAAMtR,KAAKyO,OAAO6C,GAAKvE,WAElCjK,OAAO,CAACU,EAAGT,SAAYS,EAAMT,YAC3BgK,QAAQ4E,8BACX3R,KAAK+M,QAAQ0E,oBAAoB5O,IAAIE,GAAKA,EAAIqO,QAC3CrE,QAAQ6E,6BACX5R,KAAK+M,QAAQwE,mBAAmB1O,IAAIE,GAAKA,EAAIoO,GAC3CnR,KAAK0D,OAAOxD,cACT2R,4BAKLC,uBAEG/E,QAAQC,qBACRD,QAAQtC,kDAIqC,cAA9CzK,KAAK0D,OAAOqO,mCACThF,QAAQC,aACXhN,KAAKyO,OAAOzO,KAAK+M,QAAQ2E,WAAW3E,QAAQC,kBACzCD,QAAQtC,iBACXzK,KAAKyO,OAAOzO,KAAK+M,QAAQ2E,WAAW3E,QAAQtC,qBACzC,CAAA,GAAkD,YAA9CzK,KAAK0D,OAAOqO,oCAcf,IAAIhS,MAAM,mEAbXgN,QAAQC,aAAelM,MAAMd,KAAKY,iBAAiBG,KAAK,QACxDgM,QAAQtC,iBAAmB3J,MAAMd,KAAKY,kBAA0D,SAAtCZ,KAAKgS,cAAcjK,eAA4B,EAAI,IAAIhH,KAAK,QACtHgM,QAAQ+B,OAAO5M,QAASoP,SACtBvE,QAAQC,aAAanK,IAAI,CAACE,EAAGH,IAAMG,EACtC/C,KAAK+M,QAAQ4E,8BAA8B/O,GAC3C5C,KAAKyO,OAAO6C,GAAKvE,QAAQC,aAAapK,SAEnCmK,QAAQtC,iBAAiB5H,IAAI,CAACE,EAAGH,IAAMG,EAC1C/C,KAAK+M,QAAQ4E,8BAA8B/O,GAC3C5C,KAAKyO,OAAO6C,GAAKvE,QAAQtC,iBAAiB7H,SAoBrC,SAASqP,EAAyBzO,EAAGuO,EAAgC,iBAC7ExO,EAAYC,SACT,IAAIzD,MAAM,qGAEZ4Q,EAAIhP,OAAOa,OACfgB,EACAoN,EACApN,EAAEE,OAAOxD,QAAU4R,eAEnBpO,OAAOqO,8BAAgCA,EAClCpB,EC7EF,SAASuB,EACdhO,EACA8N,EACAlG,SAEM3L,eAAEA,EAAFS,gBAAkBA,GAAoBsD,GACtCkI,UAAEA,EAAF1D,eAAaA,EAAbX,eAA6BA,GAAmBiK,SR2MzC,SACbxO,EACA4I,EAAY,EACZ1D,GAAmBkF,SAAU,KAAMC,SAAU,KAC7C9F,EAAiB,YAEZpG,OAAOC,KAAK4B,GAAGzB,SAAS,gBACrB,IAAIhC,MAAM,sGAEX4B,OAAOa,OACZgB,EACA2J,eAGO3J,EAAEE,0DQxNGyO,CACZlG,EACEiB,EAAY5J,yCAGP0O,KAELlG,GAEFM,EACA1D,EACAX,GAEWgG,MAAM7J,GAiCd,SAASkO,EACd1O,EACAgM,EAAmB,SAEbpJ,EFnFO,SAA2B9C,OACnCD,EAAYC,SACT,IAAIzD,MAAM,wGAEC,MAAO2Q,EAAiBlN,EAAEE,OAAO0I,WAAY5I,EAAEE,QAC3D/B,OAAOa,OACZgB,GACE8I,KAAM,IAAIxL,MAAM0C,EAAEE,OAAO0I,WAAWrL,KAAK,KE4E/BsR,CAAkBtC,EAC9B7C,EAAY5J,EAAUI,IACtBgM,aAEKvD,WAAWjK,QAAQ,CAACsD,EAAG5C,OACtBc,OAAOyI,WAAWvJ,GAAKjB,OAAOa,OAAOsI,EACzCpH,EAAOvD,eACPuD,EAAO9C,gBACP8C,EAAOqE,gBACNvC,OAECsL,QACCxK,EC1HT,MAAMgM,uBAMgB,kBAQJ,6BAOW9R,OACrBkM,EAAY,KACmB,YAA/B1M,KAAK0D,OAAO6O,mBACT,IAAI3P,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,OACtC6P,MAAM7P,GAAK5C,KAAK0D,OAAOgP,MAAM9P,GAChC5C,KAAK0D,OAAOiP,QAAQ/P,GAAG2J,WAAW/L,MACvBR,KAAKyS,MAAM7P,aAGrB6P,MAAQ,IAAI3R,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,QAC3C0R,MAAM,GAAKzS,KAAK0D,OAAOiP,QAAQ,GAAGpG,WAAW/L,MACrCR,KAAKyS,MAAM,WAErBG,oBAAqB,EACtBlG,EAAY,EAAG,KACZ,IAAI9J,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,OACtC6P,MAAM7P,IAAM8J,SAEZ,EAAIA,MAER,IAAI7F,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,OACtC4L,MAAM5L,GAAK,EAAI7G,KAAK0D,OAAO8O,cAE3B,0BAQchS,OACjBkM,EAAY,OACXmG,cAAgB7S,KAAKyS,MAAM/R,YAC3B,IAAImG,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,EAAG,SACzC4L,MAAM5L,GAAK,EACmB,YAA/B7G,KAAK0D,OAAO6O,mBACT,IAAI3P,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,OACtC6P,MAAM5L,IAAM7G,KAAK6S,cAAcjQ,GAClC5C,KAAK0D,OAAOoP,WAAWlQ,GAAGiE,aAGzB4L,MAAM5L,IAAM7G,KAAK6S,cAAchM,GAAK7G,KAAK0D,OAAOoP,WAAe,EAAJjM,GAC5DA,EAAI,OACD4L,MAAM5L,IAAM7G,KAAK6S,cAAchM,EAAI,GACtC7G,KAAK0D,OAAOoP,WAAsB,GAATjM,EAAI,GAAU,QAEpC4L,MAAM,IAAMzS,KAAK6S,cAAc7S,KAAK0D,OAAO8O,OAAS,GACvDxS,KAAK0D,OAAOoP,WAAiC,EAArB9S,KAAK0D,OAAO8O,OAAc,QAGnDC,MAAM5L,IAAM7G,KAAK0D,OAAOiP,QAAQ9L,GAAG0F,WAAW/L,MACtCR,KAAKyS,MAAM5L,MAEtB6F,EAAY,OAAQ,KACjB,IAAI7F,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,OACtC4L,MAAM5L,IAAM6F,SAEZ,EAAIA,SAEN,IAiBI,SAASqG,EAAYvP,OAC7BD,EAAYC,SACT,IAAIzD,MAAM,sGAEX4B,OAAOa,OAAOgB,EAAG8O,GC5G1B,MAOMU,gBAKS9O,GACNA,IAAeA,EAAYC,eAE3B8G,SAAS/G,QACTkJ,wBAAwBlJ,EAAYmJ,qBACrCrN,KAAK0D,OAAO0I,UAAY,OACrB6G,8BAA8B/O,SAE9BgP,wBAAwBhP,QACxBiP,6BAA6BjP,eAS7BA,SACD/D,iBAAAS,kBAAAwL,YAAA1D,iBAAAX,kBAMF/H,KAAK0D,YACJA,OAAOiP,QAAU7R,MAAMQ,KAC1B,IAAIR,MAAMd,KAAK0D,OAAO8O,QACtB,IAAMtF,EAAY5J,6FAQfI,OAAOiP,QAAQzQ,QAAQkR,GAAKA,EAAEnI,iBAC9BwH,MAAQ,IAAI3R,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,QAC3C8R,cAAgB,IAAI/R,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,QACnDuL,KAAO,IAAIxL,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,QAC1CsS,aAAe,IAAIvS,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,SAIjDuS,EAAYpP,EAAYqP,YACzBC,cAAgB,IAAI1S,MAAMwS,GAAWvS,KAAK,WAC1C0S,gBAAkB,IAAI3S,MAAMwS,GAAWvS,KAAK,WAC5C2S,wBAA0B,IAAI5S,MAAMwS,GAAWvS,KAAK,UAErD6B,EAAI,IACIV,QAASE,UACbuR,EAAIvR,EAAO/B,YACZmT,cAAc5Q,GAAK9B,MAAMQ,KAC5B,IAAIR,MAAM6S,GACV,IAAM,IAAI7S,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,IAER,YAA/Bf,KAAK0D,OAAO6O,oBACTkB,gBAAgB7Q,GAAK9B,MAAMQ,KAC9B,IAAIR,MAAM6S,GACV,IAAM7S,MAAMQ,KACV,IAAIR,MAAMd,KAAK0D,OAAO8O,QACtB,IAAM,IAAI1R,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,UAIxC0S,gBAAgB7Q,GAAK9B,MAAMQ,KAC9B,IAAIR,MAAM6S,GACV,IAAM,IAAI7S,MAA2B,EAArBd,KAAK0D,OAAO8O,QAAYzR,KAAK,SAG5C2S,wBAAwB9Q,GAC3B,IAAI9B,MAAMd,KAAK0D,OAAO0I,WAAWrL,KAAK,OACnC,IAAIyE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzCkO,wBAAwB9Q,GAAG4C,GAC9B1E,MAAMQ,KACJ,IAAIR,MAAM6S,GACV,IAAM,IAAI7S,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,OAM1C,SAGF6S,SAAW,IAAI9S,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,QAC9C8S,mBAAqB,IAAI/S,MAAMd,KAAK0D,OAAO8O,OAASxS,KAAK0D,OAAO0I,WAAWrL,KAAK,mBAOxEmD,OACT0H,EAAU,EAIV9J,EAAc,IACNI,QAASE,IACfA,EAAO/B,OAAS,OACPL,KAAK8T,yBAAyB1R,EAAQN,OAEpC,SAEZiS,kBAAkB7P,OAMlB,IAAItB,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,MACtC,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAOiP,QAAQ/P,GAAGc,OAAO2I,cAAc7G,GAAK,EACd,SAA/BxF,KAAK0D,OAAOqE,oBACTrE,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GAAGwC,WAC1C,IAAIlH,MAAMd,KAAK0D,OAAOzD,WAAa,GAAGc,KAAK,QAExC2C,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GAAGwC,WAC1C,IAAIlH,MAAMd,KAAK0D,OAAOzD,WAAWc,KAAK,eAKzCiT,qCAAqC9P,QACrC+P,uBAAuB/P,QACvBgQ,6BAA6BhQ,GACC,YAA/BlE,KAAK0D,OAAO6O,qBACT4B,uBAAuBjQ,QAEzBkQ,6BAA6BlQ,GAC3B0H,4BAQFyI,4BACAb,cAAgB,UAChBC,gBAAkB,UAClBC,wBAA0B,UAC1BY,SAAW,UACXC,QAAU,UACVX,SAAW,UACXC,mBAAqB,UACrBnQ,OAAOiP,QAAU3S,KAAK0D,OAAOiP,QAAQ9P,IAAIuQ,GAAKA,EAAE1P,iCAQ/B+J,GACa,YAA/BzN,KAAK0D,OAAO6O,oBACTiC,kBAEAC,qBAED7H,EAAwBa,EAAW5K,IAAI8K,GAAO9N,KAAK4B,IACvDzB,KAAK0D,OAAOgF,eAAekF,SAC3B5N,KAAK0D,OAAOgF,eAAemF,SAAWF,IAElC+G,EAAiD,SAA/B1U,KAAK0D,OAAOqE,eAClC,IAAM,IAAIjH,MAAMd,KAAK0D,OAAOzD,WAAa,GACtCc,KAAKf,KAAK0D,OAAOgF,eAAekF,SAAW,GAC9C,IAAM,IAAI9M,MAAMd,KAAK0D,OAAOzD,WACzBc,KAAK,OACL,IAAI6B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,EAAG,OAExCwQ,EAAIpT,KAAK0D,OAAOiP,QAAQ/P,KAC5BgK,sBAAwBA,MACrB,IAAIpH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,IAC5C9B,OAAOyI,WAAW3G,GAAGwC,WAAa0M,MAClChR,OAAOyI,WAAW3G,GAAGmH,WAAWC,KAChClJ,OAAO2I,cAAc7G,GAAK,EAAIxF,KAAK0D,OAAO0I,oCAW1BlI,OACjBA,GAAeA,EAAYC,QAAS,WAEpC,IAAIqD,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO8O,OAAQhL,GAAK,MACtC,IAAIxG,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW,GAAGtL,KAAKG,GAAK,QAIpDiN,EAAS,IAAInN,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,KACtCmB,QAASE,UACbkD,EAAOzF,KAAKC,MAAMsC,EAAO/B,OAASL,KAAK0D,OAAO8O,YAChDjN,EAAS,MACR,IAAIiC,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO8O,OAAQhL,GAAK,EAAG,KACzC,IAAIvG,EAAI,EAAGA,EAAIqE,EAAMrE,GAAK,MACxB,IAAID,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW,GAAGtL,KAAKG,IAC/CoB,EAAOlB,IAAIqE,EAAStE,EAAGD,MAGnBsE,IACHkC,IAAMlC,SAGZ,IAAIkC,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO8O,OAAQhL,GAAK,MACtC,IAAIxG,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW,GAAGtL,KAAKG,IAAMiN,EAAOzG,iCAWvCtD,OACtBA,GAAeA,EAAYC,QAAS,WAEpC,IAAIqD,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO8O,OAAQhL,GAAK,OACtC9D,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW,GAAGnE,WAC1C,IAAIlH,MAAMd,KAAK0D,OAAOzD,YAA6C,SAA/BD,KAAK0D,OAAOqE,eAA4B,EAAI,IAAIhH,KAAK,SAGvFkN,EAAS,IAAInN,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,GAC5C4T,EAAa,IAAI7T,MAAMd,KAAK0D,OAAO8O,OAASxS,KAAK0D,OAAOzD,WAC3Dc,KAAK,KACImB,QAASE,UACbkD,EAAOzF,KAAKC,MAAMsC,EAAO/B,OAASL,KAAK0D,OAAO8O,YAChDjN,EAAS,MACR,IAAIiC,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO8O,OAAQhL,GAAK,EAAG,KACzC,IAAIvG,EAAI,EAAGA,EAAIqE,EAAMrE,GAAK,MACxB,IAAIoJ,EAAK,EAAGA,EAAKrK,KAAK0D,OAAOzD,UAAWoK,GAAM,OACpC7C,EAAIxH,KAAK0D,OAAOzD,UAAcoK,IACvCjI,EAAOlB,IAAIqE,EAAStE,EAAGoJ,GACQ,SAA/BrK,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKtK,KAAK0D,OAAOzD,UAAWqK,GAAM,OAC5C5G,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW,GACtCnE,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,IACzClI,EAAOlB,IAAIqE,EAAStE,EAAGoJ,GACvBjI,EAAOlB,IAAIqE,EAAStE,EAAGqJ,aAGxB5G,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW,GAAGnE,WAAWqC,IACrDjI,EAAOlB,IAAIqE,EAAStE,EAAGoJ,IAAO,KAI5B/E,IACHkC,IAAMlC,SAIZ,IAAIkC,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO8O,OAAQhL,GAAK,MACtC,IAAI6C,EAAK,EAAGA,EAAKrK,KAAK0D,OAAOzD,UAAWoK,GAAM,OACrC7C,EAAIxH,KAAK0D,OAAOzD,UAAaoK,IAAO4D,EAAOzG,GACpB,SAA/BxH,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKtK,KAAK0D,OAAOzD,UAAWqK,GAAM,OAC5C5G,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW,GACtCnE,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,IACzC2D,EAAOzG,aAGR9D,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW,GAAGnE,WAAWqC,IAAO4D,EAAOzG,OAKtE,IAAIA,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO8O,OAAQhL,GAAK,EAAG,KACzC,IAAI6C,EAAK,EAAGA,EAAKrK,KAAK0D,OAAOzD,UAAWoK,GAAM,KACd,SAA/BrK,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKtK,KAAK0D,OAAOzD,UAAWqK,GAAM,OAC5C5G,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW,GACtCnE,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,IACzCqK,EAAYnN,EAAIxH,KAAK0D,OAAOzD,UAAaoK,GACzCsK,EAAYnN,EAAIxH,KAAK0D,OAAOzD,UAAaqK,aAG1C5G,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW,GAAGnE,WAAWqC,IACrDsK,EAAYnN,EAAIxH,KAAK0D,OAAOzD,UAAaoK,GACzCsK,EAAYnN,EAAIxH,KAAK0D,OAAOzD,UAAaoK,QAG1C3G,OAAOiP,QAAQnL,GAAGmF,kBAClBjJ,OAAOiP,QAAQnL,GAAGgG,2DAUGtJ,OACvB,IAAIsD,EAAI,EAAGA,EAAIxH,KAAK0D,OAAO8O,OAAQhL,GAAK,EAAG,OACxCxE,EAAKC,EAAYjD,KAAK0D,aAEhBxB,QAAQ,CAACE,EAAQN,WACrBwD,EAAOzF,KAAKC,MAAMsC,EAAO/B,OAASL,KAAK0D,OAAO8O,WAChDlN,EAAO,EAAG,GACT7E,KAAKqB,EAAaM,EAAOD,WACvB,IAAIlB,EAAIuG,EAAIlC,EAAMrE,GAAKuG,EAAI,GAAKlC,EAAMrE,GAAK,IAC3CmE,UAAUtD,GAAarB,KAAK2B,EAAO0D,SAAS7E,QAIhD+B,EAAGmB,QAAS,OACTyQ,EAAY1C,EAASlP,EAAIhD,KAAK0D,YAC/B,IAAI8B,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW3G,GAAG3E,KAC1C+T,EAAUzI,WAAW3G,GAAG3E,UACrB6C,OAAOiP,QAAQnL,GAAG9D,OAAOyI,WAAW3G,GAAGwC,WAC1C4M,EAAUzI,WAAW3G,GAAGwC,gBACrBtE,OAAOiP,QAAQnL,GAAGgG,iDAWvBnL,EAAI,EAAIrC,KAAK0D,OAAO8O,YACrB9O,OAAOgP,MAAQ,IAAI5R,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAKsB,QAClDqB,OAAOoP,WAAahS,MAAMQ,KAC7B,IAAIR,MAAMd,KAAK0D,OAAO8O,QACtB,IAAM,IAAI1R,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAKsB,yBAStCqB,OAAOgP,MAAQ,IAAI5R,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,QAClD2C,OAAOgP,MAAM,GAAK,OAClBhP,OAAOoP,WAAa,IAAIhS,MAA2B,EAArBd,KAAK0D,OAAO8O,QAAYzR,KAAK,SAC3D2C,OAAOoP,WAAsC,GAA1B9S,KAAK0D,OAAO8O,OAAS,IAAU,OAClD9O,OAAOoP,WAAuC,GAA1B9S,KAAK0D,OAAO8O,OAAS,GAAU,GAAK,6BAS1B,YAA/BxS,KAAK0D,OAAO6O,eAA8B,OACtCsC,EAAY7U,KAAK0D,OAAOgP,MAAM5P,OAAO,CAACa,EAAGC,IAAMD,EAAIC,EAAG,OACvD,IAAIhB,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,EAAG,MACzCc,OAAOgP,MAAM9P,IAAMiS,MACpBC,EAAiB,MAChB,IAAIjO,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,KACzB7G,KAAK0D,OAAOoP,WAAWlQ,GAAGiE,OAEzC,IAAIA,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,OACtCnD,OAAOoP,WAAWlQ,GAAGiE,IAAMiO,YAI/B,IAAIlS,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,EAAG,OACxCkS,EAAiB9U,KAAK0D,OAAOoP,WAAe,EAAJlQ,GAAS5C,KAAK0D,OAAOoP,WAAgB,EAAJlQ,EAAS,QACnFc,OAAOoP,WAAe,EAAJlQ,IAAUkS,OAC5BpR,OAAOoP,WAAgB,EAAJlQ,EAAS,IAAMkS,gCAWjBC,OACrB,IAAInS,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,OACtC0J,KAAK1J,GAAKmS,2BAUKA,EAAIvU,QACrB6S,aAAerT,KAAKsM,KAAK5L,YACzB,IAAIkC,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,EAAG,SACzC0J,KAAK1J,GAAK,EACoB,YAA/B5C,KAAK0D,OAAO6O,mBACT,IAAI1L,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,OACtCyF,KAAK1J,IAAM5C,KAAK0D,OAAOoP,WAAWlQ,GAAGiE,GACxC7G,KAAKqT,aAAaxM,GAClB7G,KAAK0D,OAAOiP,QAAQ9L,GAAG0F,WAAW/L,aAGjC8L,KAAK1J,IAAM5C,KAAK0D,OAAOoP,WAAe,EAAJlQ,GACrC5C,KAAKqT,aAAazQ,GAClB5C,KAAK0D,OAAOiP,QAAQ/P,GAAG2J,WAAW/L,GAChCoC,EAAI5C,KAAK0D,OAAO8O,OAAS,SACtBlG,KAAK1J,IAAM5C,KAAK0D,OAAOoP,WAAgB,EAAJlQ,EAAS,GAC/C5C,KAAKqT,aAAazQ,EAAI,GACtB5C,KAAK0D,OAAOiP,QAAQ/P,EAAI,GAAG2J,WAAW/L,SAGvC8L,KAAK1J,IAAMmS,GACZvM,OAAOC,MAAMzI,KAAKsM,KAAK1J,KAAO/C,KAAK4H,IAAIzH,KAAKsM,KAAK1J,MAASpB,EAAAA,UACvD8K,KAAK1J,GAAK,gCAYEoS,OACjBtI,EAAY,OACXmG,cAAgB7S,KAAKyS,MAAM/R,YAC3B,IAAImG,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,EAAG,SACzC4L,MAAM5L,GAAK,EACmB,YAA/B7G,KAAK0D,OAAO6O,mBACT,IAAI3P,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,OACtC6P,MAAM5L,IAAM7G,KAAK6S,cAAcjQ,GAClC5C,KAAK0D,OAAOoP,WAAWlQ,GAAGiE,aAGzB4L,MAAM5L,IAAM7G,KAAK6S,cAAchM,GAAK7G,KAAK0D,OAAOoP,WAAe,EAAJjM,GAC5DA,EAAI,OACD4L,MAAM5L,IAAM7G,KAAK6S,cAAchM,EAAI,GACtC7G,KAAK0D,OAAOoP,WAAsB,GAATjM,EAAI,GAAU,QAEpC4L,MAAM,IAAMzS,KAAK6S,cAAc7S,KAAK0D,OAAO8O,OAAS,GACvDxS,KAAK0D,OAAOoP,WAAiC,EAArB9S,KAAK0D,OAAO8O,OAAc,QAGnDC,MAAM5L,IAAMmO,EAAuBnO,MAC3B7G,KAAKyS,MAAM5L,MAEtB2B,OAAOC,MAAMiE,SACT,IAAI3M,MAAM,iBAEd2M,EAAY,OAAQ,KACjB,IAAI7F,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,OACtC4L,MAAM5L,IAAM6F,SAEZ,EAAIA,SAEN,2BAWeqI,EAAIC,QACrB3B,aAAerT,KAAKsM,KAAK5L,YACzB,IAAIkC,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,EAAG,SACzC0J,KAAK1J,GAAK,EACoB,YAA/B5C,KAAK0D,OAAO6O,mBACT,IAAI1L,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,OACtCyF,KAAK1J,IACR5C,KAAK0D,OAAOoP,WAAWlQ,GAAGiE,GAC1B7G,KAAKqT,aAAaxM,GAClBmO,EAAuBnO,aAGtByF,KAAK1J,IAAM5C,KAAK0D,OAAOoP,WAAe,EAAJlQ,GACrC5C,KAAKqT,aAAazQ,GAClBoS,EAAuBpS,GACrBA,EAAI5C,KAAK0D,OAAO8O,OAAS,SACtBlG,KAAK1J,IAAM5C,KAAK0D,OAAOoP,WAAgB,EAAJlQ,EAAS,GAC/C5C,KAAKqT,aAAazQ,EAAI,GACtBoS,EAAuBpS,EAAI,SAG5B0J,KAAK1J,IAAMmS,GACZvM,OAAOC,MAAMzI,KAAKsM,KAAK1J,KAAO/C,KAAK4H,IAAIzH,KAAKsM,KAAK1J,MAASpB,EAAAA,UACvD8K,KAAK1J,GAAK,kCAYIqS,EAAenT,SAChC6R,EAAIsB,EAAc5U,OAElB0U,EAAK,IAAIjU,MAAM6S,GAAG5S,KAAK,OACzB6K,OACC0I,iBACAC,iBAECW,EAA2BpU,MAAMQ,KACrC,IAAIR,MAAM6S,GACV,IAAM,IAAI7S,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,QAEtC,IAAIE,EAAI,EAAGA,EAAI0S,EAAG1S,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,IAClB3B,GAAG2B,GAC1B5C,KAAK0D,OAAOiP,QAAQ/P,GAAG2J,WAAW0I,EAAcnP,SAAS7E,MAK5D,GAAKjB,KAAKmV,2BAA2BF,EAAcnP,SAAS,OACpDjG,KAAKwO,IAAI0G,EAAG,SAClBT,SAAS7T,KAAKT,KAAKyS,MAAM/R,aAEzB,IAAIO,EAAI,EAAGA,EAAI0S,EAAG1S,GAAK,IACvBA,GAAKjB,KAAKoV,uBAAuBF,EAAyBjU,OAClDpB,KAAKwO,IAAI0G,EAAG9T,SAClBqT,SAAS7T,KAAKT,KAAKyS,MAAM/R,cAI3B2U,4BAA4BN,EAAGpB,EAAI,SACnCY,QAAQ9T,KAAKT,KAAKsM,KAAK5L,aAEvB,IAAIO,EAAI0S,EAAI,EAAG1S,GAAK,EAAGA,GAAK,OAC1BqU,wBAAwBP,EAAG9T,GAAIiU,EAAyBjU,EAAI,SAC5DsT,QAAQ9T,KAAKT,KAAKsM,KAAK5L,cAEzB6T,QAAQgB,cAGR,IAAItU,EAAI,EAAGA,EAAI0S,EAAG1S,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,OACtC4Q,cAAc1R,GAAab,GAAG2B,GAChC5C,KAAKsU,SAASrT,GAAG2B,GAAK5C,KAAKuU,QAAQtT,GAAG2B,GAAMmS,EAAG9T,OAKlDyL,MAEC,IAAIzL,EAAI,EAAGA,EAAI0S,EAAG1S,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,EAAG,MAClC,EACkB,IAA1B5C,KAAK0D,OAAO0I,UAAiB,OACzBoJ,EAAKN,EAAyBjU,GAAG2B,QAClC8Q,wBAAwB5R,GAAa,GAAGb,GAAG2B,GAC9C5C,KAAKwT,cAAc1R,GAAab,GAAG2B,GAAK4S,KAC7BA,WAER,IAAIhQ,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,EAAG,OAC3CgQ,EAAKxV,KAAK0D,OAAOiP,QAAQ/P,GAC5B4J,oBAAoByI,EAAcnP,SAAS7E,GAAIuE,QAC7CkO,wBAAwB5R,GAAa0D,GAAGvE,GAAG2B,GAC9C5C,KAAKwT,cAAc1R,GAAab,GAAG2B,GACnC4S,KACWA,KAGb9I,EAAY,MACT,IAAIlH,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzCkO,wBAAwB5R,GAAa0D,GAAGvE,GAAG2B,IAAM8J,KAO3B,YAA/B1M,KAAK0D,OAAO6O,mBACT,IAAItR,EAAI,EAAGA,EAAI0S,EAAI,EAAG1S,GAAK,MACzB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,MACtC,IAAIiE,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,OACtC4M,gBAAgB3R,GAAab,GAAG2B,GAAGiE,GACtC7G,KAAKsU,SAASrT,GAAG2B,GACjB5C,KAAK0D,OAAOoP,WAAWlQ,GAAGiE,GAC1B7G,KAAKuU,QAAQtT,EAAI,GAAG4F,QACjB4M,gBAAgB3R,GAAab,GAAG2B,GAAGiE,IACtCqO,EAAyBjU,EAAI,GAAG4F,YAKnC,IAAI5F,EAAI,EAAGA,EAAI0S,EAAI,EAAG1S,GAAK,MACzB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,OACtC6Q,gBAAgB3R,GAAab,GAAO,EAAJ2B,GACnC5C,KAAKsU,SAASrT,GAAG2B,GACjB5C,KAAK0D,OAAOoP,WAAe,EAAJlQ,GACvB5C,KAAKuU,QAAQtT,EAAI,GAAG2B,QACjB6Q,gBAAgB3R,GAAab,GAAO,EAAJ2B,IACnCsS,EAAyBjU,EAAI,GAAG2B,GAC9BA,EAAI5C,KAAK0D,OAAO8O,OAAS,SACtBiB,gBAAgB3R,GAAab,GAAQ,EAAJ2B,EAAS,GAC7C5C,KAAKsU,SAASrT,GAAG2B,GACjB5C,KAAK0D,OAAOoP,WAAgB,EAAJlQ,EAAS,GACjC5C,KAAKuU,QAAQtT,EAAI,GAAG2B,EAAI,QACrB6Q,gBAAgB3R,GAAab,GAAQ,EAAJ2B,EAAS,IAC7CsS,EAAyBjU,EAAI,GAAG2B,EAAI,WAMvCgJ,qBAQS1H,OACX,IAAItB,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,EAAG,MACzCgR,SAAShR,GAAK,MACd,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzCqO,mBAAoBjR,EAAI5C,KAAK0D,OAAO0I,UAAa5G,GAAK,MAI3D1D,EAAc,IACNI,QAASE,QACd,IAAIQ,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,EAAG,MACpC2S,SAAShR,IACZ5C,KAAKwT,cAAc1R,GAAab,GAAG2B,OAChC,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzCqO,mBAAoBjR,EAAI5C,KAAK0D,OAAO0I,UAAa5G,IACpDxF,KAAK0T,wBAAwB5R,GAAa0D,GAAGvE,GAAG2B,MAIzC,0CAUkBsB,OAC/BpC,EAAc,IACNI,QAASE,QACd,IAAIQ,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,MACjC,IAAIuE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAOiP,QAAQ/P,GAAGc,OAAO2I,cAAc7G,IAC1CxF,KAAK0T,wBAAwB5R,GAAa0D,GAAGvE,GAAG2B,MAIzC,QAIZ,IAAIA,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,OACtCc,OAAOiP,QAAQ/P,GAAG6S,iDAUJvR,OAChB,IAAItB,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,MACtC,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GAAG3E,KAAKE,KAAK,OAKtDe,EAAc,IACNI,QAASE,QACd,IAAIQ,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,MACjC,IAAIuE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,MACzC,IAAIxE,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,OACzC0C,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GAAG3E,KAAKG,IAC/ChB,KAAK0T,wBAAwB5R,GAAa0D,GAAGvE,GAAG2B,GAChDR,EAAOlB,IAAID,EAAGD,MAKT,QAIZ,IAAI4B,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,MACtC,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,MACzC,IAAIxE,EAAI,EAAGA,EAAIhB,KAAK0D,OAAOzD,UAAWe,GAAK,KAC1ChB,KAAK6T,mBAAoBjR,EAAI5C,KAAK0D,OAAO0I,UAAa5G,GAAK,SACxD9B,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GAAG3E,KAAKG,IAC/ChB,KAAK6T,mBAAoBjR,EAAI5C,KAAK0D,OAAO0I,UAAa5G,IAEtDgD,OAAOC,MAAMzI,KAAK0D,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GAAG3E,KAAKG,UAC1D,IAAIjB,MAAM,mDAaGmE,OACvBpC,EAAc,IACNI,QAASE,QACd,IAAIQ,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,MACjC,IAAIuE,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,MACzC,IAAI6E,EAAK,EAAGA,EAAKrK,KAAK0D,OAAOzD,UAAWoK,GAAM,KACd,SAA/BrK,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAKD,EAAIC,EAAKtK,KAAK0D,OAAOzD,UAAWqK,GAAM,OAC7C5G,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GACtCwC,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,IAC3CtK,KAAK0T,wBAAwB5R,GAAa0D,GAAGvE,GAAG2B,IAC/CR,EAAOlB,IAAID,EAAGoJ,GACbrK,KAAK0D,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GAAG3E,KAAKwJ,KAClDjI,EAAOlB,IAAID,EAAGqJ,GACbtK,KAAK0D,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GAAG3E,KAAKyJ,QAElD,OACCiE,EAAQnM,EAAOlB,IAAID,EAAGoJ,GAC1BrK,KAAK0D,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GAAG3E,KAAKwJ,QAC9C3G,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GAAGwC,WAAWqC,IACrDrK,KAAK0T,wBAAwB5R,GAAa0D,GAAGvE,GAAG2B,GAC/C2L,GAAS,KAMP,QAIZ,IAAI3L,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,EAAG,KACzC,IAAI4C,EAAI,EAAGA,EAAIxF,KAAK0D,OAAO0I,UAAW5G,GAAK,KAC1CxF,KAAK6T,mBAAoBjR,EAAI5C,KAAK0D,OAAO0I,UAAa5G,GAAK,MACxD,IAAI6E,EAAK,EAAGA,EAAKrK,KAAK0D,OAAOzD,UAAWoK,GAAM,KACd,SAA/BrK,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAKD,EAAIC,EAAKtK,KAAK0D,OAAOzD,UAAWqK,GAAM,OAC7C5G,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GACtCwC,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,IAC3CtK,KAAK6T,mBAAoBjR,EAAI5C,KAAK0D,OAAO0I,UAAa5G,GACpD6E,IAAOC,SACJ5G,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GACtCwC,WAAYsC,EAAKtK,KAAK0D,OAAOzD,UAAaoK,GAC3CrK,KAAK0D,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GACtCwC,WAAYqC,EAAKrK,KAAK0D,OAAOzD,UAAaqK,cAI9C5G,OAAOiP,QAAQ/P,GAAGc,OAAOyI,WAAW3G,GAAGwC,WAAWqC,IACrDrK,KAAK6T,mBAAoBjR,EAAI5C,KAAK0D,OAAO0I,UAAa5G,QAK3D9B,OAAOiP,QAAQ/P,GAAG+J,kBAClBjJ,OAAOiP,QAAQ/P,GAAG4K,oDASJtJ,QAChBR,OAAOgP,MAAM3R,KAAK,OAGnB2U,EAAW,MACV,IAAI5T,EAAc,EACrBA,EAAcoC,EAAYqP,OAC1BzR,GAAe,MACV,IAAIc,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,OACtCc,OAAOgP,MAAM9P,IAAM5C,KAAKwT,cAAc1R,GAAa,GAAGc,MAC/C5C,KAAK0D,OAAOgP,MAAM9P,QAK9B8S,EAAW,SAKP,IAAI3V,MAAM,kCAJX,IAAI6C,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,OACtCc,OAAOgP,MAAM9P,IAAM8S,gCAYDxR,QAEtBR,OAAOoP,WAA4C,YAA/B9S,KAAK0D,OAAO6O,eACnCzR,MAAMQ,KACJ,IAAIR,MAAMd,KAAK0D,OAAO8O,QACtB,IAAM,IAAI1R,MAAMd,KAAK0D,OAAO8O,QAAQzR,KAAK,IAE3C,IAAID,MAA2B,EAArBd,KAAK0D,OAAO8O,QAAYzR,KAAK,OAGrCe,EAAc,OACNI,QAASE,OACfA,EAAO/B,OAAS,MACb,IAAIuC,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,KAGR,cAA/B5C,KAAK0D,OAAO6O,sBACT7O,OAAOoP,WAAe,EAAJlQ,IAx1BD,KAy1BlBA,EAAI5C,KAAK0D,OAAO8O,OAAS,OACtB9O,OAAOoP,WAAgB,EAAJlQ,EAAS,IA11Bb,UA41Bfc,OAAOoP,WAAe,EAAJlQ,IA51BH,MAg2BW,YAA/B5C,KAAK0D,OAAO6O,mBACT,IAAI1L,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,MACtC,IAAI5F,EAAI,EAAGA,EAAImB,EAAO/B,OAAS,EAAGY,GAAK,OACrCyC,OAAOoP,WAAWlQ,GAAGiE,IACxB7G,KAAKyT,gBAAgB3R,GAAab,GAAG2B,GAAGiE,OAGzC,KACA,IAAI5F,EAAI,EAAGA,EAAImB,EAAO/B,OAAS,EAAGY,GAAK,OACrCyC,OAAOoP,WAAe,EAAJlQ,IACrB5C,KAAKyT,gBAAgB3R,GAAab,GAAO,EAAJ2B,MAErCA,EAAI5C,KAAK0D,OAAO8O,OAAS,MACtB,IAAIvR,EAAI,EAAGA,EAAImB,EAAO/B,OAAS,EAAGY,GAAK,OACrCyC,OAAOoP,WAAgB,EAAJlQ,EAAS,IAC/B5C,KAAKyT,gBAAgB3R,GAAab,GAAQ,EAAJ2B,EAAS,MAM5C,IAIkB,YAA/B5C,KAAK0D,OAAO6O,oBACT,IAAI3P,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,MACtC,IAAIiE,EAAI,EAAGA,EAAI7G,KAAK0D,OAAO8O,OAAQ3L,GAAK,UACtCnD,OAAOoP,WAAWlQ,GAAGiE,IACvB7G,KAAK4T,SAAShR,GAAM,KACnB4F,OAAOC,MAAMzI,KAAK0D,OAAOoP,WAAWlQ,GAAGiE,UACnC,IAAI9G,MAAM,wFAKjB,IAAI6C,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,EAAG,SACzCc,OAAOoP,WAAe,EAAJlQ,IACpB5C,KAAK4T,SAAShR,GAAM,KACnB4F,OAAOC,MAAMzI,KAAK0D,OAAOoP,WAAe,EAAJlQ,UAChC,IAAI7C,MAAM,kFAEd6C,EAAI5C,KAAK0D,OAAO8O,OAAS,SACtB9O,OAAOoP,WAAgB,EAAJlQ,EAAS,IAC9B5C,KAAK4T,SAAShR,GAAM,KACnB4F,OAAOC,MAAMzI,KAAK0D,OAAOoP,WAAgB,EAAJlQ,EAAS,WAC1C,IAAI7C,MAAM,kFC/4B5B,MAAM4V,EAAmB,CAACnD,EAAQD,wBAEpB,SACDhR,IAAK,yBAGJ,SACDA,IAAK,8BAGJ,QACH,EAAGqM,SAAAA,EAAUC,SAAAA,KACjBD,GAAYC,GAAYD,EAAW,GAAKC,EAAW,6BAG5C,SACF,UAAW,wCAGT,SACF,OAAQ,8BAGN,QACH8C,GAAwB,cAAnB4B,GAAkC5B,EAAEtQ,SAAWmS,yBAGjD,QACH7B,GAAyB,cAAnB4B,EACX5B,EAAEtQ,SAAW,EAAImS,EACjB7B,EAAEtQ,SAAWmS,sBAGL,QACH7B,GAAKA,EAAEtQ,SAAWmS,KAUvBoD,uBACgB,kBACJ,sBAQTlS,OAAOiP,QAAU3S,KAAK0D,OAAOiP,QAAQ9P,IAAIuQ,GAAKhB,EAAagB,GAAGtC,SAC5D9Q,0BAQF2P,iBAAiBJ,aACjB7L,OAAOiP,QAAQzQ,QAASkR,MAAUtC,UAChC9Q,iBAQEQ,SACHuU,EAAM/U,KAAK4S,mBACf5S,KAAK6V,uBAAuBrV,GAC5BR,KAAKmV,2BAA2B3U,eAC7BsV,yBACAC,iBACE,EAAIhB,yBAINhI,QAAQiJ,SAAW,MACnB,IAAIpT,EAAI5C,KAAKiW,eAAgBrT,EAAI5C,KAAKkW,eAAgBtT,GAAK,EAC1D5C,KAAKmW,oBACFpJ,QAAQiJ,WAAahW,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,GAAK5C,KAAKqW,OAAOzT,KACpEA,EAAI5C,KAAKsW,kCAEPvJ,QAAQiJ,UAAahW,KAAKyS,MAAM7P,GAAKA,EACxC5C,KAAKsW,iCAGNvJ,QAAQiJ,UAAYhW,KAAK0D,OAAO8O,OAAS,4BASzCzF,QAAQwJ,eAAiB,MAE1BC,EAAYxW,KAAKmW,eAClBnW,KAAKyS,MAAM,GAAKzS,KAAKoW,OAAO,GAC7BpW,KAAKyS,MAAM,OACR,IAAI7P,EAAI,EAAGA,EAAI5C,KAAK0D,OAAO8O,OAAQ5P,GAAK,EACvC5C,KAAKmW,eACFnW,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,GAAM4T,MACzBxW,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,QACnCmK,QAAQwJ,eAAiB3T,GAEvB5C,KAAKyS,MAAM7P,GAAK4T,MACbxW,KAAKyS,MAAM7P,QAClBmK,QAAQwJ,eAAiB3T,QAK7BqT,eAAiBjW,KAAK+M,QAAQwJ,eAAiB1W,KAAKC,MAAME,KAAK0D,OAAO8O,OAAS,QAC/E0D,eAAiBlW,KAAK+M,QAAQwJ,eAAiB1W,KAAKC,MAAME,KAAK0D,OAAO8O,OAAS,QAC/EyD,eAAkBjW,KAAKiW,gBAAkB,EAAKjW,KAAKiW,eAAiB,OACpEC,eAAkBlW,KAAKkW,gBAAkBlW,KAAK0D,OAAO8O,OACxDxS,KAAKkW,eAAiBlW,KAAK0D,OAAO8O,YAC/B8D,4BAA8B,MAC9B,IAAI1T,EAAI5C,KAAKiW,eAAgBrT,EAAI5C,KAAKkW,eAAgBtT,GAAK,OACzD0T,6BAA+BtW,KAAKmW,eACtCnW,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,GAC7B5C,KAAKyS,MAAM7P,KAUb6T,cASO1M,WACJgD,QAAQC,aAAelM,MAAMd,KAAK0D,OAAO9C,iBAAiBG,KAAK,QAC/DgM,QAAQtC,iBAAmB3J,MAAqC,SAA/Bd,KAAK0D,OAAOqE,eAA4B/H,KAAK0D,OAAO9C,iBAAmB,EAAIZ,KAAK0D,OAAO9C,iBAAiBG,KAAK,GAE3G,cAApCf,KAAK0D,OAAOgT,gCACThT,OAAOiP,QAAQ3S,KAAK+M,QAAQwJ,gBAAgBvF,QAAQjH,QACpDgD,QAAQC,aACXhN,KAAK0D,OAAOiP,QAAQ3S,KAAK+M,QAAQwJ,gBAAgBxJ,QAAQC,aACpDhN,KAAK+M,QAAQC,mBAGhB2J,EAAoD,SAApC3W,KAAK0D,OAAOgT,oBAChC,EAAI1W,KAAKiW,eACLW,EAAoD,SAApC5W,KAAK0D,OAAOgT,oBAChC1W,KAAK0D,OAAO8O,OAASxS,KAAKkW,mBACxBW,EAA6D,SAApC7W,KAAK0D,OAAOgT,oBACvC,EAAI1W,KAAKsW,4BAEPO,GAAyB,IAAKA,EAAwB,OAGrD,IAAIjU,EAAI+T,EAAc/T,EAAIgU,EAAchU,GAAK,EAAG,MAC9Cc,OAAOiP,QAAQ/P,GAAG2J,WAAWxC,QAC7BrG,OAAOiP,QAAQ/P,GAAGqK,WAAWlD,SAC5B+M,EAAqB9W,KAAK0D,OAAOiP,QAAQ/P,GAAGmK,QAAQC,iBACrD,IAAIhM,EAAI,EAAGA,EAAIhB,KAAK0D,OAAO9C,gBAAiBI,GAAK,KAChDhB,KAAKmW,uBACFpJ,QAAQC,aAAahM,KACvBhB,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,KAC5BkU,EAAmB9V,GAAK6V,GACQ,SAA/B7W,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKtK,KAAK0D,OAAO9C,gBAAiB0J,GAAM,OAClDyC,QAAQtC,iBAAkBzJ,EAAIhB,KAAK0D,OAAO9C,gBAAmB0J,KAC/DtK,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,KAC5B5C,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,KAC5B5C,KAAK0D,OAAOiP,QAAQ/P,GAAGmK,QACrBtC,iBAAkBzJ,EAAIhB,KAAK0D,OAAO9C,gBAAmB0J,GACxDuM,aAGC9J,QAAQtC,iBAAiBzJ,KAC3BhB,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,KAC5B5C,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,KAC5B5C,KAAK0D,OAAOiP,QAAQ/P,GAAGmK,QAAQtC,iBAAiBzJ,GACjD6V,gBAGC9J,QAAQC,aAAahM,IAAMhB,KAAKyS,MAAM7P,IACxCkU,EAAmB9V,GAAK6V,GACQ,SAA/B7W,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKtK,KAAK0D,OAAO9C,gBAAiB0J,GAAM,OAClDyC,QAAQtC,iBAAkBzJ,EAAIhB,KAAK0D,OAAO9C,gBAAmB0J,IAC/DtK,KAAKyS,MAAM7P,IAAM,GACjB5C,KAAK0D,OAAOiP,QAAQ/P,GAAGmK,QACrBtC,iBAAkBzJ,EAAIhB,KAAK0D,OAAO9C,gBAAmB0J,GACxDuM,aAGC9J,QAAQtC,iBAAiBzJ,IAC1BhB,KAAKyS,MAAM7P,IAAM,EACnB5C,KAAK0D,OAAOiP,QAAQ/P,GAAGmK,QAAQtC,iBAAiBzJ,GAChD6V,SAKH7W,KAAK+M,QAAQC,eCxNxB,MAOM+J,uBAQgB,gBAQZC,EAAahX,KAAKuT,mBACnB7P,OAAOgP,MAAQ,IAAI5R,MAAMkW,GAAYjW,KAAK,EAAIiW,QAC9CtT,OAAOoP,WAAahS,MAAMQ,KAC7B,IAAIR,MAAMkW,GACV,IAAM,IAAIlW,MAAMkW,GAAYjW,KAAK,EAAIiW,SAElCtT,OAAOuT,eAAiB,IAAInW,MAAMkW,GAAYjW,KAAK,WACjDmP,OAAOlQ,KAAKyO,QAAQvM,QAASoE,IACxBA,EACR6P,gBAAiB,SAEhBe,0BACElX,8BASemX,SAChBC,OAAkC9U,IAAtB6U,EAChBA,EACA,IAAIrW,MAAMd,KAAK0D,OAAO8O,OAAS,GAAGzR,KAAK,GACpCR,QAhDkC,YAiDhCqB,KAAK5B,KAAKyO,QAAQvM,QAASC,SAC3BsM,OAAOtM,GAAOuB,OAAOyT,kBAAoBC,EAAS1W,0BASlDwP,OAAOlQ,KAAKyO,QAAQvM,QAAQyO,GAAKA,EAAEG,cACrC/D,uJAOQ,iBAGT/M,KAAK0D,OAAOxD,cACT6Q,oBAEF6B,oBAAqB,WAOpBpS,MACFR,KAAK4S,wBACFiD,uBAAuBrV,QAEvB2U,2BAA2B3U,UAE3BoB,KAAK5B,KAAKyO,QAAQyC,OAAOhP,QAASC,UACjCmE,EAAQtG,KAAKyO,OAAOtM,KACpB2T,sBACAC,mBACAnG,cAActJ,EAAMyG,QAAQ8C,0BAE/BD,gBAED5P,KAAK0D,OAAOxD,kBACPgQ,OAAOlQ,KAAKyO,QAAQvM,QAAQyO,GAAKA,EAAE1D,WAAWzM,IAEH,cAA9CR,KAAK0D,OAAOqO,mCACThF,QAAQC,aACXhN,KAAKyO,OAAOzO,KAAK+M,QAAQ2E,WAAW3E,QAAQC,kBACzCD,QAAQtC,iBACXzK,KAAKyO,OAAOzO,KAAK+M,QAAQ2E,WAAW3E,QAAQtC,qBACzC,MACAsC,QAAQC,aAAe,IAAIlM,MAAMd,KAAKY,iBAAiBG,KAAK,QAC5DgM,QAAQtC,iBACX,IAAI3J,MAAqC,SAA/Bd,KAAK0D,OAAOqE,eACpB/H,KAAKY,iBAAmB,EACxBZ,KAAKY,iBAAiBG,KAAK,OAE3BsW,EAAa,SACVnH,OAAOlQ,KAAKyO,QAAQvM,QAASoE,QAC7B,IAAItF,EAAI,EAAGA,EAAIhB,KAAKY,gBAAiBI,GAAK,UACxC+L,QAAQC,aAAahM,IACxBhB,KAAK+M,QAAQ4E,8BAA8B0F,GAC3C/Q,EAAMgR,OAAOvK,QAAQC,aAAahM,GAED,SAA/BhB,KAAK0D,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKtK,KAAKY,gBAAiB0J,GAAM,OAC3CyC,QAAQtC,iBAAkBzJ,EAAIhB,KAAKY,gBAAmB0J,IACzDtK,KAAK+M,QAAQ4E,8BAA8B0F,GAC3C/Q,EAAMyG,QAAQtC,iBAAkBzJ,EAAIhB,KAAKY,gBAAmB0J,aAG3DyC,QAAQtC,iBAAiBzJ,IAC5BhB,KAAK+M,QAAQ4E,8BAA8B0F,GAC3C/Q,EAAMgR,OAAOvK,QAAQtC,iBAAiBzJ,MAG9B,iCAWKR,OACrBkM,EAAY,EACZ2K,EAAa,QACXtI,EAAUpN,OAAOC,KAAK5B,KAAKyO,QAAQyC,SACjChP,QAASC,UACTmE,EAAQtG,KAAKyO,OAAOtM,GACpBoV,EAAIjR,EAAM5C,OAAO8O,YACjB4D,OAAS,IAAItV,MAAMyW,GAAGxW,KAAK,KAC3BsV,OAAS,IAAIvV,MAAMyW,GAAGxW,KAAK,GAIG,YAAhCuF,EAAM5C,OAAO6O,eAA8B,GACvCxF,QAAQ8C,kBAAoB,MAC7B,IAAIjN,EAAI,EAAGA,EAAI2U,EAAG3U,GAAK,IACpB6P,MAAM7P,GAAK5C,KAAK0D,OAAOgP,MAAM2E,GACjC/Q,EAAM5C,OAAOgP,MAAM9P,GACnB0D,EAAM5C,OAAOiP,QAAQ/P,GAAG2J,WAAW/L,KAC/BuM,QAAQ8C,mBAAqBvJ,EAAMmM,MAAM7P,UAG3C6P,MAAM,GAAKzS,KAAK0D,OAAOgP,MAAM2E,GACjC/Q,EAAM5C,OAAOiP,QAAQ,GAAGpG,WAAW/L,IACpC8F,EAAMyG,QAAQ8C,mBAAqBvJ,EAAMmM,SAE/BnM,EAAMyG,QAAQ8C,qBACb,MAGR3N,QAASC,UACTmE,EAAQtG,KAAKyO,OAAOtM,GACpBoV,EAAIjR,EAAM5C,OAAO8O,WAClB,IAAI5P,EAAI,EAAGA,EAAI2U,EAAG3U,GAAK,IACpB6P,MAAM7P,IAAM8J,SAKjB8K,WAAa,IAAI1W,MAAMd,KAAKuT,MAAMxS,KAAK,QACvC0W,WAAa,IAAI3W,MAAMd,KAAKuT,MAAMxS,KAAK,QACvC6R,oBAAqB,0BAQLpS,OACjBkM,EAAY,EAGZ9E,EAAM,OAIL4P,WAAaxX,KAAK0X,gBAAgB,QAClCD,WAAazX,KAAK0X,gBAAgB,OAInCC,EAAgB,QACd5I,EAAUpN,OAAOC,KAAK5B,KAAKyO,QAAQyC,SACjChP,QAASC,UACTyV,EAAW5X,KAAKyO,OAAOtM,GACvBoV,EAAIK,EAASlU,OAAO8O,OAKpBqF,EAAQ,IAAI/W,MAAMyW,GAAGxW,KAAK,MAEO,YAAnC6W,EAASlU,OAAO6O,mBACb,IAAItN,EAAI,EAAGA,EAAIsS,EAAGtS,GAAK,EAAG,KACxB,IAAI4B,EAAI,EAAGA,EAAI0Q,EAAG1Q,GAAK,IACpB5B,IAAO2S,EAASlU,OAAOoP,WAAWjM,GAAG5B,IACxC,EAAI2S,EAASlU,OAAOyT,kBAAkBtQ,IACrC+Q,EAASnF,MAAM5L,OAInB,IAAIiR,EAAgB,EACpBA,EAAgB9X,KAAKuT,OACrBuE,GAAiB,IAEX7S,IAAM2S,EAASlU,OAAOgP,MAAMzN,IAC/BjF,KAAKwX,WAAWM,GACjB9X,KAAK0D,OAAOoP,WAAWgF,GAAeH,GACrC3X,KAAK0D,OAAOgP,MAAMiF,GACnB3X,KAAKyX,WAAWK,QAIjB,GAEC,GAAKF,EAASlU,OAAOoP,WAAW,GAAK8E,EAASnF,MAAM,OAGxD,IAAIqF,EAAgB,EACpBA,EAAgB9X,KAAKuT,OACrBuE,GAAiB,IAEX,IAAO9X,KAAKwX,WAAWM,GAC3B9X,KAAK0D,OAAOoP,WAAWgF,GAAeH,GACrC3X,KAAK0D,OAAOgP,MAAMiF,GACjB3X,KAAKyX,WAAWK,OAIjB,IAAI7S,EAAI,EAAGA,EAAIsS,EAAGtS,GAAK,IACpBA,IAAO2S,EAASlU,OAAOoP,WAAe,EAAJ7N,IACrC,EAAI2S,EAASlU,OAAOyT,kBAAkBlS,IACvC2S,EAASnF,MAAMxN,KACXA,IAAO2S,EAASlU,OAAOoP,WAAsB,GAAT7N,EAAI,GAAU,IACrD,EAAI2S,EAASlU,OAAOyT,kBAAkBlS,EAAI,IAC3C2S,EAASnF,MAAMxN,EAAI,OAGlB,IAAIA,EAAI,EAAGA,EAAIsS,EAAGtS,GAAK,IACjBwN,MAAMxN,GAAK,IACXmR,OAAOnR,GAAK,IACZoR,OAAOpR,GAAK,IAMhB8H,QAAQgL,eAAiB,IACzBhL,QAAQ8C,kBAAoB,MAGhC,IAAI5K,EAAI,EAAGA,EAAIsS,EAAGtS,GAAK,IACpB2S,EAASlU,OAAOiP,QAAQ1N,GAAGsH,WAAW/L,GAAeqX,EAAM5S,KACxDoR,OAAOpR,GAAKjF,KAAK0D,OAAOuT,eAAeU,GAC9CC,EAASlU,OAAOyT,kBAAkBlS,GAAK2C,IAChCwO,OAAOnR,IAAM,EAAIjF,KAAK0D,OAAOuT,eAAeU,IACnDC,EAASlU,OAAOyT,kBAAkBlS,GAAK2C,IAChC6K,MAAMxN,IAAM,EAAI2S,EAASlU,OAAOyT,kBAAkBlS,IAAM2C,IAExDmF,QAAQgL,gBAAkBH,EAASxB,OAAOnR,GAAK2S,EAASvB,OAAOpR,KAC/D8H,QAAQ8C,mBAAqB+H,EAASnF,MAAMxN,GACnD2S,EAASxB,OAAOnR,GAAK2S,EAASvB,OAAOpR,MAC1B2C,IAGNmF,QAAQiL,UAAYJ,EAAS7K,QAAQgL,eAC5CH,EAAS7K,QAAQ8C,qBAEF,MAGX3N,QAASC,UACTmE,EAAQtG,KAAKyO,OAAOtM,GACpBoV,EAAIjR,EAAM5C,OAAO8O,WAClB,IAAIvN,EAAI,EAAGA,EAAIsS,EAAGtS,GAAK,IACpBwN,MAAMxN,IAAMyH,IACZ0J,OAAOnR,IAAMyH,IACb2J,OAAOpR,IAAMyH,qBAUTuL,SACRC,EAAmB,IAAIpX,MAAMd,KAAKuT,QAAQxS,KAAK,MACjDkX,EAAU,EAAG,KAEXZ,EAAa,SACVzV,KAAK5B,KAAKyO,QAAQyC,OAAOhP,QAASC,UACjCmE,EAAQtG,KAAKyO,OAAOtM,KACTkV,GAAc,MAC1B,IAAIpS,EAAI,EAAGA,EAAIqB,EAAM5C,OAAO8O,OAAQvN,GAAK,IAC3BoS,IAAe/Q,EAAMgR,OAAO7E,MAAMxN,GACjDqB,EAAMgR,OAAOlB,OAAOnR,GACpBqB,EAAMgR,OAAOjB,OAAOpR,MAEV,QAEX,KAEDoS,EAAa,SACVzV,KAAK5B,KAAKyO,QAAQyC,OAAOhP,QAASC,UACjCmE,EAAQtG,KAAKyO,OAAOtM,KACTkV,GAAc,MAC3B5E,MAAEA,GAAUnM,EACA,IAAZ2R,MACM3R,EAAM8P,QAEA,IAAZ6B,MACM3R,EAAM+P,YAEX,IAAIpR,EAAI,EAAGA,EAAIqB,EAAM5C,OAAO8O,OAAQvN,GAAK,IAC3BoS,IAAe5E,EAAMxN,MAE1B,WAGXiT,IClSJ,SAASC,EACdjU,EACA8N,EACAlG,SAEM3L,eAAEA,EAAFS,gBAAkBA,GAAoBsD,GACtCsO,SAAApG,YAAA1D,iBAAA6J,iBAAAxK,kBAMFiK,SHy2BS,SACbxO,EACAgP,EAAS,EACTpG,EAAY,EACZ1D,GAAmBkF,SAAU,KAAMC,SAAU,KAC7C0E,EAAiB,YACjBxK,EAAiB,YAEZpG,OAAOC,KAAK4B,GAAGzB,SAAS,gBACrB,IAAIhC,MAAM,sGAEX4B,OAAOa,OACZgB,EACAwP,eAGOxP,EAAEE,oFGx3BG0U,CACZnM,EACE8G,EAAYzP,yCAGP0O,KAELlG,GAEF0G,EACApG,EACA1D,EACA6J,EACAxK,GAEWgG,MAAM7J,GAiCd,SAASmU,EACd3U,EACAgM,EAAmB,SAEbpJ,EFoHO,SAA2B9C,OACnCD,EAAYC,SACT,IAAIzD,MAAM,wGAEC,MAAO4V,EAAiBnS,EAAEE,OAAO8O,OAAQhP,EAAEE,OAAO6O,gBAAiB/O,EAAEE,QACjF/B,OAAOa,OACZgB,EACAoS,EACApS,EAAEE,OAAOxD,QAAUuW,YAEV,IAAI3V,MAAM0C,EAAEE,OAAO8O,QAAQzR,KAAK,mBACtB,IAAID,MAAM0C,EAAEE,OAAO8O,QAAQzR,KAAK,KAEnDuX,QEjIYC,CAAkBxI,EAC9BgD,EAAYzP,EAAUI,IACtBgM,aAEIoB,QACCxK,gCC7GM,SACbpC,EACAG,EACAC,SAEMnE,eAAEA,EAAFS,gBAAkBA,GAAoBsD,SAC9BkC,EACZ9C,wCAIAe,EACAC,GAEWyJ,MAAM7J,sCNuEd,SACLA,EACA8N,EACAlG,SAEM3L,eAAEA,EAAFS,gBAAkBA,GAAoBsD,SAC9B0K,EACZF,KAAsBvO,eAAAA,EAAgBS,gBAAAA,GAAoBoR,IAC1DhP,GAAMkP,EAASlP,EAAIgP,EAAelG,IAEvBiC,MAAM7J,8CAmCd,SACLR,EACAgM,EAAmB,SAEbpJ,EAAQ2L,EAAyBvD,EAAoBhL,aACrD+K,iBACC7M,KAAK8B,EAAOqL,SAAS7M,QAASC,MAC7BsM,OAAOtM,GAASiQ,EAAa1O,EAAOqL,QAAQ5M,GAAQuN,OAEtDoB,QACCxK,qCK3DF,SACLpC,EACA8N,EACAlG,SAEM3L,eAAEA,EAAFS,gBAAkBA,GAAoBsD,SAC9B0K,EACZF,KAAsBvO,eAAAA,EAAgBS,gBAAAA,GAAoBoR,IAC1DhP,GAAMmV,EAASnV,EAAIgP,EAAelG,IAEvBiC,MAAM7J,8CA4Bd,SACLR,EACAgM,EAAmB,SAEbpJ,EAAQ2L,EAAyBvD,EAAoBhL,aACrD+K,iBACC7M,KAAK8B,EAAOqL,SAAS7M,QAASC,MAC7BsM,OAAOtM,GAASkW,EAAa3U,EAAOqL,QAAQ5M,GAAQuN,OAEtDoB,QACCxK,8BAUF,SACL5C,EACAgM,EAAmB,OAEfpJ,EAAQoI,EAAoBhL,YAC1B+K,iBACC7M,KAAK8B,EAAOqL,SAAS7M,QAASC,MAC7BsM,OAAOtM,GAASkW,EAAa3U,EAAOqL,QAAQ5M,GAAQuN,QDyM/C,SAAuClM,OAC/CD,EAAYC,SACT,IAAIzD,MAAM,sGAOX4B,OAAOa,OACZgB,EACAuT,MAKAuB,QCvNME,CAA8BvG,EAAyB3L,KACzDwK,QACCxK"}