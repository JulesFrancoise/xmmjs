{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///webpack/bootstrap 2a7ed91a37d941f3e50f","webpack:///./src/core/model_base_mixin.js","webpack:///./src/gmm/index.js","webpack:///./src/training_set/index.js","webpack:///./src/kmeans/kmeans_training_mixin.js","webpack:///./src/core/em_training_mixin.js","webpack:///./src/gmm/gmm_base_mixin.js","webpack:///./src/core/multiclass_mixin.js","webpack:///./src/core/multiclass_training_mixin.js","webpack:///./src/core/prediction_mixin.js","webpack:///./src/common/validation.js","webpack:///./src/core/multiclass_prediction_mixin.js","webpack:///./src/training_set/phrase.js","webpack:///./src/kmeans/index.js","webpack:///./src/common/euclidean.js","webpack:///./src/common/gaussian_distribution.js","webpack:///./src/common/matrix.js","webpack:///./src/gmm/gmm_training_mixin.js","webpack:///./src/common/circular_buffer.js","webpack:///./src/gmm/gmm_prediction_mixin.js","webpack:///./src/hmm/index.js","webpack:///./src/hmm/hmm_base_mixin.js","webpack:///./src/hmm/hmm_training_mixin.js","webpack:///./src/hmm/hmm_prediction_mixin.js","webpack:///./src/hmm/hierarchical_hmm_prediction_mixin.js"],"names":["root","factory","exports","module","define","amd","self","this","installedModules","__webpack_require__","moduleId","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","configurable","enumerable","get","n","__esModule","object","property","prototype","hasOwnProperty","p","s","_ref","inputDimension","outputDimension","_objectWithoutProperties","bimodal","dimension","params","keys","includes","map","key","reduce","a","b","trainingSet","configuration","convergenceCriteria","__WEBPACK_IMPORTED_MODULE_5__core_multiclass_training_mixin__","__WEBPACK_IMPORTED_MODULE_4__core_multiclass_mixin__","MulticlassModelBase","ts","trainGMM","train","likelihoodWindow","model","__WEBPACK_IMPORTED_MODULE_8__core_multiclass_prediction_mixin__","models","classes","forEach","label","GMMPredictor","reset","gaussians","regularization","covarianceMode","__WEBPACK_IMPORTED_MODULE_3__gmm_training_mixin__","__WEBPACK_IMPORTED_MODULE_1__core_em_training_mixin__","__WEBPACK_IMPORTED_MODULE_2__gmm_base_mixin__","__WEBPACK_IMPORTED_MODULE_0__core_model_base_mixin__","ModelBase","__WEBPACK_IMPORTED_MODULE_7__gmm_prediction_mixin__","__WEBPACK_IMPORTED_MODULE_6__core_prediction_mixin__","trainingSetPrototype","size","phrases","length","empty","getPhrase","phraseIndex","toString","callback","push","phrase","undefined","__WEBPACK_IMPORTED_MODULE_0__phrase__","columnNames","remove","removeClass","filter","x","_extends","clear","getPhrasesOfClass","TrainingSet","labels","ll","concat","indices","mean","sum","Array","fill","totalLength","t","standardDeviation","stddev","Math","sqrt","minmax","from","min","Infinity","max","assign","create","clusters","trainingConfiguration","Error","trainingConfig","initialization","relativeDistanceThreshold","minIterations","maxIterations","kMeansTrainingPrototype","centers","initializeClustersRandom","initializeClustersForgy","initClustersWithFirstPhrase","trainingNbIterations","previousCenters","updateCenters","meanClusterDistance","maxRelativeCenterVariation","k","__WEBPACK_IMPORTED_MODULE_1__common_euclidean__","step","floor","offset","random","pointsPerCluster","ppc","clustIdx","_","getFrame","numFramesPerCluster","frame","minDistance","clusterMembership","distance","__webpack_exports__","percentChange","trainerPrototype","initTraining","logLikelihood","iterations","previousLogLikelihood","converged","updateTraining","pctChg","abs","Number","isNaN","terminateTraining","iteration","logProb","previousLogProb","gmmBasePrototype","gmmBimodalPrototype","allocate","components","__WEBPACK_IMPORTED_MODULE_1__common_gaussian_distribution__","mixtureCoeffs","beta","likelihood","observation","componentLikelihood","mixtureComponent","updateInverseCovariances","updateInverseCovariance","e","normalizeMixtureCoeffs","normConst","regularize","currentRegularization","regression","inputObservation","tmpOutputValues","results","outputValues","outputCovariance","d2","parameters","__WEBPACK_IMPORTED_MODULE_0__model_base_mixin__","MulticlassBasePrototype","trainingFunction","labs","instantLikelihood","predictionBasePrototype","likelihoodBuffer","__WEBPACK_IMPORTED_MODULE_1__common_circular_buffer__","setLikelihoodWindow","lw","predict","updateResults","log","bufSize","specification","values","attr","spec","required","parameter","value","constructor","checkSpec","check","transform","multiClassRegressionEstimator","MulticlassPredictionBasePrototype","MulticlassPredictionBimodalPrototype","getLikelihoodWindow","instantLikelihoods","smoothedLikelihoods","smoothedLogLikelihoods","smoothedNormalizedLikelihoods","likeliest","resetBimodal","sort","normInstant","normSmoothed","maxLogLikelihood","lab","exp","[object Object]","instantNormalizedLikelihoods","updateRegressionResults","phrasePrototype","inputData","outputData","index","dim","slice","pushInput","trim","pushOutput","clearInput","clearOutput","__WEBPACK_IMPORTED_MODULE_1__kmeans_training_mixin__","v1","v2","x1","proto","baseGaussianPrototype","bimodalGaussianPrototype","data","covarianceDeterminant","covarianceDeterminantInput","dist","covariance","inverseCovariance","allocateBimodal","inputLikelihood","euclideanDistance","tmp","PI","covMatrix","__WEBPACK_IMPORTED_MODULE_0__matrix__","inv","pinv","determinant","matrix","updateInverseCovarianceBimodal","toEllipse","dimension1","dimension2","gaussianEllipse","y","width","height","angle","trace","eigenVal1","eigenVal2","atan","fromEllipse","tantheta","tan","inverseCovarianceInput","prediction","f","covMatrixInput","d1","invInput","updateOutputCovariance","covarianceGS","covarianceSG","tmptmptmp","product","covarianceMod","Matrix","matrixPrototype","transpose","out","ncols","nrows","j","mat","gaussJordanInverse","transp","prod","dst","newMat","swapLines","ii","swapColumns","nc","absolute","relative","gmmTrainerPrototype","initParametersToDefault","initMeansWithKMeans","initCovariances","dataStddev","normCoeffs","std","kmeansParams","__WEBPACK_IMPORTED_MODULE_1__kmeans_kmeans_training_mixin__","gmeans","factor","phraseIndices","E","tbase","pix","capacity","buffer","circularBufferPrototype","full","idx","__WEBPACK_IMPORTED_MODULE_1__core_model_base_mixin__","__WEBPACK_IMPORTED_MODULE_0__common_validation__","gmmParameterSpec","trainHMM","HMMPredictor","__WEBPACK_IMPORTED_MODULE_9__hierarchical_hmm_prediction_mixin__","states","transitionMode","__WEBPACK_IMPORTED_MODULE_3__hmm_training_mixin__","__WEBPACK_IMPORTED_MODULE_2__hmm_base_mixin__","__WEBPACK_IMPORTED_MODULE_7__hmm_prediction_mixin__","hmmBasePrototype","forwardInitialized","isHierarchical","initializeForwardAlgorithm","alpha","prior","xStates","updateForwardAlgorithm","previousAlpha","transition","hmmTrainerPrototype","TRANSITION_REGULARIZATION","initMeansCovariancesWithGMMEM","initMeansWithAllPhrases","initCovariancesFullyObserved","__WEBPACK_IMPORTED_MODULE_2__gmm_gmm_base_mixin__","previousBeta","nbPhrases","gammaSequence","epsilonSequence","gammaSequenceperMixture","maxT","T","gammaSum","gammaSumPerMixture","baumWelchForwardBackward","baumWelchGammaSum","baumWelchEstimateMixtureCoefficients","baumWelchEstimateMeans","baumWelchEstimateCovariances","baumWelchEstimatePrior","baumWelchEstimateTransitions","normalizeTransitions","alphaSeq","betaSeq","setErgodic","setLeftRight","initCovariance","othermeans","__WEBPACK_IMPORTED_MODULE_0__training_set__","gmmParams","__WEBPACK_IMPORTED_MODULE_3__gmm__","normPrior","transitionNorm","initializeBackwardAlgorithm","ct","updateBackwardAlgorithm","baumWelchForwardUpdate","observationLikelihoods","baumWelchBackwardUpdate","currentPhrase","observationProbabilities","reverse","oo","sumprior","hmmParameterSpec","hmmPredictionPrototype","hmmBimodalPredictionPrototype","previous_alpha_","setup","__WEBPACK_IMPORTED_MODULE_2__gmm__","updateAlphaWindow","updateProgress","progress","windowMinindex","windowMaxindex","alpha1","alpha2","windowNormalizationConstant","likeliestState","bestAlpha","regressionEstimator","clipMinState","clipMaxState","normalizationConstant","tmpPredictedOutput","hierarchicalHmmPredictionPrototype","numClasses","exitTransition","updateExitProbabilities","exitProbabilities","exitProb","exitLikelihood","modelIndex","second","N","frontierV1","frontierV2","likelihoodAlpha","dstModelIndex","dstModel","front","srcModelIndex","exitRatio","exitNum","likelihoodVector"],"mappings":"CAAA,SAAAA,EAAAC,GACA,iBAAAC,SAAA,iBAAAC,OACAA,OAAAD,QAAAD,IACA,mBAAAG,eAAAC,IACAD,UAAAH,GACA,iBAAAC,QACAA,QAAA,KAAAD,IAEAD,EAAA,KAAAC,IARA,CASC,oBAAAK,UAAAC,KAAA,WACD,mBCTA,IAAAC,KAGA,SAAAC,EAAAC,GAGA,GAAAF,EAAAE,GACA,OAAAF,EAAAE,GAAAR,QAGA,IAAAC,EAAAK,EAAAE,IACAC,EAAAD,EACAE,GAAA,EACAV,YAUA,OANAW,EAAAH,GAAAI,KAAAX,EAAAD,QAAAC,IAAAD,QAAAO,GAGAN,EAAAS,GAAA,EAGAT,EAAAD,QAqCA,OAhCAO,EAAAM,EAAAF,EAGAJ,EAAAO,EAAAR,EAGAC,EAAAQ,EAAA,SAAAf,EAAAgB,EAAAC,GACAV,EAAAW,EAAAlB,EAAAgB,IACAG,OAAAC,eAAApB,EAAAgB,GACAK,cAAA,EACAC,YAAA,EACAC,IAAAN,KAMAV,EAAAiB,EAAA,SAAAvB,GACA,IAAAgB,EAAAhB,KAAAwB,WACA,WAA2B,OAAAxB,EAAA,SAC3B,WAAiC,OAAAA,GAEjC,OADAM,EAAAQ,EAAAE,EAAA,IAAAA,GACAA,GAIAV,EAAAW,EAAA,SAAAQ,EAAAC,GAAsD,OAAAR,OAAAS,UAAAC,eAAAjB,KAAAc,EAAAC,IAGtDpB,EAAAuB,EAAA,GAGAvB,IAAAwB,EAAA,uCCpDe,SAAAC,GAIZ,IAJ+BC,eAChCA,EADgCC,gBAEhCA,GAECF,EACD,MAAMF,yHADLK,CAAAH,GAAA,qCAMD,cAJOF,EAAEM,eACFN,EAAEG,sBACFH,EAAEI,uBACFJ,EAAEO,WAEPC,YACKR,GACHM,cACE,OAAOF,EAAkB,GAE3BD,qBACE,OAAOA,GAETC,sBACE,OAAOA,GAETG,gBACE,OAAOJ,EAAiBC,WAWzB,SAAqBhB,GAC1B,IAAKC,OAAOoB,KAAKrB,GAAGsB,SAAS,UAAW,OAAO,EAE/C,OADc,UAAW,iBAAkB,kBAAmB,aAClDC,IAAIC,GAAOvB,OAAOoB,KAAKrB,EAAEoB,QAAQE,SAASE,IACnDC,OAAO,CAACC,EAAGC,IAAMD,GAAKC,GAAG,oNCqBvB,SACLC,EACAC,EACAC,GAEA,MAAMf,eAAEA,EAAFC,gBAAkBA,GAAoBY,EAK5C,OAJc3B,OAAA8B,EAAA,EAAA9B,CACZA,OAAA+B,EAAA,EAAA/B,CAAAgC,GAAsBlB,iBAAgBC,mBAAoBa,IAC1DK,GAAMC,EAASD,EAAIL,EAAeC,IAEvBM,MAAMR,cA4Bd,SACLR,EACAiB,GAEA,MAAMC,EAAQrC,OAAAsC,EAAA,EAAAtC,CAAyBA,OAAA+B,EAAA,EAAA/B,CAAoBmB,IAM3D,OALAkB,EAAME,UACNvC,OAAOoB,KAAKD,EAAOqB,SAASC,QAASC,IACnCL,EAAME,OAAOG,GAASC,EAAaxB,EAAOqB,QAAQE,GAAQN,KAE5DC,EAAMO,QACCP,6OAlFF,SAASH,EACdP,EACAC,EACAC,GAEA,MAAMf,eAAEA,EAAFC,gBAAkBA,GAAoBY,GACtCkB,UAAEA,EAAFC,eAAaA,EAAbC,eAA6BA,GAAmBnB,EActD,OAbc5B,OAAAgD,EAAA,EAAAhD,CACZA,OAAAiD,EAAA,EAAAjD,CACEA,OAAAkD,EAAA,EAAAlD,CAAYA,OAAAmD,EAAA,EAAAnD,CAAAoD,GACVtC,iBACAC,mBACGa,KAELC,GAEFgB,EACAC,EACAC,GAEWZ,MAAMR,GAiCd,SAASgB,EACdxB,EACAiB,GAEA,MAAMC,EAAQrC,OAAAqD,EAAA,EAAArD,CAAkBA,OAAAsD,EAAA,EAAAtD,CAC9BA,OAAAkD,EAAA,EAAAlD,CAAYA,OAAAmD,EAAA,EAAAnD,CAAUmB,IACtBiB,IAGF,OADAC,EAAMO,QACCP,uNC1FT,MAAMkB,GAKJC,OACE,OAAOxD,OAAOoB,KAAKlC,KAAKuE,SAASC,QAOnCC,QACE,OAAuB,IAAhBzE,KAAKwE,QAQdE,UAAUC,GACR,OAAI7D,OAAOoB,KAAKlC,KAAKuE,SAASpC,SAASwC,EAAYC,YAC1C5E,KAAKuE,QAAQI,EAAYC,YAE3B,MAUTrB,QAAQsB,GACN/D,OAAOoB,KAAKlC,KAAKuE,SAAShB,QAASoB,IACjCE,EAAS7E,KAAKuE,QAAQI,GAAcA,EAAa3E,KAAKuE,YAY1DO,KAAKH,EAAanB,EAAmBuB,GACnC,MAAMtD,OAAgBuD,IAAXD,EAAwBA,EAASjE,OAAAmE,EAAA,EAAAnE,EAC1Cc,eAAgB5B,KAAK4B,eACrBC,gBAAiB7B,KAAK6B,gBACtBqD,YAAalF,KAAKkF,YAClB1B,WAAkBwB,IAAVxB,EAAuBA,EAAQmB,EAAYC,aAGrD,OADA5E,KAAKuE,QAAQI,GAAelD,EACrBA,GAOT0D,OAAOR,UACE3E,KAAKuE,QAAQI,IAOtBS,YAAY5B,GACVxD,KAAKuE,QAAUzD,OAAOoB,KAAKlC,KAAKuE,SAC7Bc,OAAOjF,GAAKJ,KAAKuE,QAAQnE,GAAGoD,QAAUA,GACtCpB,IAAIhC,KAAQA,EAAGJ,KAAKuE,QAAQnE,MAC5BkC,OAAO,CAACgD,EAAG7D,IAAJ8D,KAAgBD,EAAM7D,QAMlC+D,QACExF,KAAKuE,YAQPkB,kBAAkBjC,GAChB,MAAMT,EAAK2C,EAAY1F,MAKvB,OAJA+C,EAAGwB,QAAUzD,OAAOoB,KAAKlC,KAAKuE,SAC3Bc,OAAOjF,GAAKJ,KAAKuE,QAAQnE,GAAGoD,QAAUA,GACtCpB,IAAIhC,KAAQA,EAAGJ,KAAKuE,QAAQnE,MAC5BkC,OAAO,CAACgD,EAAG7D,IAAJ8D,KAAgBD,EAAM7D,OACzBsB,GAOT4C,SACE,OAAO7E,OAAOoB,KAAKlC,KAAKuE,SACrBnC,IAAIhC,GAAKJ,KAAKuE,QAAQnE,GAAGoD,OACzBlB,OAAO,CAACsD,EAAIN,IAAOM,EAAGzD,SAASmD,GAAKM,EAAKA,EAAGC,QAAQP,SAOzDQ,UACE,OAAOhF,OAAOoB,KAAKlC,KAAKuE,UAO1BwB,OACE,MAAMC,EAAMC,MAAMjG,KAAKgC,WAAWkE,KAAK,GACvC,IAAIC,EAAc,EAUlB,OATArF,OAAOoB,KAAKlC,KAAKuE,SAAShB,QAASnD,IACjC,IAAK,IAAIM,EAAI,EAAGA,EAAIV,KAAKgC,UAAWtB,GAAK,EACvC,IAAK,IAAI0F,EAAI,EAAGA,EAAIpG,KAAKuE,QAAQnE,GAAGoE,OAAQ4B,GAAK,EAC/CJ,EAAItF,IAAMV,KAAKuE,QAAQnE,GAAGc,IAAIkF,EAAG1F,GAGrCyF,GAAenG,KAAKuE,QAAQnE,GAAGoE,SAG1BwB,EAAI5D,IAAIkD,GAAKA,EAAIa,IAO1BE,oBACE,MAAMC,EAASL,MAAMjG,KAAKgC,WAAWkE,KAAK,GACpCH,EAAO/F,KAAK+F,OAClB,IAAII,EAAc,EAUlB,OATArF,OAAOoB,KAAKlC,KAAKuE,SAAShB,QAASnD,IACjC,IAAK,IAAIM,EAAI,EAAGA,EAAIV,KAAKgC,UAAWtB,GAAK,EACvC,IAAK,IAAI0F,EAAI,EAAGA,EAAIpG,KAAKuE,QAAQnE,GAAGoE,OAAQ4B,GAAK,EAC/CE,EAAO5F,KAAOV,KAAKuE,QAAQnE,GAAGc,IAAIkF,EAAG1F,GAAKqF,EAAKrF,KAAO,EAG1DyF,GAAenG,KAAKuE,QAAQnE,GAAGoE,SAG1B8B,EAAOlE,IAAIkD,GAAKiB,KAAKC,KAAKlB,EAAIa,KAOvCM,SACE,MAAMA,EAASR,MAAMS,KACnBT,MAAMjG,KAAKgC,WACX,MAAS2E,IAAMC,IAAUC,KAAMD,OAUjC,OARA9F,OAAOoB,KAAKlC,KAAKuE,SAAShB,QAASnD,IACjC,IAAK,IAAIM,EAAI,EAAGA,EAAIV,KAAKgC,UAAWtB,GAAK,EACvC,IAAK,IAAI0F,EAAI,EAAGA,EAAIpG,KAAKuE,QAAQnE,GAAGoE,OAAQ4B,GAAK,EAC/CK,EAAO/F,GAAGiG,KAAOJ,KAAKI,IAAIF,EAAO/F,GAAGiG,IAAK3G,KAAKuE,QAAQnE,GAAGc,IAAIkF,EAAG1F,IAChE+F,EAAO/F,GAAGmG,KAAON,KAAKM,IAAIJ,EAAO/F,GAAGmG,IAAK7G,KAAKuE,QAAQnE,GAAGc,IAAIkF,EAAG1F,MAI/D+F,IAqBI,SAASf,GAAY9D,eAClCA,EAAiB,EADiBC,gBAElCA,EAAkB,EAFgBqD,YAGlCA,EAAc,UAEd,MAAMlD,EAAYJ,EAAiBC,EACnC,OAAOf,OAAOgG,OACZhG,OAAOiG,OAAO1C,IAEZtC,QAASF,EAAkB,EAC3BD,iBACAC,kBACAG,YACAkD,YAAaA,GAAee,MAAMjE,GAAWkE,KAAK,IAClD3B,gDClES,SACb1D,EACAmG,EACAC,MAEA,IAAKnG,OAAAmD,EAAA,EAAAnD,CAAYD,GACf,MAAM,IAAIqG,MAAM,+FAElB,MAAMC,EAAiBrG,OAAOgG,QAC5BM,eAAgB,SAChBC,0BAA2B,KAC3BC,cAAe,EACfC,cAAe,KACdN,GACG9D,EAAQrC,OAAOgG,OAAOjG,EAAG2G,GAC7BL,mBAGF,OADAhE,EAAMlB,OAAO+E,SAAWA,EACjB7D,sBArKT,MAAMqE,GACJvE,MAAMR,GACJ,IAAKA,GAAeA,EAAYgC,QAC9B,MAAM,IAAIyC,MAAM,6BAWlB,GARAlH,KAAKiC,OAAOwF,QAAUxB,MAAMS,KAC1BT,MAAMjG,KAAKiC,OAAO+E,UAClB,IAAM,IAAIf,MAAMjG,KAAKiC,OAAOD,WAAWkE,KAAK,IAMH,WAAvClG,KAAKmH,eAAeC,eACtBpH,KAAK0H,yBAAyBjF,QACzB,GAA2C,UAAvCzC,KAAKmH,eAAeC,eAC7BpH,KAAK2H,wBAAwBlF,OACxB,IAA2C,SAAvCzC,KAAKmH,eAAeC,eAG7B,MAAM,IAAIF,MAAM,uEAFhBlH,KAAK4H,4BAA4BnF,GAKnC,IACE,IAAIoF,EAAuB,EAC3BA,EAAuB7H,KAAKmH,eAAeI,cAC3CM,GAAwB,EACxB,CACA,MAAMC,EAAkB9H,KAAKiC,OAAOwF,QAEpCzH,KAAK+H,cAAcD,EAAiBrF,GAEpC,IAAIuF,EAAsB,EACtBC,EAA6B,EACjC,IAAK,IAAIC,EAAI,EAAGA,EAAIlI,KAAKiC,OAAO+E,SAAUkB,GAAK,EAAG,CAChD,IAAK,IAAI7H,EAAI,EAAGA,EAAIL,KAAKiC,OAAO+E,SAAU3G,GAAK,EACzC6H,IAAM7H,IACR2H,GAAuBlH,OAAAqH,EAAA,EAAArH,CACrBd,KAAKiC,OAAOwF,QAAQS,GACpBlI,KAAKiC,OAAOwF,QAAQpH,KAI1B4H,EAA6B1B,KAAKM,IAChC/F,OAAAqH,EAAA,EAAArH,CACEgH,EAAgBI,GAChBlI,KAAKiC,OAAOwF,QAAQS,IAEtBD,GAMJ,GAHAD,GAAuBhI,KAAKiC,OAAO+E,UAAYhH,KAAKiC,OAAO+E,SAAW,GACtEiB,GAA8BjI,KAAKiC,OAAO+E,UAC1CiB,GAA8BD,GACGhI,KAAKmH,eAAeE,0BAA2B,MAElF,OAAOrH,KAAKiC,QAGd2F,4BAA4BnF,GAC1B,MAAMsC,EAAStC,EAAYiC,UAAUjC,EAAYqD,UAAU,IACrDsC,EAAO7B,KAAK8B,MAAMtD,EAAOP,OAASxE,KAAKiC,OAAO+E,UAEpD,IAAIsB,EAAS,EACb,IAAK,IAAI7H,EAAI,EAAGA,EAAIT,KAAKiC,OAAO+E,SAAUvG,GAAK,EAAG,CAChDT,KAAKiC,OAAOwF,QAAQhH,GAAK,IAAIwF,MAAMjG,KAAKiC,OAAOD,WAAWkE,KAAK,GAC/D,IAAK,IAAIE,EAAI,EAAGA,EAAIgC,EAAMhC,GAAK,EAC7B,IAAK,IAAI1F,EAAI,EAAGA,EAAIV,KAAKiC,OAAOD,UAAWtB,GAAK,EAC9CV,KAAKiC,OAAOwF,QAAQhH,GAAGC,IAAMqE,EAAO7D,IAAIoH,EAASlC,EAAG1F,GAAK0H,EAG7DE,GAAUF,IAIdV,yBAAyBjF,GACvB,MAAMsC,EAAStC,EAAYiC,UAAUjC,EAAYqD,UAAU,IACrDA,EAAUG,MAAMS,KACpBT,MAAMlB,EAAOP,QACb,IAAM+B,KAAK8B,MAAM9B,KAAKgC,SAAWvI,KAAKiC,OAAO+E,WAEzCwB,EAAmB1C,EAAQxD,OAC/B,CAACmG,EAAKrI,KACJ,MAAMqB,EAAIgH,EAEV,OADAhH,EAAErB,IAAM,EACDqB,GAETwE,MAAMjG,KAAKiC,OAAO+E,UAAUd,KAAK,IAEnC,IAAK,IAAI9F,EAAI,EAAGA,EAAI0F,EAAQtB,OAAQpE,GAAK,EAAG,CAC1C,MAAMsI,EAAW5C,EAAQ1F,GACzB,IAAK,IAAIM,EAAI,EAAGA,EAAIV,KAAKiC,OAAOD,UAAWtB,GAAK,EAC9CV,KAAKiC,OAAOwF,QAAQiB,GAAUhI,IAAMqE,EAAO7D,IAAId,EAAGM,GAGtDV,KAAKiC,OAAOwF,QAAQlE,QAAQ,CAACoF,EAAGlI,KAC9BT,KAAKiC,OAAOwF,QAAQhH,GAAKT,KAAKiC,OAAOwF,QAAQhH,GAC1C2B,IAAIkD,GAAKA,EAAIkD,EAAiB/H,OAIrCkH,wBAAwBlF,GACtB,MAAMsC,EAAStC,EAAYiC,UAAUjC,EAAYqD,UAAU,IACrDA,EAAUG,MAAMS,KACpBT,MAAMjG,KAAKiC,OAAO+E,UAClB,IAAMT,KAAK8B,MAAM9B,KAAKgC,SAAWxD,EAAOP,SAE1CxE,KAAKiC,OAAOwF,QAAU3B,EAAQ1D,IAAIhC,GAAK2E,EAAO6D,SAASxI,KAGzD2H,cAAcD,EAAiBrF,GAC7BzC,KAAKiC,OAAOwF,QAAUxB,MAAMS,KAAKT,MAAMjG,KAAKiC,OAAO+E,UAAW,IAC5D,IAAIf,MAAMjG,KAAKiC,OAAOD,WAAWkE,KAAK,IACxC,MAAM2C,EAAsB5C,MAAMjG,KAAKiC,OAAO+E,UAAUd,KAAK,GAC7DzD,EAAYc,QAASwB,IACnB,IAAK,IAAIqB,EAAI,EAAGA,EAAIrB,EAAOP,OAAQ4B,GAAK,EAAG,CACzC,MAAM0C,EAAQ/D,EAAO6D,SAASxC,GAC9B,IAAI2C,EAAcjI,OAAAqH,EAAA,EAAArH,CAAUgI,EAAOhB,EAAgB,IAC/CkB,EAAoB,EACxB,IAAK,IAAId,EAAI,EAAGA,EAAIlI,KAAKiC,OAAO+E,SAAUkB,GAAK,EAAG,CAChD,MAAMe,EAAWnI,OAAAqH,EAAA,EAAArH,CACfgI,EACAhB,EAAgBI,GAChBlI,KAAKiC,OAAOD,WAEViH,EAAWF,IACbC,EAAoBd,EACpBa,EAAcE,GAGlBJ,EAAoBG,IAAsB,EAC1C,IAAK,IAAItI,EAAI,EAAGA,EAAIV,KAAKiC,OAAOD,UAAWtB,GAAK,EAC9CV,KAAKiC,OAAOwF,QAAQuB,GAAmBtI,IAAMqE,EAAO7D,IAAIkF,EAAG1F,MAIjE,IAAK,IAAIwH,EAAI,EAAGA,EAAIlI,KAAKiC,OAAO+E,SAAUkB,GAAK,EAC7C,GAAIW,EAAoBX,GAAK,EAC3B,IAAK,IAAIxH,EAAI,EAAGA,EAAIV,KAAKiC,OAAOD,UAAWtB,GAAK,EAC9CV,KAAKiC,OAAOwF,QAAQS,GAAGxH,IAAMmI,EAAoBX,mCC/I3DgB,EAAA,EAkFe,SACbrI,EACA8B,GACEwG,cAAe,KACf7B,cAAe,EACfC,cAAe,MAGjB,OAAOzG,OAAOgG,OAAOjG,EAAGuI,GAAoBzG,yBA1F9C,MAAMyG,GAQJnG,MAAMR,GACJ,IAAKA,GAAeA,EAAYgC,QAC9B,MAAM,IAAIyC,MAAM,6BAGlBlH,KAAKqJ,aAAa5G,GAElB,IAAI6G,GAAiB1C,IACjB2C,EAAa,EACbC,EAAwBF,EAE5B,MAAQtJ,KAAKyJ,UAAUF,EAAYD,EAAeE,IAAwB,CACxEA,EAAwBF,EACxBA,EAAgBtJ,KAAK0J,eAAejH,GAEpC,MAAMkH,EACJ,IAAMpD,KAAKqD,KAAKN,EAAgBE,GAAyBA,GAC3D,GAAIK,OAAOC,MAAMH,IAAWJ,EAAa,EACvC,MAAM,IAAIrC,MAAM,oCAGlBqC,GAAc,EAIhB,OADAvJ,KAAK+J,oBACE/J,KAAKiC,QAedwH,UAAUO,EAAWC,EAASC,GAC5B,GAAIF,GAAahK,KAAK2C,oBAAoB4E,cAAe,OAAO,EAChE,GAAIvH,KAAK2C,oBAAoB4E,eAAiBvH,KAAK2C,oBAAoB2E,cACrE,OAAO0C,GAAahK,KAAK2C,oBAAoB4E,cAE/C,GAAIyC,EAAYhK,KAAK2C,oBAAoB2E,cAAe,OAAO,EAE/D,OADsB,IAAMf,KAAKqD,KAAKK,EAAUC,GAAmBD,IAC3CjK,KAAK2C,oBAAoBwG,kDCwGtC,SAAqBtI,GAClC,IAAKC,OAAAmD,EAAA,EAAAnD,CAAYD,GACf,MAAM,IAAIqG,MAAM,+FAElB,OAAOpG,OAAOgG,OACZjG,EACAsJ,EACAtJ,EAAEoB,OAAOF,QAAUqI,0BA9JvB,MAAMD,GAKJE,WACErK,KAAKiC,OAAOqI,WAAarE,MAAMS,KAC7BT,MAAMjG,KAAKiC,OAAO0B,WAClB,IAAM,IAAI4G,EAAA,EACRvK,KAAKiC,OAAOL,eACZ5B,KAAKiC,OAAOJ,gBACZ7B,KAAKiC,OAAO4B,iBAGhB7D,KAAKiC,OAAOuI,cAAgBvE,MAAMjG,KAAKiC,OAAO0B,WAAWuC,KAAK,GAC9DlG,KAAKyK,KAAO,IAAIxE,MAAMjG,KAAKiC,OAAO0B,WAAWuC,KAAK,IAQpDwE,WAAWC,GACT,IAAID,EAAa,EACjB,IAAK,IAAIjK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKyK,KAAKhK,GAAKT,KAAK4K,oBAAoBD,EAAalK,GACrDiK,GAAc1K,KAAKyK,KAAKhK,GAE1B,IAAK,IAAIA,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKyK,KAAKhK,IAAMiK,EAGlB,OAAOA,GAUTE,oBAAoBD,EAAaE,GAC/B,GAAIA,GAAoB7K,KAAKiC,OAAO0B,UAClC,MAAM,IAAIuD,MAAM,gEAElB,OAAOlH,KAAKiC,OAAOuI,cAAcK,GAC7B7K,KAAKiC,OAAOqI,WAAWO,GAAkBH,WAAWC,IAO1DG,2BACE9K,KAAKiC,OAAOqI,WAAW/G,QAAS9C,IAC9BA,EAAEsK,4BAEJ,IACE/K,KAAKiC,OAAOqI,WAAW/G,QAAS9C,IAC9BA,EAAEsK,4BAEJ,MAAOC,GACP,MAAM,IAAI9D,MAAM,8DAQpB+D,yBACE,IAAIC,EAAY,EAChB,IAAK,IAAIzK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CyK,GAAalL,KAAKiC,OAAOuI,cAAc/J,GAEzC,GAAIyK,EAAY,EACd,IAAK,IAAIzK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKiC,OAAOuI,cAAc/J,IAAMyK,OAGlC,IAAK,IAAIzK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKiC,OAAOuI,cAAc/J,GAAK,EAAIT,KAAKiC,OAAO0B,WASrDwH,aACEnL,KAAKiC,OAAOqI,WAAW/G,QAAS9C,IAC9BA,EAAE0K,WAAWnL,KAAKoL,2BAUlBhB,GASJiB,WAAWC,GAGT,IAAIC,EAFJvL,KAAKwL,QAAQC,aAAexF,MAAMjG,KAAKiC,OAAOJ,iBAAiBqE,KAAK,GACpElG,KAAKwL,QAAQE,iBAAmBzF,MAAqC,SAA/BjG,KAAKiC,OAAO4B,eAA4B7D,KAAKiC,OAAOJ,iBAAmB,EAAI7B,KAAKiC,OAAOJ,iBAAiBqE,KAAK,GAGnJ,IAAK,IAAIzF,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAAG,CACjD8K,EAAkBvL,KAAKiC,OAAOqI,WAAW7J,GAAG4K,WAAWC,GACvD,IAAK,IAAI5K,EAAI,EAAGA,EAAIV,KAAKiC,OAAOJ,gBAAiBnB,GAAK,EAEpD,GADAV,KAAKwL,QAAQC,aAAa/K,IAAMV,KAAKyK,KAAKhK,GAAK8K,EAAgB7K,GAC5B,SAA/BV,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAK,EAAGA,EAAK3L,KAAKiC,OAAOJ,gBAAiB8J,GAAM,EACvD3L,KAAKwL,QAAQE,iBAAkBhL,EAAIV,KAAKiC,OAAOJ,gBAAmB8J,IAC/D3L,KAAKyK,KAAKhK,IAAM,EACjBT,KAAKiC,OAAOqI,WAAW7J,GAAGiL,iBAAkBhL,EAAIV,KAAKiC,OAAOJ,gBAAmB8J,QAGnF3L,KAAKwL,QAAQE,iBAAiBhL,IAC3BV,KAAKyK,KAAKhK,IAAM,EAAKT,KAAKiC,OAAOqI,WAAW7J,GAAGiL,iBAAiBhL,GAIzE,OAAOV,KAAKwL,QAAQC,iDCnGT,SAAA9J,GAIZ,IAJyCC,eAC1CA,EAD0CC,gBAE1CA,GAECF,EADEiK,yHACF9J,CAAAH,GAAA,qCACD,OAAOb,OAAOgG,OACZhG,OAAA+K,EAAA,EAAA/K,CAAAoD,GAAYtC,iBAAgBC,mBAAoB+J,IAChDE,mLA3CJ,MAAMA,GAKJxH,OACE,OAAOxD,OAAOoB,KAAKlC,KAAKqD,QAAQmB,QAQlCrC,SAASqB,GACP,OAAO1C,OAAOoB,KAAKlC,KAAKqD,QAAQlB,SAASqB,IAO3C2B,OAAO3B,GACDxD,KAAKmC,SAASqB,WACTxD,KAAKqD,OAAOG,mCC/BzB0F,EAAA,EAQe,SACbrI,EACAkL,GAEA,OAAOjL,OAAOgG,OACZjG,GAaEoC,MAAMR,EAAakD,GACjB,IAAKlD,GAAeA,EAAYgC,QAC9B,MAAM,IAAIyC,MAAM,6BAEdvB,GACFA,EAAOpC,QAASlD,IACd,IAAKL,KAAKmC,SAAS9B,GACjB,MAAM,IAAI6G,uBAAuB7G,sBAKvCL,KAAKiC,OAAOqB,WACZ,MAAM0I,EAAOrG,GAAUlD,EAAYkD,SAMnC,OALAqG,EAAKzI,QAASC,IACZ,MAAMT,EAAKN,EAAYgD,kBAAkBjC,GAEzCxD,KAAKiC,OAAOqB,QAAQE,GAASuI,EAAiBhJ,KAEzC/C,KAAKiC,6CC6BL,SAA+BpB,EAAGqC,EAAmB,GAClE,IAAKpC,OAAA+K,EAAA,EAAA/K,CAAYD,GACf,MAAM,IAAIqG,MAAM,+FAElB,MAAMsE,EAAU1K,OAAOgG,QACnBmF,kBAAmB,EAAG3C,cAAe,GACvCzI,EAAEoB,OAAOF,SAAY0J,gBAAkBC,yBAEzC,OAAO5K,OAAOgG,OACZjG,EACAqL,EAAwBrL,EAAEoB,OAAOF,UAC/ByJ,UAASW,iBAAkBrL,OAAAsL,EAAA,EAAAtL,CAAeoC,yBA5EhD,MAAMgJ,EAA0BnK,KAM9BoK,iBAAkBrL,OAAAsL,EAAA,EAAAtL,CAAe,GAMjCuL,oBAAoBC,GAClBtM,KAAKkD,iBAAmBoJ,EACxBtM,KAAKmM,iBAAmBrL,OAAAsL,EAAA,EAAAtL,CAAewL,IAOzC5I,QAEE,OADA1D,KAAKmM,iBAAiB3G,QACfxF,MAUTuM,QAAQ5B,GACN,MAAMD,EAAa1K,KAAK0K,WAAWC,GAKnC,OAJI5I,GACF/B,KAAKqL,WAAWV,GAElB3K,KAAKwM,cAAc9B,GACZ1K,KAAKwL,SAQdgB,cAAcP,GACZjM,KAAKwL,QAAQS,kBAAoBA,EACjCjM,KAAKmM,iBAAiBrH,KAAKyB,KAAKkG,IAAIR,IACpCjM,KAAKwL,QAAQlC,cAAgB,EAC7B,MAAMoD,EAAU1M,KAAKmM,iBAAiB3H,OACtC,IAAK,IAAIpE,EAAI,EAAGA,EAAIsM,EAAStM,GAAK,EAChCJ,KAAKwL,QAAQlC,eAAiBtJ,KAAKmM,iBAAiBjL,IAAId,GAE1DJ,KAAKwL,QAAQlC,eAAiBoD,mCChElCxD,EAAA,EA8Fe,SAA4B/F,EAAOwJ,EAAeC,GAC/D,MAAMhB,EAAa9K,OAAOgG,UAAW8F,GAgBrC,OAfA9L,OAAOoB,KAAKyK,GAAepJ,QAASsJ,IAClC,MAAMC,EAAOH,EAAcE,GAG3B,GAAIC,EAAKC,WAAajM,OAAOoB,KAAK0K,GAAQzK,SAAS0K,GACjD,MAAM,IAAI3F,2BAA2B2F,6BAAgC1J,QAzF3E,SAAmBA,EAAO6J,EAAWL,EAAeM,GAClD,GAAKN,EAAL,CACA,GAAIA,EAAcO,cAAgBjH,QAAU0G,EAAcxK,SAAS8K,GACjE,MAAM,IAAI/F,oBAAoB8F,eAAuBC,iCAAqC9J,iBAAqBwJ,QAC1G,GAAIA,EAAcO,cAAgBpM,OAAQ,CAC/C,GAAIA,OAAOoB,KAAKyK,GAAexK,SAAS,QAAU8K,EAAQN,EAAchG,IACtE,MAAM,IAAIO,oBAAoB8F,cAAsBC,mDAAuDN,EAAchG,kBAAkBxD,OAE7I,GAAIrC,OAAOoB,KAAKyK,GAAexK,SAAS,QAAU8K,EAAQN,EAAc9F,IACtE,MAAM,IAAIK,oBAAoB8F,cAAsBC,mDAAuDN,EAAchG,kBAAkBxD,YAExI,GAA6B,mBAAlBwJ,IACXA,EAAcM,GACjB,MAAM,IAAI/F,oBAAoB8F,cAAsBC,kCAAsC9J,QAgF5FgK,CAAUhK,EAAO0J,EAAMC,EAAKM,MAAOR,EAAOC,IAE1CjB,EAAWiB,GAAQC,EAAKO,UACtBP,EAAKO,UAAUT,EAAOC,IACtBD,EAAOC,KAEJjB,qCCoBM,SAAkC/K,EAAGyM,EAAgC,aAClF,IAAKxM,OAAA+K,EAAA,EAAA/K,CAAYD,GACf,MAAM,IAAIqG,MAAM,+FAElB,MAAM1G,EAAIM,OAAOgG,OACfjG,EACA0M,EACA1M,EAAEoB,OAAOF,QAAUyL,MAGrB,OADAhN,EAAEyB,OAAOqL,8BAAgCA,EAClC9M,kLAtIT,MAAM+M,GAKJE,sBACE,OAAOzN,KAAKkD,kBAOdmJ,oBAAoBC,GAClBtM,KAAKkD,iBAAmBoJ,EACxBxL,OAAOoB,KAAKlC,KAAKqD,QAAQE,QAASC,IAChCxD,KAAKqD,OAAOG,GAAO6I,oBAAoBC,MAQ3C5I,QACE5C,OAAO8L,OAAO5M,KAAKqD,QAAQE,QAAQ/C,GAAKA,EAAEkD,SAC1C1D,KAAKwL,SACH7F,UACA+H,sBACAC,uBACAC,0BACAC,iCACAC,UAAW,KACXxK,YAEEtD,KAAKiC,OAAOF,SACd/B,KAAK+N,gBAQTxB,QAAQ5B,GACN7J,OAAO8L,OAAO5M,KAAKqD,QAAQE,QAAQ/C,GAAKA,EAAE+L,QAAQ5B,IAClD3K,KAAKwM,iBAGPA,gBACE,MAAMR,EAAOlL,OAAOoB,KAAKlC,KAAKqD,QAAQ2K,OACtChO,KAAKwL,QAAQ7F,OAASqG,EACtB,IAAIiC,EAAc,EACdC,EAAe,EACfC,GAAoBvH,IACxB5G,KAAKwL,QAAQlI,QAAU0I,EACpB5J,IAAI,CAACgM,EAAKhO,KACTJ,KAAKwL,QAAQkC,mBAAmBtN,GAC9BJ,KAAKqD,OAAO+K,GAAK5C,QAAQS,kBAC3BjM,KAAKwL,QAAQoC,uBAAuBxN,GAClCJ,KAAKqD,OAAO+K,GAAK5C,QAAQlC,cAC3BtJ,KAAKwL,QAAQmC,oBAAoBvN,GAC/BmG,KAAK8H,IAAIrO,KAAKwL,QAAQoC,uBAAuBxN,IAC/C6N,GAAejO,KAAKwL,QAAQkC,mBAAmBtN,GAC/C8N,GAAgBlO,KAAKwL,QAAQmC,oBAAoBvN,GAC7CJ,KAAKwL,QAAQoC,uBAAuBxN,GAAK+N,IAC3CA,EAAmBnO,KAAKwL,QAAQoC,uBAAuBxN,GACvDJ,KAAKwL,QAAQsC,UAAYM,IAElBE,CAACF,GAAMpO,KAAKqD,OAAO+K,GAAK5C,WAElClJ,OAAO,CAACzB,EAAGyE,IAAJC,KAAgB1E,EAAMyE,OAChCtF,KAAKwL,QAAQqC,8BACX7N,KAAKwL,QAAQmC,oBAAoBvL,IAAIkD,GAAKA,EAAI4I,GAChDlO,KAAKwL,QAAQ+C,6BACXvO,KAAKwL,QAAQkC,mBAAmBtL,IAAIkD,GAAKA,EAAI2I,GAC3CjO,KAAKiC,OAAOF,SACd/B,KAAKwO,4BAKLhB,GACJO,eACE/N,KAAKwL,QAAQC,gBACbzL,KAAKwL,QAAQE,qBAGf8C,0BACE,GAAkD,cAA9CxO,KAAKiC,OAAOqL,8BACdtN,KAAKwL,QAAQC,aACXzL,KAAKqD,OAAOrD,KAAKwL,QAAQsC,WAAWtC,QAAQC,aAC9CzL,KAAKwL,QAAQE,iBACX1L,KAAKqD,OAAOrD,KAAKwL,QAAQsC,WAAWtC,QAAQE,qBACzC,IAAkD,YAA9C1L,KAAKiC,OAAOqL,8BAcrB,MAAM,IAAIpG,MAAM,8DAbhBlH,KAAKwL,QAAQC,aAAexF,MAAMjG,KAAK6B,iBAAiBqE,KAAK,GAC7DlG,KAAKwL,QAAQE,iBAAmBzF,MAAMjG,KAAK6B,kBAA0D,SAAtC7B,KAAK0C,cAAcmB,eAA4B,EAAI,IAAIqC,KAAK,GAC3HlG,KAAKwL,QAAQ7F,OAAOpC,QAAS6K,IAC3BpO,KAAKwL,QAAQC,aAAarJ,IAAI,CAACkD,EAAGlF,IAAMkF,EACtCtF,KAAKwL,QAAQqC,8BAA8BzN,GAC3CJ,KAAKqD,OAAO+K,GAAK5C,QAAQC,aAAarL,IAExCJ,KAAKwL,QAAQE,iBAAiBtJ,IAAI,CAACkD,EAAGlF,IAAMkF,EAC1CtF,KAAKwL,QAAQqC,8BAA8BzN,GAC3CJ,KAAKqD,OAAO+K,GAAK5C,QAAQE,iBAAiBtL,qrBC/GpD8I,EAAA,EAkOe,UAAgBtH,eAC7BA,EAAiB,EADYC,gBAE7BA,EAAkB,EAFWqD,YAG7BA,EAAc,KAHe1B,MAI7BA,EAAQ,QAER,MAAMxB,EAAYJ,EAAiBC,EACnC,OAAOf,OAAOgG,OACZhG,OAAOiG,OAAO0H,IAEZ1M,QAASF,EAAkB,EAC3BD,iBACAC,kBACAG,YACAwC,OAAQ,EACRhB,QACAkL,aACAC,cACAzJ,YAAaA,GAAee,MAAMjE,GAAWkE,KAAK,OAhPxD,MAAMuI,GAOJvN,IAAI0N,EAAOC,GACT,GAAqB,iBAAVD,GAAsBrI,KAAK8B,MAAMuG,KAAWA,EACrD,MAAM,IAAI1H,MAAM,gCAElB,GAAI2H,GAAO7O,KAAKgC,UACd,MAAM,IAAIkF,MAAM,mCAElB,GAAIlH,KAAK+B,QAAS,CAChB,GAAI8M,EAAM7O,KAAK4B,eAAgB,CAC7B,GAAIgN,GAAS5O,KAAK0O,UAAUlK,OAC1B,MAAM,IAAI0C,MAAM,+BAElB,OAAOlH,KAAK0O,UAAUE,GAAOC,GAE/B,GAAID,GAAS5O,KAAK2O,WAAWnK,OAC3B,MAAM,IAAI0C,MAAM,+BAElB,OAAOlH,KAAK2O,WAAWC,GAAOC,EAAM7O,KAAK4B,gBAE3C,GAAIgN,GAAS5O,KAAKwE,OAChB,MAAM,IAAI0C,MAAM,+BAElB,IAAKlH,KAAK0O,UAAUE,GAClB,MAAM,IAAI1H,MAAM,QAElB,OAAOlH,KAAK0O,UAAUE,GAAOC,IAS/BjG,SAASgG,GACP,GAAIA,GAAS5O,KAAKwE,OAChB,MAAM,IAAI0C,MAAM,+BAElB,OAAIlH,KAAK+B,QACA/B,KAAK0O,UAAUE,GAAO/I,OAAO7F,KAAK2O,WAAWC,IAE/C5O,KAAK0O,UAAUE,IASxB9J,KAAK6F,GAEH,GAAIA,EAAYnG,SAAWxE,KAAKgC,UAC9B,MAAM,IAAIkF,MAAM,mCAGdlH,KAAK+B,SACP/B,KAAK0O,UAAU5J,KAAK6F,EAAYmE,MAAM,EAAG9O,KAAK4B,iBAC9C5B,KAAK2O,WAAW7J,KAAK6F,EAAYmE,MAAM9O,KAAK4B,eAAgB5B,KAAKgC,aAEjEhC,KAAK0O,UAAU5J,KAAK6F,GAGtB3K,KAAKwE,QAAU,GAUjBuK,UAAUpE,GACR,IAAK3K,KAAK+B,QACR,MAAM,IAAImF,MAAM,uCAElB,GAAIyD,EAAYrG,SAAWtE,KAAK4B,eAC9B,MAAM,IAAIsF,MAAM,mCAGlBlH,KAAK0O,UAAU5J,KAAK6F,GACpB3K,KAAKgP,QAUPC,WAAWtE,GACT,IAAK3K,KAAK+B,QACR,MAAM,IAAImF,MAAM,uCAElB,GAAIyD,EAAYrG,SAAWtE,KAAK6B,gBAC9B,MAAM,IAAIqF,MAAM,mCAGlBlH,KAAK2O,WAAW7J,KAAK6F,GACrB3K,KAAKgP,QAMPxJ,QACExF,KAAKwE,OAAS,EACdxE,KAAK0O,aACL1O,KAAK2O,eAMPO,aACElP,KAAK0O,aACL1O,KAAKgP,QAMPG,cACEnP,KAAK2O,cACL3O,KAAKgP,QAQPjJ,OACE,MAAMA,EAAOE,MAAMjG,KAAKgC,WAAWkE,KAAK,GACxC,IAAK,IAAIxF,EAAI,EAAGA,EAAIV,KAAKgC,UAAWtB,GAAK,EAAG,CAC1C,IAAK,IAAI0F,EAAI,EAAGA,EAAIpG,KAAKwE,OAAQ4B,GAAK,EACpCL,EAAKrF,IAAMV,KAAKkB,IAAIkF,EAAG1F,GAEzBqF,EAAKrF,IAAMV,KAAKwE,OAElB,OAAOuB,GAQTM,oBACE,MAAMC,EAASL,MAAMjG,KAAKgC,WAAWkE,KAAK,GACpCH,EAAO/F,KAAK+F,OAClB,IAAK,IAAIrF,EAAI,EAAGA,EAAIV,KAAKgC,UAAWtB,GAAK,EAAG,CAC1C,IAAK,IAAI0F,EAAI,EAAGA,EAAIpG,KAAKwE,OAAQ4B,GAAK,EACpCE,EAAO5F,KAAOV,KAAKkB,IAAIkF,EAAG1F,GAAKqF,EAAKrF,KAAOV,KAAKkB,IAAIkF,EAAG1F,GAAKqF,EAAKrF,IAEnE4F,EAAO5F,IAAMV,KAAKwE,OAClB8B,EAAO5F,GAAK6F,KAAKC,KAAKF,EAAO5F,IAE/B,OAAO4F,GAQTG,SACE,MAAMA,EAASR,MAAMS,KACnBT,MAAMjG,KAAKgC,WACX,MAAS2E,IAAMC,IAAUC,KAAMD,OAEjC,IAAK,IAAIlG,EAAI,EAAGA,EAAIV,KAAKgC,UAAWtB,GAAK,EACvC,IAAK,IAAI0F,EAAI,EAAGA,EAAIpG,KAAKwE,OAAQ4B,GAAK,EACpCK,EAAO/F,GAAGiG,IAAMJ,KAAKI,IAAI3G,KAAKkB,IAAIkF,EAAG1F,GAAI+F,EAAO/F,GAAGiG,KACnDF,EAAO/F,GAAGmG,IAAMN,KAAKM,IAAI7G,KAAKkB,IAAIkF,EAAG1F,GAAI+F,EAAO/F,GAAGmG,KAGvD,OAAOJ,GAOTuI,OACMhP,KAAK+B,UACP/B,KAAKwE,OAAS+B,KAAKI,IAAI3G,KAAK0O,UAAUlK,OAAQxE,KAAK2O,WAAWnK,6CC1LrD,SACb/B,EACAuE,EACAG,GAEA,MAAMvF,eAAEA,EAAFC,gBAAkBA,GAAoBY,EAS5C,OARc3B,OAAAsO,EAAA,EAAAtO,CACZA,OAAAmD,EAAA,EAAAnD,EACEc,iBACAC,oBAEFmF,EACAG,GAEWlE,MAAMR,oDC3BrByG,EAAA,EAMe,SAAmBmG,EAAIC,GACpC,OAAO/I,KAAKC,KAAK6I,EACdjN,IAAI,CAACmN,EAAInP,KAAOmP,EAAKD,EAAGlP,KAAO,GAC/BkC,OAAO,CAACC,EAAG+C,IAAO/C,EAAI+C,EAAI,uCC4ZhB,SACb1D,EAAiB,EACjBC,EAAkB,EAClBgC,EAAiB,QAEjB,MAAM9B,EAAUF,EAAkB,EAC5BG,EAAYJ,EAAiBC,EAC7B2N,EAAQzN,EACZjB,OAAOgG,UAAW2I,EAAuBC,GACzCD,EACIE,EAAO7O,OAAOgG,QAEhB/E,UACAC,YACAJ,iBACAC,kBACAgC,iBACA+L,sBAAuB,GAEzB7N,GAAY8N,2BAA4B,OAEpCC,EAAOhP,OAAOgG,OAClBhG,OAAOiG,OAAOyI,GACdG,GAGF,OADAG,EAAKzF,WACEyF,eA9aT,MAAML,GAKJpF,WACErK,KAAK+F,KAAO,IAAIE,MAAMjG,KAAKgC,WAAWkE,KAAK,GACf,SAAxBlG,KAAK6D,gBACP7D,KAAK+P,WAAa,IAAI9J,MAAMjG,KAAKgC,WAAa,GAAGkE,KAAK,GACtDlG,KAAKgQ,kBAAoB,IAAI/J,MAAMjG,KAAKgC,WAAa,GAAGkE,KAAK,KAE7DlG,KAAK+P,WAAa,IAAI9J,MAAMjG,KAAKgC,WAAWkE,KAAK,GACjDlG,KAAKgQ,kBAAoB,IAAI/J,MAAMjG,KAAKgC,WAAWkE,KAAK,IAEtDlG,KAAK+B,SACP/B,KAAKiQ,mBAcTvF,WAAWC,GACT,GAAmC,IAA/B3K,KAAK4P,sBACP,MAAM,IAAI1I,MAAM,uCAElB,GAAIlH,KAAK+B,SAAW4I,EAAYnG,SAAWxE,KAAK4B,eAC9C,OAAO5B,KAAKkQ,gBAAgBvF,GAE9B,GAAIA,EAAYnG,SAAWxE,KAAKgC,UAC9B,MAAM,IAAIkF,2EAA2ElH,KAAKgC,sBAAsB2I,EAAYnG,YAG9H,IAAI2L,EAAoB,EACxB,GAA4B,SAAxBnQ,KAAK6D,eACP,IAAK,IAAIxD,EAAI,EAAGA,EAAIL,KAAKgC,UAAW3B,GAAK,EAAG,CAC1C,IAAI+P,EAAM,EACV,IAAK,IAAIlI,EAAI,EAAGA,EAAIlI,KAAKgC,UAAWkG,GAAK,EACvCkI,GAAOpQ,KAAKgQ,kBAAmB3P,EAAIL,KAAKgC,UAAakG,IAClDyC,EAAYzC,GAAKlI,KAAK+F,KAAKmC,IAEhCiI,IAAsBxF,EAAYtK,GAAKL,KAAK+F,KAAK1F,IAAM+P,OAGzD,IAAK,IAAI/P,EAAI,EAAGA,EAAIL,KAAKgC,UAAW3B,GAAK,EACvC8P,GAAqBnQ,KAAKgQ,kBAAkB3P,IACzCsK,EAAYtK,GAAKL,KAAK+F,KAAK1F,KAC3BsK,EAAYtK,GAAKL,KAAK+F,KAAK1F,IAIlC,IAAIoB,EAAI8E,KAAK8H,KAAK,GAAM8B,GACtB5J,KAAKC,KAAKxG,KAAK4P,uBAA0B,EAAIrJ,KAAK8J,KAAOrQ,KAAKgC,WAMhE,OAJIP,EAAI,QAAUoI,OAAOC,MAAMrI,IAAM8E,KAAKqD,IAAInI,KAAQmF,OACpDnF,EAAI,QAGCA,GAUT0J,WAAWvH,GACT,GAA4B,SAAxB5D,KAAK6D,eACP,IAAK,IAAInD,EAAI,EAAGA,EAAIV,KAAKgC,UAAWtB,GAAK,EACvCV,KAAK+P,WAAYrP,EAAIV,KAAKgC,UAAatB,IAAMkD,EAAelD,QAG9D,IAAK,IAAIA,EAAI,EAAGA,EAAIV,KAAKgC,UAAWtB,GAAK,EACvCV,KAAK+P,WAAWrP,IAAMkD,EAAelD,IAS3CqK,0BACE,GAA4B,SAAxB/K,KAAK6D,eAA2B,CAClC,MAAMyM,EAAYxP,OAAAyP,EAAA,EAAAzP,CAAOd,KAAKgC,UAAWhC,KAAKgC,WAE9CsO,EAAUX,KAAO3P,KAAK+P,WAAWjB,QACjC,MAAM0B,EAAMF,EAAUG,OACtBzQ,KAAK4P,sBAAwBY,EAAIE,YACjC1Q,KAAKgQ,kBAAoBQ,EAAIG,OAAOhB,SAC/B,CACL3P,KAAK4P,sBAAwB,EAC7B,IAAK,IAAIlP,EAAI,EAAGA,EAAIV,KAAKgC,UAAWtB,GAAK,EAAG,CAC1C,GAAIV,KAAK+P,WAAWrP,IAAM,EACxB,MAAM,IAAIwG,MAAM,yBAElBlH,KAAKgQ,kBAAkBtP,GAAK,EAAIV,KAAK+P,WAAWrP,GAChDV,KAAK4P,uBAAyB5P,KAAK+P,WAAWrP,IAG9CV,KAAK+B,SACP/B,KAAK4Q,kCAWTC,UAAUC,EAAYC,GACpB,GAAID,GAAc9Q,KAAKgC,WAAa+O,GAAc/Q,KAAKgC,UACrD,MAAM,IAAIkF,MAAM,2BAGlB,MAAM8J,GACJ1L,EAAG,EACH2L,EAAG,EACHC,MAAO,EACPC,OAAQ,EACRC,MAAO,GAQT,IAAI7O,EACAC,EACA/B,EARJuQ,EAAgB1L,EAAItF,KAAK+F,KAAK+K,GAC9BE,EAAgBC,EAAIjR,KAAK+F,KAAKgL,GAQF,SAAxB/Q,KAAK6D,gBACPtB,EAAIvC,KAAK+P,WAAYe,EAAa9Q,KAAKgC,UAAa8O,GACpDtO,EAAIxC,KAAK+P,WAAYe,EAAa9Q,KAAKgC,UAAa+O,GACpDtQ,EAAIT,KAAK+P,WAAYgB,EAAa/Q,KAAKgC,UAAa+O,KAEpDxO,EAAIvC,KAAK+P,WAAWe,GACpBtO,EAAI,EACJ/B,EAAIT,KAAK+P,WAAWgB,IAItB,MAAMM,EAAQ9O,EAAI9B,EACZiQ,EAAenO,EAAI9B,EAAM+B,EAAIA,EAC7B8O,EAAY,IAAOD,EAAQ9K,KAAKC,KAAM6K,GAAS,EAAM,EAAIX,IACzDa,EAAY,IAAOF,EAAQ9K,KAAKC,KAAM6K,GAAS,EAAM,EAAIX,IAQ/D,OAPAM,EAAgBE,MAAQ3K,KAAKC,KAAK,MAAQ8K,GAC1CN,EAAgBG,OAAS5K,KAAKC,KAAK,MAAQ+K,GAC3CP,EAAgBI,MAAQ7K,KAAKiL,KAAKhP,GAAK8O,EAAY7Q,IAC/CoJ,OAAOC,MAAMkH,EAAgBI,SAC/BJ,EAAgBI,MAAQ7K,KAAK8J,GAAK,GAG7BW,GAYTS,YAAYT,EAAiBF,EAAYC,GACvC,GAAID,GAAc9Q,KAAKgC,WAAa+O,GAAc/Q,KAAKgC,UACrD,MAAM,IAAIkF,MAAM,2BAGlBlH,KAAK+F,KAAK+K,GAAcE,EAAgB1L,EACxCtF,KAAK+F,KAAKgL,GAAcC,EAAgBC,EAExC,MAAMK,EAAaN,EAAgBE,MAAQF,EAAgBE,MAAS,MAC9DK,EAAaP,EAAgBG,OAASH,EAAgBG,OAAU,MAChEO,EAAWnL,KAAKoL,IAAIX,EAAgBI,OACpC5O,GAAM8O,EAAYC,GAAaG,GAAcA,GAAY,EAAK,GAC9DjR,EAAI6Q,EAAa9O,EAAIkP,EACrBnP,EAAIgP,EAAa/O,EAAIkP,EAEC,SAAxB1R,KAAK6D,gBACP7D,KAAK+P,WAAYe,EAAa9Q,KAAKgC,UAAa8O,GAAcvO,EAC9DvC,KAAK+P,WAAYe,EAAa9Q,KAAKgC,UAAa+O,GAAcvO,EAC9DxC,KAAK+P,WAAYgB,EAAa/Q,KAAKgC,UAAa8O,GAActO,EAC9DxC,KAAK+P,WAAYgB,EAAa/Q,KAAKgC,UAAa+O,GAActQ,IAE9DT,KAAK+P,WAAWe,GAAcvO,EAC9BvC,KAAK+P,WAAWgB,GAActQ,GAEhCT,KAAK+K,4BAqBH2E,GAKJO,kBAC8B,SAAxBjQ,KAAK6D,eACP7D,KAAK4R,uBAAyB,IAAI3L,MAAMjG,KAAK4B,gBAAkB,GAAGsE,KAAK,GAEvElG,KAAK4R,uBAAyB,IAAI3L,MAAMjG,KAAK4B,gBAAgBsE,KAAK,IAWtEgK,gBAAgB5E,GACd,GAAwC,IAApCtL,KAAK6P,2BACP,MAAM,IAAI3I,MAAM,yDAGlB,IAAIiJ,EAAoB,EACxB,GAA4B,SAAxBnQ,KAAK6D,eACP,IAAK,IAAIxD,EAAI,EAAGA,EAAIL,KAAK4B,eAAgBvB,GAAK,EAAG,CAC/C,IAAI+P,EAAM,EACV,IAAK,IAAIlI,EAAI,EAAGA,EAAIlI,KAAK4B,eAAgBsG,GAAK,EAC5CkI,GAAOpQ,KAAK4R,uBAAwBvR,EAAIL,KAAK4B,eAAkBsG,IAC5DoD,EAAiBpD,GAAKlI,KAAK+F,KAAKmC,IAErCiI,IAAsB7E,EAAiBjL,GAAKL,KAAK+F,KAAK1F,IAAM+P,OAG9D,IAAK,IAAI/P,EAAI,EAAGA,EAAIL,KAAK4B,eAAgBvB,GAAK,EAC5C8P,GAAqBnQ,KAAKgQ,kBAAkB3P,IACzCiL,EAAiBjL,GAAKL,KAAK+F,KAAK1F,KAChCiL,EAAiBjL,GAAKL,KAAK+F,KAAK1F,IAIvC,IAAIoB,EAAI8E,KAAK8H,KAAK,GAAM8B,GACb5J,KAAKC,KAAKxG,KAAK6P,4BACR,EAAItJ,KAAK8J,KAAOrQ,KAAK4B,gBAIvC,OAFIH,EAAI,QAAUoI,OAAOC,MAAMrI,IAAM8E,KAAKqD,IAAInI,KAAQmF,OAAUnF,EAAI,QAE7DA,GAYT4J,WAAWC,GACT,MAAMzJ,EAAkB7B,KAAKgC,UAAYhC,KAAK4B,eACxCiQ,EAAa5L,MAAMpE,GAAiBqE,KAAK,GAE/C,GAA4B,SAAxBlG,KAAK6D,eACP,IAAK,IAAInD,EAAI,EAAGA,EAAImB,EAAiBnB,GAAK,EAAG,CAC3CmR,EAAWnR,GAAKV,KAAK+F,KAAK/F,KAAK4B,eAAiBlB,GAChD,IAAK,IAAIsK,EAAI,EAAGA,EAAIhL,KAAK4B,eAAgBoJ,GAAK,EAAG,CAC/C,IAAIoF,EAAM,EACV,IAAK,IAAI0B,EAAI,EAAGA,EAAI9R,KAAK4B,eAAgBkQ,GAAK,EAC5C1B,GAAOpQ,KAAK4R,uBAAwB5G,EAAIhL,KAAK4B,eAAkBkQ,IAC5DxG,EAAiBwG,GAAK9R,KAAK+F,KAAK+L,IAErCD,EAAWnR,IAAM0P,EACfpQ,KAAK+P,YAAarP,EAAIV,KAAK4B,gBAAkB5B,KAAKgC,UAAagJ,SAIrE,IAAK,IAAItK,EAAI,EAAGA,EAAImB,EAAiBnB,GAAK,EACxCmR,EAAWnR,GAAKV,KAAK+F,KAAK/F,KAAK4B,eAAiBlB,GAGpD,OAAOmR,GAOTjB,iCACE,GAA4B,SAAxB5Q,KAAK6D,eAA2B,CAClC,MAAMkO,EAAiBjR,OAAAyP,EAAA,EAAAzP,CAAOd,KAAK4B,eAAgB5B,KAAK4B,gBACxD,IAAK,IAAIoQ,EAAK,EAAGA,EAAKhS,KAAK4B,eAAgBoQ,GAAM,EAC/C,IAAK,IAAIrG,EAAK,EAAGA,EAAK3L,KAAK4B,eAAgB+J,GAAM,EAC/CoG,EAAepC,KAAMqC,EAAKhS,KAAK4B,eAAkB+J,GAC/C3L,KAAK+P,WAAYiC,EAAKhS,KAAKgC,UAAa2J,GAG9C,MAAMsG,EAAWF,EAAetB,OAChCzQ,KAAK6P,2BAA6BoC,EAASvB,YAC3C1Q,KAAK4R,uBAAyBK,EAAStB,OAAOhB,SACzC,CACL3P,KAAK6P,2BAA6B,EAClC,IAAK,IAAInP,EAAI,EAAGA,EAAIV,KAAK4B,eAAgBlB,GAAK,EAAG,CAC/C,GAAIV,KAAK+P,WAAWrP,IAAM,EACxB,MAAM,IAAIwG,MAAM,yBAElBlH,KAAK4R,uBAAuBlR,GAAK,EAAIV,KAAK+P,WAAWrP,GACrDV,KAAK6P,4BAA8B7P,KAAK+P,WAAWrP,IAGvDV,KAAKkS,0BAOPA,yBACE,GAA4B,aAAxBlS,KAAK6D,eAEP,YADA7D,KAAK0L,iBAAmB1L,KAAK+P,WAAWjB,MAAM,EAAG9O,KAAK4B,iBAKxD,MAAMmQ,EAAiBjR,OAAAyP,EAAA,EAAAzP,CAAOd,KAAK4B,eAAgB5B,KAAK4B,gBACxD,IAAK,IAAIoQ,EAAK,EAAGA,EAAKhS,KAAK4B,eAAgBoQ,GAAM,EAC/C,IAAK,IAAIrG,EAAK,EAAGA,EAAK3L,KAAK4B,eAAgB+J,GAAM,EAC/CoG,EAAepC,KAAMqC,EAAKhS,KAAK4B,eAAkB+J,GAC/C3L,KAAK+P,WAAYiC,EAAKhS,KAAKgC,UAAa2J,GAG9C,MAAM6E,EAAMuB,EAAetB,OACrB0B,EAAerR,OAAAyP,EAAA,EAAAzP,CAAOd,KAAK4B,eAAgB5B,KAAK6B,iBACtD,IAAK,IAAImQ,EAAK,EAAGA,EAAKhS,KAAK4B,eAAgBoQ,GAAM,EAC/C,IAAK,IAAIrG,EAAK,EAAGA,EAAK3L,KAAK6B,gBAAiB8J,GAAM,EAChDwG,EAAaxC,KAAMqC,EAAKhS,KAAK6B,gBAAmB8J,GAC9C3L,KAAK+P,WAAYiC,EAAKhS,KAAKgC,UAAahC,KAAK4B,eAAiB+J,GAGpE,MAAMyG,EAAetR,OAAAyP,EAAA,EAAAzP,CAAOd,KAAK6B,gBAAiB7B,KAAK4B,gBACvD,IAAK,IAAIoQ,EAAK,EAAGA,EAAKhS,KAAK6B,gBAAiBmQ,GAAM,EAChD,IAAK,IAAIrG,EAAK,EAAGA,EAAK3L,KAAK4B,eAAgB+J,GAAM,EAC/CyG,EAAazC,KAAMqC,EAAKhS,KAAK4B,eAAkB+J,GAC7C3L,KAAK+P,YAAa/P,KAAK4B,eAAiBoQ,GAAMhS,KAAKgC,UAAa2J,GAGtE,MAAM0G,EAAY7B,EAAIG,OAAO2B,QAAQH,GAC/BI,EAAgBH,EAAaE,QAAQD,GAC3CrS,KAAK0L,iBAAmBzF,MAAMjG,KAAK6B,iBAAmB,GAAGqE,KAAK,GAC9D,IAAK,IAAI8L,EAAK,EAAGA,EAAKhS,KAAK6B,gBAAiBmQ,GAAM,EAChD,IAAK,IAAIrG,EAAK,EAAGA,EAAK3L,KAAK6B,gBAAiB8J,GAAM,EAChD3L,KAAK0L,iBAAkBsG,EAAKhS,KAAK6B,gBAAmB8J,GAClD3L,KAAK+P,YAAa/P,KAAK4B,eAAiBoQ,GAAMhS,KAAKgC,UACjDhC,KAAK4B,eAAiB+J,GACtB4G,EAAc5C,KAAMqC,EAAKhS,KAAK6B,gBAAmB8J,mCC1Y7DzC,EAAA,EAAAsJ,EACA,MAWMC,GAKJzM,MACE,OAAOhG,KAAK2P,KAAKrN,OAAO,CAACC,EAAGC,IAAMD,EAAIC,EAAG,IAO3CkQ,YACE,MAAMC,EAAMH,EAAOxS,KAAK4S,MAAO5S,KAAK6S,OACpC,IAAK,IAAIzS,EAAI,EAAGA,EAAIJ,KAAK4S,MAAOxS,GAAK,EACnC,IAAK,IAAI0S,EAAI,EAAGA,EAAI9S,KAAK6S,MAAOC,GAAK,EACnCH,EAAIhD,KAAMvP,EAAIJ,KAAK6S,MAASC,GAAK9S,KAAK2P,KAAMmD,EAAI9S,KAAK4S,MAASxS,GAGlE,OAAOuS,GAQTL,QAAQS,GACN,GAAI/S,KAAK4S,QAAUG,EAAIF,MACrB,MAAM,IAAI3L,MAAM,uCAElB,MAAMyL,EAAMH,EAAOxS,KAAK6S,MAAOE,EAAIH,OACnC,IAAK,IAAIxS,EAAI,EAAGA,EAAIJ,KAAK6S,MAAOzS,GAAK,EACnC,IAAK,IAAI0S,EAAI,EAAGA,EAAIC,EAAIH,MAAOE,GAAK,EAAG,CACrCH,EAAIhD,KAAMvP,EAAI2S,EAAIH,MAASE,GAAK,EAChC,IAAK,IAAI5K,EAAI,EAAGA,EAAIlI,KAAK4S,MAAO1K,GAAK,EACnCyK,EAAIhD,KAAMvP,EAAI2S,EAAIH,MAASE,IACzB9S,KAAK2P,KAAMvP,EAAIJ,KAAK4S,MAAS1K,GAAK6K,EAAIpD,KAAMzH,EAAI6K,EAAIH,MAASE,GAIrE,OAAOH,GAQTlC,OACE,GAAIzQ,KAAK6S,QAAU7S,KAAK4S,MACtB,OAAO5S,KAAKgT,qBAGd,MAAMC,EAASjT,KAAK0S,YACpB,GAAI1S,KAAK6S,OAAS7S,KAAK4S,MAAO,CAC5B,MAAMM,EAAOD,EAAOX,QAAQtS,OACtB0Q,YAAEA,EAAaC,OAAQwC,GAAQD,EAAKF,qBAC1C,OAAStC,cAAaC,OAAQwC,EAAIb,QAAQW,IAE5C,MAAMC,EAAOlT,KAAKsS,QAAQW,IACpBvC,YAAEA,EAAaC,OAAQwC,GAAQD,EAAKF,qBAC1C,OAAStC,cAAaC,OAAQsC,EAAOX,QAAQa,KAQ/CH,qBACE,GAAIhT,KAAK6S,QAAU7S,KAAK4S,MACtB,MAAM,IAAI1L,MAAM,2DAElB,IAAIwJ,EAAc,EAClB,MAAMqC,EAAMP,EAAOxS,KAAK6S,MAAoB,EAAb7S,KAAK4S,OAC9BQ,EAASZ,EAAOxS,KAAK6S,MAAoB,EAAb7S,KAAK4S,OACjCzR,EAAInB,KAAK6S,MAGf,IAAK,IAAIzS,EAAI,EAAGA,EAAIe,EAAGf,GAAK,EAAG,CAC7B,IAAK,IAAI0S,EAAI,EAAGA,EAAI3R,EAAG2R,GAAK,EAC1BC,EAAIpD,KAAU,EAAJvP,EAAQe,EAAK2R,GAAK9S,KAAK2P,KAAMvP,EAAIe,EAAK2R,GAElDC,EAAIpD,KAAU,EAAJvP,EAAQe,EAAKA,EAAIf,GAAK,EAGlC,IAAK,IAAI8H,EAAI,EAAGA,EAAI/G,EAAG+G,GAAK,EAAG,CAC7B,IAAI9H,EAAI8H,EACR,KAAO3B,KAAKqD,IAAImJ,EAAIpD,KAAU,EAAJvP,EAAQe,EAAK+G,IArGf,MAuGtB,IADA9H,GAAK,KACKe,EACR,MAAM,IAAI+F,MAAM,yBAGpBwJ,GAAeqC,EAAIpD,KAAU,EAAJvP,EAAQe,EAAK+G,GAGlC9H,IAAM8H,GACR6K,EAAIM,UAAUjT,EAAG8H,GAGnBkL,EAAOzD,KAAOoD,EAAIpD,KAAKb,QAEvB,IAAK,IAAIgE,EAAI,EAAGA,EAAI,EAAI3R,EAAG2R,GAAK,EAC9BM,EAAOzD,KAAU,EAAJzH,EAAQ/G,EAAK2R,IAAMC,EAAIpD,KAAU,EAAJzH,EAAQ/G,EAAK+G,GAEzD,IAAK,IAAIoL,EAAK,EAAGA,EAAKnS,EAAGmS,GAAM,EAC7B,GAAIA,IAAOpL,EACT,IAAK,IAAI4K,EAAI,EAAGA,EAAI,EAAI3R,EAAG2R,GAAK,EAC9BM,EAAOzD,KAAW,EAAL2D,EAASnS,EAAK2R,IACvBC,EAAIpD,KAAW,EAAL2D,EAASnS,EAAK+G,GACxBkL,EAAOzD,KAAU,EAAJzH,EAAQ/G,EAAK2R,GAIpCC,EAAIpD,KAAOyD,EAAOzD,KAAKb,QAGzB,MAAMqE,EAAMX,EAAOxS,KAAK6S,MAAO7S,KAAK4S,OACpC,IAAK,IAAIxS,EAAI,EAAGA,EAAIe,EAAGf,GAAK,EAC1B,IAAK,IAAI0S,EAAI,EAAGA,EAAI3R,EAAG2R,GAAK,EAC1BK,EAAIxD,KAAMvP,EAAIe,EAAK2R,GAAKC,EAAIpD,KAAU,EAAJvP,EAAQe,EAAKA,EAAI2R,GAGvD,OAASpC,cAAaC,OAAQwC,IAShCE,UAAUjT,EAAG0S,GACX,IAAK,IAAI5K,EAAI,EAAGA,EAAIlI,KAAK4S,MAAO1K,GAAK,EAAG,CACtC,MAAMkI,EAAMpQ,KAAK2P,KAAMvP,EAAIJ,KAAK4S,MAAS1K,GACzClI,KAAK2P,KAAMvP,EAAIJ,KAAK4S,MAAS1K,GAAKlI,KAAK2P,KAAMmD,EAAI9S,KAAK4S,MAAS1K,GAC/DlI,KAAK2P,KAAMmD,EAAI9S,KAAK4S,MAAS1K,GAAKkI,IAUtCmD,YAAYnT,EAAG0S,GACb,IAAK,IAAI5K,EAAI,EAAGA,EAAIlI,KAAK6S,MAAO3K,GAAK,EAAG,CACtC,MAAMkI,EAAMpQ,KAAK2P,KAAMzH,EAAIlI,KAAK4S,MAASxS,GACzCJ,KAAK2P,KAAMzH,EAAIlI,KAAK4S,MAASxS,GAAKJ,KAAK2P,KAAMzH,EAAIlI,KAAK4S,MAASE,GAC/D9S,KAAK2P,KAAMzH,EAAIlI,KAAK4S,MAASE,GAAK1C,KAiBzB,SAASoC,EAAOK,EAAQ,EAAGD,GAAQ,GAChD,MAAMY,EAAKZ,EAAQ,EAAIC,EAAQD,EAC/B,OAAO9R,OAAOgG,OACZhG,OAAOiG,OAAO0L,IAEZI,QACAD,MAAOY,EACP7D,KAAM1J,MAAM4M,EAAQW,GAAItN,KAAK,wCCoFpB,SACbrF,EACA8C,EAAY,EACZC,GAAmB6P,SAAU,KAAMC,SAAU,KAC7C7P,EAAiB,QAEjB,IAAK/C,OAAOoB,KAAKrB,GAAGsB,SAAS,UAC3B,MAAM,IAAI+E,MAAM,+FAElB,OAAOpG,OAAOgG,OACZjG,EACA8S,GAEE1R,YACKpB,EAAEoB,QACL0B,YACAC,iBACAC,4MA1RR,MAAM8P,GAKJtK,aAAa5G,GACXzC,KAAKqK,WACLrK,KAAK4T,wBAAwBnR,EAAY4D,qBACzCrG,KAAK6T,oBAAoBpR,GACzBzC,KAAK8T,gBAAgBrR,GACrBzC,KAAKmL,aACLnL,KAAK8K,4BAQP8I,wBAAwBG,GACtB,IAAIC,EAAa,EACjBhU,KAAKoL,sBAAwB2I,EAAW3R,IAAI6R,GAAO1N,KAAKM,IACtD7G,KAAKiC,OAAO2B,eAAe6P,SAC3BzT,KAAKiC,OAAO2B,eAAe8P,SAAWO,IAExC,IAAK,IAAIxT,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EACX,SAA/BT,KAAKiC,OAAO4B,eACd7D,KAAKiC,OAAOqI,WAAW7J,GAAGsP,WAAa9J,MAAMjG,KAAKiC,OAAOD,WAAa,GACnEkE,KAAKlG,KAAKiC,OAAO2B,eAAe6P,SAAW,GAE9CzT,KAAKiC,OAAOqI,WAAW7J,GAAGsP,WAAa9J,MAAMjG,KAAKiC,OAAOD,WAAWkE,KAAK,GAE3ElG,KAAKiC,OAAOqI,WAAW7J,GAAG0K,WAAWnL,KAAKoL,uBAC1CpL,KAAKiC,OAAOuI,cAAc/J,GAAK,EAAIT,KAAKiC,OAAO0B,UAC/CqQ,GAAchU,KAAKiC,OAAOuI,cAAc/J,GAE1C,IAAK,IAAIA,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKiC,OAAOuI,cAAc/J,IAAMuT,GAYpCH,oBAAoBpR,GAClB,IAAKA,GAAeA,EAAYgC,QAAS,OACzC,MAQMyP,EARSpT,OAAAqT,EAAA,EAAArT,CACbA,OAAAmD,EAAA,EAAAnD,EACEc,eAAgB5B,KAAKiC,OAAOL,eAC5BC,gBAAiB7B,KAAKiC,OAAOJ,kBAE/B7B,KAAKiC,OAAO0B,WACVyD,eAAgB,SAEQnE,MAAMR,GAClC,IAAK,IAAIhC,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKiC,OAAOqI,WAAW7J,GAAGsF,KAAOmO,EAAazM,QAAQhH,IAU1DqT,gBAAgBrR,GAGd,IAAKA,GAAeA,EAAYgC,QAAS,OAEzC,IAAK,IAAItD,EAAI,EAAGA,EAAInB,KAAKiC,OAAO0B,UAAWxC,GAAK,EAC9CnB,KAAKiC,OAAOqI,WAAWnJ,GAAG4O,WAAa9J,MAAsC,SAA/BjG,KAAKiC,OAAO4B,eAA6B7D,KAAKiC,OAAOD,WAAa,EAAIhC,KAAKiC,OAAOD,WAAWkE,KAAK,GAGlJ,MAAMkO,EAASnO,MAAMjG,KAAKiC,OAAO0B,UAAY3D,KAAKiC,OAAOD,WAAWkE,KAAK,GACnEmO,EAASpO,MAAMjG,KAAKiC,OAAO0B,WAAWuC,KAAK,GACjDzD,EAAYc,QAASwB,IACnB,MAAMqD,EAAO7B,KAAK8B,MAAMtD,EAAOP,OAASxE,KAAKiC,OAAO0B,WACpD,IAAI2E,EAAS,EACb,IAAK,IAAInH,EAAI,EAAGA,EAAInB,KAAKiC,OAAO0B,UAAWxC,GAAK,EAAG,CACjD,IAAK,IAAIiF,EAAI,EAAGA,EAAIgC,EAAMhC,GAAK,EAC7B,IAAK,IAAI4L,EAAK,EAAGA,EAAKhS,KAAKiC,OAAOD,UAAWgQ,GAAM,EAEjD,GADAoC,EAAQjT,EAAInB,KAAKiC,OAAOD,UAAagQ,IAAOjN,EAAO7D,IAAIoH,EAASlC,EAAG4L,GAChC,SAA/BhS,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAK,EAAGA,EAAK3L,KAAKiC,OAAOD,UAAW2J,GAAM,EACjD3L,KAAKiC,OAAOqI,WAAWnJ,GACpB4O,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,IAC3C5G,EAAO7D,IAAIoH,EAASlC,EAAG4L,GAAMjN,EAAO7D,IAAIoH,EAASlC,EAAGuF,QAGxD3L,KAAKiC,OAAOqI,WAAWnJ,GAAG4O,WAAWiC,IACnCjN,EAAO7D,IAAIoH,EAASlC,EAAG4L,IAAO,EAItC1J,GAAUF,EACViM,EAAOlT,IAAMiH,KAIjB,IAAK,IAAIjH,EAAI,EAAGA,EAAInB,KAAKiC,OAAO0B,UAAWxC,GAAK,EAC9C,IAAK,IAAI6Q,EAAK,EAAGA,EAAKhS,KAAKiC,OAAOD,UAAWgQ,GAAM,EAEjD,GADAoC,EAAQjT,EAAInB,KAAKiC,OAAOD,UAAagQ,IAAOqC,EAAOlT,GAChB,SAA/BnB,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAK,EAAGA,EAAK3L,KAAKiC,OAAOD,UAAW2J,GAAM,EACjD3L,KAAKiC,OAAOqI,WAAWnJ,GAAG4O,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,IAAO0I,EAAOlT,QAGpFnB,KAAKiC,OAAOqI,WAAWnJ,GAAG4O,WAAWiC,IAAOqC,EAAOlT,GAKzD,IAAK,IAAIA,EAAI,EAAGA,EAAInB,KAAKiC,OAAO0B,UAAWxC,GAAK,EAC9C,IAAK,IAAI6Q,EAAK,EAAGA,EAAKhS,KAAKiC,OAAOD,UAAWgQ,GAAM,EACjD,GAAmC,SAA/BhS,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAK,EAAGA,EAAK3L,KAAKiC,OAAOD,UAAW2J,GAAM,EACjD3L,KAAKiC,OAAOqI,WAAWnJ,GAAG4O,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,IAClEyI,EAAQjT,EAAInB,KAAKiC,OAAOD,UAAagQ,GACrCoC,EAAQjT,EAAInB,KAAKiC,OAAOD,UAAa2J,QAGzC3L,KAAKiC,OAAOqI,WAAWnJ,GAAG4O,WAAWiC,IACnCoC,EAAQjT,EAAInB,KAAKiC,OAAOD,UAAagQ,IAAO,GAUtDtI,eAAejH,GACb,IAAIwH,EAAU,EACV9D,EAAc,EAClB1D,EAAYc,QAASwB,IACnBoB,GAAepB,EAAOP,SAExB,MAAM8P,EAAgBxT,OAAOoB,KAAKO,EAAY8B,SAExC9C,EAAIwE,MAAMS,KACdT,MAAMjG,KAAKiC,OAAO0B,WAClB,IAAM,IAAIsC,MAAME,GAAaD,KAAK,IAE9BqO,EAAItO,MAAMjG,KAAKiC,OAAO0B,WAAWuC,KAAK,GAC5C,IAAIsO,EAAQ,EAEZ/R,EAAYc,QAASwB,IACnB,IAAK,IAAIqB,EAAI,EAAGA,EAAIrB,EAAOP,OAAQ4B,GAAK,EAAG,CACzC,IAAI8E,EAAY,EAChB,IAAK,IAAIzK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CgB,EAAEhB,GAAG+T,EAAQpO,GAAKpG,KAAK4K,oBAAoB7F,EAAO6D,SAASxC,GAAI3F,IAEvC,IAApBgB,EAAEhB,GAAG+T,EAAQpO,IACfyD,OAAOC,MAAMrI,EAAEhB,GAAG+T,EAAQpO,KAC1B3E,EAAEhB,GAAG+T,EAAQpO,KAAQQ,OACrBnF,EAAEhB,GAAG+T,EAAQpO,GAAK,QAEpB8E,GAAazJ,EAAEhB,GAAG+T,EAAQpO,GAE5B,IAAK,IAAI3F,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CgB,EAAEhB,GAAG+T,EAAQpO,IAAM8E,EACnBqJ,EAAE9T,IAAMgB,EAAEhB,GAAG+T,EAAQpO,GAEvB6D,GAAW1D,KAAKkG,IAAIvB,GAEtBsJ,GAASzP,EAAOP,SAIlB,IAAK,IAAI/D,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKiC,OAAOuI,cAAc/J,GAAK8T,EAAE9T,GAAK0F,EAIxC,IAAK,IAAI1F,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9C,IAAK,IAAIC,EAAI,EAAGA,EAAIV,KAAKiC,OAAOD,UAAWtB,GAAK,EAAG,CACjDV,KAAKiC,OAAOqI,WAAW7J,GAAGsF,KAAKrF,GAAK,EACpC8T,EAAQ,EACR,IAAK,IAAIC,EAAM,EAAGA,EAAMH,EAAc9P,OAAQiQ,GAAO,EAAG,CACtD,MAAM1P,EAAStC,EAAY8B,QAAQ+P,EAAcG,IACjD,IAAK,IAAIrO,EAAI,EAAGA,EAAIrB,EAAOP,OAAQ4B,GAAK,EACtCpG,KAAKiC,OAAOqI,WAAW7J,GAAGsF,KAAKrF,IAC7Be,EAAEhB,GAAG+T,EAAQpO,GAAKrB,EAAO7D,IAAIkF,EAAG1F,GAEpC8T,GAASzP,EAAOP,OAElBxE,KAAKiC,OAAOqI,WAAW7J,GAAGsF,KAAKrF,IAAM6T,EAAE9T,GAK3C,GAAmC,SAA/BT,KAAKiC,OAAO4B,eACd,IAAK,IAAIpD,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9C,IAAK,IAAIuR,EAAK,EAAGA,EAAKhS,KAAKiC,OAAOD,UAAWgQ,GAAM,EACjD,IAAK,IAAIrG,EAAKqG,EAAIrG,EAAK3L,KAAKiC,OAAOD,UAAW2J,GAAM,EAAG,CACrD3L,KAAKiC,OAAOqI,WAAW7J,GAAGsP,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,GAAM,EAC1E6I,EAAQ,EACR,IAAK,IAAIC,EAAM,EAAGA,EAAMH,EAAc9P,OAAQiQ,GAAO,EAAG,CACtD,MAAM1P,EAAStC,EAAY8B,QAAQ+P,EAAcG,IACjD,IAAK,IAAIrO,EAAI,EAAGA,EAAIrB,EAAOP,OAAQ4B,GAAK,EACtCpG,KAAKiC,OAAOqI,WAAW7J,GAAGsP,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,IAClElK,EAAEhB,GAAG+T,EAAQpO,IACZrB,EAAO7D,IAAIkF,EAAG4L,GAAMhS,KAAKiC,OAAOqI,WAAW7J,GAAGsF,KAAKiM,KACnDjN,EAAO7D,IAAIkF,EAAGuF,GAAM3L,KAAKiC,OAAOqI,WAAW7J,GAAGsF,KAAK4F,IAExD6I,GAASzP,EAAOP,OAElBxE,KAAKiC,OAAOqI,WAAW7J,GAAGsP,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,IAAO4I,EAAE9T,GACzEuR,IAAOrG,IACT3L,KAAKiC,OAAOqI,WAAW7J,GAAGsP,WAAYpE,EAAK3L,KAAKiC,OAAOD,UAAagQ,GAClEhS,KAAKiC,OAAOqI,WAAW7J,GAAGsP,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,SAM9E,IAAK,IAAIlL,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9C,IAAK,IAAIuR,EAAK,EAAGA,EAAKhS,KAAKiC,OAAOD,UAAWgQ,GAAM,EAAG,CACpDhS,KAAKiC,OAAOqI,WAAW7J,GAAGsP,WAAWiC,GAAM,EAC3CwC,EAAQ,EACR,IAAK,IAAIC,EAAM,EAAGA,EAAMH,EAAc9P,OAAQiQ,GAAO,EAAG,CACtD,MAAM1P,EAAStC,EAAY8B,QAAQ+P,EAAcG,IACjD,IAAK,IAAIrO,EAAI,EAAGA,EAAIrB,EAAOP,OAAQ4B,GAAK,EAAG,CACzC,MAAM6G,EAASlI,EAAO7D,IAAIkF,EAAG4L,GAAMhS,KAAKiC,OAAOqI,WAAW7J,GAAGsF,KAAKiM,GAClEhS,KAAKiC,OAAOqI,WAAW7J,GAAGsP,WAAWiC,IAC/BvQ,EAAEhB,GAAG+T,EAAQpO,GAAK6G,EAAQA,EAElCuH,GAASzP,EAAOP,OAElBxE,KAAKiC,OAAOqI,WAAW7J,GAAGsP,WAAWiC,IAAOuC,EAAE9T,GAQpD,OAHAT,KAAKmL,aACLnL,KAAK8K,2BAEEb,GAMTF,qDCnQFb,EAAA,EAsFe,SAAwBwL,GACrC,MAAMC,EAAS7T,OAAOiG,OAAO6N,GAG7B,OAFAD,EAAOD,SAAWA,EAClBC,EAAOnP,QACAmP,GAjFT,MAAMC,GAIJpP,QACExF,KAAKwE,OAAS,EACdxE,KAAK4O,MAAQ,EACb5O,KAAK6U,MAAO,EACZ7U,KAAK2U,WAOP7P,KAAKmI,GACCjN,KAAK6U,MACP7U,KAAK2U,OAAO3U,KAAK4O,OAAS3B,EAC1BjN,KAAK4O,OAAS5O,KAAK4O,MAAQ,GAAK5O,KAAK0U,WAErC1U,KAAK2U,OAAO7P,KAAKmI,GACjBjN,KAAKwE,QAAU,EACfxE,KAAK6U,KAAQ7U,KAAKwE,SAAWxE,KAAK0U,WAStCxT,IAAI4T,GACF,OAAO9U,KAAK2U,QAAQG,EAAM9U,KAAK4O,OAAS5O,KAAK0U,WAO/CxO,KAAK+G,GACHjN,KAAKwE,OAASxE,KAAK0U,SACnB1U,KAAK4O,MAAQ,EACb5O,KAAK6U,MAAO,EACZ7U,KAAK2U,OAAS1O,MAAMjG,KAAK0U,UAAUxO,KAAK+G,IAQ1C1J,QAAQsB,GACN,IAAK,IAAIzE,EAAI,EAAGA,EAAIJ,KAAKwE,OAAQpE,GAAK,EACpCyE,EAAS7E,KAAK2U,QAAQvU,EAAIJ,KAAK4O,OAAS5O,KAAK0U,UAAWtU,IAQ5DwM,SACE,OAAO5M,KAAK2U,OAAO7F,MAAM9O,KAAK4O,OAC3B/I,OAAO7F,KAAK2U,OAAO7F,MAAM,EAAG9O,KAAK4O,4CClCzB,SAA2B/N,GACxC,IAAKC,OAAAiU,EAAA,EAAAjU,CAAYD,GACf,MAAM,IAAIqG,MAAM,+FAGlB,OADApG,OAAAkU,EAAA,EAAAlU,CAAmB,MAAOmU,EAAiBpU,EAAEoB,OAAO0B,WAAY9C,EAAEoB,QAC3DnB,OAAOgG,OACZjG,GACE4J,KAAM,IAAIxE,MAAMpF,EAAEoB,OAAO0B,WAAWuC,KAAK,wBA1C/C,MAAM+O,EAAmBtR,KACvBA,WACEoJ,UAAU,EACVK,OAASzG,IAAK,IAEhB/C,gBACEmJ,UAAU,EACVK,MAAO,EAAGqG,WAAUC,cACjBD,GAAYC,GAAYD,EAAW,GAAKC,EAAW,GAExD7P,gBACEkJ,UAAU,EACVK,OAAQ,OAAQ,aAElB5C,eACEuC,UAAU,EACVK,MAAO5M,GAAKA,EAAEgE,SAAWb,GAE3B2G,YACEyC,UAAU,EACVK,MAAO3M,GAAKA,EAAE+D,SAAWb,6CCyDtB,SACLlB,EACAC,EACAC,GAEA,MAAMf,eAAEA,EAAFC,gBAAkBA,GAAoBY,EAK5C,OAJc3B,OAAA8B,EAAA,EAAA9B,CACZA,OAAA+B,EAAA,EAAA/B,CAAAgC,GAAsBlB,iBAAgBC,mBAAoBa,IAC1DK,GAAMmS,EAASnS,EAAIL,EAAeC,IAEvBM,MAAMR,cA4Bd,SACLR,EACAiB,GAEA,MAAMC,EAAQrC,OAAAsC,EAAA,EAAAtC,CAAyBA,OAAA+B,EAAA,EAAA/B,CAAoBmB,IAM3D,OALAkB,EAAME,UACNvC,OAAOoB,KAAKD,EAAOqB,SAASC,QAASC,IACnCL,EAAME,OAAOG,GAAS2R,EAAalT,EAAOqB,QAAQE,GAAQN,KAE5DC,EAAMO,QACCP,OAUF,SACLlB,EACAiB,GAEA,IAAIC,EAAQrC,OAAA+B,EAAA,EAAA/B,CAAoBmB,GAOhC,OANAkB,EAAME,UACNvC,OAAOoB,KAAKD,EAAOqB,SAASC,QAASC,IACnCL,EAAME,OAAOG,GAAS2R,EAAalT,EAAOqB,QAAQE,GAAQN,MAE5DC,EAAQrC,OAAAsU,EAAA,EAAAtU,CAA8BA,OAAAsC,EAAA,EAAAtC,CAAyBqC,KACzDO,QACCP,sPA/GF,SAAS+R,EACdzS,EACAC,EACAC,GAEA,MAAMf,eAAEA,EAAFC,gBAAkBA,GAAoBY,GACtC4S,OACJA,EADI1R,UAEJA,EAFIC,eAGJA,EAHI0R,eAIJA,EAJIzR,eAKJA,GACEnB,EAgBJ,OAfc5B,OAAAyU,EAAA,EAAAzU,CACZA,OAAAiD,EAAA,EAAAjD,CACEA,OAAA0U,EAAA,EAAA1U,CAAYA,OAAAmD,EAAA,EAAAnD,CAAAoD,GACVtC,iBACAC,mBACGa,KAELC,GAEF0S,EACA1R,EACAC,EACA0R,EACAzR,GAEWZ,MAAMR,GAiCd,SAAS0S,EACdlT,EACAiB,GAEA,MAAMC,EAAQrC,OAAA2U,EAAA,EAAA3U,CAAkBA,OAAAsD,EAAA,EAAAtD,CAC9BA,OAAA0U,EAAA,EAAA1U,CAAYA,OAAAmD,EAAA,EAAAnD,CAAUmB,IACtBiB,IAGF,OADAC,EAAMO,QACCP,qCCCM,SAAqBtC,GAClC,IAAKC,OAAAmD,EAAA,EAAAnD,CAAYD,GACf,MAAM,IAAIqG,MAAM,+FAElB,OAAOpG,OAAOgG,OAAOjG,EAAG6U,eAtG1B,MAAMA,GAMJC,oBAAoB,EAQpBC,gBAAgB,EAOhBC,2BAA2BlL,GACzB,IAAIO,EAAY,EAChB,GAAmC,YAA/BlL,KAAKiC,OAAOqT,eACd,IAAK,IAAIlV,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3CJ,KAAK8V,MAAM1V,GAAKJ,KAAKiC,OAAO8T,MAAM3V,GAChCJ,KAAKiC,OAAO+T,QAAQ5V,GAAGsK,WAAWC,GACpCO,GAAalL,KAAK8V,MAAM1V,QAG1BJ,KAAK8V,MAAQ,IAAI7P,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,GAChDlG,KAAK8V,MAAM,GAAK9V,KAAKiC,OAAO+T,QAAQ,GAAGtL,WAAWC,GAClDO,GAAalL,KAAK8V,MAAM,GAG1B,GADA9V,KAAK2V,oBAAqB,EACtBzK,EAAY,EAAG,CACjB,IAAK,IAAI9K,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3CJ,KAAK8V,MAAM1V,IAAM8K,EAEnB,OAAO,EAAIA,EAEb,IAAK,IAAI4H,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAC3C9S,KAAK8V,MAAMhD,GAAK,EAAI9S,KAAKiC,OAAOoT,OAElC,OAAO,GAQTY,uBAAuBtL,GACrB,IAAIO,EAAY,EAChBlL,KAAKkW,cAAgBlW,KAAK8V,MAAMhH,QAChC,IAAK,IAAIgE,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAAG,CAE9C,GADA9S,KAAK8V,MAAMhD,GAAK,EACmB,YAA/B9S,KAAKiC,OAAOqT,eACd,IAAK,IAAIlV,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3CJ,KAAK8V,MAAMhD,IAAM9S,KAAKkW,cAAc9V,GAClCJ,KAAKiC,OAAOkU,WAAW/V,GAAG0S,QAG9B9S,KAAK8V,MAAMhD,IAAM9S,KAAKkW,cAAcpD,GAAK9S,KAAKiC,OAAOkU,WAAe,EAAJrD,GAC5DA,EAAI,EACN9S,KAAK8V,MAAMhD,IAAM9S,KAAKkW,cAAcpD,EAAI,GACtC9S,KAAKiC,OAAOkU,WAAsB,GAATrD,EAAI,GAAU,GAEzC9S,KAAK8V,MAAM,IAAM9V,KAAKkW,cAAclW,KAAKiC,OAAOoT,OAAS,GACvDrV,KAAKiC,OAAOkU,WAAiC,EAArBnW,KAAKiC,OAAOoT,OAAc,GAGxDrV,KAAK8V,MAAMhD,IAAM9S,KAAKiC,OAAO+T,QAAQlD,GAAGpI,WAAWC,GACnDO,GAAalL,KAAK8V,MAAMhD,GAE1B,GAAI5H,EAAY,OAAQ,CACtB,IAAK,IAAI4H,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAC3C9S,KAAK8V,MAAMhD,IAAM5H,EAEnB,OAAO,EAAIA,EAEb,OAAO,sCC60BI,SACbrK,EACAwU,EAAS,EACT1R,EAAY,EACZC,GAAmB6P,SAAU,KAAMC,SAAU,KAC7C4B,EAAiB,YACjBzR,EAAiB,QAEjB,IAAK/C,OAAOoB,KAAKrB,GAAGsB,SAAS,UAC3B,MAAM,IAAI+E,MAAM,+FAElB,OAAOpG,OAAOgG,OACZjG,EACAuV,GAEEnU,YACKpB,EAAEoB,QACLoT,SACA1R,YACAC,iBACA0R,iBACAzR,0NAz7BR,MAAMwS,EAA4B,KAO5BD,GAKJ/M,aAAa5G,GACNA,IAAeA,EAAYgC,UAEhCzE,KAAKqK,SAAS5H,GACdzC,KAAK4T,wBAAwBnR,EAAY4D,qBACrCrG,KAAKiC,OAAO0B,UAAY,EAC1B3D,KAAKsW,8BAA8B7T,IAEnCzC,KAAKuW,wBAAwB9T,GAC7BzC,KAAKwW,6BAA6B/T,MAStC4H,SAAS5H,GACP,MAAMb,eACJA,EADIC,gBAEJA,EAFI8B,UAGJA,EAHIC,eAIJA,EAJIC,eAKJA,GACE7D,KAAKiC,OACTjC,KAAKiC,OAAO+T,QAAU/P,MAAMS,KAC1B,IAAIT,MAAMjG,KAAKiC,OAAOoT,QACtB,IAAMvU,OAAA2V,EAAA,EAAA3V,CAAYA,OAAAiU,EAAA,EAAAjU,EAChBc,iBACAC,kBACA8B,YACAC,iBACAC,qBAGJ7D,KAAKiC,OAAO+T,QAAQzS,QAAQ7B,GAAKA,EAAE2I,YACnCrK,KAAK8V,MAAQ,IAAI7P,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,GAChDlG,KAAKkW,cAAgB,IAAIjQ,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,GACxDlG,KAAKyK,KAAO,IAAIxE,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,GAC/ClG,KAAK0W,aAAe,IAAIzQ,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,GAIvD,MAAMyQ,EAAYlU,EAAY6B,OAC9BtE,KAAK4W,cAAgB,IAAI3Q,MAAM0Q,GAAWzQ,KAAK,MAC/ClG,KAAK6W,gBAAkB,IAAI5Q,MAAM0Q,GAAWzQ,KAAK,MACjDlG,KAAK8W,wBAA0B,IAAI7Q,MAAM0Q,GAAWzQ,KAAK,MACzD,IAAI6Q,EAAO,EACP3W,EAAI,EACRqC,EAAYc,QAASwB,IACnB,MAAMiS,EAAIjS,EAAOP,OACjBxE,KAAK4W,cAAcxW,GAAK6F,MAAMS,KAC5B,IAAIT,MAAM+Q,GACV,IAAM,IAAI/Q,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,IAER,YAA/BlG,KAAKiC,OAAOqT,eACdtV,KAAK6W,gBAAgBzW,GAAK6F,MAAMS,KAC9B,IAAIT,MAAM+Q,GACV,IAAM/Q,MAAMS,KACV,IAAIT,MAAMjG,KAAKiC,OAAOoT,QACtB,IAAM,IAAIpP,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,KAI7ClG,KAAK6W,gBAAgBzW,GAAK6F,MAAMS,KAC9B,IAAIT,MAAM+Q,GACV,IAAM,IAAI/Q,MAA2B,EAArBjG,KAAKiC,OAAOoT,QAAYnP,KAAK,IAGjDlG,KAAK8W,wBAAwB1W,GAC3B,IAAI6F,MAAMjG,KAAKiC,OAAO0B,WAAWuC,KAAK,GACxC,IAAK,IAAIzF,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAK8W,wBAAwB1W,GAAGK,GAC9BwF,MAAMS,KACJ,IAAIT,MAAM+Q,GACV,IAAM,IAAI/Q,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,IAG3C8Q,EAAID,IACNA,EAAOC,GAET5W,GAAK,IAGPJ,KAAKiX,SAAW,IAAIhR,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,GACnDlG,KAAKkX,mBAAqB,IAAIjR,MAAMjG,KAAKiC,OAAOoT,OAASrV,KAAKiC,OAAO0B,WAAWuC,KAAK,IAOvFwD,eAAejH,GACb,IAAIwH,EAAU,EAIVtF,EAAc,EAClBlC,EAAYc,QAASwB,IACfA,EAAOP,OAAS,IAClByF,GAAWjK,KAAKmX,yBAAyBpS,EAAQJ,IAEnDA,GAAe,IAEjB3E,KAAKoX,kBAAkB3U,GAMvB,IAAK,IAAIrC,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3C,IAAK,IAAIK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOuI,cAAc/J,GAAK,EACd,SAA/BT,KAAKiC,OAAO4B,eACd7D,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GAAGsP,WAC1C,IAAI9J,MAAMjG,KAAKiC,OAAOD,WAAa,GAAGkE,KAAK,GAE7ClG,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GAAGsP,WAC1C,IAAI9J,MAAMjG,KAAKiC,OAAOD,WAAWkE,KAAK,GAY9C,OAPAlG,KAAKqX,qCAAqC5U,GAC1CzC,KAAKsX,uBAAuB7U,GAC5BzC,KAAKuX,6BAA6B9U,GACC,YAA/BzC,KAAKiC,OAAOqT,gBACdtV,KAAKwX,uBAAuB/U,GAE9BzC,KAAKyX,6BAA6BhV,GAC3BwH,GAOTF,oBACE/J,KAAK0X,uBACL1X,KAAK4W,cAAgB,KACrB5W,KAAK6W,gBAAkB,KACvB7W,KAAK8W,wBAA0B,KAC/B9W,KAAK2X,SAAW,KAChB3X,KAAK4X,QAAU,KACf5X,KAAKiX,SAAW,KAChBjX,KAAKkX,mBAAqB,KAC1BlX,KAAKiC,OAAO+T,QAAUhW,KAAKiC,OAAO+T,QAAQ5T,IAAIV,GAAKA,EAAEO,SAQvD2R,wBAAwBG,GACa,YAA/B/T,KAAKiC,OAAOqT,eACdtV,KAAK6X,aAEL7X,KAAK8X,eAEP,MAAM1M,EAAwB2I,EAAW3R,IAAI6R,GAAO1N,KAAKM,IACvD7G,KAAKiC,OAAO2B,eAAe6P,SAC3BzT,KAAKiC,OAAO2B,eAAe8P,SAAWO,IAElC8D,EAAiD,SAA/B/X,KAAKiC,OAAO4B,eAClC,IAAM,IAAIoC,MAAMjG,KAAKiC,OAAOD,WAAa,GACtCkE,KAAKlG,KAAKiC,OAAO2B,eAAe6P,SAAW,GAC9C,IAAM,IAAIxN,MAAMjG,KAAKiC,OAAOD,WACzBkE,KAAK,GACV,IAAK,IAAI9F,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAAG,CAE9C,MAAMsB,EAAI1B,KAAKiC,OAAO+T,QAAQ5V,GAC9BsB,EAAE0J,sBAAwBA,EAC1B,IAAK,IAAI3K,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CiB,EAAEO,OAAOqI,WAAW7J,GAAGsP,WAAagI,IACpCrW,EAAEO,OAAOqI,WAAW7J,GAAG0K,WAAWC,GAClC1J,EAAEO,OAAOuI,cAAc/J,GAAK,EAAIT,KAAKiC,OAAO0B,YAWlD4S,wBAAwB9T,GACtB,IAAKA,GAAeA,EAAYgC,QAAS,OAEzC,IAAK,IAAItD,EAAI,EAAGA,EAAInB,KAAKiC,OAAOoT,OAAQlU,GAAK,EAC3C,IAAK,IAAIT,EAAI,EAAGA,EAAIV,KAAKiC,OAAOD,UAAWtB,GAAK,EAC9CV,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW,GAAGvE,KAAKrF,GAAK,EAI1D,MAAM2T,EAAS,IAAIpO,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,GAClDzD,EAAYc,QAASwB,IACnB,MAAMqD,EAAO7B,KAAK8B,MAAMtD,EAAOP,OAASxE,KAAKiC,OAAOoT,QACpD,IAAI/M,EAAS,EACb,IAAK,IAAInH,EAAI,EAAGA,EAAInB,KAAKiC,OAAOoT,OAAQlU,GAAK,EAAG,CAC9C,IAAK,IAAIiF,EAAI,EAAGA,EAAIgC,EAAMhC,GAAK,EAC7B,IAAK,IAAI1F,EAAI,EAAGA,EAAIV,KAAKiC,OAAOD,UAAWtB,GAAK,EAC9CV,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW,GAAGvE,KAAKrF,IAC/CqE,EAAO7D,IAAIoH,EAASlC,EAAG1F,GAG7B4H,GAAUF,EACViM,EAAOlT,IAAMiH,KAGjB,IAAK,IAAIjH,EAAI,EAAGA,EAAInB,KAAKiC,OAAOoT,OAAQlU,GAAK,EAC3C,IAAK,IAAIT,EAAI,EAAGA,EAAIV,KAAKiC,OAAOD,UAAWtB,GAAK,EAC9CV,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW,GAAGvE,KAAKrF,IAAM2T,EAAOlT,IAWpEqV,6BAA6B/T,GAC3B,IAAKA,GAAeA,EAAYgC,QAAS,OAEzC,IAAK,IAAItD,EAAI,EAAGA,EAAInB,KAAKiC,OAAOoT,OAAQlU,GAAK,EAC3CnB,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW,GAAGyF,WAC1C,IAAI9J,MAAMjG,KAAKiC,OAAOD,YAA6C,SAA/BhC,KAAKiC,OAAO4B,eAA4B,EAAI,IAAIqC,KAAK,GAG7F,MAAMmO,EAAS,IAAIpO,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,GAC5C8R,EAAa,IAAI/R,MAAMjG,KAAKiC,OAAOoT,OAASrV,KAAKiC,OAAOD,WAC3DkE,KAAK,GACRzD,EAAYc,QAASwB,IACnB,MAAMqD,EAAO7B,KAAK8B,MAAMtD,EAAOP,OAASxE,KAAKiC,OAAOoT,QACpD,IAAI/M,EAAS,EACb,IAAK,IAAInH,EAAI,EAAGA,EAAInB,KAAKiC,OAAOoT,OAAQlU,GAAK,EAAG,CAC9C,IAAK,IAAIiF,EAAI,EAAGA,EAAIgC,EAAMhC,GAAK,EAC7B,IAAK,IAAI4L,EAAK,EAAGA,EAAKhS,KAAKiC,OAAOD,UAAWgQ,GAAM,EAGjD,GAFAgG,EAAa7W,EAAInB,KAAKiC,OAAOD,UAAcgQ,IACvCjN,EAAO7D,IAAIoH,EAASlC,EAAG4L,GACQ,SAA/BhS,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAK,EAAGA,EAAK3L,KAAKiC,OAAOD,UAAW2J,GAAM,EACjD3L,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW,GACtCyF,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,IACzC5G,EAAO7D,IAAIoH,EAASlC,EAAG4L,GACvBjN,EAAO7D,IAAIoH,EAASlC,EAAGuF,QAG7B3L,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW,GAAGyF,WAAWiC,IACrDjN,EAAO7D,IAAIoH,EAASlC,EAAG4L,IAAO,EAItC1J,GAAUF,EACViM,EAAOlT,IAAMiH,KAIjB,IAAK,IAAIjH,EAAI,EAAGA,EAAInB,KAAKiC,OAAOoT,OAAQlU,GAAK,EAC3C,IAAK,IAAI6Q,EAAK,EAAGA,EAAKhS,KAAKiC,OAAOD,UAAWgQ,GAAM,EAEjD,GADAgG,EAAY7W,EAAInB,KAAKiC,OAAOD,UAAagQ,IAAOqC,EAAOlT,GACpB,SAA/BnB,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAK,EAAGA,EAAK3L,KAAKiC,OAAOD,UAAW2J,GAAM,EACjD3L,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW,GACtCyF,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,IACzC0I,EAAOlT,QAGbnB,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW,GAAGyF,WAAWiC,IAAOqC,EAAOlT,GAK3E,IAAK,IAAIA,EAAI,EAAGA,EAAInB,KAAKiC,OAAOoT,OAAQlU,GAAK,EAAG,CAC9C,IAAK,IAAI6Q,EAAK,EAAGA,EAAKhS,KAAKiC,OAAOD,UAAWgQ,GAAM,EACjD,GAAmC,SAA/BhS,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAK,EAAGA,EAAK3L,KAAKiC,OAAOD,UAAW2J,GAAM,EACjD3L,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW,GACtCyF,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,IACzCqM,EAAY7W,EAAInB,KAAKiC,OAAOD,UAAagQ,GACzCgG,EAAY7W,EAAInB,KAAKiC,OAAOD,UAAa2J,QAG/C3L,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW,GAAGyF,WAAWiC,IACrDgG,EAAY7W,EAAInB,KAAKiC,OAAOD,UAAagQ,GACzCgG,EAAY7W,EAAInB,KAAKiC,OAAOD,UAAagQ,GAG/ChS,KAAKiC,OAAO+T,QAAQ7U,GAAGgK,aACvBnL,KAAKiC,OAAO+T,QAAQ7U,GAAG2J,6BAU3BwL,8BAA8B7T,GAC5B,IAAK,IAAItB,EAAI,EAAGA,EAAInB,KAAKiC,OAAOoT,OAAQlU,GAAK,EAAG,CAC9C,MAAM4B,EAAKjC,OAAAmX,EAAA,EAAAnX,CAAYd,KAAKiC,QAW5B,GATAQ,EAAYc,QAAQ,CAACwB,EAAQJ,KAC3B,MAAMyD,EAAO7B,KAAK8B,MAAMtD,EAAOP,OAASxE,KAAKiC,OAAOoT,QACpD,GAAIjN,EAAO,EAAG,CACZrF,EAAG+B,KAAKH,EAAaI,EAAOvB,OAC5B,IAAK,IAAI4C,EAAIjF,EAAIiH,EAAMhC,GAAKjF,EAAI,GAAKiH,EAAMhC,GAAK,EAC9CrD,EAAG2B,UAAUC,GAAaG,KAAKC,EAAO6D,SAASxC,QAIhDrD,EAAG0B,QAAS,CACf,MAAMyT,EAAYpX,OAAAqX,EAAA,EAAArX,CAASiC,EAAI/C,KAAKiC,QACpC,IAAK,IAAIxB,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW7J,GAAGsF,KAC1CmS,EAAU5N,WAAW7J,GAAGsF,KAC1B/F,KAAKiC,OAAO+T,QAAQ7U,GAAGc,OAAOqI,WAAW7J,GAAGsP,WAC1CmI,EAAU5N,WAAW7J,GAAGsP,WAC1B/P,KAAKiC,OAAO+T,QAAQ7U,GAAG2J,8BAU/B+M,aACE,MAAMpW,EAAI,EAAIzB,KAAKiC,OAAOoT,OAC1BrV,KAAKiC,OAAO8T,MAAQ,IAAI9P,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAKzE,GACvDzB,KAAKiC,OAAOkU,WAAalQ,MAAMS,KAC7B,IAAIT,MAAMjG,KAAKiC,OAAOoT,QACtB,IAAM,IAAIpP,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAKzE,KAQ7CqW,eACE9X,KAAKiC,OAAO8T,MAAQ,IAAI9P,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,GACvDlG,KAAKiC,OAAO8T,MAAM,GAAK,EACvB/V,KAAKiC,OAAOkU,WAAa,IAAIlQ,MAA2B,EAArBjG,KAAKiC,OAAOoT,QAAYnP,KAAK,IAChElG,KAAKiC,OAAOkU,WAAsC,GAA1BnW,KAAKiC,OAAOoT,OAAS,IAAU,EACvDrV,KAAKiC,OAAOkU,WAAuC,GAA1BnW,KAAKiC,OAAOoT,OAAS,GAAU,GAAK,GAQ/DqC,uBACE,GAAmC,YAA/B1X,KAAKiC,OAAOqT,eAA8B,CAC5C,MAAM8C,EAAYpY,KAAKiC,OAAO8T,MAAMzT,OAAO,CAACC,EAAGC,IAAMD,EAAIC,EAAG,GAC5D,IAAK,IAAIpC,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAAG,CAC9CJ,KAAKiC,OAAO8T,MAAM3V,IAAMgY,EACxB,IAAIC,EAAiB,EACrB,IAAK,IAAIvF,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAC3CuF,GAAkBrY,KAAKiC,OAAOkU,WAAW/V,GAAG0S,GAE9C,IAAK,IAAIA,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAC3C9S,KAAKiC,OAAOkU,WAAW/V,GAAG0S,IAAMuF,QAIpC,IAAK,IAAIjY,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAAG,CAC9C,MAAMiY,EAAiBrY,KAAKiC,OAAOkU,WAAe,EAAJ/V,GAASJ,KAAKiC,OAAOkU,WAAgB,EAAJ/V,EAAS,GACxFJ,KAAKiC,OAAOkU,WAAe,EAAJ/V,IAAUiY,EACjCrY,KAAKiC,OAAOkU,WAAgB,EAAJ/V,EAAS,IAAMiY,IAW7CC,4BAA4BC,GAC1B,IAAK,IAAInY,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3CJ,KAAKyK,KAAKrK,GAAKmY,GAUnBC,wBAAwBD,EAAI5N,GAC1B3K,KAAK0W,aAAe1W,KAAKyK,KAAKqE,QAC9B,IAAK,IAAI1O,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAAG,CAE9C,GADAJ,KAAKyK,KAAKrK,GAAK,EACoB,YAA/BJ,KAAKiC,OAAOqT,eACd,IAAK,IAAIxC,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAC3C9S,KAAKyK,KAAKrK,IAAMJ,KAAKiC,OAAOkU,WAAW/V,GAAG0S,GACxC9S,KAAK0W,aAAa5D,GAClB9S,KAAKiC,OAAO+T,QAAQlD,GAAGpI,WAAWC,QAGtC3K,KAAKyK,KAAKrK,IAAMJ,KAAKiC,OAAOkU,WAAe,EAAJ/V,GACrCJ,KAAK0W,aAAatW,GAClBJ,KAAKiC,OAAO+T,QAAQ5V,GAAGsK,WAAWC,GAChCvK,EAAIJ,KAAKiC,OAAOoT,OAAS,IAC3BrV,KAAKyK,KAAKrK,IAAMJ,KAAKiC,OAAOkU,WAAgB,EAAJ/V,EAAS,GAC/CJ,KAAK0W,aAAatW,EAAI,GACtBJ,KAAKiC,OAAO+T,QAAQ5V,EAAI,GAAGsK,WAAWC,IAG5C3K,KAAKyK,KAAKrK,IAAMmY,GACZ1O,OAAOC,MAAM9J,KAAKyK,KAAKrK,KAAOmG,KAAKqD,IAAI5J,KAAKyK,KAAKrK,MAASwG,OAC5D5G,KAAKyK,KAAKrK,GAAK,SAYrBqY,uBAAuBC,GACrB,IAAIxN,EAAY,EAChBlL,KAAKkW,cAAgBlW,KAAK8V,MAAMhH,QAChC,IAAK,IAAIgE,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAAG,CAE9C,GADA9S,KAAK8V,MAAMhD,GAAK,EACmB,YAA/B9S,KAAKiC,OAAOqT,eACd,IAAK,IAAIlV,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3CJ,KAAK8V,MAAMhD,IAAM9S,KAAKkW,cAAc9V,GAClCJ,KAAKiC,OAAOkU,WAAW/V,GAAG0S,QAG9B9S,KAAK8V,MAAMhD,IAAM9S,KAAKkW,cAAcpD,GAAK9S,KAAKiC,OAAOkU,WAAe,EAAJrD,GAC5DA,EAAI,EACN9S,KAAK8V,MAAMhD,IAAM9S,KAAKkW,cAAcpD,EAAI,GACtC9S,KAAKiC,OAAOkU,WAAsB,GAATrD,EAAI,GAAU,GAEzC9S,KAAK8V,MAAM,IAAM9V,KAAKkW,cAAclW,KAAKiC,OAAOoT,OAAS,GACvDrV,KAAKiC,OAAOkU,WAAiC,EAArBnW,KAAKiC,OAAOoT,OAAc,GAGxDrV,KAAK8V,MAAMhD,IAAM4F,EAAuB5F,GACxC5H,GAAalL,KAAK8V,MAAMhD,GAE1B,GAAIjJ,OAAOC,MAAMoB,GACf,MAAM,IAAIhE,MAAM,cAElB,GAAIgE,EAAY,OAAQ,CACtB,IAAK,IAAI4H,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAC3C9S,KAAK8V,MAAMhD,IAAM5H,EAEnB,OAAO,EAAIA,EAEb,OAAO,GAWTyN,wBAAwBJ,EAAIG,GAC1B1Y,KAAK0W,aAAe1W,KAAKyK,KAAKqE,QAC9B,IAAK,IAAI1O,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAAG,CAE9C,GADAJ,KAAKyK,KAAKrK,GAAK,EACoB,YAA/BJ,KAAKiC,OAAOqT,eACd,IAAK,IAAIxC,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAC3C9S,KAAKyK,KAAKrK,IACRJ,KAAKiC,OAAOkU,WAAW/V,GAAG0S,GAC1B9S,KAAK0W,aAAa5D,GAClB4F,EAAuB5F,QAG3B9S,KAAKyK,KAAKrK,IAAMJ,KAAKiC,OAAOkU,WAAe,EAAJ/V,GACrCJ,KAAK0W,aAAatW,GAClBsY,EAAuBtY,GACrBA,EAAIJ,KAAKiC,OAAOoT,OAAS,IAC3BrV,KAAKyK,KAAKrK,IAAMJ,KAAKiC,OAAOkU,WAAgB,EAAJ/V,EAAS,GAC/CJ,KAAK0W,aAAatW,EAAI,GACtBsY,EAAuBtY,EAAI,IAGjCJ,KAAKyK,KAAKrK,IAAMmY,GACZ1O,OAAOC,MAAM9J,KAAKyK,KAAKrK,KAAOmG,KAAKqD,IAAI5J,KAAKyK,KAAKrK,MAASwG,OAC5D5G,KAAKyK,KAAKrK,GAAK,SAYrB+W,yBAAyByB,EAAejU,GACtC,MAAMqS,EAAI4B,EAAcpU,OAElB+T,EAAK,IAAItS,MAAM+Q,GAAG9Q,KAAK,GAC7B,IAAI+D,EACJjK,KAAK2X,YACL3X,KAAK4X,WAEL,MAAMiB,EAA2B5S,MAAMS,KACrC,IAAIT,MAAM+Q,GACV,IAAM,IAAI/Q,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,IAE3C,IAAK,IAAIE,EAAI,EAAGA,EAAI4Q,EAAG5Q,GAAK,EAC1B,IAAK,IAAIhG,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3CyY,EAAyBzS,GAAGhG,GAC1BJ,KAAKiC,OAAO+T,QAAQ5V,GAAGsK,WAAWkO,EAAchQ,SAASxC,IAK/DmS,EAAG,GAAKvY,KAAK6V,2BAA2B+C,EAAchQ,SAAS,IAC/DqB,GAAW1D,KAAKkG,IAAI8L,EAAG,IACvBvY,KAAK2X,SAAS7S,KAAK9E,KAAK8V,MAAMhH,SAE9B,IAAK,IAAI1I,EAAI,EAAGA,EAAI4Q,EAAG5Q,GAAK,EAC1BmS,EAAGnS,GAAKpG,KAAKyY,uBAAuBI,EAAyBzS,IAC7D6D,GAAW1D,KAAKkG,IAAI8L,EAAGnS,IACvBpG,KAAK2X,SAAS7S,KAAK9E,KAAK8V,MAAMhH,SAIhC9O,KAAKsY,4BAA4BC,EAAGvB,EAAI,IACxChX,KAAK4X,QAAQ9S,KAAK9E,KAAKyK,KAAKqE,SAE5B,IAAK,IAAI1I,EAAI4Q,EAAI,EAAG5Q,GAAK,EAAGA,GAAK,EAC/BpG,KAAK2Y,wBAAwBJ,EAAGnS,GAAIyS,EAAyBzS,EAAI,IACjEpG,KAAK4X,QAAQ9S,KAAK9E,KAAKyK,KAAKqE,SAE9B9O,KAAK4X,QAAQkB,UAGb,IAAK,IAAI1S,EAAI,EAAGA,EAAI4Q,EAAG5Q,GAAK,EAC1B,IAAK,IAAIhG,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3CJ,KAAK4W,cAAcjS,GAAayB,GAAGhG,GAChCJ,KAAK2X,SAASvR,GAAGhG,GAAKJ,KAAK4X,QAAQxR,GAAGhG,GAAMmY,EAAGnS,GAKtD,IAAI8E,EAEJ,IAAK,IAAI9E,EAAI,EAAGA,EAAI4Q,EAAG5Q,GAAK,EAC1B,IAAK,IAAIhG,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAAG,CAE9C,GADA8K,EAAY,EACkB,IAA1BlL,KAAKiC,OAAO0B,UAAiB,CAC/B,MAAMoV,EAAKF,EAAyBzS,GAAGhG,GACvCJ,KAAK8W,wBAAwBnS,GAAa,GAAGyB,GAAGhG,GAC9CJ,KAAK4W,cAAcjS,GAAayB,GAAGhG,GAAK2Y,EAC1C7N,GAAa6N,OAEb,IAAK,IAAItY,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAAG,CACjD,MAAMsY,EAAK/Y,KAAKiC,OAAO+T,QAAQ5V,GAC5BwK,oBAAoBgO,EAAchQ,SAASxC,GAAI3F,GAClDT,KAAK8W,wBAAwBnS,GAAalE,GAAG2F,GAAGhG,GAC9CJ,KAAK4W,cAAcjS,GAAayB,GAAGhG,GACnC2Y,EACF7N,GAAa6N,EAGjB,GAAI7N,EAAY,EACd,IAAK,IAAIzK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAK8W,wBAAwBnS,GAAalE,GAAG2F,GAAGhG,IAAM8K,EAO9D,GAAmC,YAA/BlL,KAAKiC,OAAOqT,eACd,IAAK,IAAIlP,EAAI,EAAGA,EAAI4Q,EAAI,EAAG5Q,GAAK,EAC9B,IAAK,IAAIhG,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3C,IAAK,IAAI0S,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAC3C9S,KAAK6W,gBAAgBlS,GAAayB,GAAGhG,GAAG0S,GACtC9S,KAAK2X,SAASvR,GAAGhG,GACjBJ,KAAKiC,OAAOkU,WAAW/V,GAAG0S,GAC1B9S,KAAK4X,QAAQxR,EAAI,GAAG0M,GACtB9S,KAAK6W,gBAAgBlS,GAAayB,GAAGhG,GAAG0S,IACtC+F,EAAyBzS,EAAI,GAAG0M,QAKxC,IAAK,IAAI1M,EAAI,EAAGA,EAAI4Q,EAAI,EAAG5Q,GAAK,EAC9B,IAAK,IAAIhG,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3CJ,KAAK6W,gBAAgBlS,GAAayB,GAAO,EAAJhG,GACnCJ,KAAK2X,SAASvR,GAAGhG,GACjBJ,KAAKiC,OAAOkU,WAAe,EAAJ/V,GACvBJ,KAAK4X,QAAQxR,EAAI,GAAGhG,GACtBJ,KAAK6W,gBAAgBlS,GAAayB,GAAO,EAAJhG,IACnCyY,EAAyBzS,EAAI,GAAGhG,GAC9BA,EAAIJ,KAAKiC,OAAOoT,OAAS,IAC3BrV,KAAK6W,gBAAgBlS,GAAayB,GAAQ,EAAJhG,EAAS,GAC7CJ,KAAK2X,SAASvR,GAAGhG,GACjBJ,KAAKiC,OAAOkU,WAAgB,EAAJ/V,EAAS,GACjCJ,KAAK4X,QAAQxR,EAAI,GAAGhG,EAAI,GAC1BJ,KAAK6W,gBAAgBlS,GAAayB,GAAQ,EAAJhG,EAAS,IAC7CyY,EAAyBzS,EAAI,GAAGhG,EAAI,IAM9C,OAAO6J,GAQTmN,kBAAkB3U,GAChB,IAAK,IAAIrC,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAAG,CAC9CJ,KAAKiX,SAAS7W,GAAK,EACnB,IAAK,IAAIK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKkX,mBAAoB9W,EAAIJ,KAAKiC,OAAO0B,UAAalD,GAAK,EAI/D,IAAIkE,EAAc,EAClBlC,EAAYc,QAASwB,IACnB,IAAK,IAAI3E,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3C,IAAK,IAAIgG,EAAI,EAAGA,EAAIrB,EAAOP,OAAQ4B,GAAK,EAAG,CACzCpG,KAAKiX,SAAS7W,IACZJ,KAAK4W,cAAcjS,GAAayB,GAAGhG,GACrC,IAAK,IAAIK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKkX,mBAAoB9W,EAAIJ,KAAKiC,OAAO0B,UAAalD,IACpDT,KAAK8W,wBAAwBnS,GAAalE,GAAG2F,GAAGhG,GAIxDuE,GAAe,KAUnB0S,qCAAqC5U,GACnC,IAAIkC,EAAc,EAClBlC,EAAYc,QAASwB,IACnB,IAAK,IAAI3E,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3C,IAAK,IAAIgG,EAAI,EAAGA,EAAIrB,EAAOP,OAAQ4B,GAAK,EACtC,IAAK,IAAI3F,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOuI,cAAc/J,IAC1CT,KAAK8W,wBAAwBnS,GAAalE,GAAG2F,GAAGhG,GAIxDuE,GAAe,IAIjB,IAAK,IAAIvE,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3CJ,KAAKiC,OAAO+T,QAAQ5V,GAAG6K,0BAU3BqM,uBAAuB7U,GACrB,IAAK,IAAIrC,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3C,IAAK,IAAIK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9CT,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GAAGsF,KAAKG,KAAK,GAK1D,IAAIvB,EAAc,EAClBlC,EAAYc,QAASwB,IACnB,IAAK,IAAI3E,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3C,IAAK,IAAIgG,EAAI,EAAGA,EAAIrB,EAAOP,OAAQ4B,GAAK,EACtC,IAAK,IAAI3F,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9C,IAAK,IAAIC,EAAI,EAAGA,EAAIV,KAAKiC,OAAOD,UAAWtB,GAAK,EAC9CV,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GAAGsF,KAAKrF,IAC/CV,KAAK8W,wBAAwBnS,GAAalE,GAAG2F,GAAGhG,GAChD2E,EAAO7D,IAAIkF,EAAG1F,GAKxBiE,GAAe,IAIjB,IAAK,IAAIvE,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3C,IAAK,IAAIK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9C,IAAK,IAAIC,EAAI,EAAGA,EAAIV,KAAKiC,OAAOD,UAAWtB,GAAK,EAK9C,GAJIV,KAAKkX,mBAAoB9W,EAAIJ,KAAKiC,OAAO0B,UAAalD,GAAK,IAC7DT,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GAAGsF,KAAKrF,IAC/CV,KAAKkX,mBAAoB9W,EAAIJ,KAAKiC,OAAO0B,UAAalD,IAEtDoJ,OAAOC,MAAM9J,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GAAGsF,KAAKrF,IAChE,MAAM,IAAIwG,MAAM,sBAa1BqQ,6BAA6B9U,GAC3B,IAAIkC,EAAc,EAClBlC,EAAYc,QAASwB,IACnB,IAAK,IAAI3E,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3C,IAAK,IAAIgG,EAAI,EAAGA,EAAIrB,EAAOP,OAAQ4B,GAAK,EACtC,IAAK,IAAI3F,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9C,IAAK,IAAIuR,EAAK,EAAGA,EAAKhS,KAAKiC,OAAOD,UAAWgQ,GAAM,EACjD,GAAmC,SAA/BhS,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAKqG,EAAIrG,EAAK3L,KAAKiC,OAAOD,UAAW2J,GAAM,EAClD3L,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GACtCsP,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,IAC3C3L,KAAK8W,wBAAwBnS,GAAalE,GAAG2F,GAAGhG,IAC/C2E,EAAO7D,IAAIkF,EAAG4L,GACbhS,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GAAGsF,KAAKiM,KAClDjN,EAAO7D,IAAIkF,EAAGuF,GACb3L,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GAAGsF,KAAK4F,QAElD,CACL,MAAMsB,EAAQlI,EAAO7D,IAAIkF,EAAG4L,GAC1BhS,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GAAGsF,KAAKiM,GACnDhS,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GAAGsP,WAAWiC,IACrDhS,KAAK8W,wBAAwBnS,GAAalE,GAAG2F,GAAGhG,GAC/C6M,GAAS,EAMtBtI,GAAe,IAIjB,IAAK,IAAIvE,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAAG,CAC9C,IAAK,IAAIK,EAAI,EAAGA,EAAIT,KAAKiC,OAAO0B,UAAWlD,GAAK,EAC9C,GAAIT,KAAKkX,mBAAoB9W,EAAIJ,KAAKiC,OAAO0B,UAAalD,GAAK,EAC7D,IAAK,IAAIuR,EAAK,EAAGA,EAAKhS,KAAKiC,OAAOD,UAAWgQ,GAAM,EACjD,GAAmC,SAA/BhS,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAKqG,EAAIrG,EAAK3L,KAAKiC,OAAOD,UAAW2J,GAAM,EAClD3L,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GACtCsP,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,IAC3C3L,KAAKkX,mBAAoB9W,EAAIJ,KAAKiC,OAAO0B,UAAalD,GACpDuR,IAAOrG,IACT3L,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GACtCsP,WAAYpE,EAAK3L,KAAKiC,OAAOD,UAAagQ,GAC3ChS,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GACtCsP,WAAYiC,EAAKhS,KAAKiC,OAAOD,UAAa2J,SAInD3L,KAAKiC,OAAO+T,QAAQ5V,GAAG6B,OAAOqI,WAAW7J,GAAGsP,WAAWiC,IACrDhS,KAAKkX,mBAAoB9W,EAAIJ,KAAKiC,OAAO0B,UAAalD,GAKhET,KAAKiC,OAAO+T,QAAQ5V,GAAG+K,aACvBnL,KAAKiC,OAAO+T,QAAQ5V,GAAG0K,6BAS3B0M,uBAAuB/U,GACrBzC,KAAKiC,OAAO8T,MAAM7P,KAAK,GAGvB,IAAI8S,EAAW,EACf,IAAK,IAAIrU,EAAc,EACrBA,EAAclC,EAAY6B,OAC1BK,GAAe,EACf,IAAK,IAAIvE,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3CJ,KAAKiC,OAAO8T,MAAM3V,IAAMJ,KAAK4W,cAAcjS,GAAa,GAAGvE,GAC3D4Y,GAAYhZ,KAAKiC,OAAO8T,MAAM3V,GAKlC,KAAI4Y,EAAW,GAKb,MAAM,IAAI9R,MAAM,8BAJhB,IAAK,IAAI9G,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3CJ,KAAKiC,OAAO8T,MAAM3V,IAAM4Y,GAY9BvB,6BAA6BhV,GAE3BzC,KAAKiC,OAAOkU,WAA4C,YAA/BnW,KAAKiC,OAAOqT,eACnCrP,MAAMS,KACJ,IAAIT,MAAMjG,KAAKiC,OAAOoT,QACtB,IAAM,IAAIpP,MAAMjG,KAAKiC,OAAOoT,QAAQnP,KAAK,IAE3C,IAAID,MAA2B,EAArBjG,KAAKiC,OAAOoT,QAAYnP,KAAK,GAGzC,IAAIvB,EAAc,EAwClB,GAvCAlC,EAAYc,QAASwB,IACnB,GAAIA,EAAOP,OAAS,EAClB,IAAK,IAAIpE,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAY3C,GATmC,cAA/BJ,KAAKiC,OAAOqT,iBACdtV,KAAKiC,OAAOkU,WAAe,EAAJ/V,IAAUiW,EAC7BjW,EAAIJ,KAAKiC,OAAOoT,OAAS,EAC3BrV,KAAKiC,OAAOkU,WAAgB,EAAJ/V,EAAS,IAAMiW,EAEvCrW,KAAKiC,OAAOkU,WAAe,EAAJ/V,IAAUiW,GAIF,YAA/BrW,KAAKiC,OAAOqT,eACd,IAAK,IAAIxC,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAC3C,IAAK,IAAI1M,EAAI,EAAGA,EAAIrB,EAAOP,OAAS,EAAG4B,GAAK,EAC1CpG,KAAKiC,OAAOkU,WAAW/V,GAAG0S,IACxB9S,KAAK6W,gBAAgBlS,GAAayB,GAAGhG,GAAG0S,OAGzC,CACL,IAAK,IAAI1M,EAAI,EAAGA,EAAIrB,EAAOP,OAAS,EAAG4B,GAAK,EAC1CpG,KAAKiC,OAAOkU,WAAe,EAAJ/V,IACrBJ,KAAK6W,gBAAgBlS,GAAayB,GAAO,EAAJhG,GAEzC,GAAIA,EAAIJ,KAAKiC,OAAOoT,OAAS,EAC3B,IAAK,IAAIjP,EAAI,EAAGA,EAAIrB,EAAOP,OAAS,EAAG4B,GAAK,EAC1CpG,KAAKiC,OAAOkU,WAAgB,EAAJ/V,EAAS,IAC/BJ,KAAK6W,gBAAgBlS,GAAayB,GAAQ,EAAJhG,EAAS,GAM3DuE,GAAe,IAIkB,YAA/B3E,KAAKiC,OAAOqT,gBACd,IAAK,IAAIlV,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAC3C,IAAK,IAAI0S,EAAI,EAAGA,EAAI9S,KAAKiC,OAAOoT,OAAQvC,GAAK,EAG3C,GAFA9S,KAAKiC,OAAOkU,WAAW/V,GAAG0S,IACvB9S,KAAKiX,SAAS7W,GAAM,KACnByJ,OAAOC,MAAM9J,KAAKiC,OAAOkU,WAAW/V,GAAG0S,IACzC,MAAM,IAAI5L,MAAM,oFAKtB,IAAK,IAAI9G,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EAAG,CAG9C,GAFAJ,KAAKiC,OAAOkU,WAAe,EAAJ/V,IACpBJ,KAAKiX,SAAS7W,GAAM,KACnByJ,OAAOC,MAAM9J,KAAKiC,OAAOkU,WAAe,EAAJ/V,IACtC,MAAM,IAAI8G,MAAM,+EAElB,GAAI9G,EAAIJ,KAAKiC,OAAOoT,OAAS,IAC3BrV,KAAKiC,OAAOkU,WAAgB,EAAJ/V,EAAS,IAC9BJ,KAAKiX,SAAS7W,GAAM,KACnByJ,OAAOC,MAAM9J,KAAKiC,OAAOkU,WAAgB,EAAJ/V,EAAS,KAChD,MAAM,IAAI8G,MAAM,oHC1qBb,SAA2BrG,GACxC,IAAKC,OAAAiU,EAAA,EAAAjU,CAAYD,GACf,MAAM,IAAIqG,MAAM,+FAGlB,OADApG,OAAAkU,EAAA,EAAAlU,CAAmB,MAAOmY,EAAiBpY,EAAEoB,OAAOoT,OAAQxU,EAAEoB,OAAOqT,gBAAiBzU,EAAEoB,QACjFnB,OAAOgG,OACZjG,EACAqY,EACArY,EAAEoB,OAAOF,QAAUoX,MAEjBrD,MAAO,IAAI7P,MAAMpF,EAAEoB,OAAOoT,QAAQnP,KAAK,GACvCkT,gBAAiB,IAAInT,MAAMpF,EAAEoB,OAAOoT,QAAQnP,KAAK,KAEnDmT,kCAlPJ,MAAMJ,EAAmB,CAAC5D,EAAQC,MAChCD,QACEtI,UAAU,EACVK,OAASzG,IAAK,IAEhBhD,WACEoJ,UAAU,EACVK,OAASzG,IAAK,IAEhB/C,gBACEmJ,UAAU,EACVK,MAAO,EAAGqG,WAAUC,cACjBD,GAAYC,GAAYD,EAAW,GAAKC,EAAW,GAExD4B,gBACEvI,UAAU,EACVK,OAAQ,UAAW,cAErBvJ,gBACEkJ,UAAU,EACVK,OAAQ,OAAQ,aAElB2I,OACEhJ,UAAU,EACVK,MAAO5M,GAAwB,cAAnB8U,GAAkC9U,EAAEgE,SAAW6Q,GAE7Dc,YACEpJ,UAAU,EACVK,MAAO5M,GAAyB,cAAnB8U,EACX9U,EAAEgE,SAAW,EAAI6Q,EACjB7U,EAAEgE,SAAW6Q,GAEjBW,SACEjJ,UAAU,EACVK,MAAO5M,GAAKA,EAAEgE,SAAW6Q,KAUvB6D,GACJvD,oBAAoB,EACpBC,gBAAgB,EAOhByD,QAEE,OADArZ,KAAKiC,OAAO+T,QAAUhW,KAAKiC,OAAO+T,QAAQ5T,IAAIV,GAAKZ,OAAAwY,EAAA,EAAAxY,CAAaY,GAAGgC,SAC5D1D,MAOT0D,QAGE,OAFA1D,KAAKmM,iBAAiB3G,QACtBxF,KAAKiC,OAAO+T,QAAQzS,QAAS7B,IAAQA,EAAEgC,UAChC1D,MAQT0K,WAAWC,GACT,MAAM4N,EAAMvY,KAAK2V,mBACf3V,KAAKiW,uBAAuBtL,GAC5B3K,KAAK6V,2BAA2BlL,GAGlC,OAFA3K,KAAKuZ,oBACLvZ,KAAKwZ,iBACE,EAAIjB,GAGbiB,iBACExZ,KAAKwL,QAAQiO,SAAW,EACxB,IAAK,IAAIrZ,EAAIJ,KAAK0Z,eAAgBtZ,EAAIJ,KAAK2Z,eAAgBvZ,GAAK,EAC1DJ,KAAK4V,eACP5V,KAAKwL,QAAQiO,WAAazZ,KAAK8V,MAAM1V,GAAKJ,KAAK4Z,OAAOxZ,GAAKJ,KAAK6Z,OAAOzZ,KACpEA,EAAIJ,KAAK8Z,6BAEZ9Z,KAAKwL,QAAQiO,UAAazZ,KAAK8V,MAAM1V,GAAKA,EACxCJ,KAAK8Z,4BAGX9Z,KAAKwL,QAAQiO,UAAYzZ,KAAKiC,OAAOoT,OAAS,GAQhDkE,oBACEvZ,KAAKwL,QAAQuO,eAAiB,EAE9B,IAAIC,EAAYha,KAAK4V,eAClB5V,KAAK8V,MAAM,GAAK9V,KAAK4Z,OAAO,GAC7B5Z,KAAK8V,MAAM,GACb,IAAK,IAAI1V,EAAI,EAAGA,EAAIJ,KAAKiC,OAAOoT,OAAQjV,GAAK,EACvCJ,KAAK4V,eACF5V,KAAK8V,MAAM1V,GAAKJ,KAAK4Z,OAAOxZ,GAAM4Z,IACrCA,EAAYha,KAAK8V,MAAM1V,GAAKJ,KAAK4Z,OAAOxZ,GACxCJ,KAAKwL,QAAQuO,eAAiB3Z,GAEvBJ,KAAK8V,MAAM1V,GAAK4Z,IACzBA,EAAYha,KAAK8V,MAAM1V,GACvBJ,KAAKwL,QAAQuO,eAAiB3Z,GAKlCJ,KAAK0Z,eAAiB1Z,KAAKwL,QAAQuO,eAAiBxT,KAAK8B,MAAMrI,KAAKiC,OAAOoT,OAAS,GACpFrV,KAAK2Z,eAAiB3Z,KAAKwL,QAAQuO,eAAiBxT,KAAK8B,MAAMrI,KAAKiC,OAAOoT,OAAS,GACpFrV,KAAK0Z,eAAkB1Z,KAAK0Z,gBAAkB,EAAK1Z,KAAK0Z,eAAiB,EACzE1Z,KAAK2Z,eAAkB3Z,KAAK2Z,gBAAkB3Z,KAAKiC,OAAOoT,OACxDrV,KAAK2Z,eAAiB3Z,KAAKiC,OAAOoT,OACpCrV,KAAK8Z,4BAA8B,EACnC,IAAK,IAAI1Z,EAAIJ,KAAK0Z,eAAgBtZ,EAAIJ,KAAK2Z,eAAgBvZ,GAAK,EAC9DJ,KAAK8Z,6BAA+B9Z,KAAK4V,eACtC5V,KAAK8V,MAAM1V,GAAKJ,KAAK4Z,OAAOxZ,GAC7BJ,KAAK8V,MAAM1V,KAUb+Y,GASJ9N,WAAWC,GAIT,GAHAtL,KAAKwL,QAAQC,aAAexF,MAAMjG,KAAKiC,OAAOJ,iBAAiBqE,KAAK,GACpElG,KAAKwL,QAAQE,iBAAmBzF,MAAqC,SAA/BjG,KAAKiC,OAAO4B,eAA4B7D,KAAKiC,OAAOJ,iBAAmB,EAAI7B,KAAKiC,OAAOJ,iBAAiBqE,KAAK,GAE3G,cAApClG,KAAKiC,OAAOgY,oBAId,OAHAja,KAAKiC,OAAO+T,QAAQhW,KAAKwL,QAAQuO,gBAAgBxN,QAAQjB,GACzDtL,KAAKwL,QAAQC,aACXzL,KAAKiC,OAAO+T,QAAQhW,KAAKwL,QAAQuO,gBAAgBvO,QAAQC,aACpDzL,KAAKwL,QAAQC,aAGtB,MAAMyO,EAAoD,SAApCla,KAAKiC,OAAOgY,oBAChC,EAAIja,KAAK0Z,eACLS,EAAoD,SAApCna,KAAKiC,OAAOgY,oBAChCja,KAAKiC,OAAOoT,OAASrV,KAAK2Z,eAC5B,IAAIS,EAA6D,SAApCpa,KAAKiC,OAAOgY,oBACvC,EAAIja,KAAK8Z,4BAEPM,GAAyB,IAAKA,EAAwB,GAG1D,IAAK,IAAIha,EAAI8Z,EAAc9Z,EAAI+Z,EAAc/Z,GAAK,EAAG,CACnDJ,KAAKiC,OAAO+T,QAAQ5V,GAAGsK,WAAWY,GAClCtL,KAAKiC,OAAO+T,QAAQ5V,GAAGiL,WAAWC,GAClC,MAAM+O,EAAqBra,KAAKiC,OAAO+T,QAAQ5V,GAAGoL,QAAQC,aAC1D,IAAK,IAAI/K,EAAI,EAAGA,EAAIV,KAAKiC,OAAOJ,gBAAiBnB,GAAK,EACpD,GAAIV,KAAK4V,eAIP,GAHA5V,KAAKwL,QAAQC,aAAa/K,KACvBV,KAAK8V,MAAM1V,GAAKJ,KAAK4Z,OAAOxZ,KAC5Bia,EAAmB3Z,GAAK0Z,GACQ,SAA/Bpa,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAK,EAAGA,EAAK3L,KAAKiC,OAAOJ,gBAAiB8J,GAAM,EACvD3L,KAAKwL,QAAQE,iBAAkBhL,EAAIV,KAAKiC,OAAOJ,gBAAmB8J,KAC/D3L,KAAK8V,MAAM1V,GAAKJ,KAAK4Z,OAAOxZ,KAC5BJ,KAAK8V,MAAM1V,GAAKJ,KAAK4Z,OAAOxZ,KAC5BJ,KAAKiC,OAAO+T,QAAQ5V,GAAGoL,QACrBE,iBAAkBhL,EAAIV,KAAKiC,OAAOJ,gBAAmB8J,GACxDyO,QAGJpa,KAAKwL,QAAQE,iBAAiBhL,KAC3BV,KAAK8V,MAAM1V,GAAKJ,KAAK4Z,OAAOxZ,KAC5BJ,KAAK8V,MAAM1V,GAAKJ,KAAK4Z,OAAOxZ,KAC5BJ,KAAKiC,OAAO+T,QAAQ5V,GAAGoL,QAAQE,iBAAiBhL,GACjD0Z,QAKJ,GAFApa,KAAKwL,QAAQC,aAAa/K,IAAMV,KAAK8V,MAAM1V,IACxCia,EAAmB3Z,GAAK0Z,GACQ,SAA/Bpa,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAK,EAAGA,EAAK3L,KAAKiC,OAAOJ,gBAAiB8J,GAAM,EACvD3L,KAAKwL,QAAQE,iBAAkBhL,EAAIV,KAAKiC,OAAOJ,gBAAmB8J,IAC/D3L,KAAK8V,MAAM1V,IAAM,GACjBJ,KAAKiC,OAAO+T,QAAQ5V,GAAGoL,QACrBE,iBAAkBhL,EAAIV,KAAKiC,OAAOJ,gBAAmB8J,GACxDyO,QAGJpa,KAAKwL,QAAQE,iBAAiBhL,IAC1BV,KAAK8V,MAAM1V,IAAM,EACnBJ,KAAKiC,OAAO+T,QAAQ5V,GAAGoL,QAAQE,iBAAiBhL,GAChD0Z,EAKV,OAAOpa,KAAKwL,QAAQC,iDC8IT,SAAuC5K,GACpD,IAAKC,OAAAmD,EAAA,EAAAnD,CAAYD,GACf,MAAM,IAAIqG,MAAM,+FAOlB,OAAOpG,OAAOgG,OACZjG,EACAyZ,MAKAjB,oBAtXJ,MAOMiB,GAQJ3E,oBAAoB,EAOpB0D,QACE,MAAMkB,EAAava,KAAKsE,OAYxB,OAXAtE,KAAKiC,OAAO8T,MAAQ,IAAI9P,MAAMsU,GAAYrU,KAAK,EAAIqU,GACnDva,KAAKiC,OAAOkU,WAAalQ,MAAMS,KAC7B,IAAIT,MAAMsU,GACV,IAAM,IAAItU,MAAMsU,GAAYrU,KAAK,EAAIqU,IAEvCva,KAAKiC,OAAOuY,eAAiB,IAAIvU,MAAMsU,GAAYrU,KAAK,IACxDpF,OAAO8L,OAAO5M,KAAKqD,QAAQE,QAASJ,IACxBA,EACRyS,gBAAiB,IAErB5V,KAAKya,0BACEza,MASTya,wBAAwBC,GACtB,MAAMC,OAAkC3V,IAAtB0V,EAChBA,EACA,IAAIzU,MAAMjG,KAAKiC,OAAOoT,OAAS,GAAGnP,KAAK,GACpCL,QAhDkC,KAiDvC/E,OAAOoB,KAAKlC,KAAKqD,QAAQE,QAASC,IAChCxD,KAAKqD,OAAOG,GAAOvB,OAAOyY,kBAAoBC,EAAS7L,WAQ3DpL,QACE5C,OAAO8L,OAAO5M,KAAKqD,QAAQE,QAAQ/C,GAAKA,EAAEkD,SAC1C1D,KAAKwL,SACH7F,UACA+H,sBACAC,uBACAC,0BACAC,iCACA+M,kBACA9M,UAAW,KACXxK,YAEEtD,KAAKiC,OAAOF,SACd/B,KAAK+N,eAEP/N,KAAK2V,oBAAqB,GAO5BpJ,QAAQ5B,GAcN,GAbI3K,KAAK2V,mBACP3V,KAAKiW,uBAAuBtL,GAE5B3K,KAAK6V,2BAA2BlL,GAElC7J,OAAOoB,KAAKlC,KAAKqD,QAAQ2K,OAAOzK,QAASC,IACvC,MAAML,EAAQnD,KAAKqD,OAAOG,GAC1BL,EAAMoW,oBACNpW,EAAMqW,iBACNrW,EAAMqJ,cAAcrJ,EAAMqI,QAAQS,qBAEpCjM,KAAKwM,gBAEDxM,KAAKiC,OAAOF,QAGd,GAFAjB,OAAO8L,OAAO5M,KAAKqD,QAAQE,QAAQ/C,GAAKA,EAAE6K,WAAWV,IAEH,cAA9C3K,KAAKiC,OAAOqL,8BACdtN,KAAKwL,QAAQC,aACXzL,KAAKqD,OAAOrD,KAAKwL,QAAQsC,WAAWtC,QAAQC,aAC9CzL,KAAKwL,QAAQE,iBACX1L,KAAKqD,OAAOrD,KAAKwL,QAAQsC,WAAWtC,QAAQE,qBACzC,CACL1L,KAAKwL,QAAQC,aAAe,IAAIxF,MAAMjG,KAAK6B,iBAAiBqE,KAAK,GACjElG,KAAKwL,QAAQE,iBACX,IAAIzF,MAAqC,SAA/BjG,KAAKiC,OAAO4B,eACpB7D,KAAK6B,iBAAmB,EACxB7B,KAAK6B,iBAAiBqE,KAAK,GAE/B,IAAI2U,EAAa,EACjB/Z,OAAO8L,OAAO5M,KAAKqD,QAAQE,QAASJ,IAClC,IAAK,IAAIzC,EAAI,EAAGA,EAAIV,KAAK6B,gBAAiBnB,GAAK,EAK7C,GAJAV,KAAKwL,QAAQC,aAAa/K,IACxBV,KAAKwL,QAAQqC,8BAA8BgN,GAC3C1X,EAAM2X,OAAOtP,QAAQC,aAAa/K,GAED,SAA/BV,KAAKiC,OAAO4B,eACd,IAAK,IAAI8H,EAAK,EAAGA,EAAK3L,KAAK6B,gBAAiB8J,GAAM,EAChD3L,KAAKwL,QAAQE,iBAAkBhL,EAAIV,KAAK6B,gBAAmB8J,IACzD3L,KAAKwL,QAAQqC,8BAA8BgN,GAC3C1X,EAAMqI,QAAQE,iBAAkBhL,EAAIV,KAAK6B,gBAAmB8J,QAGhE3L,KAAKwL,QAAQE,iBAAiBhL,IAC5BV,KAAKwL,QAAQqC,8BAA8BgN,GAC3C1X,EAAM2X,OAAOtP,QAAQE,iBAAiBhL,GAG5Cma,GAAc,MAWtBhF,2BAA2BlL,GACzB,IAAIO,EAAY,EACZ2P,EAAa,EACjB,MAAMvX,EAAUxC,OAAOoB,KAAKlC,KAAKqD,QAAQ2K,OACzC1K,EAAQC,QAASC,IACf,MAAML,EAAQnD,KAAKqD,OAAOG,GACpBuX,EAAI5X,EAAMlB,OAAOoT,OAMvB,GALAlS,EAAMyW,OAAS,IAAI3T,MAAM8U,GAAG7U,KAAK,GACjC/C,EAAM0W,OAAS,IAAI5T,MAAM8U,GAAG7U,KAAK,GAIG,YAAhC/C,EAAMlB,OAAOqT,eAA8B,CAC7CnS,EAAMqI,QAAQS,kBAAoB,EAClC,IAAK,IAAI7L,EAAI,EAAGA,EAAI2a,EAAG3a,GAAK,EAC1B+C,EAAM2S,MAAM1V,GAAKJ,KAAKiC,OAAO8T,MAAM8E,GACjC1X,EAAMlB,OAAO8T,MAAM3V,GACnB+C,EAAMlB,OAAO+T,QAAQ5V,GAAGsK,WAAWC,GACrCxH,EAAMqI,QAAQS,mBAAqB9I,EAAM2S,MAAM1V,QAGjD+C,EAAM2S,MAAM,GAAK9V,KAAKiC,OAAO8T,MAAM8E,GACjC1X,EAAMlB,OAAO+T,QAAQ,GAAGtL,WAAWC,IACpCxH,EAAMqI,QAAQS,mBAAqB9I,EAAM2S,MAE5C5K,GAAa/H,EAAMqI,QAAQS,kBAC3B4O,GAAc,IAGhBvX,EAAQC,QAASC,IACf,MAAML,EAAQnD,KAAKqD,OAAOG,GACpBuX,EAAI5X,EAAMlB,OAAOoT,OACvB,IAAK,IAAIjV,EAAI,EAAGA,EAAI2a,EAAG3a,GAAK,EAC1B+C,EAAM2S,MAAM1V,IAAM8K,IAKtBlL,KAAKgb,WAAa,IAAI/U,MAAMjG,KAAKsE,MAAM4B,KAAK,GAC5ClG,KAAKib,WAAa,IAAIhV,MAAMjG,KAAKsE,MAAM4B,KAAK,GAC5ClG,KAAK2V,oBAAqB,GAQ5BM,uBAAuBtL,GACrB,IAAIO,EAAY,EAGZkF,EAAM,EAIVpQ,KAAKgb,WAAahb,KAAKkb,gBAAgB,GACvClb,KAAKib,WAAajb,KAAKkb,gBAAgB,GAIvC,IAAIC,EAAgB,EACpB,MAAM7X,EAAUxC,OAAOoB,KAAKlC,KAAKqD,QAAQ2K,OACzC1K,EAAQC,QAASC,IACf,MAAM4X,EAAWpb,KAAKqD,OAAOG,GACvBuX,EAAIK,EAASnZ,OAAOoT,OAKpBgG,EAAQ,IAAIpV,MAAM8U,GAAG7U,KAAK,GAEhC,GAAuC,YAAnCkV,EAASnZ,OAAOqT,eAClB,IAAK,IAAIpN,EAAI,EAAGA,EAAI6S,EAAG7S,GAAK,EAAG,CAC7B,IAAK,IAAI4K,EAAI,EAAGA,EAAIiI,EAAGjI,GAAK,EAC1BuI,EAAMnT,IAAOkT,EAASnZ,OAAOkU,WAAWrD,GAAG5K,IACxC,EAAIkT,EAASnZ,OAAOyY,kBAAkB5H,IACrCsI,EAAStF,MAAMhD,GAGrB,IACE,IAAIwI,EAAgB,EACpBA,EAAgBtb,KAAKsE,OACrBgX,GAAiB,EAEjBD,EAAMnT,IAAMkT,EAASnZ,OAAO8T,MAAM7N,IAC/BlI,KAAKgb,WAAWM,GACjBtb,KAAKiC,OAAOkU,WAAWmF,GAAeH,GACrCnb,KAAKiC,OAAO8T,MAAMoF,GACnBnb,KAAKib,WAAWK,QAIjB,CAELD,EAAM,GAAKD,EAASnZ,OAAOkU,WAAW,GAAKiF,EAAStF,MAAM,GAE1D,IACE,IAAIwF,EAAgB,EACpBA,EAAgBtb,KAAKsE,OACrBgX,GAAiB,EAEjBD,EAAM,IAAOrb,KAAKgb,WAAWM,GAC3Btb,KAAKiC,OAAOkU,WAAWmF,GAAeH,GACrCnb,KAAKiC,OAAO8T,MAAMoF,GACjBnb,KAAKib,WAAWK,GAItB,IAAK,IAAIpT,EAAI,EAAGA,EAAI6S,EAAG7S,GAAK,EAC1BmT,EAAMnT,IAAOkT,EAASnZ,OAAOkU,WAAe,EAAJjO,IACrC,EAAIkT,EAASnZ,OAAOyY,kBAAkBxS,IACvCkT,EAAStF,MAAM5N,GACjBmT,EAAMnT,IAAOkT,EAASnZ,OAAOkU,WAAsB,GAATjO,EAAI,GAAU,IACrD,EAAIkT,EAASnZ,OAAOyY,kBAAkBxS,EAAI,IAC3CkT,EAAStF,MAAM5N,EAAI,GAGvB,IAAK,IAAIA,EAAI,EAAGA,EAAI6S,EAAG7S,GAAK,EAC1BkT,EAAStF,MAAM5N,GAAK,EACpBkT,EAASxB,OAAO1R,GAAK,EACrBkT,EAASvB,OAAO3R,GAAK,EAMzBkT,EAAS5P,QAAQoP,eAAiB,EAClCQ,EAAS5P,QAAQS,kBAAoB,EAGrC,IAAK,IAAI/D,EAAI,EAAGA,EAAI6S,EAAG7S,GAAK,EAC1BkI,EAAMgL,EAASnZ,OAAO+T,QAAQ9N,GAAGwC,WAAWC,GAAe0Q,EAAMnT,GACjEkT,EAASvB,OAAO3R,GAAKlI,KAAKiC,OAAOuY,eAAeW,GAC9CC,EAASnZ,OAAOyY,kBAAkBxS,GAAKkI,EACzCgL,EAASxB,OAAO1R,IAAM,EAAIlI,KAAKiC,OAAOuY,eAAeW,IACnDC,EAASnZ,OAAOyY,kBAAkBxS,GAAKkI,EACzCgL,EAAStF,MAAM5N,IAAM,EAAIkT,EAASnZ,OAAOyY,kBAAkBxS,IAAMkI,EAEjEgL,EAAS5P,QAAQoP,gBAAkBQ,EAASxB,OAAO1R,GAAKkT,EAASvB,OAAO3R,GACxEkT,EAAS5P,QAAQS,mBAAqBmP,EAAStF,MAAM5N,GACnDkT,EAASxB,OAAO1R,GAAKkT,EAASvB,OAAO3R,GACvCgD,GAAakF,EAGfgL,EAAS5P,QAAQ+P,UAAYH,EAAS5P,QAAQoP,eAC5CQ,EAAS5P,QAAQS,kBAEnBkP,GAAiB,IAGnB7X,EAAQC,QAASC,IACf,MAAML,EAAQnD,KAAKqD,OAAOG,GACpBuX,EAAI5X,EAAMlB,OAAOoT,OACvB,IAAK,IAAInN,EAAI,EAAGA,EAAI6S,EAAG7S,GAAK,EAC1B/E,EAAM2S,MAAM5N,IAAMgD,EAClB/H,EAAMyW,OAAO1R,IAAMgD,EACnB/H,EAAM0W,OAAO3R,IAAMgD,KAUzBgQ,gBAAgBM,GACd,MAAMC,EAAmB,IAAIxV,MAAMjG,KAAKsE,QAAQ4B,KAAK,GACrD,GAAIsV,EAAU,EAAG,CAEf,IAAIX,EAAa,EACjB/Z,OAAOoB,KAAKlC,KAAKqD,QAAQ2K,OAAOzK,QAASC,IACvC,MAAML,EAAQnD,KAAKqD,OAAOG,GAC1BiY,EAAiBZ,GAAc,EAC/B,IAAK,IAAI3S,EAAI,EAAGA,EAAI/E,EAAMlB,OAAOoT,OAAQnN,GAAK,EAC5CuT,EAAiBZ,IAAe1X,EAAM2X,OAAOhF,MAAM5N,GACjD/E,EAAM2X,OAAOlB,OAAO1R,GACpB/E,EAAM2X,OAAOjB,OAAO3R,GAExB2S,GAAc,QAEX,CAEL,IAAIA,EAAa,EACjB/Z,OAAOoB,KAAKlC,KAAKqD,QAAQ2K,OAAOzK,QAASC,IACvC,MAAML,EAAQnD,KAAKqD,OAAOG,GAC1BiY,EAAiBZ,GAAc,EAC/B,IAAI/E,MAAEA,GAAU3S,EACA,IAAZqY,IACF1F,EAAQ3S,EAAMyW,QAEA,IAAZ4B,IACF1F,EAAQ3S,EAAM0W,QAEhB,IAAK,IAAI3R,EAAI,EAAGA,EAAI/E,EAAMlB,OAAOoT,OAAQnN,GAAK,EAC5CuT,EAAiBZ,IAAe/E,EAAM5N,GAExC2S,GAAc,IAGlB,OAAOY","file":"mars.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"mars\"] = factory();\n\telse\n\t\troot[\"mars\"] = factory();\n})(typeof self !== 'undefined' ? self : this, function() {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 11);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap 2a7ed91a37d941f3e50f","/**\n * Create the skeleton of a model\n *\n * @function\n * @param       {Number} inputDimension  input dimension\n * @param       {Number} outputDimension output dimension\n * @param       {Object} parameters      additional parameters to be copied\n * @constructor\n */\nexport default function ModelBase({\n  inputDimension,\n  outputDimension,\n  ...parameters\n}) {\n  const p = parameters;\n  delete p.bimodal;\n  delete p.inputDimension;\n  delete p.outputDimension;\n  delete p.dimension;\n  return /** @lends ModelBase */{\n    params: {\n      ...p,\n      get bimodal() {\n        return outputDimension > 0;\n      },\n      get inputDimension() {\n        return inputDimension;\n      },\n      get outputDimension() {\n        return outputDimension;\n      },\n      get dimension() {\n        return inputDimension + outputDimension;\n      },\n    },\n  };\n}\n\n/**\n * Check if an object is a base model (check for attribute existence)\n * @param  {Object}  o Source object\n * @return {Boolean}\n */\nexport function isBaseModel(o) {\n  if (!Object.keys(o).includes('params')) return false;\n  const keys = ['bimodal', 'inputDimension', 'outputDimension', 'dimension'];\n  return keys.map(key => Object.keys(o.params).includes(key))\n    .reduce((a, b) => a && b, true);\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/core/model_base_mixin.js","import ModelBase from '../core/model_base_mixin';\nimport withEMTraining from '../core/em_training_mixin';\nimport withGMMBase from './gmm_base_mixin';\nimport withGMMTraining from './gmm_training_mixin';\nimport MulticlassModelBase from '../core/multiclass_mixin';\nimport withMulticlassTraining from '../core/multiclass_training_mixin';\nimport withAbtractPrediction from '../core/prediction_mixin';\nimport withGMMPrediction from './gmm_prediction_mixin';\nimport withMulticlassPrediction from '../core/multiclass_prediction_mixin';\n\n/**\n * @typedef {Object} GMMParameters\n * @property {Boolean} bimodal Specifies if the model is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} gaussians Number of gaussian components in the mixture\n * @property {String} covarianceMode Covariance mode ('full' or 'diagonal')\n * @property {Array<Number>} mixtureCoeffs mixture coefficients ('weight' of\n * each gaussian component)\n * @property {Array<GaussianDistribution>} components Gaussian components\n */\n\n/**\n * Train a single-class GMM Model.\n *\n * @todo GMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {GMMParameters} Parameters of the trained GMM\n */\nexport function trainGMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const { gaussians, regularization, covarianceMode } = configuration;\n  const model = withGMMTraining(\n    withEMTraining(\n      withGMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        ...configuration,\n      })),\n      convergenceCriteria,\n    ),\n    gaussians,\n    regularization,\n    covarianceMode,\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Train a multi-class GMM Model.\n *\n * @todo GMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {Object} Parameters of the trained GMM\n */\nexport function trainMulticlassGMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withMulticlassTraining(\n    MulticlassModelBase({ inputDimension, outputDimension, ...configuration }),\n    ts => trainGMM(ts, configuration, convergenceCriteria),\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Create a GMM Predictor from a full set of parameters (generated by trainGMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function GMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withGMMPrediction(withAbtractPrediction(\n    withGMMBase(ModelBase(params)),\n    likelihoodWindow,\n  ));\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass GMM Predictor from a full set of parameters\n * (generated by trainMulticlassGMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function MulticlassGMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withMulticlassPrediction(MulticlassModelBase(params));\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = GMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model.reset();\n  return model;\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/gmm/index.js","import Phrase from './phrase';\n\n/**\n * Training Set Prototype\n * @ignore\n */\nconst trainingSetPrototype = /** @lends TrainingSet */ {\n  /**\n   * Get the training set size (number of phrases)\n   * @return {number}\n   */\n  size() {\n    return Object.keys(this.phrases).length;\n  },\n\n  /**\n   * Checks if the training set is empty\n   * @return {boolean}\n   */\n  empty() {\n    return this.length === 0;\n  },\n\n  /**\n   * Get a reference to a phrase by index\n   * @param  {number} phraseIndex phrase index\n   * @return {Phrase}\n   */\n  getPhrase(phraseIndex) {\n    if (Object.keys(this.phrases).includes(phraseIndex.toString())) {\n      return this.phrases[phraseIndex.toString()];\n    }\n    return null;\n  },\n\n  /**\n   * Iterate over all phrases in the training set. The callback function\n   * should take 3 arguments: the phrase, its index in the training set,\n   * and the phrases structure.\n   *\n   * @param  {Function} callback Callback function\n   */\n  forEach(callback) {\n    Object.keys(this.phrases).forEach((phraseIndex) => {\n      callback(this.phrases[phraseIndex], phraseIndex, this.phrases);\n    });\n  },\n\n  /**\n   * Add a phrase to the training set and return it.\n   * @param  {number} phraseIndex        phrase index\n   * @param  {string} [label=undefined]  phrase label (its index if undefined)\n   * @param  {Phrase} [phrase=undefined] Phrase data. If unspecified, an empty\n   * phrase is created.\n   * @return {Phrase}\n   */\n  push(phraseIndex, label = undefined, phrase = undefined) {\n    const p = (phrase !== undefined) ? phrase : Phrase({\n      inputDimension: this.inputDimension,\n      outputDimension: this.outputDimension,\n      columnNames: this.columnNames,\n      label: (label !== undefined) ? label : phraseIndex.toString(),\n    });\n    this.phrases[phraseIndex] = p;\n    return p;\n  },\n\n  /**\n   * Remove a phrase\n   * @param  {number} phraseIndex phrase index\n   */\n  remove(phraseIndex) {\n    delete this.phrases[phraseIndex];\n  },\n\n  /**\n   * Remove all phrases with a given label\n   * @param  {string} label class label\n   */\n  removeClass(label) {\n    this.phrases = Object.keys(this.phrases)\n      .filter(i => this.phrases[i].label !== label)\n      .map(i => ({ i: this.phrases[i] }))\n      .reduce((x, p) => ({ ...x, ...p }), {});\n  },\n\n  /**\n   * Clear the training set (delete all phrases)\n   */\n  clear() {\n    this.phrases = {};\n  },\n\n  /**\n   * Get the sub-training set composed of all phrases of a given class\n   * @param  {string} label class label\n   * @return {TrainingSet}\n   */\n  getPhrasesOfClass(label) {\n    const ts = TrainingSet(this); // eslint-disable-line no-use-before-define\n    ts.phrases = Object.keys(this.phrases)\n      .filter(i => this.phrases[i].label === label)\n      .map(i => ({ i: this.phrases[i] }))\n      .reduce((x, p) => ({ ...x, ...p }), {});\n    return ts;\n  },\n\n  /**\n   * Get the list of unique labels in the training set\n   * @return {Array<string>}\n   */\n  labels() {\n    return Object.keys(this.phrases)\n      .map(i => this.phrases[i].label)\n      .reduce((ll, x) => (ll.includes(x) ? ll : ll.concat([x])), []);\n  },\n\n  /**\n   * Get the list of phrase indices\n   * @return {Array<number>}\n   */\n  indices() {\n    return Object.keys(this.phrases);\n  },\n\n  /**\n   * Get the mean of the training set over all phrases\n   * @return {Array<number>} mean (same dimension as the training set)\n   */\n  mean() {\n    const sum = Array(this.dimension).fill(0);\n    let totalLength = 0;\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          sum[d] += this.phrases[i].get(t, d);\n        }\n      }\n      totalLength += this.phrases[i].length;\n    });\n\n    return sum.map(x => x / totalLength);\n  },\n\n  /**\n   * Get the standard deviation of the training set over all phrases\n   * @return {Array<number>} standard deviation (same dimension as the training set)\n   */\n  standardDeviation() {\n    const stddev = Array(this.dimension).fill(0);\n    const mean = this.mean();\n    let totalLength = 0;\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          stddev[d] += (this.phrases[i].get(t, d) - mean[d]) ** 2;\n        }\n      }\n      totalLength += this.phrases[i].length;\n    });\n\n    return stddev.map(x => Math.sqrt(x / totalLength));\n  },\n\n  /**\n   * Get the min and max of the training set over all phrases\n   * @return {Array<{ min: number, max: number }>} min/max (same dimension as the training set)\n   */\n  minmax() {\n    const minmax = Array.from(\n      Array(this.dimension),\n      () => ({ min: +Infinity, max: -Infinity }),\n    );\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          minmax[d].min += Math.min(minmax[d].min, this.phrases[i].get(t, d));\n          minmax[d].max += Math.max(minmax[d].max, this.phrases[i].get(t, d));\n        }\n      }\n    });\n    return minmax;\n  },\n};\n\n/**\n * Create a Training set, composed of a set of indexed data phrases\n * @param {Object} [params]                   Training set parameters\n * @param {Number} [params.inputDimension=1]  Dimension of the input modality\n * @param {Number} [params.outputDimension=0] Dimension of the output modality\n * (optional)\n * @param {Array<String>} [params.columnNames=null] Data column names, e.g.\n * \\['accX', 'accY', 'accZ'\\] (optional)\n * @return {TrainingSet}\n * @function\n *\n * @property {Boolean} bimodal Specifies if the training set is bimodal\n * @property {Number}  inputDimension Dimension of the input modality\n * @property {Number}  outputDimension Dimension of the output modality\n * @property {Number}  dimension Total dimension\n * @property {Array<String>} columnNames Columns names\n */\nexport default function TrainingSet({\n  inputDimension = 1,\n  outputDimension = 0,\n  columnNames = null,\n} = {}) {\n  const dimension = inputDimension + outputDimension;\n  return Object.assign(\n    Object.create(trainingSetPrototype),\n    {\n      bimodal: outputDimension > 0,\n      inputDimension,\n      outputDimension,\n      dimension,\n      columnNames: columnNames || Array(dimension).fill(''),\n      phrases: {},\n    },\n  );\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/training_set/index.js","import { isBaseModel } from '../core/model_base_mixin';\nimport euclidean from '../common/euclidean';\n\nconst kMeansTrainingPrototype = {\n  train(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) {\n      throw new Error('The training set is empty');\n    }\n\n    this.params.centers = Array.from(\n      Array(this.params.clusters),\n      () => new Array(this.params.dimension).fill(0),\n    );\n\n    // TODO: improve initialization =>\n    // https://www.slideshare.net/djempol/kmeans-initialization-15041920\n    //\n    if (this.trainingConfig.initialization === 'random') {\n      this.initializeClustersRandom(trainingSet);\n    } else if (this.trainingConfig.initialization === 'forgy') {\n      this.initializeClustersForgy(trainingSet);\n    } else if (this.trainingConfig.initialization === 'data') {\n      this.initClustersWithFirstPhrase(trainingSet);\n    } else {\n      throw new Error('Unknown K-Means initialization, must be `random`, `forgy` or `data`');\n    }\n\n    for (\n      let trainingNbIterations = 0;\n      trainingNbIterations < this.trainingConfig.maxIterations;\n      trainingNbIterations += 1\n    ) {\n      const previousCenters = this.params.centers;\n\n      this.updateCenters(previousCenters, trainingSet);\n\n      let meanClusterDistance = 0;\n      let maxRelativeCenterVariation = 0;\n      for (let k = 0; k < this.params.clusters; k += 1) {\n        for (let l = 0; l < this.params.clusters; l += 1) {\n          if (k !== l) {\n            meanClusterDistance += euclidean(\n              this.params.centers[k],\n              this.params.centers[l],\n            );\n          }\n        }\n        maxRelativeCenterVariation = Math.max(\n          euclidean(\n            previousCenters[k],\n            this.params.centers[k],\n          ),\n          maxRelativeCenterVariation,\n        );\n      }\n      meanClusterDistance /= this.params.clusters * (this.params.clusters - 1);\n      maxRelativeCenterVariation /= this.params.clusters;\n      maxRelativeCenterVariation /= meanClusterDistance;\n      if (maxRelativeCenterVariation < this.trainingConfig.relativeDistanceThreshold) break;\n    }\n    return this.params;\n  },\n\n  initClustersWithFirstPhrase(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const step = Math.floor(phrase.length / this.params.clusters);\n\n    let offset = 0;\n    for (let c = 0; c < this.params.clusters; c += 1) {\n      this.params.centers[c] = new Array(this.params.dimension).fill(0);\n      for (let t = 0; t < step; t += 1) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[c][d] += phrase.get(offset + t, d) / step;\n        }\n      }\n      offset += step;\n    }\n  },\n\n  initializeClustersRandom(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const indices = Array.from(\n      Array(phrase.length),\n      () => Math.floor(Math.random() * this.params.clusters),\n    );\n    const pointsPerCluster = indices.reduce(\n      (ppc, i) => {\n        const p = ppc;\n        p[i] += 1;\n        return p;\n      },\n      Array(this.params.clusters).fill(0),\n    );\n    for (let i = 0; i < indices.length; i += 1) {\n      const clustIdx = indices[i];\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.centers[clustIdx][d] += phrase.get(i, d);\n      }\n    }\n    this.params.centers.forEach((_, c) => {\n      this.params.centers[c] = this.params.centers[c]\n        .map(x => x / pointsPerCluster[c]);\n    });\n  },\n\n  initializeClustersForgy(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const indices = Array.from(\n      Array(this.params.clusters),\n      () => Math.floor(Math.random() * phrase.length),\n    );\n    this.params.centers = indices.map(i => phrase.getFrame(i));\n  },\n\n  updateCenters(previousCenters, trainingSet) {\n    this.params.centers = Array.from(Array(this.params.clusters), () =>\n      new Array(this.params.dimension).fill(0));\n    const numFramesPerCluster = Array(this.params.clusters).fill(0);\n    trainingSet.forEach((phrase) => {\n      for (let t = 0; t < phrase.length; t += 1) {\n        const frame = phrase.getFrame(t);\n        let minDistance = euclidean(frame, previousCenters[0]);\n        let clusterMembership = 0;\n        for (let k = 1; k < this.params.clusters; k += 1) {\n          const distance = euclidean(\n            frame,\n            previousCenters[k],\n            this.params.dimension,\n          );\n          if (distance < minDistance) {\n            clusterMembership = k;\n            minDistance = distance;\n          }\n        }\n        numFramesPerCluster[clusterMembership] += 1;\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[clusterMembership][d] += phrase.get(t, d);\n        }\n      }\n    });\n    for (let k = 0; k < this.params.clusters; k += 1) {\n      if (numFramesPerCluster[k] > 0) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[k][d] /= numFramesPerCluster[k];\n        }\n      }\n    }\n  },\n};\n\nexport default function withKMeansTraining(\n  o,\n  clusters,\n  trainingConfiguration = {},\n) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const trainingConfig = Object.assign({\n    initialization: 'random',\n    relativeDistanceThreshold: 1e-3,\n    minIterations: 5,\n    maxIterations: 100,\n  }, trainingConfiguration);\n  const model = Object.assign(o, kMeansTrainingPrototype, {\n    trainingConfig,\n  });\n  model.params.clusters = clusters;\n  return model;\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/kmeans/kmeans_training_mixin.js","const trainerPrototype = /** @lends withEMTraining */ {\n  /**\n   * Train the model from the given training set, using the\n   * Expectation-Maximisation algorithm.\n   *\n   * @param  {TrainingSet} trainingSet Training Set\n   * @return {Object} Parameters of the trained model\n   */\n  train(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) {\n      throw new Error('The training set is empty');\n    }\n\n    this.initTraining(trainingSet);\n\n    let logLikelihood = -Infinity;\n    let iterations = 0;\n    let previousLogLikelihood = logLikelihood;\n\n    while (!this.converged(iterations, logLikelihood, previousLogLikelihood)) {\n      previousLogLikelihood = logLikelihood;\n      logLikelihood = this.updateTraining(trainingSet);\n\n      const pctChg =\n        100 * Math.abs((logLikelihood - previousLogLikelihood) / previousLogLikelihood);\n      if (Number.isNaN(pctChg) && iterations > 1) {\n        throw new Error('An error occured during training');\n      }\n\n      iterations += 1;\n    }\n\n    this.terminateTraining();\n    return this.params;\n  },\n\n  /**\n   * Return `true` if the training has converged according to the criteria\n   * specified at the creation\n   *\n   * @param  {number} iteration       Current iteration\n   * @param  {number} logProb         Current log-likelihood of the training set\n   * @param  {number} previousLogProb Previous log-likelihood of the training\n   * set\n   * @return {boolean}\n   *\n   * @private\n   */\n  converged(iteration, logProb, previousLogProb) {\n    if (iteration >= this.convergenceCriteria.maxIterations) return true;\n    if (this.convergenceCriteria.maxIterations >= this.convergenceCriteria.minIterations) {\n      return iteration >= this.convergenceCriteria.maxIterations;\n    }\n    if (iteration < this.convergenceCriteria.minIterations) return false;\n    const percentChange = 100 * Math.abs((logProb - previousLogProb) / logProb);\n    return percentChange <= this.convergenceCriteria.percentChange;\n  },\n};\n\n/**\n * Add ABSTRACT training capabilities to a model for which the training process\n * use the Expectation-Maximisation (EM) algorithm. This is used in particular\n * for training GMMs and HMMs.\n *\n * The final instance needs to implement `initTraining`, `updateTraining` and\n * `terminateTraining` methods. `updateTraining` will be called until the\n * convergence criteria are met. Convergence depends on\n * - A minimum number of iterations\n * - A maximum number of iterations\n * - A threshold on the relative change of the log-likelihood of the training\n * data between successive iterations.\n *\n * @todo details\n *\n * @param  {Object} [o]                   Source object\n * @param  {Object} [convergenceCriteria] Set of convergence criteria\n * @param  {number} [convergenceCriteria.percentChange=1e-3] Threshold in % of\n * the relative change of the log-likelihood, under which the training stops.\n * @param  {number} [convergenceCriteria.minIterations=5]    minimum number of iterations\n * @param  {number} [convergenceCriteria.maxIterations=100]  maximum number of iterations\n * @return {Object}\n */\nexport default function withEMTraining(\n  o,\n  convergenceCriteria = {\n    percentChange: 1e-3,\n    minIterations: 5,\n    maxIterations: 100,\n  },\n) {\n  return Object.assign(o, trainerPrototype, { convergenceCriteria });\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/core/em_training_mixin.js","import { isBaseModel } from '../core/model_base_mixin';\nimport GaussianDistribution from '../common/gaussian_distribution';\n\n/**\n * GMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst gmmBasePrototype = /** @lends withGMMBase */ {\n  /**\n   * Allocate the training variables\n   * @private\n   */\n  allocate() {\n    this.params.components = Array.from(\n      Array(this.params.gaussians),\n      () => new GaussianDistribution(\n        this.params.inputDimension,\n        this.params.outputDimension,\n        this.params.covarianceMode,\n      ),\n    );\n    this.params.mixtureCoeffs = Array(this.params.gaussians).fill(0);\n    this.beta = new Array(this.params.gaussians).fill(0);\n  },\n\n  /**\n   * Compute the likelihood of an observation given the GMM's parameters\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}\n   */\n  likelihood(observation) {\n    let likelihood = 0;\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.beta[c] = this.componentLikelihood(observation, c);\n      likelihood += this.beta[c];\n    }\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.beta[c] /= likelihood;\n    }\n\n    return likelihood;\n  },\n\n  /**\n   * Compute the likelihood of an observation for a single component\n   * @param  {Array<Number>} observation Observation vector\n   * @param  {Number} mixtureComponent Component index\n   * @return {Number}\n   * @private\n   */\n  componentLikelihood(observation, mixtureComponent) {\n    if (mixtureComponent >= this.params.gaussians) {\n      throw new Error('The index of the Gaussian Mixture Component is out of bounds');\n    }\n    return this.params.mixtureCoeffs[mixtureComponent] *\n        this.params.components[mixtureComponent].likelihood(observation);\n  },\n\n  /**\n   * Update the inverse covariance of each Gaussian component\n   * @private\n   */\n  updateInverseCovariances() {\n    this.params.components.forEach((c) => {\n      c.updateInverseCovariance();\n    });\n    try {\n      this.params.components.forEach((c) => {\n        c.updateInverseCovariance();\n      });\n    } catch (e) {\n      throw new Error('Matrix inversion error: varianceoffset must be too small');\n    }\n  },\n\n  /**\n   * Normalize the mixing coefficients of the Gaussian mixture\n   * @private\n   */\n  normalizeMixtureCoeffs() {\n    let normConst = 0;\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      normConst += this.params.mixtureCoeffs[c];\n    }\n    if (normConst > 0) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.mixtureCoeffs[c] /= normConst;\n      }\n    } else {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      }\n    }\n  },\n\n  /**\n   * Regularize the covariances\n   * @private\n   */\n  regularize() {\n    this.params.components.forEach((c) => {\n      c.regularize(this.currentRegularization);\n    });\n  },\n};\n\n/**\n * Bimodal (regression) GMM Prototype\n * @type {Object}\n * @ignore\n */\nconst gmmBimodalPrototype = /** @lends withGMMBase */ {\n  /**\n   * Estimate the output values corresponding to the input observation, by\n   * regression given the GMM's parameters. This method is called Gaussian\n   * Mixture Regression (GMR).\n   *\n   * @param  {Array<Number>} inputObservation Observation on the input modality\n   * @return {Array<Number>} Output values (length = outputDimension)\n   */\n  regression(inputObservation) {\n    this.results.outputValues = Array(this.params.outputDimension).fill(0);\n    this.results.outputCovariance = Array(this.params.covarianceMode === 'full' ? this.params.outputDimension ** 2 : this.params.outputDimension).fill(0);\n    let tmpOutputValues;\n\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      tmpOutputValues = this.params.components[c].regression(inputObservation);\n      for (let d = 0; d < this.params.outputDimension; d += 1) {\n        this.results.outputValues[d] += this.beta[c] * tmpOutputValues[d];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n            this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n              (this.beta[c] ** 2) *\n              this.params.components[c].outputCovariance[(d * this.params.outputDimension) + d2];\n          }\n        } else {\n          this.results.outputCovariance[d] +=\n            (this.beta[c] ** 2) * this.params.components[c].outputCovariance[d];\n        }\n      }\n    }\n    return this.results.outputValues;\n  },\n};\n\n/**\n * Add basic GMM capabilities to a single-class model. This enables the\n * computation of the likelihoods and regression operations common to\n * training and prediction\n *\n * @see withGMMTraining\n * @see withGMMPrediction\n *\n * @param  {ModelBase} o Source Model\n * @return {GMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withGMMBase(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    gmmBasePrototype,\n    o.params.bimodal ? gmmBimodalPrototype : {},\n  );\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/gmm/gmm_base_mixin.js","import ModelBase from './model_base_mixin';\n\n/**\n * Multiclass Models Mixin\n * @type {Object}\n * @ignore\n */\nconst MulticlassBasePrototype = /** @lends MulticlassModelBase */{\n  /**\n   * Get the number of classes in the model\n   * @return {number} number of classes\n   */\n  size() {\n    return Object.keys(this.models).length;\n  },\n\n  /**\n   * Check if a class with the given label exists\n   * @param  {string} label Class label\n   * @return {boolean}\n   */\n  includes(label) {\n    return Object.keys(this.models).includes(label);\n  },\n\n  /**\n   * Remove a class by label\n   * @param  {string} label Class label\n   */\n  remove(label) {\n    if (this.includes(label)) {\n      delete this.models[label];\n    }\n  },\n};\n\n/**\n * Create an abstract Multiclass Model\n * @param       {number]} inputDimension  input dimension\n * @param       {number]} outputDimension output dimension\n * @param       {Object} parameters       additional parameters to copy\n * @function\n */\nexport default function MulticlassModelBase({\n  inputDimension,\n  outputDimension,\n  ...parameters\n}) {\n  return Object.assign(\n    ModelBase({ inputDimension, outputDimension, ...parameters }),\n    MulticlassBasePrototype,\n  );\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/core/multiclass_mixin.js","/**\n * Add multiclass training capabilities to a model. It takes as argument\n * the training function called to train each class of the training set.\n *\n * @param  {MulticlassModelBase} o Source model\n * @param  {Function}  trainingFunction Training function for a single class\n * @return {MulticlassModelBase}\n */\nexport default function withMulticlassTraining(\n  o,\n  trainingFunction,\n) {\n  return Object.assign(\n    o,\n    /** @lends withMulticlassTraining */ {\n      /**\n       * Train the model, optionally specifying a set of classes to train\n       *\n       * @param  {TrainingSet} trainingSet   Training data set\n       * @param  {undefined|Array<String>} [labels=undefined] Labels\n       * corresponding to the classes to be trained (all if unspecified)\n       * @return {Object} the parameters of the trained model\n       *\n       * @throws {Error} if the training set is empty\n       * @throws {Error} if one of the specified class does not exist\n       */\n      train(trainingSet, labels = undefined) {\n        if (!trainingSet || trainingSet.empty()) {\n          throw new Error('The training set is empty');\n        }\n        if (labels) {\n          labels.forEach((l) => {\n            if (!this.includes(l)) {\n              throw new Error(`Class labeled ${l} does not exist`);\n            }\n          });\n        }\n\n        this.params.classes = {};\n        const labs = labels || trainingSet.labels();\n        labs.forEach((label) => {\n          const ts = trainingSet.getPhrasesOfClass(label);\n          // console.log(ts);\n          this.params.classes[label] = trainingFunction(ts);\n        });\n        return this.params;\n      },\n    },\n  );\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/core/multiclass_training_mixin.js","import { isBaseModel } from './model_base_mixin';\nimport CircularBuffer from '../common/circular_buffer';\n\n/**\n * Prototype for models with prediction capabilities\n * @param  {Boolean} bimodal Specifies whether the model is bimodal\n * @return {Object}\n * @ignore\n */\nconst predictionBasePrototype = bimodal => (/** @lends withAbtractPrediction */{\n  /**\n   * Likelihood Buffer\n   * @type {CircularBuffer}\n   * @private\n   */\n  likelihoodBuffer: CircularBuffer(1),\n\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @param {Number} [lw] Size (in frames) of the likelihood smoothing window\n   */\n  setLikelihoodWindow(lw) {\n    this.likelihoodWindow = lw;\n    this.likelihoodBuffer = CircularBuffer(lw);\n  },\n\n  /**\n   * Reset the prediction process\n   * @return {Modelbase} the model\n   */\n  reset() {\n    this.likelihoodBuffer.clear();\n    return this;\n  },\n\n  /**\n   * Update the predictions with a new observation\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Object} Prediction results\n   *\n   * @todo document results data structure\n   */\n  predict(observation) {\n    const likelihood = this.likelihood(observation);\n    if (bimodal) {\n      this.regression(observation);\n    }\n    this.updateResults(likelihood);\n    return this.results;\n  },\n\n  /**\n   * Update the prediction results\n   * @param  {Number} instantLikelihood Instantaneous likelihood\n   * @private\n   */\n  updateResults(instantLikelihood) {\n    this.results.instantLikelihood = instantLikelihood;\n    this.likelihoodBuffer.push(Math.log(instantLikelihood));\n    this.results.logLikelihood = 0;\n    const bufSize = this.likelihoodBuffer.length;\n    for (let i = 0; i < bufSize; i += 1) {\n      this.results.logLikelihood += this.likelihoodBuffer.get(i);\n    }\n    this.results.logLikelihood /= bufSize;\n  },\n});\n\n/**\n * Add ABSTRACT prediction capabilities to an existing model\n * @param  {Modelbase} o                 Source model\n * @param  {Number} [likelihoodWindow=1] Size of the likelihood smoothing window\n * @return {Modelbase}\n */\nexport default function withAbtractPrediction(o, likelihoodWindow = 1) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const results = Object.assign(\n    { instantLikelihood: 0, logLikelihood: 0 },\n    o.params.bimodal ? { outputValues: [], outputCovariance: [] } : {},\n  );\n  return Object.assign(\n    o,\n    predictionBasePrototype(o.params.bimodal),\n    { results, likelihoodBuffer: CircularBuffer(likelihoodWindow) },\n  );\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/core/prediction_mixin.js","/**\n * Check if the specification is respected for a given parameter and value,\n * and clip if relevant.\n *\n * @ignore\n *\n * @param  {String}        model      Stream Operator Name (for logging)\n * @param  {String}        parameter     Attribute name\n * @param  {Specification} specification Attribute specification\n * @param  {*}             value         Attribute value\n * @return {*}                           Type-checked parameter value\n */\nfunction checkSpec(model, parameter, specification, value) {\n  if (!specification) return;\n  if (specification.constructor === Array && !specification.includes(value)) {\n    throw new Error(`Attribute '${parameter}' (value: '${value}') is not allowed for model '${model}' (options: [${specification}]).`);\n  } else if (specification.constructor === Object) {\n    if (Object.keys(specification).includes('min') && value < specification.min) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is inferior to the minimum required value of ${specification.min} for model '${model}'.`);\n    }\n    if (Object.keys(specification).includes('max') && value > specification.max) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is superior to the maximum required value of ${specification.min} for model '${model}'.`);\n    }\n  } else if (typeof specification === 'function') {\n    if (!specification(value)) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is incompatible with model '${model}'.`);\n    }\n  }\n}\n\n/**\n * Check the parameters of a model and return the parameters of the\n * output stream.\n *\n * The specification should be a structure of the form:\n * ```\n * const streamSpecification = {\n *   <parameter name>: {\n *     required: <boolean>,\n *     check: <null || Array || { min: <minimum value>, max: <maximum value>} || Function >,\n *     transform: Function,\n *   },\n * };\n * ```\n *\n * @param  {String} model      Name of the model for logging\n * @param  {Object} specification I/O Stream Specification\n * @param  {Object} values        Attributes of the input stream\n * @return {Object}               Attributes of the output stream\n *\n * @example\n * import setupStreamAttributes from 'stream';\n *\n * const specification = {\n *   type: {\n *     required: false,\n *     check: null,\n *     transform: x => x || null,\n *   },\n *   format: {\n *     required: true,\n *     check: ['scalar', 'vector'],\n *     transform: x => x,\n *   },\n *   size: {\n *     required: true,\n *     check: { min: 1 },\n *     transform: x => 2 * x,\n *   },\n *   stuff: {\n *     required: true,\n *     check: x => Math.log2(x) === Math.floor(Math.log2(x)),\n *     transform: x => Math.log2(x),\n *   },\n * };\n *\n * const values = {\n *   type: 'anything',\n *   format: 'vector',\n *   size: 3,\n *   stuff: 8,\n *   another: 'one',\n * };\n *\n * setupStreamAttributes('module name', specification, values);\n * // Returns:\n * // {\n * //   type: 'anything',\n * //   format: 'vector',\n * //   size: 6,\n * //   stuff: 3,\n * //   another: 'one',\n * // }\n */\nexport default function validateParameters(model, specification, values) {\n  const parameters = Object.assign({}, values);\n  Object.keys(specification).forEach((attr) => {\n    const spec = specification[attr];\n\n    // Check for required parameters\n    if (spec.required && !Object.keys(values).includes(attr)) {\n      throw new Error(`Stream parameter '${attr}' is required for model '${model}'.`);\n    }\n\n    // Check the validity of the input parameters\n    checkSpec(model, attr, spec.check, values[attr]);\n\n    parameters[attr] = spec.transform ?\n      spec.transform(values[attr]) :\n      values[attr];\n  });\n  return parameters;\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/common/validation.js","import { isBaseModel } from './model_base_mixin';\n\n/**\n * Multiclass prediction mixin\n * @type {Object}\n * @ignore\n */\nconst MulticlassPredictionBasePrototype = /** @lends withMulticlassPrediction */ {\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @return {Number}\n   */\n  getLikelihoodWindow() {\n    return this.likelihoodWindow;\n  },\n\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @param {Number} [lw] Size (in frames) of the likelihood smoothing window\n   */\n  setLikelihoodWindow(lw) {\n    this.likelihoodWindow = lw;\n    Object.keys(this.models).forEach((label) => {\n      this.models[label].setLikelihoodWindow(lw);\n    });\n  },\n\n  /**\n   * Reset the prediction process. This is particularly important for temporal\n   * models such as HMMs, that depends on previous observations.\n   */\n  reset() {\n    Object.values(this.models).forEach(m => m.reset());\n    this.results = {\n      labels: [],\n      instantLikelihoods: [],\n      smoothedLikelihoods: [],\n      smoothedLogLikelihoods: [],\n      smoothedNormalizedLikelihoods: [],\n      likeliest: null,\n      classes: {},\n    };\n    if (this.params.bimodal) {\n      this.resetBimodal();\n    }\n  },\n\n  /**\n   * Make a prediction from a new observation (updates the results member)\n   * @param  {Array<Number>} observation Observation vector\n   */\n  predict(observation) {\n    Object.values(this.models).forEach(m => m.predict(observation));\n    this.updateResults();\n  },\n\n  updateResults() {\n    const labs = Object.keys(this.models).sort();\n    this.results.labels = labs;\n    let normInstant = 0;\n    let normSmoothed = 0;\n    let maxLogLikelihood = -Infinity;\n    this.results.classes = labs\n      .map((lab, i) => {\n        this.results.instantLikelihoods[i] =\n          this.models[lab].results.instantLikelihood;\n        this.results.smoothedLogLikelihoods[i] =\n          this.models[lab].results.logLikelihood;\n        this.results.smoothedLikelihoods[i] =\n          Math.exp(this.results.smoothedLogLikelihoods[i]);\n        normInstant += this.results.instantLikelihoods[i];\n        normSmoothed += this.results.smoothedLikelihoods[i];\n        if (this.results.smoothedLogLikelihoods[i] > maxLogLikelihood) {\n          maxLogLikelihood = this.results.smoothedLogLikelihoods[i];\n          this.results.likeliest = lab;\n        }\n        return { [lab]: this.models[lab].results };\n      })\n      .reduce((o, x) => ({ ...o, ...x }), {});\n    this.results.smoothedNormalizedLikelihoods =\n      this.results.smoothedLikelihoods.map(x => x / normSmoothed);\n    this.results.instantNormalizedLikelihoods =\n      this.results.instantLikelihoods.map(x => x / normInstant);\n    if (this.params.bimodal) {\n      this.updateRegressionResults();\n    }\n  },\n};\n\nconst MulticlassPredictionBimodalPrototype = {\n  resetBimodal() {\n    this.results.outputValues = [];\n    this.results.outputCovariance = [];\n  },\n\n  updateRegressionResults() {\n    if (this.params.multiClassRegressionEstimator === 'likeliest') {\n      this.results.outputValues =\n        this.models[this.results.likeliest].results.outputValues;\n      this.results.outputCovariance =\n        this.models[this.results.likeliest].results.outputCovariance;\n    } else if (this.params.multiClassRegressionEstimator === 'mixture') {\n      this.results.outputValues = Array(this.outputDimension).fill(0);\n      this.results.outputCovariance = Array(this.outputDimension ** (this.configuration.covarianceMode === 'full' ? 2 : 1)).fill(0);\n      this.results.labels.forEach((lab) => {\n        this.results.outputValues.map((x, i) => x + (\n          this.results.smoothedNormalizedLikelihoods[i] *\n          this.models[lab].results.outputValues[i]\n        ));\n        this.results.outputCovariance.map((x, i) => x + (\n          this.results.smoothedNormalizedLikelihoods[i] *\n          this.models[lab].results.outputCovariance[i]\n        ));\n      });\n    } else {\n      throw new Error('Unknown regression estimator, use `likeliest` or `mixture`');\n    }\n  },\n};\n\n/**\n * Add multiclass prediction capabilities to a multiclass model\n * @param  {MulticlassModelBase} o Source model\n * @param  {String} [multiClassRegressionEstimator='likeliest'] Type of\n * regression estimator:\n * - `likeliest` selects the output values from the likeliest class\n * - `mixture` computes the output values as the weighted sum of the\n * contributions of each class, weighed by their normalized likelihood\n * @return {MulticlassPredictionBasePrototype}\n * @function\n */\nexport default function withMulticlassPrediction(o, multiClassRegressionEstimator = 'likeliest') {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const m = Object.assign(\n    o,\n    MulticlassPredictionBasePrototype,\n    o.params.bimodal ? MulticlassPredictionBimodalPrototype : {},\n  );\n  m.params.multiClassRegressionEstimator = multiClassRegressionEstimator;\n  return m;\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/core/multiclass_prediction_mixin.js","/**\n * Data Phrase Prototype\n * @ignore\n */\nconst phrasePrototype = /** @lends Phrase */ {\n  /**\n   * Get the value at a given index and dimension\n   * @param  {Number} index index\n   * @param  {Number} dim   dimension\n   * @return {Number}\n   */\n  get(index, dim) {\n    if (typeof index !== 'number' || Math.floor(index) !== index) {\n      throw new Error('The index must be an integer');\n    }\n    if (dim >= this.dimension) {\n      throw new Error('Phrase: dimension out of bounds');\n    }\n    if (this.bimodal) {\n      if (dim < this.inputDimension) {\n        if (index >= this.inputData.length) {\n          throw new Error('Phrase: index out of bounds');\n        }\n        return this.inputData[index][dim];\n      }\n      if (index >= this.outputData.length) {\n        throw new Error('Phrase: index out of bounds');\n      }\n      return this.outputData[index][dim - this.inputDimension];\n    }\n    if (index >= this.length) {\n      throw new Error('Phrase: index out of bounds');\n    }\n    if (!this.inputData[index]) {\n      throw new Error('WTF?');\n    }\n    return this.inputData[index][dim];\n  },\n\n  /**\n   * Get the data frame at a given index\n   * @param  {Number} index index\n   * @return {Array<number>}\n   * @throws {Error} if the index is out of bounds\n   */\n  getFrame(index) {\n    if (index >= this.length) {\n      throw new Error('Phrase: index out of bounds');\n    }\n    if (this.bimodal) {\n      return this.inputData[index].concat(this.outputData[index]);\n    }\n    return this.inputData[index];\n  },\n\n  /**\n   * Push an observation vector to the phrase\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the observation's dimension does not match the\n   * dimension of the training set\n   */\n  push(observation) {\n    // console.log('push:', observation);\n    if (observation.length !== this.dimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    if (this.bimodal) {\n      this.inputData.push(observation.slice(0, this.inputDimension));\n      this.outputData.push(observation.slice(this.inputDimension, this.dimension));\n    } else {\n      this.inputData.push(observation);\n    }\n\n    this.length += 1;\n  },\n\n  /**\n   * Push an observation to the input modality only\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the phrase is not bimodal\n   * @throws {Error} if the observation's dimension does not match the\n   * input dimension of the training set\n   */\n  pushInput(observation) {\n    if (!this.bimodal) {\n      throw new Error('this phrase is unimodal, use `push`');\n    }\n    if (observation.size() !== this.inputDimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    this.inputData.push(observation);\n    this.trim();\n  },\n\n  /**\n   * Push an observation to the output modality only\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the phrase is not bimodal\n   * @throws {Error} if the observation's dimension does not match the\n   * output dimension of the training set\n   */\n  pushOutput(observation) {\n    if (!this.bimodal) {\n      throw new Error('this phrase is unimodal, use `push`');\n    }\n    if (observation.size() !== this.outputDimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    this.outputData.push(observation);\n    this.trim();\n  },\n\n  /**\n   * Clear the phrase's data\n   */\n  clear() {\n    this.length = 0;\n    this.inputData = [];\n    this.outputData = [];\n  },\n\n  /**\n   * Clear the phrase's input data\n   */\n  clearInput() {\n    this.inputData = [];\n    this.trim();\n  },\n\n  /**\n   * Clear the phrase's output data\n   */\n  clearOutput() {\n    this.outputData = [];\n    this.trim();\n  },\n\n  /**\n   * Compute the mean of the phrase (across time)\n   * @return {Array<number>} The mean vector (same dimension as the\n   * training set)\n   */\n  mean() {\n    const mean = Array(this.dimension).fill(0);\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        mean[d] += this.get(t, d);\n      }\n      mean[d] /= this.length;\n    }\n    return mean;\n  },\n\n  /**\n   * Compute the standard deviation of the phrase (across time)\n   * @return {Array<number>} The standard deviation vector (same dimension as\n   * the training set)\n   */\n  standardDeviation() {\n    const stddev = Array(this.dimension).fill(0);\n    const mean = this.mean();\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        stddev[d] += (this.get(t, d) - mean[d]) * (this.get(t, d) - mean[d]);\n      }\n      stddev[d] /= this.length;\n      stddev[d] = Math.sqrt(stddev[d]);\n    }\n    return stddev;\n  },\n\n  /**\n   * Compute the minimum and maximum of the phrase (across time)\n   * @return {Array<{ min: number, max: number }>} The min/max vector (same\n   * dimension as the training set)\n   */\n  minmax() {\n    const minmax = Array.from(\n      Array(this.dimension),\n      () => ({ min: +Infinity, max: -Infinity }),\n    );\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        minmax[d].min = Math.min(this.get(t, d), minmax[d].min);\n        minmax[d].max = Math.max(this.get(t, d), minmax[d].max);\n      }\n    }\n    return minmax;\n  },\n\n  /**\n   * Trim the phrase length to the minimum of the input and output lengths\n   * @private\n   */\n  trim() {\n    if (this.bimodal) {\n      this.length = Math.min(this.inputData.length, this.outputData.length);\n    }\n  },\n};\n\n/**\n * Create a data phrase, potentially bimodal. Phrases are data structures for\n * temporal data (e.g. gestures), used to constitute training sets.\n *\n * @param {Object} [params]                   Phrase parameters\n * @param {Number} [params.inputDimension=1]  Dimension of the input modality\n * @param {Number} [params.outputDimension=0] Dimension of the output modality\n * (optional)\n * @param {Array<String>} [params.columnNames=null] Data column names, e.g.\n * \\['accX', 'accY', 'accZ'\\] (optional)\n * @param {String} [params.label='']          Phrase label\n * @return {Phrase}\n * @function\n *\n * @property {Boolean} bimodal Specifies if the phrase is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} length Phrase length (number of frames)\n * @property {String} label Phrase label\n * @property {Array<String>} columnNames Columns names\n */\nexport default function Phrase({\n  inputDimension = 1,\n  outputDimension = 0,\n  columnNames = null,\n  label = '',\n} = {}) {\n  const dimension = inputDimension + outputDimension;\n  return Object.assign(\n    Object.create(phrasePrototype),\n    {\n      bimodal: outputDimension > 0,\n      inputDimension,\n      outputDimension,\n      dimension,\n      length: 0,\n      label,\n      inputData: [],\n      outputData: [],\n      columnNames: columnNames || Array(dimension).fill(''),\n    },\n  );\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/training_set/phrase.js","import ModelBase from '../core/model_base_mixin';\nimport withKMeansTraining from './kmeans_training_mixin';\n\n/**\n * Train a K-Means model.\n *\n * @todo K-Means details\n *\n * @param  {TrainingSet} trainingSet           training set\n * @param  {number} clusters                   Number of clusters\n * @param  {Object} [trainingConfig=undefined] Training configuration\n * @return {Object}                            K-Means parameters\n */\nexport default function trainKmeans(\n  trainingSet,\n  clusters,\n  trainingConfig = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withKMeansTraining(\n    ModelBase({\n      inputDimension,\n      outputDimension,\n    }),\n    clusters,\n    trainingConfig,\n  );\n  return model.train(trainingSet);\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/kmeans/index.js","/**\n * Compute the euclidean distance between to vectors\n * @param  {Array} v1\n * @param  {Array} v2\n * @return {number}\n */\nexport default function euclidean(v1, v2) {\n  return Math.sqrt(v1\n    .map((x1, i) => (x1 - v2[i]) ** 2)\n    .reduce((a, x) => (a + x), 0));\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/common/euclidean.js","import Matrix from './matrix';\n\n/**\n * Gaussian Distribution Prototype\n *\n * @type {Object}\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n *\n * @ignore\n */\nconst baseGaussianPrototype = /** @lends GaussianDistribution */ {\n  /**\n   * Allocate the distribution\n   * @private\n   */\n  allocate() {\n    this.mean = new Array(this.dimension).fill(0);\n    if (this.covarianceMode === 'full') {\n      this.covariance = new Array(this.dimension ** 2).fill(0);\n      this.inverseCovariance = new Array(this.dimension ** 2).fill(0);\n    } else {\n      this.covariance = new Array(this.dimension).fill(0);\n      this.inverseCovariance = new Array(this.dimension).fill(0);\n    }\n    if (this.bimodal) {\n      this.allocateBimodal();\n    }\n  },\n\n  /**\n   * @brief Estimate the likelihood of an observation vector.\n   *\n   * If the distribution is bimodal an the observation is a vector of the size\n   * of the input modality, the likelihood is computed only on the\n   * distribution for the input modality\n   *\n   * @param  {array} observation data observation\n   * @return {number}\n   */\n  likelihood(observation) {\n    if (this.covarianceDeterminant === 0) {\n      throw new Error('Covariance Matrix is not invertible');\n    }\n    if (this.bimodal && observation.length === this.inputDimension) {\n      return this.inputLikelihood(observation);\n    }\n    if (observation.length !== this.dimension) {\n      throw new Error(`GaussianDistribution: observation has wrong dimension. Expected \\`${this.dimension}\\`, got \\`${observation.length}\\``);\n    }\n\n    let euclideanDistance = 0;\n    if (this.covarianceMode === 'full') {\n      for (let l = 0; l < this.dimension; l += 1) {\n        let tmp = 0;\n        for (let k = 0; k < this.dimension; k += 1) {\n          tmp += this.inverseCovariance[(l * this.dimension) + k] *\n            (observation[k] - this.mean[k]);\n        }\n        euclideanDistance += (observation[l] - this.mean[l]) * tmp;\n      }\n    } else {\n      for (let l = 0; l < this.dimension; l += 1) {\n        euclideanDistance += this.inverseCovariance[l] *\n          (observation[l] - this.mean[l]) *\n          (observation[l] - this.mean[l]);\n      }\n    }\n\n    let p = Math.exp(-0.5 * euclideanDistance) /\n      Math.sqrt(this.covarianceDeterminant * ((2 * Math.PI) ** this.dimension));\n\n    if (p < 1e-180 || Number.isNaN(p) || Math.abs(p) === +Infinity) {\n      p = 1e-180;\n    }\n\n    return p;\n  },\n\n  /**\n   * Regularize the distribution, given a regularization vector of the same\n   * dimension. Regularization adds the vector to the variance of the\n   * distribution.\n   *\n   * @param  {Array} regularization regularization vector\n   */\n  regularize(regularization) {\n    if (this.covarianceMode === 'full') {\n      for (let d = 0; d < this.dimension; d += 1) {\n        this.covariance[(d * this.dimension) + d] += regularization[d];\n      }\n    } else {\n      for (let d = 0; d < this.dimension; d += 1) {\n        this.covariance[d] += regularization[d];\n      }\n    }\n  },\n\n  /**\n   * Update the inverse covariance of the distribution\n   * @private\n   */\n  updateInverseCovariance() {\n    if (this.covarianceMode === 'full') {\n      const covMatrix = Matrix(this.dimension, this.dimension);\n\n      covMatrix.data = this.covariance.slice();\n      const inv = covMatrix.pinv();\n      this.covarianceDeterminant = inv.determinant;\n      this.inverseCovariance = inv.matrix.data;\n    } else { // DIAGONAL COVARIANCE\n      this.covarianceDeterminant = 1;\n      for (let d = 0; d < this.dimension; d += 1) {\n        if (this.covariance[d] <= 0) {\n          throw new Error('Non-invertible matrix');\n        }\n        this.inverseCovariance[d] = 1 / this.covariance[d];\n        this.covarianceDeterminant *= this.covariance[d];\n      }\n    }\n    if (this.bimodal) {\n      this.updateInverseCovarianceBimodal();\n    }\n  },\n\n  /**\n   * Convert to an ellipse allong two dimensions\n   *\n   * @param  {number} dimension1 first dimension\n   * @param  {number} dimension2 second dimension\n   * @return {Ellipse}\n   */\n  toEllipse(dimension1, dimension2) {\n    if (dimension1 >= this.dimension || dimension2 >= this.dimension) {\n      throw new Error('dimensions out of range');\n    }\n\n    const gaussianEllipse = {\n      x: 0,\n      y: 0,\n      width: 0,\n      height: 0,\n      angle: 0,\n    };\n    gaussianEllipse.x = this.mean[dimension1];\n    gaussianEllipse.y = this.mean[dimension2];\n\n    // Represent 2D covariance with square matrix\n    // |a b|\n    // |b c|\n    let a;\n    let b;\n    let c;\n    if (this.covarianceMode === 'full') {\n      a = this.covariance[(dimension1 * this.dimension) + dimension1];\n      b = this.covariance[(dimension1 * this.dimension) + dimension2];\n      c = this.covariance[(dimension2 * this.dimension) + dimension2];\n    } else {\n      a = this.covariance[dimension1];\n      b = 0;\n      c = this.covariance[dimension2];\n    }\n\n    // Compute Eigen Values to get width, height and angle\n    const trace = a + c;\n    const determinant = (a * c) - (b * b);\n    const eigenVal1 = 0.5 * (trace + Math.sqrt((trace ** 2) - (4 * determinant)));\n    const eigenVal2 = 0.5 * (trace - Math.sqrt((trace ** 2) - (4 * determinant)));\n    gaussianEllipse.width = Math.sqrt(5.991 * eigenVal1);\n    gaussianEllipse.height = Math.sqrt(5.991 * eigenVal2);\n    gaussianEllipse.angle = Math.atan(b / (eigenVal1 - c));\n    if (Number.isNaN(gaussianEllipse.angle)) {\n      gaussianEllipse.angle = Math.PI / 2;\n    }\n\n    return gaussianEllipse;\n  },\n\n  /**\n   * Modify the distribution along two dimensions given the equivalent values\n   * as an Ellipse representation.\n   *\n   * @param  {Ellipse} gaussianEllipse The Ellipse corresponding to the 2D\n   * covariance along the two target dimensions\n   * @param  {number} dimension1      first dimension\n   * @param  {number} dimension2      second dimension\n   */\n  fromEllipse(gaussianEllipse, dimension1, dimension2) {\n    if (dimension1 >= this.dimension || dimension2 >= this.dimension) {\n      throw new Error('dimensions out of range');\n    }\n\n    this.mean[dimension1] = gaussianEllipse.x;\n    this.mean[dimension2] = gaussianEllipse.y;\n\n    const eigenVal1 = (gaussianEllipse.width * gaussianEllipse.width) / 5.991;\n    const eigenVal2 = (gaussianEllipse.height * gaussianEllipse.height) / 5.991;\n    const tantheta = Math.tan(gaussianEllipse.angle);\n    const b = ((eigenVal1 - eigenVal2) * tantheta) / ((tantheta ** 2) + 1);\n    const c = eigenVal1 - (b / tantheta);\n    const a = eigenVal2 + (b / tantheta);\n\n    if (this.covarianceMode === 'full') {\n      this.covariance[(dimension1 * this.dimension) + dimension1] = a;\n      this.covariance[(dimension1 * this.dimension) + dimension2] = b;\n      this.covariance[(dimension2 * this.dimension) + dimension1] = b;\n      this.covariance[(dimension2 * this.dimension) + dimension2] = c;\n    } else {\n      this.covariance[dimension1] = a;\n      this.covariance[dimension2] = c;\n    }\n    this.updateInverseCovariance();\n  },\n};\n\n/**\n * Bimodal Gaussian Distribution Prototype, for Regression purposes\n *\n * @type {Object}\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n * @property {Array}   inverseCovarianceInput Inverse covariance of the input\n * modality\n *\n * @ignore\n */\nconst bimodalGaussianPrototype = /** @lends GaussianDistribution */ {\n  /**\n   * Allocate the distribution\n   * @private\n   */\n  allocateBimodal() {\n    if (this.covarianceMode === 'full') {\n      this.inverseCovarianceInput = new Array(this.inputDimension ** 2).fill(0);\n    } else {\n      this.inverseCovarianceInput = new Array(this.inputDimension).fill(0);\n    }\n  },\n\n  /**\n   * Estimate the likelihood of an observation for the input modality only.\n   * Called by `likelihood` when relevant.\n   * @param  {Array} inputObservation observation (input modality only)\n   * @return {number}\n   * @private\n   */\n  inputLikelihood(inputObservation) {\n    if (this.covarianceDeterminantInput === 0) {\n      throw new Error('Covariance Matrix of input modality is not invertible');\n    }\n\n    let euclideanDistance = 0;\n    if (this.covarianceMode === 'full') {\n      for (let l = 0; l < this.inputDimension; l += 1) {\n        let tmp = 0;\n        for (let k = 0; k < this.inputDimension; k += 1) {\n          tmp += this.inverseCovarianceInput[(l * this.inputDimension) + k] *\n            (inputObservation[k] - this.mean[k]);\n        }\n        euclideanDistance += (inputObservation[l] - this.mean[l]) * tmp;\n      }\n    } else {\n      for (let l = 0; l < this.inputDimension; l += 1) {\n        euclideanDistance += this.inverseCovariance[l] *\n          (inputObservation[l] - this.mean[l]) *\n          (inputObservation[l] - this.mean[l]);\n      }\n    }\n\n    let p = Math.exp(-0.5 * euclideanDistance) /\n               Math.sqrt(this.covarianceDeterminantInput *\n                    ((2 * Math.PI) ** this.inputDimension));\n\n    if (p < 1e-180 || Number.isNaN(p) || Math.abs(p) === +Infinity) p = 1e-180;\n\n    return p;\n  },\n\n  /**\n   * Estimate the output values associated with an input observation by\n   * regression, given the distribution parameters.\n   *\n   * @todo Clarify the maths here.\n   *\n   * @param  {Array} inputObservation observation (input modality only)\n   * @return {Array} Output values\n   */\n  regression(inputObservation) {\n    const outputDimension = this.dimension - this.inputDimension;\n    const prediction = Array(outputDimension).fill(0);\n\n    if (this.covarianceMode === 'full') {\n      for (let d = 0; d < outputDimension; d += 1) {\n        prediction[d] = this.mean[this.inputDimension + d];\n        for (let e = 0; e < this.inputDimension; e += 1) {\n          let tmp = 0;\n          for (let f = 0; f < this.inputDimension; f += 1) {\n            tmp += this.inverseCovarianceInput[(e * this.inputDimension) + f] *\n              (inputObservation[f] - this.mean[f]);\n          }\n          prediction[d] += tmp *\n            this.covariance[((d + this.inputDimension) * this.dimension) + e];\n        }\n      }\n    } else {\n      for (let d = 0; d < outputDimension; d += 1) {\n        prediction[d] = this.mean[this.inputDimension + d];\n      }\n    }\n    return prediction;\n  },\n\n  /**\n   * Update the inverse covariance\n   * @private\n   */\n  updateInverseCovarianceBimodal() {\n    if (this.covarianceMode === 'full') {\n      const covMatrixInput = Matrix(this.inputDimension, this.inputDimension);\n      for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n        for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n          covMatrixInput.data[(d1 * this.inputDimension) + d2] =\n            this.covariance[(d1 * this.dimension) + d2];\n        }\n      }\n      const invInput = covMatrixInput.pinv();\n      this.covarianceDeterminantInput = invInput.determinant;\n      this.inverseCovarianceInput = invInput.matrix.data;\n    } else { // DIAGONAL COVARIANCE\n      this.covarianceDeterminantInput = 1;\n      for (let d = 0; d < this.inputDimension; d += 1) {\n        if (this.covariance[d] <= 0) {\n          throw new Error('Non-invertible matrix');\n        }\n        this.inverseCovarianceInput[d] = 1 / this.covariance[d];\n        this.covarianceDeterminantInput *= this.covariance[d];\n      }\n    }\n    this.updateOutputCovariance();\n  },\n\n  /**\n   * Update the output covariance\n   * @private\n   */\n  updateOutputCovariance() {\n    if (this.covarianceMode === 'diagonal') {\n      this.outputCovariance = this.covariance.slice(0, this.inputDimension);\n      return;\n    }\n\n    // CASE: FULL COVARIANCE\n    const covMatrixInput = Matrix(this.inputDimension, this.inputDimension);\n    for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n        covMatrixInput.data[(d1 * this.inputDimension) + d2] =\n          this.covariance[(d1 * this.dimension) + d2];\n      }\n    }\n    const inv = covMatrixInput.pinv();\n    const covarianceGS = Matrix(this.inputDimension, this.outputDimension);\n    for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n        covarianceGS.data[(d1 * this.outputDimension) + d2] =\n          this.covariance[(d1 * this.dimension) + this.inputDimension + d2];\n      }\n    }\n    const covarianceSG = Matrix(this.outputDimension, this.inputDimension);\n    for (let d1 = 0; d1 < this.outputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n        covarianceSG.data[(d1 * this.inputDimension) + d2] =\n          this.covariance[((this.inputDimension + d1) * this.dimension) + d2];\n      }\n    }\n    const tmptmptmp = inv.matrix.product(covarianceGS);\n    const covarianceMod = covarianceSG.product(tmptmptmp);\n    this.outputCovariance = Array(this.outputDimension ** 2).fill(0);\n    for (let d1 = 0; d1 < this.outputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n        this.outputCovariance[(d1 * this.outputDimension) + d2] =\n          this.covariance[((this.inputDimension + d1) * this.dimension) +\n            this.inputDimension + d2] -\n            covarianceMod.data[(d1 * this.outputDimension) + d2];\n      }\n    }\n  },\n};\n\n/**\n * Multivariate Gaussian Distribution factory function.\n * Full covariance, optionally multimodal with support for regression.\n *\n * @function\n * @param {Number} [inputDimension=1]      Dimension of the input modality\n * @param {Number} [outputDimension=0]     Dimension of the output\n * modality (positive for regression, otherwise 0 for recognition).\n * @param {String} [covarianceMode='full'] covariance mode (full vs\n * diagonal)\n * @return {baseGaussianPrototype|bimodalGaussianPrototype}\n *\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n */\nexport default function GaussianDistribution(\n  inputDimension = 1,\n  outputDimension = 0,\n  covarianceMode = 'full',\n) {\n  const bimodal = outputDimension > 0;\n  const dimension = inputDimension + outputDimension;\n  const proto = bimodal ?\n    Object.assign({}, baseGaussianPrototype, bimodalGaussianPrototype) :\n    baseGaussianPrototype;\n  const data = Object.assign(\n    {\n      bimodal,\n      dimension,\n      inputDimension,\n      outputDimension,\n      covarianceMode,\n      covarianceDeterminant: 0,\n    },\n    bimodal ? { covarianceDeterminantInput: 0 } : {},\n  );\n  const dist = Object.assign(\n    Object.create(proto),\n    data,\n  );\n  dist.allocate();\n  return dist;\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/common/gaussian_distribution.js","/* eslint-disable no-use-before-define */\nconst kEpsilonPseudoInverse = 1.0e-9;\n\n/**\n * Matrix Prototype\n * @type {Object}\n * @property {Array} data Matrix data\n * @property {Number} ncols Number of columns\n * @property {Number} nrows Number of rows\n *\n * @ignore\n */\nconst matrixPrototype = /** @lends Matrix */ {\n  /**\n   * Compute the Sum of the matrix\n   * @return {Number} Sum of all elements in the matrix\n   */\n  sum() {\n    return this.data.reduce((a, b) => a + b, 0);\n  },\n\n  /**\n   * Compute the transpose matrix\n   * @return {Matrix}\n   */\n  transpose() {\n    const out = Matrix(this.ncols, this.nrows);\n    for (let i = 0; i < this.ncols; i += 1) {\n      for (let j = 0; j < this.nrows; j += 1) {\n        out.data[(i * this.nrows) + j] = this.data[(j * this.ncols) + i];\n      }\n    }\n    return out;\n  },\n\n  /**\n   * Compute the product of matrices\n   * @param  {Matrix} mat Second matrix\n   * @return {Matrix}     Product of the current matrix by `mat`\n   */\n  product(mat) {\n    if (this.ncols !== mat.nrows) {\n      throw new Error('Wrong dimensions for matrix product');\n    }\n    const out = Matrix(this.nrows, mat.ncols);\n    for (let i = 0; i < this.nrows; i += 1) {\n      for (let j = 0; j < mat.ncols; j += 1) {\n        out.data[(i * mat.ncols) + j] = 0;\n        for (let k = 0; k < this.ncols; k += 1) {\n          out.data[(i * mat.ncols) + j] +=\n            this.data[(i * this.ncols) + k] * mat.data[(k * mat.ncols) + j];\n        }\n      }\n    }\n    return out;\n  },\n\n  /**\n   * Compute the Pseudo-Inverse of a Matrix\n   * @param  {Number} determinant Determinant (computed with the inversion)\n   * @return {Matrix}             Pseudo-inverse of the matrix\n   */\n  pinv() {\n    if (this.nrows === this.ncols) {\n      return this.gaussJordanInverse();\n    }\n\n    const transp = this.transpose();\n    if (this.nrows >= this.ncols) {\n      const prod = transp.product(this);\n      const { determinant, matrix: dst } = prod.gaussJordanInverse();\n      return { determinant, matrix: dst.product(transp) };\n    }\n    const prod = this.product(transp);\n    const { determinant, matrix: dst } = prod.gaussJordanInverse();\n    return { determinant, matrix: transp.product(dst) };\n  },\n\n  /**\n   * Compute the Gauss-Jordan Inverse of a Square Matrix\n   * !!! Determinant (computed with the inversion\n   * @private\n   */\n  gaussJordanInverse() {\n    if (this.nrows !== this.ncols) {\n      throw new Error('Gauss-Jordan inversion: Cannot invert Non-square matrix');\n    }\n    let determinant = 1;\n    const mat = Matrix(this.nrows, this.ncols * 2);\n    const newMat = Matrix(this.nrows, this.ncols * 2);\n    const n = this.nrows;\n\n    // Create matrix\n    for (let i = 0; i < n; i += 1) {\n      for (let j = 0; j < n; j += 1) {\n        mat.data[(i * 2 * n) + j] = this.data[(i * n) + j];\n      }\n      mat.data[(i * 2 * n) + n + i] = 1;\n    }\n\n    for (let k = 0; k < n; k += 1) {\n      let i = k;\n      while (Math.abs(mat.data[(i * 2 * n) + k]) < kEpsilonPseudoInverse) {\n        i += 1;\n        if (i === n) {\n          throw new Error('Non-invertible matrix');\n        }\n      }\n      determinant *= mat.data[(i * 2 * n) + k];\n\n      // if found > Exchange lines\n      if (i !== k) {\n        mat.swapLines(i, k);\n      }\n\n      newMat.data = mat.data.slice();\n\n      for (let j = 0; j < 2 * n; j += 1) {\n        newMat.data[(k * 2 * n) + j] /= mat.data[(k * 2 * n) + k];\n      }\n      for (let ii = 0; ii < n; ii += 1) {\n        if (ii !== k) {\n          for (let j = 0; j < 2 * n; j += 1) {\n            newMat.data[(ii * 2 * n) + j] -=\n                mat.data[(ii * 2 * n) + k] *\n                newMat.data[(k * 2 * n) + j];\n          }\n        }\n      }\n      mat.data = newMat.data.slice();\n    }\n\n    const dst = Matrix(this.nrows, this.ncols);\n    for (let i = 0; i < n; i += 1) {\n      for (let j = 0; j < n; j += 1) {\n        dst.data[(i * n) + j] = mat.data[(i * 2 * n) + n + j];\n      }\n    }\n    return { determinant, matrix: dst };\n  },\n\n  /**\n   * Swap 2 lines of the matrix\n   * @param  {[type]} i index of the first line\n   * @param  {[type]} j index of the second line\n   * @private\n   */\n  swapLines(i, j) {\n    for (let k = 0; k < this.ncols; k += 1) {\n      const tmp = this.data[(i * this.ncols) + k];\n      this.data[(i * this.ncols) + k] = this.data[(j * this.ncols) + k];\n      this.data[(j * this.ncols) + k] = tmp;\n    }\n  },\n\n  /**\n   * Swap 2 columns of the matrix\n   * @param  {[type]} i index of the first column\n   * @param  {[type]} j index of the second column\n   * @private\n   */\n  swapColumns(i, j) {\n    for (let k = 0; k < this.nrows; k += 1) {\n      const tmp = this.data[(k * this.ncols) + i];\n      this.data[(k * this.ncols) + i] = this.data[(k * this.ncols) + j];\n      this.data[(k * this.ncols) + j] = tmp;\n    }\n  },\n};\n\n/**\n * Create a matrix\n *\n * @function\n * @param       {Number} [nrows=0]  Number of rows\n * @param       {Number} [ncols=-1] Number of columns\n * @return {matrixPrototype}\n *\n * @property {Array} data Matrix data\n * @property {Number} ncols Number of columns\n * @property {Number} nrows Number of rows\n */\nexport default function Matrix(nrows = 0, ncols = -1) {\n  const nc = ncols < 0 ? nrows : ncols;\n  return Object.assign(\n    Object.create(matrixPrototype), //\n    {\n      nrows,\n      ncols: nc,\n      data: Array(nrows * nc).fill(0),\n    },\n  );\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/common/matrix.js","import ModelBase from '../core/model_base_mixin';\nimport withKMeansTraining from '../kmeans/kmeans_training_mixin';\n\n/**\n * GMM Training Prototype\n * @type {Object}\n * @ignore\n */\nconst gmmTrainerPrototype = /** @lends withGMMTraining */ {\n  /**\n   * Initialize the EM Training process\n   * @param  {TrainingSet} trainingSet Training set\n   */\n  initTraining(trainingSet) {\n    this.allocate();\n    this.initParametersToDefault(trainingSet.standardDeviation());\n    this.initMeansWithKMeans(trainingSet);\n    this.initCovariances(trainingSet);\n    this.regularize();\n    this.updateInverseCovariances();\n  },\n\n  /**\n   * Initialize the model parameters to their default values\n   * @param  {Array<Number>} dataStddev Standard deviation of the training data\n   * @private\n   */\n  initParametersToDefault(dataStddev) {\n    let normCoeffs = 0;\n    this.currentRegularization = dataStddev.map(std => Math.max(\n      this.params.regularization.absolute,\n      this.params.regularization.relative * std,\n    ));\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      if (this.params.covarianceMode === 'full') {\n        this.params.components[c].covariance = Array(this.params.dimension ** 2)\n          .fill(this.params.regularization.absolute / 2);\n      } else {\n        this.params.components[c].covariance = Array(this.params.dimension).fill(0);\n      }\n      this.params.components[c].regularize(this.currentRegularization);\n      this.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      normCoeffs += this.params.mixtureCoeffs[c];\n    }\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.mixtureCoeffs[c] /= normCoeffs;\n    }\n  },\n\n  /**\n   * Initialize the means of the model using a K-Means algorithm\n   *\n   * @see withKMeansTraining\n   *\n   * @param  {TrainingSet} trainingSet training set\n   * @private\n   */\n  initMeansWithKMeans(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n    const kmeans = withKMeansTraining(\n      ModelBase({\n        inputDimension: this.params.inputDimension,\n        outputDimension: this.params.outputDimension,\n      }),\n      this.params.gaussians,\n      { initialization: 'data' },\n    );\n    const kmeansParams = kmeans.train(trainingSet);\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.components[c].mean = kmeansParams.centers[c];\n    }\n  },\n\n  /**\n   * Initialize the covariances of the model from the training set\n   *\n   * @param  {TrainingSet} trainingSet training set\n   * @private\n   */\n  initCovariances(trainingSet) {\n    // TODO: simplify with covariance symmetricity\n    // TODO: If Kmeans, covariances from cluster members\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      this.params.components[n].covariance = Array((this.params.covarianceMode === 'full') ? this.params.dimension ** 2 : this.params.dimension).fill(0);\n    }\n\n    const gmeans = Array(this.params.gaussians * this.params.dimension).fill(0);\n    const factor = Array(this.params.gaussians).fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.gaussians);\n      let offset = 0;\n      for (let n = 0; n < this.params.gaussians; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            gmeans[(n * this.params.dimension) + d1] += phrase.get(offset + t, d1);\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n                this.params.components[n]\n                  .covariance[(d1 * this.params.dimension) + d2] +=\n                  phrase.get(offset + t, d1) * phrase.get(offset + t, d2);\n              }\n            } else {\n              this.params.components[n].covariance[d1] +=\n                phrase.get(offset + t, d1) ** 2;\n            }\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        gmeans[(n * this.params.dimension) + d1] /= factor[n];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[n].covariance[(d1 * this.params.dimension) + d2] /= factor[n];\n          }\n        } else {\n          this.params.components[n].covariance[d1] /= factor[n];\n        }\n      }\n    }\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[n].covariance[(d1 * this.params.dimension) + d2] -=\n              gmeans[(n * this.params.dimension) + d1] *\n              gmeans[(n * this.params.dimension) + d2];\n          }\n        } else {\n          this.params.components[n].covariance[d1] -=\n            gmeans[(n * this.params.dimension) + d1] ** 2;\n        }\n      }\n    }\n  },\n\n  /**\n   * Update the EM Training process (1 EM iteration).\n   * @param  TrainingSet trainingSet training set\n   */\n  updateTraining(trainingSet) {\n    let logProb = 0;\n    let totalLength = 0;\n    trainingSet.forEach((phrase) => {\n      totalLength += phrase.length;\n    });\n    const phraseIndices = Object.keys(trainingSet.phrases);\n\n    const p = Array.from(\n      Array(this.params.gaussians),\n      () => new Array(totalLength).fill(0),\n    );\n    const E = Array(this.params.gaussians).fill(0);\n    let tbase = 0;\n\n    trainingSet.forEach((phrase) => {\n      for (let t = 0; t < phrase.length; t += 1) {\n        let normConst = 0;\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          p[c][tbase + t] = this.componentLikelihood(phrase.getFrame(t), c);\n\n          if (p[c][tbase + t] === 0 ||\n            Number.isNaN(p[c][tbase + t]) ||\n            p[c][tbase + t] === +Infinity) {\n            p[c][tbase + t] = 1e-100;\n          }\n          normConst += p[c][tbase + t];\n        }\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          p[c][tbase + t] /= normConst;\n          E[c] += p[c][tbase + t];\n        }\n        logProb += Math.log(normConst);\n      }\n      tbase += phrase.length;\n    });\n\n    // Estimate Mixture coefficients\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.mixtureCoeffs[c] = E[c] / totalLength;\n    }\n\n    // Estimate means\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.components[c].mean[d] = 0;\n        tbase = 0;\n        for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n          const phrase = trainingSet.phrases[phraseIndices[pix]];\n          for (let t = 0; t < phrase.length; t += 1) {\n            this.params.components[c].mean[d] +=\n              p[c][tbase + t] * phrase.get(t, d);\n          }\n          tbase += phrase.length;\n        }\n        this.params.components[c].mean[d] /= E[c];\n      }\n    }\n\n    // estimate covariances\n    if (this.params.covarianceMode === 'full') {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n          for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[c].covariance[(d1 * this.params.dimension) + d2] = 0;\n            tbase = 0;\n            for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n              const phrase = trainingSet.phrases[phraseIndices[pix]];\n              for (let t = 0; t < phrase.length; t += 1) {\n                this.params.components[c].covariance[(d1 * this.params.dimension) + d2] +=\n                  p[c][tbase + t] *\n                  (phrase.get(t, d1) - this.params.components[c].mean[d1]) *\n                  (phrase.get(t, d2) - this.params.components[c].mean[d2]);\n              }\n              tbase += phrase.length;\n            }\n            this.params.components[c].covariance[(d1 * this.params.dimension) + d2] /= E[c];\n            if (d1 !== d2) {\n              this.params.components[c].covariance[(d2 * this.params.dimension) + d1] =\n                this.params.components[c].covariance[(d1 * this.params.dimension) + d2];\n            }\n          }\n        }\n      }\n    } else {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n          this.params.components[c].covariance[d1] = 0;\n          tbase = 0;\n          for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n            const phrase = trainingSet.phrases[phraseIndices[pix]];\n            for (let t = 0; t < phrase.length; t += 1) {\n              const value = (phrase.get(t, d1) - this.params.components[c].mean[d1]);\n              this.params.components[c].covariance[d1] +=\n                    p[c][tbase + t] * value * value;\n            }\n            tbase += phrase.length;\n          }\n          this.params.components[c].covariance[d1] /= E[c];\n        }\n      }\n    }\n\n    this.regularize();\n    this.updateInverseCovariances();\n\n    return logProb;\n  },\n\n  /**\n   * Terminate the EM Training process\n   */\n  terminateTraining() {},\n};\n\n/**\n * Add GMM Training capabilities to a GMM Model\n * @param  {GMMBase} o               Source GMM Model\n * @param  {Number} [gaussians=1]    Number of Gaussian components\n * @param  {Object} [regularization] Regularization parameters\n * @param  {Number} [regularization.absolute=1e-3] Absolute regularization\n * @param  {Number} [regularization.relative=1e-2] Relative Regularization\n (relative to the training set's variance along each dimension)\n * @param  {String} [covarianceMode='full'] Covariance mode ('full' or diagonal)\n * @return {BMMBase}\n */\nexport default function withGMMTraining(\n  o,\n  gaussians = 1,\n  regularization = { absolute: 1e-3, relative: 1e-2 },\n  covarianceMode = 'full',\n) {\n  if (!Object.keys(o).includes('params')) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    gmmTrainerPrototype,\n    {\n      params: {\n        ...o.params,\n        gaussians,\n        regularization,\n        covarianceMode,\n      },\n    },\n  );\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/gmm/gmm_training_mixin.js","/**\n * Circular Buffer prototype\n *\n * @property {number}  capacity Buffer capacity\n * @property {number}  length Current buffer length\n * @property {boolean} full Specifies if the buffer is full\n *\n * @ignore\n */\nconst circularBufferPrototype = /** @lends CircularBuffer */ {\n  /**\n   * Clear the buffer contents\n   */\n  clear() {\n    this.length = 0;\n    this.index = 0;\n    this.full = false;\n    this.buffer = [];\n  },\n\n  /**\n   * Push a value to the buffer\n   * @param  {*} value data value (any type)\n   */\n  push(value) {\n    if (this.full) {\n      this.buffer[this.index] = value;\n      this.index = (this.index + 1) % this.capacity;\n    } else {\n      this.buffer.push(value);\n      this.length += 1;\n      this.full = (this.length === this.capacity);\n    }\n  },\n\n  /**\n   * Get the value at a given index\n   * @param  {number} idx data index\n   * @return {anything}   value at index\n   */\n  get(idx) {\n    return this.buffer[(idx + this.index) % this.capacity];\n  },\n\n  /**\n   * Fill the buffer with a constant value\n   * @param  {*} value data value (any type)\n   */\n  fill(value) {\n    this.length = this.capacity;\n    this.index = 0;\n    this.full = true;\n    this.buffer = Array(this.capacity).fill(value);\n  },\n\n  /**\n   * Iterate over the buffer's data\n   * @param  {Function} callback Callback function\n   * (@see Array.prototype.forEach).\n   */\n  forEach(callback) {\n    for (let i = 0; i < this.length; i += 1) {\n      callback(this.buffer[(i + this.index) % this.capacity], i);\n    }\n  },\n\n  /**\n   * Get an array of the buffer current values (ordered)\n   * @return {Array} Buffer contents\n   */\n  values() {\n    return this.buffer.slice(this.index)\n      .concat(this.buffer.slice(0, this.index));\n  },\n};\n\n/**\n * Circular Buffer Data Structure (any data type)\n * @param  {number} capacity Buffer capacity\n * @return {circularBufferPrototype}\n * @function\n *\n * @property {number}  capacity Buffer capacity\n * @property {number}  length Current buffer length\n * @property {boolean} full Specifies if the buffer is full\n */\nexport default function CircularBuffer(capacity) {\n  const buffer = Object.create(circularBufferPrototype);\n  buffer.capacity = capacity;\n  buffer.clear();\n  return buffer;\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/common/circular_buffer.js","import validateParameters from '../common/validation';\nimport { isBaseModel } from '../core/model_base_mixin';\n\nconst gmmParameterSpec = gaussians => ({\n  gaussians: {\n    required: true,\n    check: { min: 1 },\n  },\n  regularization: {\n    required: true,\n    check: ({ absolute, relative }) =>\n      (absolute && relative && absolute > 0 && relative > 0),\n  },\n  covarianceMode: {\n    required: true,\n    check: ['full', 'diagonal'],\n  },\n  mixtureCoeffs: {\n    required: true,\n    check: m => m.length === gaussians,\n  },\n  components: {\n    required: true,\n    check: c => c.length === gaussians,\n  },\n});\n\n/**\n * Add GMM prediction capabilities to a single-class model. Mostly, this checks\n * the validity of the model parameters\n *\n * @todo validate gaussian components\n *\n * @param  {GMMBaseModel} o Source Model\n * @return {GMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withGMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  validateParameters('GMM', gmmParameterSpec(o.params.gaussians), o.params);\n  return Object.assign(\n    o,\n    { beta: new Array(o.params.gaussians).fill(0) },\n  );\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/gmm/gmm_prediction_mixin.js","import ModelBase from '../core/model_base_mixin';\nimport withEMTraining from '../core/em_training_mixin';\nimport withHMMBase from './hmm_base_mixin';\nimport withHMMTraining from './hmm_training_mixin';\nimport MulticlassModelBase from '../core/multiclass_mixin';\nimport withMulticlassTraining from '../core/multiclass_training_mixin';\nimport withAbtractPrediction from '../core/prediction_mixin';\nimport withHMMPrediction from './hmm_prediction_mixin';\nimport withMulticlassPrediction from '../core/multiclass_prediction_mixin';\nimport withHierarchicalHMMPrediction from './hierarchical_hmm_prediction_mixin';\n\n/**\n * @typedef {Object} HMMParameters\n * @property {Boolean} bimodal Specifies if the model is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} states Number of hidden states in the Markov model\n * @property {Number} gaussians Number of components in the Gaussian mixture\n * observation distribution of each state\n * @property {String} transitionMode Transition matrix mode ('ergodic' or 'leftright')\n * @property {String} covarianceMode Covariance mode ('full' or 'diagonal')\n * @property {Array<Number>} mixtureCoeffs mixture coefficients ('weight' of\n * each gaussian component)\n * @property {Array<GaussianDistribution>} components Gaussian components\n */\n\n/**\n * Train a single-class HMM Model.\n *\n * @todo HMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {HMMParameters} Parameters of the trained HMM\n */\nexport function trainHMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const {\n    states,\n    gaussians,\n    regularization,\n    transitionMode,\n    covarianceMode,\n  } = configuration;\n  const model = withHMMTraining(\n    withEMTraining(\n      withHMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        ...configuration,\n      })),\n      convergenceCriteria,\n    ),\n    states,\n    gaussians,\n    regularization,\n    transitionMode,\n    covarianceMode,\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Train a multi-class HMM Model.\n *\n * @todo HMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {Object} Parameters of the trained HMM\n */\nexport function trainMulticlassHMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withMulticlassTraining(\n    MulticlassModelBase({ inputDimension, outputDimension, ...configuration }),\n    ts => trainHMM(ts, configuration, convergenceCriteria),\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Create a HMM Predictor from a full set of parameters (generated by trainHMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function HMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withHMMPrediction(withAbtractPrediction(\n    withHMMBase(ModelBase(params)),\n    likelihoodWindow,\n  ));\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass HMM Predictor from a full set of parameters\n * (generated by trainMulticlassHMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function MulticlassHMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withMulticlassPrediction(MulticlassModelBase(params));\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = HMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass HMM Predictor from a full set of parameters\n * (generated by trainMulticlassHMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function HierarchicalHMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  let model = MulticlassModelBase(params);\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = HMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model = withHierarchicalHMMPrediction(withMulticlassPrediction(model));\n  model.reset();\n  return model;\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/hmm/index.js","import { isBaseModel } from '../core/model_base_mixin';\n\n//\n// TODO: hierarchical + exit probabilities methods.\n//\n\n/**\n * HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hmmBasePrototype = /** @lends withHMMBase */ {\n  /**\n   * Specifies if the forward algorithm has been initialized\n   * @type {Boolean}\n   * @private\n   */\n  forwardInitialized: false,\n\n  /**\n   * Specifies if the containing multiclass model is isHierarchical\n   * @todo check that\n   * @type {Boolean}\n   * @private\n   */\n  isHierarchical: false,\n\n  /**\n   * Initialize the forward algorithm (See rabiner, 1989)\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}                    `ct` (inverse likelihood)\n   */\n  initializeForwardAlgorithm(observation) {\n    let normConst = 0;\n    if (this.params.transitionMode === 'ergodic') {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.alpha[i] = this.params.prior[i] *\n          this.params.xStates[i].likelihood(observation);\n        normConst += this.alpha[i];\n      }\n    } else {\n      this.alpha = new Array(this.params.states).fill(0);\n      this.alpha[0] = this.params.xStates[0].likelihood(observation);\n      normConst += this.alpha[0];\n    }\n    this.forwardInitialized = true;\n    if (normConst > 0) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.alpha[i] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 1 / this.params.states;\n    }\n    return 1;\n  },\n\n  /**\n   * Update the forward algorithm (See rabiner, 1989)\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}                    `ct` (inverse likelihood)\n   */\n  updateForwardAlgorithm(observation) {\n    let normConst = 0;\n    this.previousAlpha = this.alpha.slice();\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.alpha[j] += this.previousAlpha[i] *\n            this.params.transition[i][j];\n        }\n      } else {\n        this.alpha[j] += this.previousAlpha[j] * this.params.transition[j * 2];\n        if (j > 0) {\n          this.alpha[j] += this.previousAlpha[j - 1] *\n            this.params.transition[((j - 1) * 2) + 1];\n        } else {\n          this.alpha[0] += this.previousAlpha[this.params.states - 1] *\n            this.params.transition[(this.params.states * 2) - 1];\n        }\n      }\n      this.alpha[j] *= this.params.xStates[j].likelihood(observation);\n      normConst += this.alpha[j];\n    }\n    if (normConst > 1e-300) {\n      for (let j = 0; j < this.params.states; j += 1) {\n        this.alpha[j] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    return 0;\n  },\n};\n\n/**\n * Add basic HMM capabilities to a single-class model. This enables the\n * computation of the likelihoods and regression operations common to\n * training and prediction\n *\n * @see withHMMTraining\n * @see withHMMPrediction\n *\n * @param  {ModelBase} o Source Model\n * @return {HMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHMMBase(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(o, hmmBasePrototype);\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/hmm/hmm_base_mixin.js","import TrainingSet from '../training_set';\nimport ModelBase from '../core/model_base_mixin';\nimport withGMMBase from '../gmm/gmm_base_mixin';\nimport { trainGMM } from '../gmm';\n\nconst TRANSITION_REGULARIZATION = 1e-5;\n\n/**\n * HMM Training Prototype\n * @type {Object}\n * @ignore\n */\nconst hmmTrainerPrototype = /** @lends withHMMTraining */ {\n  /**\n   * Initialize the EM Training process\n   * @param  {TrainingSet} trainingSet Training set\n   */\n  initTraining(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    this.allocate(trainingSet);\n    this.initParametersToDefault(trainingSet.standardDeviation());\n    if (this.params.gaussians > 1) {\n      this.initMeansCovariancesWithGMMEM(trainingSet);\n    } else {\n      this.initMeansWithAllPhrases(trainingSet);\n      this.initCovariancesFullyObserved(trainingSet);\n    }\n  },\n\n  /**\n   * Allocate the model's parameters and training variables\n   * @param  {TrainingSet} trainingSet The training set\n   * @private\n   */\n  allocate(trainingSet) {\n    const {\n      inputDimension,\n      outputDimension,\n      gaussians,\n      regularization,\n      covarianceMode,\n    } = this.params;\n    this.params.xStates = Array.from(\n      new Array(this.params.states),\n      () => withGMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        gaussians,\n        regularization,\n        covarianceMode,\n      })),\n    );\n    this.params.xStates.forEach(s => s.allocate());\n    this.alpha = new Array(this.params.states).fill(0);\n    this.previousAlpha = new Array(this.params.states).fill(0);\n    this.beta = new Array(this.params.states).fill(0);\n    this.previousBeta = new Array(this.params.states).fill(0);\n\n    // Initialize Algorithm variables\n    // ---------------------------------------\n    const nbPhrases = trainingSet.size();\n    this.gammaSequence = new Array(nbPhrases).fill(null);\n    this.epsilonSequence = new Array(nbPhrases).fill(null);\n    this.gammaSequenceperMixture = new Array(nbPhrases).fill(null);\n    let maxT = 0;\n    let i = 0;\n    trainingSet.forEach((phrase) => {\n      const T = phrase.length;\n      this.gammaSequence[i] = Array.from(\n        new Array(T),\n        () => new Array(this.params.states).fill(0),\n      );\n      if (this.params.transitionMode === 'ergodic') {\n        this.epsilonSequence[i] = Array.from(\n          new Array(T),\n          () => Array.from(\n            new Array(this.params.states),\n            () => new Array(this.params.states).fill(0),\n          ),\n        );\n      } else {\n        this.epsilonSequence[i] = Array.from(\n          new Array(T),\n          () => new Array(this.params.states * 2).fill(0),\n        );\n      }\n      this.gammaSequenceperMixture[i] =\n        new Array(this.params.gaussians).fill(0);\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.gammaSequenceperMixture[i][c] =\n          Array.from(\n            new Array(T),\n            () => new Array(this.params.states).fill(0),\n          );\n      }\n      if (T > maxT) {\n        maxT = T;\n      }\n      i += 1;\n    });\n\n    this.gammaSum = new Array(this.params.states).fill(0);\n    this.gammaSumPerMixture = new Array(this.params.states * this.params.gaussians).fill(0);\n  },\n\n  /**\n   * Update the EM Training process (1 EM iteration).\n   * @param  TrainingSet trainingSet training set\n   */\n  updateTraining(trainingSet) {\n    let logProb = 0;\n\n    // Forward-backward for each phrase\n    // =================================================\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      if (phrase.length > 0) {\n        logProb += this.baumWelchForwardBackward(phrase, phraseIndex);\n      }\n      phraseIndex += 1;\n    });\n    this.baumWelchGammaSum(trainingSet);\n\n    // Re-estimate model parameters\n    // =================================================\n\n    // set covariance and mixture coefficients to zero for each state\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.xStates[i].params.mixtureCoeffs[c] = 0;\n        if (this.params.covarianceMode === 'full') {\n          this.params.xStates[i].params.components[c].covariance =\n            new Array(this.params.dimension ** 2).fill(0);\n        } else {\n          this.params.xStates[i].params.components[c].covariance =\n            new Array(this.params.dimension).fill(0);\n        }\n      }\n    }\n\n    this.baumWelchEstimateMixtureCoefficients(trainingSet);\n    this.baumWelchEstimateMeans(trainingSet);\n    this.baumWelchEstimateCovariances(trainingSet);\n    if (this.params.transitionMode === 'ergodic') {\n      this.baumWelchEstimatePrior(trainingSet);\n    }\n    this.baumWelchEstimateTransitions(trainingSet);\n    return logProb;\n  },\n\n  /**\n   * terminate the EM Training process\n   * @param  TrainingSet trainingSet training set\n   */\n  terminateTraining() {\n    this.normalizeTransitions();\n    this.gammaSequence = null;\n    this.epsilonSequence = null;\n    this.gammaSequenceperMixture = null;\n    this.alphaSeq = null;\n    this.betaSeq = null;\n    this.gammaSum = null;\n    this.gammaSumPerMixture = null;\n    this.params.xStates = this.params.xStates.map(s => s.params);\n  },\n\n  /**\n   * Initialize the model parameters to their default values\n   * @param  {Array<Number>} dataStddev Standard deviation of the training data\n   * @private\n   */\n  initParametersToDefault(dataStddev) {\n    if (this.params.transitionMode === 'ergodic') {\n      this.setErgodic();\n    } else {\n      this.setLeftRight();\n    }\n    const currentRegularization = dataStddev.map(std => Math.max(\n      this.params.regularization.absolute,\n      this.params.regularization.relative * std,\n    ));\n    const initCovariance = (this.params.covarianceMode === 'full') ?\n      () => new Array(this.params.dimension ** 2)\n        .fill(this.params.regularization.absolute / 2) :\n      () => new Array(this.params.dimension)\n        .fill(0);\n    for (let i = 0; i < this.params.states; i += 1) {\n      // this.params.xStates[i].initParametersToDefault(dataStddev);\n      const s = this.params.xStates[i];\n      s.currentRegularization = currentRegularization;\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        s.params.components[c].covariance = initCovariance();\n        s.params.components[c].regularize(currentRegularization);\n        s.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      }\n    }\n  },\n\n  /**\n   * Initialize the means of each state using all available phrases in the\n   * training set\n   * @param  {TrainingSet} trainingSet Training set\n   * @private\n   */\n  initMeansWithAllPhrases(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.xStates[n].params.components[0].mean[d] = 0.0;\n      }\n    }\n\n    const factor = new Array(this.params.states).fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.states);\n      let offset = 0;\n      for (let n = 0; n < this.params.states; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d = 0; d < this.params.dimension; d += 1) {\n            this.params.xStates[n].params.components[0].mean[d] +=\n              phrase.get(offset + t, d);\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.xStates[n].params.components[0].mean[d] /= factor[n];\n      }\n    }\n  },\n\n  /**\n   * Initialize the covariance by direct (fully-observed) estimation from the\n   * training data.\n   * @param  {[type]} trainingSet [description]\n   * @private\n   */\n  initCovariancesFullyObserved(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      this.params.xStates[n].params.components[0].covariance =\n        new Array(this.params.dimension ** (this.params.covarianceMode === 'full' ? 2 : 1)).fill(0);\n    }\n\n    const factor = new Array(this.params.states).fill(0);\n    const othermeans = new Array(this.params.states * this.params.dimension)\n      .fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.states);\n      let offset = 0;\n      for (let n = 0; n < this.params.states; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            othermeans[((n * this.params.dimension)) + d1] +=\n                phrase.get(offset + t, d1);\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n                this.params.xStates[n].params.components[0]\n                  .covariance[(d1 * this.params.dimension) + d2] +=\n                    phrase.get(offset + t, d1) *\n                    phrase.get(offset + t, d2);\n              }\n            } else {\n              this.params.xStates[n].params.components[0].covariance[d1] +=\n                phrase.get(offset + t, d1) ** 2;\n            }\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        othermeans[(n * this.params.dimension) + d1] /= factor[n];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.xStates[n].params.components[0]\n              .covariance[(d1 * this.params.dimension) + d2] /=\n                factor[n];\n          }\n        } else {\n          this.params.xStates[n].params.components[0].covariance[d1] /= factor[n];\n        }\n      }\n    }\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.xStates[n].params.components[0]\n              .covariance[(d1 * this.params.dimension) + d2] -=\n                othermeans[(n * this.params.dimension) + d1] *\n                othermeans[(n * this.params.dimension) + d2];\n          }\n        } else {\n          this.params.xStates[n].params.components[0].covariance[d1] -=\n            othermeans[(n * this.params.dimension) + d1] *\n            othermeans[(n * this.params.dimension) + d1];\n        }\n      }\n      this.params.xStates[n].regularize();\n      this.params.xStates[n].updateInverseCovariances();\n    }\n  },\n\n  /**\n   * Initialize the means and covariance of each state's observation probability\n   * distribution using the Expectation-Maximization algorithm for GMMs\n   * @param  {[type]} trainingSet [description]\n   * @private\n   */\n  initMeansCovariancesWithGMMEM(trainingSet) {\n    for (let n = 0; n < this.params.states; n += 1) {\n      const ts = TrainingSet(this.params);\n      // eslint-disable-next-line no-loop-func\n      trainingSet.forEach((phrase, phraseIndex) => {\n        const step = Math.floor(phrase.length / this.params.states);\n        if (step > 0) {\n          ts.push(phraseIndex, phrase.label);\n          for (let t = n * step; t < (n + 1) * step; t += 1) {\n            ts.getPhrase(phraseIndex).push(phrase.getFrame(t));\n          }\n        }\n      });\n      if (!ts.empty()) {\n        const gmmParams = trainGMM(ts, this.params);\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          this.params.xStates[n].params.components[c].mean =\n            gmmParams.components[c].mean;\n          this.params.xStates[n].params.components[c].covariance =\n            gmmParams.components[c].covariance;\n          this.params.xStates[n].updateInverseCovariances();\n        }\n      }\n    }\n  },\n\n  /**\n   * Initialize the transition matrix to an ergodic transition matrix\n   * @private\n   */\n  setErgodic() {\n    const p = 1 / this.params.states;\n    this.params.prior = new Array(this.params.states).fill(p);\n    this.params.transition = Array.from(\n      new Array(this.params.states),\n      () => new Array(this.params.states).fill(p),\n    );\n  },\n\n  /**\n   * Initialize the transition matrix to a left-right transition matrix\n   * @private\n   */\n  setLeftRight() {\n    this.params.prior = new Array(this.params.states).fill(0);\n    this.params.prior[0] = 1;\n    this.params.transition = new Array(this.params.states * 2).fill(0.5);\n    this.params.transition[(this.params.states - 1) * 2] = 1;\n    this.params.transition[((this.params.states - 1) * 2) + 1] = 0;\n  },\n\n  /**\n   * Normalize the hidden state transition parameters\n   * (prior + transition matrix)\n   * @private\n   */\n  normalizeTransitions() {\n    if (this.params.transitionMode === 'ergodic') {\n      const normPrior = this.params.prior.reduce((a, b) => a + b, 0);\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] /= normPrior;\n        let transitionNorm = 0;\n        for (let j = 0; j < this.params.states; j += 1) {\n          transitionNorm += this.params.transition[i][j];\n        }\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.params.transition[i][j] /= transitionNorm;\n        }\n      }\n    } else {\n      for (let i = 0; i < this.params.states; i += 1) {\n        const transitionNorm = this.params.transition[i * 2] + this.params.transition[(i * 2) + 1];\n        this.params.transition[i * 2] /= transitionNorm;\n        this.params.transition[(i * 2) + 1] /= transitionNorm;\n      }\n    }\n  },\n\n  /**\n   * Initialize the backward algorithm (see rabiner, 1989)\n   * @param  {Number} ct Inverse probability at time T - 1 (last observation of\n   * the sequence)\n   * @private\n   */\n  initializeBackwardAlgorithm(ct) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = ct;\n    }\n  },\n\n  /**\n   * Initialize the backward algorithm (see rabiner, 1989)\n   * @param  {Number} ct Inverse probability at time t\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  updateBackwardAlgorithm(ct, observation) {\n    this.previousBeta = this.beta.slice();\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.beta[i] += this.params.transition[i][j] *\n            this.previousBeta[j] *\n            this.params.xStates[j].likelihood(observation);\n        }\n      } else {\n        this.beta[i] += this.params.transition[i * 2] *\n          this.previousBeta[i] *\n          this.params.xStates[i].likelihood(observation);\n        if (i < this.params.states - 1) {\n          this.beta[i] += this.params.transition[(i * 2) + 1] *\n            this.previousBeta[i + 1] *\n            this.params.xStates[i + 1].likelihood(observation);\n        }\n      }\n      this.beta[i] *= ct;\n      if (Number.isNaN(this.beta[i]) || Math.abs(this.beta[i]) === +Infinity) {\n        this.beta[i] = 1e100;\n      }\n    }\n  },\n\n  /**\n   * Forward algorithm update step for the Baum-Welch algorithms. It is similar\n   * to `updateForwardAlgorithm` except it takes precomputed observation\n   * likelihoods as argument.\n   * @param  {Array<Number>} observationLikelihoods observation likelihoods\n   * @private\n   */\n  baumWelchForwardUpdate(observationLikelihoods) {\n    let normConst = 0;\n    this.previousAlpha = this.alpha.slice();\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.alpha[j] += this.previousAlpha[i] *\n            this.params.transition[i][j];\n        }\n      } else {\n        this.alpha[j] += this.previousAlpha[j] * this.params.transition[j * 2];\n        if (j > 0) {\n          this.alpha[j] += this.previousAlpha[j - 1] *\n            this.params.transition[((j - 1) * 2) + 1];\n        } else {\n          this.alpha[0] += this.previousAlpha[this.params.states - 1] *\n            this.params.transition[(this.params.states * 2) - 1];\n        }\n      }\n      this.alpha[j] *= observationLikelihoods[j];\n      normConst += this.alpha[j];\n    }\n    if (Number.isNaN(normConst)) {\n      throw new Error('Holy molly');\n    }\n    if (normConst > 1e-300) {\n      for (let j = 0; j < this.params.states; j += 1) {\n        this.alpha[j] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    return 0;\n  },\n\n  /**\n   * Backward algorithm update step for the Baum-Welch algorithms. It is similar\n   * to `updatebackwardAlgorithm` except it takes precomputed observation\n   * likelihoods as argument.\n   * @param  {Number} ct Inverse probability at time t\n   * @param  {Array<Number>} observationLikelihoods observation likelihoods\n   * @private\n   */\n  baumWelchBackwardUpdate(ct, observationLikelihoods) {\n    this.previousBeta = this.beta.slice();\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.beta[i] +=\n            this.params.transition[i][j] *\n            this.previousBeta[j] *\n            observationLikelihoods[j];\n        }\n      } else {\n        this.beta[i] += this.params.transition[i * 2] *\n          this.previousBeta[i] *\n          observationLikelihoods[i];\n        if (i < this.params.states - 1) {\n          this.beta[i] += this.params.transition[(i * 2) + 1] *\n            this.previousBeta[i + 1] *\n            observationLikelihoods[i + 1];\n        }\n      }\n      this.beta[i] *= ct;\n      if (Number.isNaN(this.beta[i]) || Math.abs(this.beta[i]) === +Infinity) {\n        this.beta[i] = 1e100;\n      }\n    }\n  },\n\n  /**\n   * Forward-Backward algorithm for the Baum-Welch training algorithm\n   * @param  {Phrase} currentPhrase Current data phrase\n   * @param  {Number} phraseIndex   Current phrase index\n   * @return {Number} Log-likelihood\n   * @private\n   */\n  baumWelchForwardBackward(currentPhrase, phraseIndex) {\n    const T = currentPhrase.length;\n\n    const ct = new Array(T).fill(0);\n    let logProb;\n    this.alphaSeq = [];\n    this.betaSeq = [];\n\n    const observationProbabilities = Array.from(\n      new Array(T),\n      () => new Array(this.params.states).fill(0),\n    );\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        observationProbabilities[t][i] =\n          this.params.xStates[i].likelihood(currentPhrase.getFrame(t));\n      }\n    }\n\n    // Forward algorithm\n    ct[0] = this.initializeForwardAlgorithm(currentPhrase.getFrame(0));\n    logProb = -Math.log(ct[0]);\n    this.alphaSeq.push(this.alpha.slice());\n\n    for (let t = 1; t < T; t += 1) {\n      ct[t] = this.baumWelchForwardUpdate(observationProbabilities[t]);\n      logProb -= Math.log(ct[t]);\n      this.alphaSeq.push(this.alpha.slice());\n    }\n\n    // Backward algorithm\n    this.initializeBackwardAlgorithm(ct[T - 1]);\n    this.betaSeq.push(this.beta.slice());\n\n    for (let t = T - 2; t >= 0; t -= 1) {\n      this.baumWelchBackwardUpdate(ct[t], observationProbabilities[t + 1]);\n      this.betaSeq.push(this.beta.slice());\n    }\n    this.betaSeq.reverse();\n\n    // Compute Gamma Variable\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.gammaSequence[phraseIndex][t][i] =\n          (this.alphaSeq[t][i] * this.betaSeq[t][i]) / ct[t];\n      }\n    }\n\n    // Compute Gamma variable for each mixture component\n    let normConst;\n\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        normConst = 0;\n        if (this.params.gaussians === 1) {\n          const oo = observationProbabilities[t][i];\n          this.gammaSequenceperMixture[phraseIndex][0][t][i] =\n            this.gammaSequence[phraseIndex][t][i] * oo;\n          normConst += oo;\n        } else {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            const oo = this.params.xStates[i]\n              .componentLikelihood(currentPhrase.getFrame(t), c);\n            this.gammaSequenceperMixture[phraseIndex][c][t][i] =\n              this.gammaSequence[phraseIndex][t][i] *\n              oo;\n            normConst += oo;\n          }\n        }\n        if (normConst > 0) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.gammaSequenceperMixture[phraseIndex][c][t][i] /= normConst;\n          }\n        }\n      }\n    }\n\n    // Compute Epsilon Variable\n    if (this.params.transitionMode === 'ergodic') {\n      for (let t = 0; t < T - 1; t += 1) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          for (let j = 0; j < this.params.states; j += 1) {\n            this.epsilonSequence[phraseIndex][t][i][j] =\n              this.alphaSeq[t][i] *\n              this.params.transition[i][j] *\n              this.betaSeq[t + 1][j];\n            this.epsilonSequence[phraseIndex][t][i][j] *=\n              observationProbabilities[t + 1][j];\n          }\n        }\n      }\n    } else {\n      for (let t = 0; t < T - 1; t += 1) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.epsilonSequence[phraseIndex][t][i * 2] =\n            this.alphaSeq[t][i] *\n            this.params.transition[i * 2] *\n            this.betaSeq[t + 1][i];\n          this.epsilonSequence[phraseIndex][t][i * 2] *=\n            observationProbabilities[t + 1][i];\n          if (i < this.params.states - 1) {\n            this.epsilonSequence[phraseIndex][t][(i * 2) + 1] =\n              this.alphaSeq[t][i] *\n              this.params.transition[(i * 2) + 1] *\n              this.betaSeq[t + 1][i + 1];\n            this.epsilonSequence[phraseIndex][t][(i * 2) + 1] *=\n              observationProbabilities[t + 1][i + 1];\n          }\n        }\n      }\n    }\n\n    return logProb;\n  },\n\n  /**\n   * Sums the Gamma variables used for parameter estimation during training\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchGammaSum(trainingSet) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.gammaSum[i] = 0;\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.gammaSumPerMixture[(i * this.params.gaussians) + c] = 0;\n      }\n    }\n\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          this.gammaSum[i] +=\n            this.gammaSequence[phraseIndex][t][i];\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.gammaSumPerMixture[(i * this.params.gaussians) + c] +=\n              this.gammaSequenceperMixture[phraseIndex][c][t][i];\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n  },\n\n  /**\n   * Estimate the mixture coefficients of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateMixtureCoefficients(trainingSet) {\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.params.xStates[i].params.mixtureCoeffs[c] +=\n              this.gammaSequenceperMixture[phraseIndex][c][t][i];\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale mixture coefficients\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.params.xStates[i].normalizeMixtureCoeffs();\n    }\n  },\n\n  /**\n   * Estimate the means of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateMeans(trainingSet) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.xStates[i].params.components[c].mean.fill(0);\n      }\n    }\n\n    // Re-estimate Mean\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            for (let d = 0; d < this.params.dimension; d += 1) {\n              this.params.xStates[i].params.components[c].mean[d] +=\n                this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                phrase.get(t, d);\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Normalize mean\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          if (this.gammaSumPerMixture[(i * this.params.gaussians) + c] > 0) {\n            this.params.xStates[i].params.components[c].mean[d] /=\n              this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n          }\n          if (Number.isNaN(this.params.xStates[i].params.components[c].mean[d])) {\n            throw new Error('Convergence Error');\n          }\n        }\n      }\n    }\n  },\n\n  /**\n   * Estimate the covariances of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateCovariances(trainingSet) {\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n              if (this.params.covarianceMode === 'full') {\n                for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n                  this.params.xStates[i].params.components[c]\n                    .covariance[(d1 * this.params.dimension) + d2] +=\n                    this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                    (phrase.get(t, d1) -\n                      this.params.xStates[i].params.components[c].mean[d1]) *\n                    (phrase.get(t, d2) -\n                      this.params.xStates[i].params.components[c].mean[d2]);\n                }\n              } else {\n                const value = phrase.get(t, d1) -\n                  this.params.xStates[i].params.components[c].mean[d1];\n                this.params.xStates[i].params.components[c].covariance[d1] +=\n                  this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                  (value ** 2);\n              }\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale covariance\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        if (this.gammaSumPerMixture[(i * this.params.gaussians) + c] > 0) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n                this.params.xStates[i].params.components[c]\n                  .covariance[(d1 * this.params.dimension) + d2] /=\n                  this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n                if (d1 !== d2) {\n                  this.params.xStates[i].params.components[c]\n                    .covariance[(d2 * this.params.dimension) + d1] =\n                    this.params.xStates[i].params.components[c]\n                      .covariance[(d1 * this.params.dimension) + d2];\n                }\n              }\n            } else {\n              this.params.xStates[i].params.components[c].covariance[d1] /=\n                this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n            }\n          }\n        }\n      }\n      this.params.xStates[i].regularize();\n      this.params.xStates[i].updateInverseCovariances();\n    }\n  },\n\n  /**\n   * Estimate the prior probabilities of the model\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimatePrior(trainingSet) {\n    this.params.prior.fill(0);\n\n    // Re-estimate Prior probabilities\n    let sumprior = 0;\n    for (let phraseIndex = 0;\n      phraseIndex < trainingSet.size();\n      phraseIndex += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] += this.gammaSequence[phraseIndex][0][i];\n        sumprior += this.params.prior[i];\n      }\n    }\n\n    // Scale Prior vector\n    if (sumprior > 0) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] /= sumprior;\n      }\n    } else {\n      throw new Error('The Prior is all ZERO.....');\n    }\n  },\n\n  /**\n   * Estimate the transition probabilities of the model\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateTransitions(trainingSet) {\n    // Set transition matrix to 0\n    this.params.transition = this.params.transitionMode === 'ergodic' ?\n      Array.from(\n        new Array(this.params.states),\n        () => new Array(this.params.states).fill(0),\n      ) :\n      new Array(this.params.states * 2).fill(0);\n\n    // Re-estimate Transition probabilities\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      if (phrase.length > 0) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          // Experimental: A bit of regularization (sometimes avoids\n          // numerical errors)\n          if (this.params.transitionMode === 'leftright') {\n            this.params.transition[i * 2] += TRANSITION_REGULARIZATION;\n            if (i < this.params.states - 1) {\n              this.params.transition[(i * 2) + 1] += TRANSITION_REGULARIZATION;\n            } else {\n              this.params.transition[i * 2] += TRANSITION_REGULARIZATION;\n            }\n          }\n          // End Regularization\n          if (this.params.transitionMode === 'ergodic') {\n            for (let j = 0; j < this.params.states; j += 1) {\n              for (let t = 0; t < phrase.length - 1; t += 1) {\n                this.params.transition[i][j] +=\n                  this.epsilonSequence[phraseIndex][t][i][j];\n              }\n            }\n          } else {\n            for (let t = 0; t < phrase.length - 1; t += 1) {\n              this.params.transition[i * 2] +=\n                this.epsilonSequence[phraseIndex][t][i * 2];\n            }\n            if (i < this.params.states - 1) {\n              for (let t = 0; t < phrase.length - 1; t += 1) {\n                this.params.transition[(i * 2) + 1] +=\n                  this.epsilonSequence[phraseIndex][t][(i * 2) + 1];\n              }\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale transition matrix\n    if (this.params.transitionMode === 'ergodic') {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.params.transition[i][j] /=\n            (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n          if (Number.isNaN(this.params.transition[i][j])) {\n            throw new Error('Convergence Error. Check your training data or increase the variance offset');\n          }\n        }\n      }\n    } else {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.transition[i * 2] /=\n          (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n        if (Number.isNaN(this.params.transition[i * 2])) {\n          throw new Error('Convergence Error. Check your training data or increase the variance offset');\n        }\n        if (i < this.params.states - 1) {\n          this.params.transition[(i * 2) + 1] /=\n            (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n          if (Number.isNaN(this.params.transition[(i * 2) + 1])) {\n            throw new Error('Convergence Error. Check your training data or increase the variance offset');\n          }\n        }\n      }\n    }\n  },\n};\n\n/**\n * Add HMM Training capabilities to a HMM Model\n * @param  {HMMBase} o               Source HMM Model\n * @param  {Number} [states=1]       Number of hidden states\n * @param  {Number} [gaussians=1]    Number of Gaussian components\n * @param  {Object} [regularization] Regularization parameters\n * @param  {Number} [regularization.absolute=1e-3] Absolute regularization\n * @param  {Number} [regularization.relative=1e-2] Relative Regularization\n (relative to the training set's variance along each dimension)\n * @param  {String} [transitionMode='ergodic'] Structure of the transition\n * matrix ('ergodic' or 'left-right').\n * @param  {String} [covarianceMode='full'] Covariance mode ('full' or diagonal)\n * @return {BMMBase}\n */\nexport default function withHMMTraining(\n  o,\n  states = 1,\n  gaussians = 1,\n  regularization = { absolute: 1e-3, relative: 1e-2 },\n  transitionMode = 'leftright',\n  covarianceMode = 'full',\n) {\n  if (!Object.keys(o).includes('params')) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    hmmTrainerPrototype,\n    {\n      params: {\n        ...o.params,\n        states,\n        gaussians,\n        regularization,\n        transitionMode,\n        covarianceMode,\n      },\n    },\n  );\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/hmm/hmm_training_mixin.js","import validateParameters from '../common/validation';\nimport { isBaseModel } from '../core/model_base_mixin';\nimport { GMMPredictor } from '../gmm';\n\nconst hmmParameterSpec = (states, transitionMode) => ({\n  states: {\n    required: true,\n    check: { min: 1 },\n  },\n  gaussians: {\n    required: true,\n    check: { min: 1 },\n  },\n  regularization: {\n    required: true,\n    check: ({ absolute, relative }) =>\n      (absolute && relative && absolute > 0 && relative > 0),\n  },\n  transitionMode: {\n    required: true,\n    check: ['ergodic', 'leftright'],\n  },\n  covarianceMode: {\n    required: true,\n    check: ['full', 'diagonal'],\n  },\n  prior: {\n    required: true,\n    check: m => transitionMode === 'leftright' || m.length === states,\n  },\n  transition: {\n    required: true,\n    check: m => (transitionMode === 'leftright' ?\n      m.length === 2 * states :\n      m.length === states),\n  },\n  xStates: {\n    required: true,\n    check: m => m.length === states,\n  },\n});\n\n\n/**\n * HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hmmPredictionPrototype = /** @lends withHMMPrediction */ {\n  forwardInitialized: false,\n  isHierarchical: false,\n\n  /**\n   * Setup the Model by allocating GMM predictors to each of the hidden states\n   * @return {HMMBaseModel} the model\n   * @private\n   */\n  setup() {\n    this.params.xStates = this.params.xStates.map(s => GMMPredictor(s).reset());\n    return this;\n  },\n\n  /**\n   * Reset the prediction process\n   * @return {HMMBaseModel} the model\n   */\n  reset() {\n    this.likelihoodBuffer.clear();\n    this.params.xStates.forEach((s) => { s.reset(); });\n    return this;\n  },\n\n  /**\n   * Compute the likelihood of an observation given the HMM's parameters\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}\n   */\n  likelihood(observation) {\n    const ct = (this.forwardInitialized) ?\n      this.updateForwardAlgorithm(observation) :\n      this.initializeForwardAlgorithm(observation);\n    this.updateAlphaWindow();\n    this.updateProgress();\n    return 1 / ct;\n  },\n\n  updateProgress() {\n    this.results.progress = 0.0;\n    for (let i = this.windowMinindex; i < this.windowMaxindex; i += 1) {\n      if (this.isHierarchical) {\n        this.results.progress += (this.alpha[i] + this.alpha1[i] + this.alpha2[i]) *\n          (i / this.windowNormalizationConstant);\n      } else {\n        this.results.progress += (this.alpha[i] * i) /\n          this.windowNormalizationConstant;\n      }\n    }\n    this.results.progress /= this.params.states - 1;\n  },\n\n  /**\n   * Update the state probabilities filtering window (for multiclass\n   * hierarchical HMM I think...)\n   * @private\n   */\n  updateAlphaWindow() {\n    this.results.likeliestState = 0;\n    // Get likeliest State\n    let bestAlpha = this.isHierarchical ?\n      (this.alpha[0] + this.alpha1[0]) :\n      this.alpha[0];\n    for (let i = 1; i < this.params.states; i += 1) {\n      if (this.isHierarchical) {\n        if ((this.alpha[i] + this.alpha1[i]) > bestAlpha) {\n          bestAlpha = this.alpha[i] + this.alpha1[i];\n          this.results.likeliestState = i;\n        }\n      } else if (this.alpha[i] > bestAlpha) {\n        bestAlpha = this.alpha[i];\n        this.results.likeliestState = i;\n      }\n    }\n\n    // Compute Window\n    this.windowMinindex = this.results.likeliestState - Math.floor(this.params.states / 2);\n    this.windowMaxindex = this.results.likeliestState + Math.floor(this.params.states / 2);\n    this.windowMinindex = (this.windowMinindex >= 0) ? this.windowMinindex : 0;\n    this.windowMaxindex = (this.windowMaxindex <= this.params.states) ?\n      this.windowMaxindex : this.params.states;\n    this.windowNormalizationConstant = 0.0;\n    for (let i = this.windowMinindex; i < this.windowMaxindex; i += 1) {\n      this.windowNormalizationConstant += this.isHierarchical ?\n        (this.alpha[i] + this.alpha1[i]) :\n        this.alpha[i];\n    }\n  },\n};\n\n/**\n * Bimodal (regression) HMM Prototype\n * @type {Object}\n * @ignore\n */\nconst hmmBimodalPredictionPrototype = /** @lends withHMMPrediction */ {\n  /**\n   * Estimate the output values corresponding to the input observation, by\n   * regression given the HMM's parameters. This method is called Hidden\n   * Mixture Regression (GMR).\n   *\n   * @param  {Array<Number>} inputObservation Observation on the input modality\n   * @return {Array<Number>} Output values (length = outputDimension)\n   */\n  regression(inputObservation) {\n    this.results.outputValues = Array(this.params.outputDimension).fill(0);\n    this.results.outputCovariance = Array(this.params.covarianceMode === 'full' ? this.params.outputDimension ** 2 : this.params.outputDimension).fill(0);\n\n    if (this.params.regressionEstimator === 'likeliest') {\n      this.params.xStates[this.results.likeliestState].predict(inputObservation);\n      this.results.outputValues =\n        this.params.xStates[this.results.likeliestState].results.outputValues;\n      return this.results.outputValues;\n    }\n\n    const clipMinState = (this.params.regressionEstimator === 'full') ?\n      0 : this.windowMinindex;\n    const clipMaxState = (this.params.regressionEstimator === 'full') ?\n      this.params.states : this.windowMaxindex;\n    let normalizationConstant = (this.params.regressionEstimator === 'full') ?\n      1 : this.windowNormalizationConstant;\n\n    if (normalizationConstant <= 0.0) normalizationConstant = 1;\n\n    // Compute Regression\n    for (let i = clipMinState; i < clipMaxState; i += 1) {\n      this.params.xStates[i].likelihood(inputObservation);\n      this.params.xStates[i].regression(inputObservation);\n      const tmpPredictedOutput = this.params.xStates[i].results.outputValues;\n      for (let d = 0; d < this.params.outputDimension; d += 1) {\n        if (this.isHierarchical) {\n          this.results.outputValues[d] +=\n            (this.alpha[i] + this.alpha1[i]) *\n            (tmpPredictedOutput[d] / normalizationConstant);\n          if (this.params.covarianceMode === 'full') {\n            for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n              this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n                (this.alpha[i] + this.alpha1[i]) *\n                (this.alpha[i] + this.alpha1[i]) *\n                (this.params.xStates[i].results\n                  .outputCovariance[(d * this.params.outputDimension) + d2] /\n                normalizationConstant);\n            }\n          } else {\n            this.results.outputCovariance[d] +=\n              (this.alpha[i] + this.alpha1[i]) *\n              (this.alpha[i] + this.alpha1[i]) *\n              (this.params.xStates[i].results.outputCovariance[d] /\n              normalizationConstant);\n          }\n        } else {\n          this.results.outputValues[d] += this.alpha[i] *\n            (tmpPredictedOutput[d] / normalizationConstant);\n          if (this.params.covarianceMode === 'full') {\n            for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n              this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n                (this.alpha[i] ** 2) *\n                (this.params.xStates[i].results\n                  .outputCovariance[(d * this.params.outputDimension) + d2] /\n                normalizationConstant);\n            }\n          } else {\n            this.results.outputCovariance[d] +=\n              ((this.alpha[i] ** 2) *\n              this.params.xStates[i].results.outputCovariance[d]) /\n              normalizationConstant;\n          }\n        }\n      }\n    }\n    return this.results.outputValues;\n  },\n};\n\n/**\n * Add HMM prediction capabilities to a single-class model. Mostly, this checks\n * the validity of the model parameters\n *\n * @todo validate gaussian components\n *\n * @param  {HMMBaseModel} o Source Model\n * @return {HMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  validateParameters('HMM', hmmParameterSpec(o.params.states, o.params.transitionMode), o.params);\n  return Object.assign(\n    o,\n    hmmPredictionPrototype,\n    o.params.bimodal ? hmmBimodalPredictionPrototype : {},\n    {\n      alpha: new Array(o.params.states).fill(0),\n      previous_alpha_: new Array(o.params.states).fill(0),\n    },\n  ).setup();\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/hmm/hmm_prediction_mixin.js","import { isBaseModel } from '../core/model_base_mixin';\n\nconst DEFAULT_EXITPROBABILITY_LAST_STATE = 0.1;\n\n/**\n * Hierarchical HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hierarchicalHmmPredictionPrototype =\n/** @lends withHierarchicalHMMPrediction */\n{\n  /**\n   * Specificies if the forward algorithm has been initialized\n   * @type {Boolean}\n   * @private\n   */\n  forwardInitialized: false,\n\n  /**\n   * Setup the model (allocate transition parameters)\n   * @return {HierarchicalHMM} [description]\n   * @private\n   */\n  setup() {\n    const numClasses = this.size();\n    this.params.prior = new Array(numClasses).fill(1 / numClasses);\n    this.params.transition = Array.from(\n      new Array(numClasses),\n      () => new Array(numClasses).fill(1 / numClasses),\n    );\n    this.params.exitTransition = new Array(numClasses).fill(0.1);\n    Object.values(this.models).forEach((model) => {\n      const m = model;\n      m.isHierarchical = true;\n    });\n    this.updateExitProbabilities();\n    return this;\n  },\n\n  /**\n   * Update the exit probabilities of each sub-Markov model\n   * @param  {Array<Number>|undefined} [exitProbabilities=undefined] Vector of\n   * exit probabilities (optional)\n   * @private\n   */\n  updateExitProbabilities(exitProbabilities = undefined) {\n    const exitProb = (exitProbabilities !== undefined) ?\n      exitProbabilities :\n      new Array(this.params.states - 1).fill(0)\n        .concat([DEFAULT_EXITPROBABILITY_LAST_STATE]);\n    Object.keys(this.models).forEach((label) => {\n      this.models[label].params.exitProbabilities = exitProb.slice();\n    });\n  },\n\n  /**\n   * Reset the prediction process. This is particularly important for temporal\n   * models such as HMMs, that depends on previous observations.\n   */\n  reset() {\n    Object.values(this.models).forEach(m => m.reset());\n    this.results = {\n      labels: [],\n      instantLikelihoods: [],\n      smoothedLikelihoods: [],\n      smoothedLogLikelihoods: [],\n      smoothedNormalizedLikelihoods: [],\n      exitLikelihood: [],\n      likeliest: null,\n      classes: {},\n    };\n    if (this.params.bimodal) {\n      this.resetBimodal();\n    }\n    this.forwardInitialized = false;\n  },\n\n  /**\n   * Make a prediction from a new observation (updates the results member)\n   * @param  {Array<Number>} observation Observation vector\n   */\n  predict(observation) {\n    if (this.forwardInitialized) {\n      this.updateForwardAlgorithm(observation);\n    } else {\n      this.initializeForwardAlgorithm(observation);\n    }\n    Object.keys(this.models).sort().forEach((label) => {\n      const model = this.models[label];\n      model.updateAlphaWindow();\n      model.updateProgress();\n      model.updateResults(model.results.instantLikelihood);\n    });\n    this.updateResults();\n\n    if (this.params.bimodal) {\n      Object.values(this.models).forEach(m => m.regression(observation));\n\n      if (this.params.multiClassRegressionEstimator === 'likeliest') {\n        this.results.outputValues =\n          this.models[this.results.likeliest].results.outputValues;\n        this.results.outputCovariance =\n          this.models[this.results.likeliest].results.outputCovariance;\n      } else {\n        this.results.outputValues = new Array(this.outputDimension).fill(0);\n        this.results.outputCovariance =\n          new Array(this.params.covarianceMode === 'full' ?\n            this.outputDimension ** 2 :\n            this.outputDimension).fill(0);\n\n        let modelIndex = 0;\n        Object.values(this.models).forEach((model) => {\n          for (let d = 0; d < this.outputDimension; d += 1) {\n            this.results.outputValues[d] +=\n              this.results.smoothedNormalizedLikelihoods[modelIndex] *\n              model.second.results.outputValues[d];\n\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n                this.results.outputCovariance[(d * this.outputDimension) + d2] +=\n                  this.results.smoothedNormalizedLikelihoods[modelIndex] *\n                  model.results.outputCovariance[(d * this.outputDimension) + d2];\n              }\n            } else {\n              this.results.outputCovariance[d] +=\n                this.results.smoothedNormalizedLikelihoods[modelIndex] *\n                model.second.results.outputCovariance[d];\n            }\n          }\n          modelIndex += 1;\n        });\n      }\n    }\n  },\n\n  /**\n   * Initialize the forward algorithm of the hierarchical HMM\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  initializeForwardAlgorithm(observation) {\n    let normConst = 0;\n    let modelIndex = 0;\n    const classes = Object.keys(this.models).sort();\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      model.alpha1 = new Array(N).fill(0);\n      model.alpha2 = new Array(N).fill(0);\n\n      // Compute Emission probability and initialize on the first state of\n      // the primitive\n      if (model.params.transitionMode === 'ergodic') {\n        model.results.instantLikelihood = 0;\n        for (let i = 0; i < N; i += 1) {\n          model.alpha[i] = this.params.prior[modelIndex] *\n            model.params.prior[i] *\n            model.params.xStates[i].likelihood(observation);\n          model.results.instantLikelihood += model.alpha[i];\n        }\n      } else {\n        model.alpha[0] = this.params.prior[modelIndex] *\n          model.params.xStates[0].likelihood(observation);\n        [model.results.instantLikelihood] = model.alpha;\n      }\n      normConst += model.results.instantLikelihood;\n      modelIndex += 1;\n    });\n\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      for (let i = 0; i < N; i += 1) {\n        model.alpha[i] /= normConst;\n      }\n    });\n\n\n    this.frontierV1 = new Array(this.size).fill(0);\n    this.frontierV2 = new Array(this.size).fill(0);\n    this.forwardInitialized = true;\n  },\n\n  /**\n   * Update the forward algorithm of the hierarchical HMM\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  updateForwardAlgorithm(observation) {\n    let normConst = 0;\n\n    // Frontier Algorithm: variables\n    let tmp = 0;\n\n    // Intermediate variables: compute the sum of probabilities of making a\n    // transition to a new primitive\n    this.frontierV1 = this.likelihoodAlpha(1);\n    this.frontierV2 = this.likelihoodAlpha(2);\n\n    // FORWARD UPDATE\n    // --------------------------------------\n    let dstModelIndex = 0;\n    const classes = Object.keys(this.models).sort();\n    classes.forEach((label) => {\n      const dstModel = this.models[label];\n      const N = dstModel.params.states;\n\n      // 1) COMPUTE FRONTIER VARIABLE\n      //    --------------------------------------\n      // frontier variable : intermediate computation variable\n      const front = new Array(N).fill(0);\n\n      if (dstModel.params.transitionMode === 'ergodic') {\n        for (let k = 0; k < N; k += 1) {\n          for (let j = 0; j < N; j += 1) {\n            front[k] += (dstModel.params.transition[j][k] /\n              (1 - dstModel.params.exitProbabilities[j]))\n              * dstModel.alpha[j];\n          }\n\n          for (\n            let srcModelIndex = 0;\n            srcModelIndex < this.size();\n            srcModelIndex += 1\n          ) {\n            front[k] += dstModel.params.prior[k] * (\n              (this.frontierV1[srcModelIndex] *\n              this.params.transition[srcModelIndex][dstModelIndex]) +\n              (this.params.prior[dstModelIndex] *\n              this.frontierV2[srcModelIndex])\n            );\n          }\n        }\n      } else {\n        // k=0: first state of the primitive\n        front[0] = dstModel.params.transition[0] * dstModel.alpha[0];\n\n        for (\n          let srcModelIndex = 0;\n          srcModelIndex < this.size();\n          srcModelIndex += 1\n        ) {\n          front[0] += (this.frontierV1[srcModelIndex] *\n            this.params.transition[srcModelIndex][dstModelIndex]) +\n            (this.params.prior[dstModelIndex] *\n              this.frontierV2[srcModelIndex]);\n        }\n\n        // k>0: rest of the primitive\n        for (let k = 1; k < N; k += 1) {\n          front[k] += (dstModel.params.transition[k * 2] /\n            (1 - dstModel.params.exitProbabilities[k])) *\n            dstModel.alpha[k];\n          front[k] += (dstModel.params.transition[((k - 1) * 2) + 1] /\n            (1 - dstModel.params.exitProbabilities[k - 1])) *\n            dstModel.alpha[k - 1];\n        }\n\n        for (let k = 0; k < N; k += 1) {\n          dstModel.alpha[k] = 0;\n          dstModel.alpha1[k] = 0;\n          dstModel.alpha2[k] = 0;\n        }\n      }\n\n      // 2) UPDATE FORWARD VARIABLE\n      //    --------------------------------------\n      dstModel.results.exitLikelihood = 0.0;\n      dstModel.results.instantLikelihood = 0.0;\n\n      // end of the primitive: handle exit states\n      for (let k = 0; k < N; k += 1) {\n        tmp = dstModel.params.xStates[k].likelihood(observation) * front[k];\n        dstModel.alpha2[k] = this.params.exitTransition[dstModelIndex] *\n          dstModel.params.exitProbabilities[k] * tmp;\n        dstModel.alpha1[k] = (1 - this.params.exitTransition[dstModelIndex]) *\n          dstModel.params.exitProbabilities[k] * tmp;\n        dstModel.alpha[k] = (1 - dstModel.params.exitProbabilities[k]) * tmp;\n\n        dstModel.results.exitLikelihood += dstModel.alpha1[k] + dstModel.alpha2[k];\n        dstModel.results.instantLikelihood += dstModel.alpha[k] +\n          dstModel.alpha1[k] + dstModel.alpha2[k];\n        normConst += tmp;\n      }\n\n      dstModel.results.exitRatio = dstModel.results.exitLikelihood /\n        dstModel.results.instantLikelihood;\n\n      dstModelIndex += 1;\n    });\n\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      for (let k = 0; k < N; k += 1) {\n        model.alpha[k] /= normConst;\n        model.alpha1[k] /= normConst;\n        model.alpha2[k] /= normConst;\n      }\n    });\n  },\n\n  /**\n   * Compute the likelihood of a given probability.\n   * @param  {Number} exitNum Exit level number\n   * @return {Array<Number>}\n   */\n  likelihoodAlpha(exitNum) {\n    const likelihoodVector = new Array(this.size()).fill(0);\n    if (exitNum < 0) {\n      // Likelihood over all exit states\n      let modelIndex = 0;\n      Object.keys(this.models).sort().forEach((label) => {\n        const model = this.models[label];\n        likelihoodVector[modelIndex] = 0.0;\n        for (let k = 0; k < model.params.states; k += 1) {\n          likelihoodVector[modelIndex] += model.second.alpha[k] +\n            model.second.alpha1[k] +\n            model.second.alpha2[k];\n        }\n        modelIndex += 1;\n      });\n    } else {\n      // Likelihood for exit state \"exitNum\"\n      let modelIndex = 0;\n      Object.keys(this.models).sort().forEach((label) => {\n        const model = this.models[label];\n        likelihoodVector[modelIndex] = 0;\n        let { alpha } = model;\n        if (exitNum === 1) {\n          alpha = model.alpha1;\n        }\n        if (exitNum === 2) {\n          alpha = model.alpha2;\n        }\n        for (let k = 0; k < model.params.states; k += 1) {\n          likelihoodVector[modelIndex] += alpha[k];\n        }\n        modelIndex += 1;\n      });\n    }\n    return likelihoodVector;\n  },\n};\n\n/**\n * Add Hierarchical HMM prediction capabilities to a multi-class model.\n *\n * @todo algorithmic details\n * @todo validate parameters\n * @todo validate gaussian components\n *\n * @param  {MulticlassBaseModel} o Source Model\n * @return {HierarchicalHMM}\n *\n * @extends withMulticlassPrediction\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHierarchicalHMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  // validateParameters(\n  //   'Hierarchical HMM',\n  //   hierarchicalHmmParameterSpec(o.params.states, o.params.transitionMode),\n  //   o.params,\n  // );\n  return Object.assign(\n    o,\n    hierarchicalHmmPredictionPrototype,\n    {\n      // alpha: new Array(o.params.states).fill(0),\n      // previous_alpha_: new Array(o.params.states).fill(0),\n    },\n  ).setup();\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/hmm/hierarchical_hmm_prediction_mixin.js"],"sourceRoot":""}