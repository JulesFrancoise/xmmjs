{"version":3,"file":"index.js","sources":["../src/training_set/phrase.js","../src/training_set/index.js","../src/core/model_base_mixin.js","../src/common/euclidean.js","../src/kmeans/kmeans_training_mixin.js","../src/common/matrix.js","../src/common/gaussian_distribution.js","../src/core/em_training_mixin.js","../src/gmm/gmm_base_mixin.js","../src/gmm/gmm_training_mixin.js","../src/core/multiclass_mixin.js","../src/core/multiclass_training_mixin.js","../src/common/circular_buffer.js","../src/core/prediction_mixin.js","../src/common/validation.js","../src/gmm/gmm_prediction_mixin.js","../src/core/multiclass_prediction_mixin.js","../src/gmm/index.js","../src/hmm/hmm_base_mixin.js","../src/hmm/hmm_training_mixin.js","../src/hmm/hmm_prediction_mixin.js","../src/hmm/hierarchical_hmm_prediction_mixin.js","../src/hmm/index.js","../src/kmeans/index.js"],"sourcesContent":["/**\n * Data Phrase Prototype\n * @ignore\n */\nconst phrasePrototype = /** @lends Phrase */ {\n  /**\n   * Get the value at a given index and dimension\n   * @param  {Number} index index\n   * @param  {Number} dim   dimension\n   * @return {Number}\n   */\n  get(index, dim) {\n    if (typeof index !== 'number' || Math.floor(index) !== index) {\n      throw new Error('The index must be an integer');\n    }\n    if (dim >= this.dimension) {\n      throw new Error('Phrase: dimension out of bounds');\n    }\n    if (this.bimodal) {\n      if (dim < this.inputDimension) {\n        if (index >= this.inputData.length) {\n          throw new Error('Phrase: index out of bounds');\n        }\n        return this.inputData[index][dim];\n      }\n      if (index >= this.outputData.length) {\n        throw new Error('Phrase: index out of bounds');\n      }\n      return this.outputData[index][dim - this.inputDimension];\n    }\n    if (index >= this.length) {\n      throw new Error('Phrase: index out of bounds');\n    }\n    if (!this.inputData[index]) {\n      throw new Error('WTF?');\n    }\n    return this.inputData[index][dim];\n  },\n\n  /**\n   * Get the data frame at a given index\n   * @param  {Number} index index\n   * @return {Array<number>}\n   * @throws {Error} if the index is out of bounds\n   */\n  getFrame(index) {\n    if (index >= this.length) {\n      throw new Error('Phrase: index out of bounds');\n    }\n    if (this.bimodal) {\n      return this.inputData[index].concat(this.outputData[index]);\n    }\n    return this.inputData[index];\n  },\n\n  /**\n   * Push an observation vector to the phrase\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the observation's dimension does not match the\n   * dimension of the training set\n   */\n  push(observation) {\n    // console.log('push:', observation);\n    if (observation.length !== this.dimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    if (this.bimodal) {\n      this.inputData.push(observation.slice(0, this.inputDimension));\n      this.outputData.push(observation.slice(this.inputDimension, this.dimension));\n    } else {\n      this.inputData.push(observation);\n    }\n\n    this.length += 1;\n  },\n\n  /**\n   * Push an observation to the input modality only\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the phrase is not bimodal\n   * @throws {Error} if the observation's dimension does not match the\n   * input dimension of the training set\n   */\n  pushInput(observation) {\n    if (!this.bimodal) {\n      throw new Error('this phrase is unimodal, use `push`');\n    }\n    if (observation.length !== this.inputDimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    this.inputData.push(observation);\n    this.trim();\n  },\n\n  /**\n   * Push an observation to the output modality only\n   * @param  {Array<number>} observation observation data\n   * @throws {Error} if the phrase is not bimodal\n   * @throws {Error} if the observation's dimension does not match the\n   * output dimension of the training set\n   */\n  pushOutput(observation) {\n    if (!this.bimodal) {\n      throw new Error('this phrase is unimodal, use `push`');\n    }\n    if (observation.length !== this.outputDimension) {\n      throw new Error('Observation has wrong dimension');\n    }\n\n    this.outputData.push(observation);\n    this.trim();\n  },\n\n  /**\n   * Clear the phrase's data\n   */\n  clear() {\n    this.length = 0;\n    this.inputData = [];\n    this.outputData = [];\n  },\n\n  /**\n   * Clear the phrase's input data\n   */\n  clearInput() {\n    this.inputData = [];\n    this.trim();\n  },\n\n  /**\n   * Clear the phrase's output data\n   */\n  clearOutput() {\n    this.outputData = [];\n    this.trim();\n  },\n\n  /**\n   * Compute the mean of the phrase (across time)\n   * @return {Array<number>} The mean vector (same dimension as the\n   * training set)\n   */\n  mean() {\n    const mean = Array(this.dimension).fill(0);\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        mean[d] += this.get(t, d);\n      }\n      mean[d] /= this.length;\n    }\n    return mean;\n  },\n\n  /**\n   * Compute the standard deviation of the phrase (across time)\n   * @return {Array<number>} The standard deviation vector (same dimension as\n   * the training set)\n   */\n  standardDeviation() {\n    const stddev = Array(this.dimension).fill(0);\n    const mean = this.mean();\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        stddev[d] += (this.get(t, d) - mean[d]) * (this.get(t, d) - mean[d]);\n      }\n      stddev[d] /= this.length;\n      stddev[d] = Math.sqrt(stddev[d]);\n    }\n    return stddev;\n  },\n\n  /**\n   * Compute the minimum and maximum of the phrase (across time)\n   * @return {Array<{ min: number, max: number }>} The min/max vector (same\n   * dimension as the training set)\n   */\n  minmax() {\n    const minmax = Array.from(\n      Array(this.dimension),\n      () => ({ min: +Infinity, max: -Infinity }),\n    );\n    for (let d = 0; d < this.dimension; d += 1) {\n      for (let t = 0; t < this.length; t += 1) {\n        minmax[d].min = Math.min(this.get(t, d), minmax[d].min);\n        minmax[d].max = Math.max(this.get(t, d), minmax[d].max);\n      }\n    }\n    return minmax;\n  },\n\n  /**\n   * Trim the phrase length to the minimum of the input and output lengths\n   * @private\n   */\n  trim() {\n    if (this.bimodal) {\n      this.length = Math.min(this.inputData.length, this.outputData.length);\n    }\n  },\n};\n\n/**\n * Create a data phrase, potentially bimodal. Phrases are data structures for\n * temporal data (e.g. gestures), used to constitute training sets.\n *\n * @param {Object} [params]                   Phrase parameters\n * @param {Number} [params.inputDimension=1]  Dimension of the input modality\n * @param {Number} [params.outputDimension=0] Dimension of the output modality\n * (optional)\n * @param {Array<String>} [params.columnNames=null] Data column names, e.g.\n * \\['accX', 'accY', 'accZ'\\] (optional)\n * @param {String} [params.label='']          Phrase label\n * @return {Phrase}\n * @function\n *\n * @property {Boolean} bimodal Specifies if the phrase is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} length Phrase length (number of frames)\n * @property {String} label Phrase label\n * @property {Array<String>} columnNames Columns names\n */\nexport default function Phrase({\n  inputDimension = 1,\n  outputDimension = 0,\n  columnNames = null,\n  label = '',\n} = {}) {\n  const dimension = inputDimension + outputDimension;\n  return Object.assign(\n    Object.create(phrasePrototype),\n    {\n      bimodal: outputDimension > 0,\n      inputDimension,\n      outputDimension,\n      dimension,\n      length: 0,\n      label,\n      inputData: [],\n      outputData: [],\n      columnNames: columnNames || Array(dimension).fill(''),\n    },\n  );\n}\n","import Phrase from './phrase';\n\n/**\n * Training Set Prototype\n * @ignore\n */\nconst trainingSetPrototype = /** @lends TrainingSet */ {\n  /**\n   * Get the training set size (number of phrases)\n   * @return {number}\n   */\n  size() {\n    return Object.keys(this.phrases).length;\n  },\n\n  /**\n   * Checks if the training set is empty\n   * @return {boolean}\n   */\n  empty() {\n    return this.length === 0;\n  },\n\n  /**\n   * Get a reference to a phrase by index\n   * @param  {number} phraseIndex phrase index\n   * @return {Phrase}\n   */\n  getPhrase(phraseIndex) {\n    if (Object.keys(this.phrases).includes(phraseIndex.toString())) {\n      return this.phrases[phraseIndex.toString()];\n    }\n    return null;\n  },\n\n  /**\n   * Iterate over all phrases in the training set. The callback function\n   * should take 3 arguments: the phrase, its index in the training set,\n   * and the phrases structure.\n   *\n   * @param  {Function} callback Callback function\n   */\n  forEach(callback) {\n    Object.keys(this.phrases).forEach((phraseIndex) => {\n      callback(this.phrases[phraseIndex], phraseIndex, this.phrases);\n    });\n  },\n\n  /**\n   * Add a phrase to the training set and return it.\n   * @param  {number} phraseIndex        phrase index\n   * @param  {string} [label=undefined]  phrase label (its index if undefined)\n   * @param  {Phrase} [phrase=undefined] Phrase data. If unspecified, an empty\n   * phrase is created.\n   * @return {Phrase}\n   */\n  push(phraseIndex, label = undefined, phrase = undefined) {\n    const p = (phrase !== undefined) ? phrase : Phrase({\n      inputDimension: this.inputDimension,\n      outputDimension: this.outputDimension,\n      columnNames: this.columnNames,\n      label: (label !== undefined) ? label : phraseIndex.toString(),\n    });\n    this.phrases[phraseIndex] = p;\n    return p;\n  },\n\n  /**\n   * Remove a phrase\n   * @param  {number} phraseIndex phrase index\n   */\n  remove(phraseIndex) {\n    delete this.phrases[phraseIndex];\n  },\n\n  /**\n   * Remove all phrases with a given label\n   * @param  {string} label class label\n   */\n  removeClass(label) {\n    this.phrases = Object.keys(this.phrases)\n      .filter(i => this.phrases[i].label !== label)\n      .map(i => ({ i: this.phrases[i] }))\n      .reduce((x, p) => ({ ...x, ...p }), {});\n  },\n\n  /**\n   * Clear the training set (delete all phrases)\n   */\n  clear() {\n    this.phrases = {};\n  },\n\n  /**\n   * Get the sub-training set composed of all phrases of a given class\n   * @param  {string} label class label\n   * @return {TrainingSet}\n   */\n  getPhrasesOfClass(label) {\n    const ts = TrainingSet(this); // eslint-disable-line no-use-before-define\n    ts.phrases = Object.keys(this.phrases)\n      .filter(i => this.phrases[i].label === label)\n      .map(i => ({ i: this.phrases[i] }))\n      .reduce((x, p) => ({ ...x, ...p }), {});\n    return ts;\n  },\n\n  /**\n   * Get the list of unique labels in the training set\n   * @return {Array<string>}\n   */\n  labels() {\n    return Object.keys(this.phrases)\n      .map(i => this.phrases[i].label)\n      .reduce((ll, x) => (ll.includes(x) ? ll : ll.concat([x])), []);\n  },\n\n  /**\n   * Get the list of phrase indices\n   * @return {Array<number>}\n   */\n  indices() {\n    return Object.keys(this.phrases);\n  },\n\n  /**\n   * Get the mean of the training set over all phrases\n   * @return {Array<number>} mean (same dimension as the training set)\n   */\n  mean() {\n    const sum = Array(this.dimension).fill(0);\n    let totalLength = 0;\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          sum[d] += this.phrases[i].get(t, d);\n        }\n      }\n      totalLength += this.phrases[i].length;\n    });\n\n    return sum.map(x => x / totalLength);\n  },\n\n  /**\n   * Get the standard deviation of the training set over all phrases\n   * @return {Array<number>} standard deviation (same dimension as the training set)\n   */\n  standardDeviation() {\n    const stddev = Array(this.dimension).fill(0);\n    const mean = this.mean();\n    let totalLength = 0;\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          stddev[d] += (this.phrases[i].get(t, d) - mean[d]) ** 2;\n        }\n      }\n      totalLength += this.phrases[i].length;\n    });\n\n    return stddev.map(x => Math.sqrt(x / totalLength));\n  },\n\n  /**\n   * Get the min and max of the training set over all phrases\n   * @return {Array<{ min: number, max: number }>} min/max (same dimension as the training set)\n   */\n  minmax() {\n    const minmax = Array.from(\n      Array(this.dimension),\n      () => ({ min: +Infinity, max: -Infinity }),\n    );\n    Object.keys(this.phrases).forEach((i) => {\n      for (let d = 0; d < this.dimension; d += 1) {\n        for (let t = 0; t < this.phrases[i].length; t += 1) {\n          minmax[d].min += Math.min(minmax[d].min, this.phrases[i].get(t, d));\n          minmax[d].max += Math.max(minmax[d].max, this.phrases[i].get(t, d));\n        }\n      }\n    });\n    return minmax;\n  },\n};\n\n/**\n * Create a Training set, composed of a set of indexed data phrases\n * @param {Object} [params]                   Training set parameters\n * @param {Number} [params.inputDimension=1]  Dimension of the input modality\n * @param {Number} [params.outputDimension=0] Dimension of the output modality\n * (optional)\n * @param {Array<String>} [params.columnNames=null] Data column names, e.g.\n * \\['accX', 'accY', 'accZ'\\] (optional)\n * @return {TrainingSet}\n * @function\n *\n * @property {Boolean} bimodal Specifies if the training set is bimodal\n * @property {Number}  inputDimension Dimension of the input modality\n * @property {Number}  outputDimension Dimension of the output modality\n * @property {Number}  dimension Total dimension\n * @property {Array<String>} columnNames Columns names\n */\nexport default function TrainingSet({\n  inputDimension = 1,\n  outputDimension = 0,\n  columnNames = null,\n} = {}) {\n  const dimension = inputDimension + outputDimension;\n  return Object.assign(\n    Object.create(trainingSetPrototype),\n    {\n      bimodal: outputDimension > 0,\n      inputDimension,\n      outputDimension,\n      dimension,\n      columnNames: columnNames || Array(dimension).fill(''),\n      phrases: {},\n    },\n  );\n}\n","/**\n * Create the skeleton of a model\n *\n * @function\n * @param       {Number} inputDimension  input dimension\n * @param       {Number} outputDimension output dimension\n * @param       {Object} parameters      additional parameters to be copied\n * @constructor\n */\nexport default function ModelBase({\n  inputDimension,\n  outputDimension,\n  ...parameters\n}) {\n  const p = parameters;\n  delete p.bimodal;\n  delete p.inputDimension;\n  delete p.outputDimension;\n  delete p.dimension;\n  return /** @lends ModelBase */{\n    params: {\n      ...p,\n      get bimodal() {\n        return outputDimension > 0;\n      },\n      get inputDimension() {\n        return inputDimension;\n      },\n      get outputDimension() {\n        return outputDimension;\n      },\n      get dimension() {\n        return inputDimension + outputDimension;\n      },\n    },\n  };\n}\n\n/**\n * Check if an object is a base model (check for attribute existence)\n * @param  {Object}  o Source object\n * @return {Boolean}\n */\nexport function isBaseModel(o) {\n  if (!Object.keys(o).includes('params')) return false;\n  const keys = ['bimodal', 'inputDimension', 'outputDimension', 'dimension'];\n  return keys.map(key => Object.keys(o.params).includes(key))\n    .reduce((a, b) => a && b, true);\n}\n","/**\n * Compute the euclidean distance between to vectors\n * @param  {Array} v1\n * @param  {Array} v2\n * @return {number}\n */\nexport default function euclidean(v1, v2) {\n  return Math.sqrt(v1\n    .map((x1, i) => (x1 - v2[i]) ** 2)\n    .reduce((a, x) => (a + x), 0));\n}\n","import { isBaseModel } from '../core/model_base_mixin';\nimport euclidean from '../common/euclidean';\n\nconst kMeansTrainingPrototype = {\n  train(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) {\n      throw new Error('The training set is empty');\n    }\n\n    this.params.centers = Array.from(\n      Array(this.params.clusters),\n      () => new Array(this.params.dimension).fill(0),\n    );\n\n    // TODO: improve initialization =>\n    // https://www.slideshare.net/djempol/kmeans-initialization-15041920\n    //\n    if (this.trainingConfig.initialization === 'random') {\n      this.initializeClustersRandom(trainingSet);\n    } else if (this.trainingConfig.initialization === 'forgy') {\n      this.initializeClustersForgy(trainingSet);\n    } else if (this.trainingConfig.initialization === 'data') {\n      this.initClustersWithFirstPhrase(trainingSet);\n    } else {\n      throw new Error('Unknown K-Means initialization, must be `random`, `forgy` or `data`');\n    }\n\n    for (\n      let trainingNbIterations = 0;\n      trainingNbIterations < this.trainingConfig.maxIterations;\n      trainingNbIterations += 1\n    ) {\n      const previousCenters = this.params.centers;\n\n      this.updateCenters(previousCenters, trainingSet);\n\n      let meanClusterDistance = 0;\n      let maxRelativeCenterVariation = 0;\n      for (let k = 0; k < this.params.clusters; k += 1) {\n        for (let l = 0; l < this.params.clusters; l += 1) {\n          if (k !== l) {\n            meanClusterDistance += euclidean(\n              this.params.centers[k],\n              this.params.centers[l],\n            );\n          }\n        }\n        maxRelativeCenterVariation = Math.max(\n          euclidean(\n            previousCenters[k],\n            this.params.centers[k],\n          ),\n          maxRelativeCenterVariation,\n        );\n      }\n      meanClusterDistance /= this.params.clusters * (this.params.clusters - 1);\n      maxRelativeCenterVariation /= this.params.clusters;\n      maxRelativeCenterVariation /= meanClusterDistance;\n      if (maxRelativeCenterVariation < this.trainingConfig.relativeDistanceThreshold) break;\n    }\n    return this.params;\n  },\n\n  initClustersWithFirstPhrase(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const step = Math.floor(phrase.length / this.params.clusters);\n\n    let offset = 0;\n    for (let c = 0; c < this.params.clusters; c += 1) {\n      this.params.centers[c] = new Array(this.params.dimension).fill(0);\n      for (let t = 0; t < step; t += 1) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[c][d] += phrase.get(offset + t, d) / step;\n        }\n      }\n      offset += step;\n    }\n  },\n\n  initializeClustersRandom(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const indices = Array.from(\n      Array(phrase.length),\n      () => Math.floor(Math.random() * this.params.clusters),\n    );\n    const pointsPerCluster = indices.reduce(\n      (ppc, i) => {\n        const p = ppc;\n        p[i] += 1;\n        return p;\n      },\n      Array(this.params.clusters).fill(0),\n    );\n    for (let i = 0; i < indices.length; i += 1) {\n      const clustIdx = indices[i];\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.centers[clustIdx][d] += phrase.get(i, d);\n      }\n    }\n    this.params.centers.forEach((_, c) => {\n      this.params.centers[c] = this.params.centers[c]\n        .map(x => x / pointsPerCluster[c]);\n    });\n  },\n\n  initializeClustersForgy(trainingSet) {\n    const phrase = trainingSet.getPhrase(trainingSet.indices()[0]);\n    const indices = Array.from(\n      Array(this.params.clusters),\n      () => Math.floor(Math.random() * phrase.length),\n    );\n    this.params.centers = indices.map(i => phrase.getFrame(i));\n  },\n\n  updateCenters(previousCenters, trainingSet) {\n    this.params.centers = Array.from(Array(this.params.clusters), () =>\n      new Array(this.params.dimension).fill(0));\n    const numFramesPerCluster = Array(this.params.clusters).fill(0);\n    trainingSet.forEach((phrase) => {\n      for (let t = 0; t < phrase.length; t += 1) {\n        const frame = phrase.getFrame(t);\n        let minDistance = euclidean(frame, previousCenters[0]);\n        let clusterMembership = 0;\n        for (let k = 1; k < this.params.clusters; k += 1) {\n          const distance = euclidean(\n            frame,\n            previousCenters[k],\n            this.params.dimension,\n          );\n          if (distance < minDistance) {\n            clusterMembership = k;\n            minDistance = distance;\n          }\n        }\n        numFramesPerCluster[clusterMembership] += 1;\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[clusterMembership][d] += phrase.get(t, d);\n        }\n      }\n    });\n    for (let k = 0; k < this.params.clusters; k += 1) {\n      if (numFramesPerCluster[k] > 0) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          this.params.centers[k][d] /= numFramesPerCluster[k];\n        }\n      }\n    }\n  },\n};\n\nexport default function withKMeansTraining(\n  o,\n  clusters,\n  trainingConfiguration = {},\n) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const trainingConfig = Object.assign({\n    initialization: 'random',\n    relativeDistanceThreshold: 1e-3,\n    minIterations: 5,\n    maxIterations: 100,\n  }, trainingConfiguration);\n  const model = Object.assign(o, kMeansTrainingPrototype, {\n    trainingConfig,\n  });\n  model.params.clusters = clusters;\n  return model;\n}\n","/* eslint-disable no-use-before-define */\nconst kEpsilonPseudoInverse = 1.0e-9;\n\n/**\n * Matrix Prototype\n * @type {Object}\n * @property {Array} data Matrix data\n * @property {Number} ncols Number of columns\n * @property {Number} nrows Number of rows\n *\n * @ignore\n */\nconst matrixPrototype = /** @lends Matrix */ {\n  /**\n   * Compute the Sum of the matrix\n   * @return {Number} Sum of all elements in the matrix\n   */\n  sum() {\n    return this.data.reduce((a, b) => a + b, 0);\n  },\n\n  /**\n   * Compute the transpose matrix\n   * @return {Matrix}\n   */\n  transpose() {\n    const out = Matrix(this.ncols, this.nrows);\n    for (let i = 0; i < this.ncols; i += 1) {\n      for (let j = 0; j < this.nrows; j += 1) {\n        out.data[(i * this.nrows) + j] = this.data[(j * this.ncols) + i];\n      }\n    }\n    return out;\n  },\n\n  /**\n   * Compute the product of matrices\n   * @param  {Matrix} mat Second matrix\n   * @return {Matrix}     Product of the current matrix by `mat`\n   */\n  product(mat) {\n    if (this.ncols !== mat.nrows) {\n      throw new Error('Wrong dimensions for matrix product');\n    }\n    const out = Matrix(this.nrows, mat.ncols);\n    for (let i = 0; i < this.nrows; i += 1) {\n      for (let j = 0; j < mat.ncols; j += 1) {\n        out.data[(i * mat.ncols) + j] = 0;\n        for (let k = 0; k < this.ncols; k += 1) {\n          out.data[(i * mat.ncols) + j] +=\n            this.data[(i * this.ncols) + k] * mat.data[(k * mat.ncols) + j];\n        }\n      }\n    }\n    return out;\n  },\n\n  /**\n   * Compute the Pseudo-Inverse of a Matrix\n   * @param  {Number} determinant Determinant (computed with the inversion)\n   * @return {Matrix}             Pseudo-inverse of the matrix\n   */\n  pinv() {\n    if (this.nrows === this.ncols) {\n      return this.gaussJordanInverse();\n    }\n\n    const transp = this.transpose();\n    if (this.nrows >= this.ncols) {\n      const prod = transp.product(this);\n      const { determinant, matrix: dst } = prod.gaussJordanInverse();\n      return { determinant, matrix: dst.product(transp) };\n    }\n    const prod = this.product(transp);\n    const { determinant, matrix: dst } = prod.gaussJordanInverse();\n    return { determinant, matrix: transp.product(dst) };\n  },\n\n  /**\n   * Compute the Gauss-Jordan Inverse of a Square Matrix\n   * !!! Determinant (computed with the inversion\n   * @private\n   */\n  gaussJordanInverse() {\n    if (this.nrows !== this.ncols) {\n      throw new Error('Gauss-Jordan inversion: Cannot invert Non-square matrix');\n    }\n    let determinant = 1;\n    const mat = Matrix(this.nrows, this.ncols * 2);\n    const newMat = Matrix(this.nrows, this.ncols * 2);\n    const n = this.nrows;\n\n    // Create matrix\n    for (let i = 0; i < n; i += 1) {\n      for (let j = 0; j < n; j += 1) {\n        mat.data[(i * 2 * n) + j] = this.data[(i * n) + j];\n      }\n      mat.data[(i * 2 * n) + n + i] = 1;\n    }\n\n    for (let k = 0; k < n; k += 1) {\n      let i = k;\n      while (Math.abs(mat.data[(i * 2 * n) + k]) < kEpsilonPseudoInverse) {\n        i += 1;\n        if (i === n) {\n          throw new Error('Non-invertible matrix');\n        }\n      }\n      determinant *= mat.data[(i * 2 * n) + k];\n\n      // if found > Exchange lines\n      if (i !== k) {\n        mat.swapLines(i, k);\n      }\n\n      newMat.data = mat.data.slice();\n\n      for (let j = 0; j < 2 * n; j += 1) {\n        newMat.data[(k * 2 * n) + j] /= mat.data[(k * 2 * n) + k];\n      }\n      for (let ii = 0; ii < n; ii += 1) {\n        if (ii !== k) {\n          for (let j = 0; j < 2 * n; j += 1) {\n            newMat.data[(ii * 2 * n) + j] -=\n                mat.data[(ii * 2 * n) + k] *\n                newMat.data[(k * 2 * n) + j];\n          }\n        }\n      }\n      mat.data = newMat.data.slice();\n    }\n\n    const dst = Matrix(this.nrows, this.ncols);\n    for (let i = 0; i < n; i += 1) {\n      for (let j = 0; j < n; j += 1) {\n        dst.data[(i * n) + j] = mat.data[(i * 2 * n) + n + j];\n      }\n    }\n    return { determinant, matrix: dst };\n  },\n\n  /**\n   * Swap 2 lines of the matrix\n   * @param  {[type]} i index of the first line\n   * @param  {[type]} j index of the second line\n   * @private\n   */\n  swapLines(i, j) {\n    for (let k = 0; k < this.ncols; k += 1) {\n      const tmp = this.data[(i * this.ncols) + k];\n      this.data[(i * this.ncols) + k] = this.data[(j * this.ncols) + k];\n      this.data[(j * this.ncols) + k] = tmp;\n    }\n  },\n\n  /**\n   * Swap 2 columns of the matrix\n   * @param  {[type]} i index of the first column\n   * @param  {[type]} j index of the second column\n   * @private\n   */\n  swapColumns(i, j) {\n    for (let k = 0; k < this.nrows; k += 1) {\n      const tmp = this.data[(k * this.ncols) + i];\n      this.data[(k * this.ncols) + i] = this.data[(k * this.ncols) + j];\n      this.data[(k * this.ncols) + j] = tmp;\n    }\n  },\n};\n\n/**\n * Create a matrix\n *\n * @function\n * @param       {Number} [nrows=0]  Number of rows\n * @param       {Number} [ncols=-1] Number of columns\n * @return {matrixPrototype}\n *\n * @property {Array} data Matrix data\n * @property {Number} ncols Number of columns\n * @property {Number} nrows Number of rows\n */\nexport default function Matrix(nrows = 0, ncols = -1) {\n  const nc = ncols < 0 ? nrows : ncols;\n  return Object.assign(\n    Object.create(matrixPrototype), //\n    {\n      nrows,\n      ncols: nc,\n      data: Array(nrows * nc).fill(0),\n    },\n  );\n}\n","import Matrix from './matrix';\n\n/**\n * Gaussian Distribution Prototype\n *\n * @type {Object}\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n *\n * @ignore\n */\nconst baseGaussianPrototype = /** @lends GaussianDistribution */ {\n  /**\n   * Allocate the distribution\n   * @private\n   */\n  allocate() {\n    this.mean = new Array(this.dimension).fill(0);\n    if (this.covarianceMode === 'full') {\n      this.covariance = new Array(this.dimension ** 2).fill(0);\n      this.inverseCovariance = new Array(this.dimension ** 2).fill(0);\n    } else {\n      this.covariance = new Array(this.dimension).fill(0);\n      this.inverseCovariance = new Array(this.dimension).fill(0);\n    }\n    if (this.bimodal) {\n      this.allocateBimodal();\n    }\n  },\n\n  /**\n   * @brief Estimate the likelihood of an observation vector.\n   *\n   * If the distribution is bimodal an the observation is a vector of the size\n   * of the input modality, the likelihood is computed only on the\n   * distribution for the input modality\n   *\n   * @param  {array} observation data observation\n   * @return {number}\n   */\n  likelihood(observation) {\n    if (this.covarianceDeterminant === 0) {\n      throw new Error('Covariance Matrix is not invertible');\n    }\n    if (this.bimodal && observation.length === this.inputDimension) {\n      return this.inputLikelihood(observation);\n    }\n    if (observation.length !== this.dimension) {\n      throw new Error(`GaussianDistribution: observation has wrong dimension. Expected \\`${this.dimension}\\`, got \\`${observation.length}\\``);\n    }\n\n    let euclideanDistance = 0;\n    if (this.covarianceMode === 'full') {\n      for (let l = 0; l < this.dimension; l += 1) {\n        let tmp = 0;\n        for (let k = 0; k < this.dimension; k += 1) {\n          tmp += this.inverseCovariance[(l * this.dimension) + k] *\n            (observation[k] - this.mean[k]);\n        }\n        euclideanDistance += (observation[l] - this.mean[l]) * tmp;\n      }\n    } else {\n      for (let l = 0; l < this.dimension; l += 1) {\n        euclideanDistance += this.inverseCovariance[l] *\n          (observation[l] - this.mean[l]) *\n          (observation[l] - this.mean[l]);\n      }\n    }\n\n    let p = Math.exp(-0.5 * euclideanDistance) /\n      Math.sqrt(this.covarianceDeterminant * ((2 * Math.PI) ** this.dimension));\n\n    if (p < 1e-180 || Number.isNaN(p) || Math.abs(p) === +Infinity) {\n      p = 1e-180;\n    }\n\n    return p;\n  },\n\n  /**\n   * Regularize the distribution, given a regularization vector of the same\n   * dimension. Regularization adds the vector to the variance of the\n   * distribution.\n   *\n   * @param  {Array} regularization regularization vector\n   */\n  regularize(regularization) {\n    if (this.covarianceMode === 'full') {\n      for (let d = 0; d < this.dimension; d += 1) {\n        this.covariance[(d * this.dimension) + d] += regularization[d];\n      }\n    } else {\n      for (let d = 0; d < this.dimension; d += 1) {\n        this.covariance[d] += regularization[d];\n      }\n    }\n  },\n\n  /**\n   * Update the inverse covariance of the distribution\n   * @private\n   */\n  updateInverseCovariance() {\n    if (this.covarianceMode === 'full') {\n      const covMatrix = Matrix(this.dimension, this.dimension);\n\n      covMatrix.data = this.covariance.slice();\n      const inv = covMatrix.pinv();\n      this.covarianceDeterminant = inv.determinant;\n      this.inverseCovariance = inv.matrix.data;\n    } else { // DIAGONAL COVARIANCE\n      this.covarianceDeterminant = 1;\n      for (let d = 0; d < this.dimension; d += 1) {\n        if (this.covariance[d] <= 0) {\n          throw new Error('Non-invertible matrix');\n        }\n        this.inverseCovariance[d] = 1 / this.covariance[d];\n        this.covarianceDeterminant *= this.covariance[d];\n      }\n    }\n    if (this.bimodal) {\n      this.updateInverseCovarianceBimodal();\n    }\n  },\n\n  /**\n   * Convert to an ellipse allong two dimensions\n   *\n   * @param  {number} dimension1 first dimension\n   * @param  {number} dimension2 second dimension\n   * @return {Ellipse}\n   */\n  toEllipse(dimension1, dimension2) {\n    if (dimension1 >= this.dimension || dimension2 >= this.dimension) {\n      throw new Error('dimensions out of range');\n    }\n\n    const gaussianEllipse = {\n      x: 0,\n      y: 0,\n      width: 0,\n      height: 0,\n      angle: 0,\n    };\n    gaussianEllipse.x = this.mean[dimension1];\n    gaussianEllipse.y = this.mean[dimension2];\n\n    // Represent 2D covariance with square matrix\n    // |a b|\n    // |b c|\n    let a;\n    let b;\n    let c;\n    if (this.covarianceMode === 'full') {\n      a = this.covariance[(dimension1 * this.dimension) + dimension1];\n      b = this.covariance[(dimension1 * this.dimension) + dimension2];\n      c = this.covariance[(dimension2 * this.dimension) + dimension2];\n    } else {\n      a = this.covariance[dimension1];\n      b = 0;\n      c = this.covariance[dimension2];\n    }\n\n    // Compute Eigen Values to get width, height and angle\n    const trace = a + c;\n    const determinant = (a * c) - (b * b);\n    const eigenVal1 = 0.5 * (trace + Math.sqrt((trace ** 2) - (4 * determinant)));\n    const eigenVal2 = 0.5 * (trace - Math.sqrt((trace ** 2) - (4 * determinant)));\n    gaussianEllipse.width = Math.sqrt(5.991 * eigenVal1);\n    gaussianEllipse.height = Math.sqrt(5.991 * eigenVal2);\n    gaussianEllipse.angle = Math.atan(b / (eigenVal1 - c));\n    if (Number.isNaN(gaussianEllipse.angle)) {\n      gaussianEllipse.angle = Math.PI / 2;\n    }\n\n    return gaussianEllipse;\n  },\n\n  /**\n   * Modify the distribution along two dimensions given the equivalent values\n   * as an Ellipse representation.\n   *\n   * @param  {Ellipse} gaussianEllipse The Ellipse corresponding to the 2D\n   * covariance along the two target dimensions\n   * @param  {number} dimension1      first dimension\n   * @param  {number} dimension2      second dimension\n   */\n  fromEllipse(gaussianEllipse, dimension1, dimension2) {\n    if (dimension1 >= this.dimension || dimension2 >= this.dimension) {\n      throw new Error('dimensions out of range');\n    }\n\n    this.mean[dimension1] = gaussianEllipse.x;\n    this.mean[dimension2] = gaussianEllipse.y;\n\n    const eigenVal1 = (gaussianEllipse.width * gaussianEllipse.width) / 5.991;\n    const eigenVal2 = (gaussianEllipse.height * gaussianEllipse.height) / 5.991;\n    const tantheta = Math.tan(gaussianEllipse.angle);\n    const b = ((eigenVal1 - eigenVal2) * tantheta) / ((tantheta ** 2) + 1);\n    const c = eigenVal1 - (b / tantheta);\n    const a = eigenVal2 + (b / tantheta);\n\n    if (this.covarianceMode === 'full') {\n      this.covariance[(dimension1 * this.dimension) + dimension1] = a;\n      this.covariance[(dimension1 * this.dimension) + dimension2] = b;\n      this.covariance[(dimension2 * this.dimension) + dimension1] = b;\n      this.covariance[(dimension2 * this.dimension) + dimension2] = c;\n    } else {\n      this.covariance[dimension1] = a;\n      this.covariance[dimension2] = c;\n    }\n    this.updateInverseCovariance();\n  },\n};\n\n/**\n * Bimodal Gaussian Distribution Prototype, for Regression purposes\n *\n * @type {Object}\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n * @property {Array}   inverseCovarianceInput Inverse covariance of the input\n * modality\n *\n * @ignore\n */\nconst bimodalGaussianPrototype = /** @lends GaussianDistribution */ {\n  /**\n   * Allocate the distribution\n   * @private\n   */\n  allocateBimodal() {\n    if (this.covarianceMode === 'full') {\n      this.inverseCovarianceInput = new Array(this.inputDimension ** 2).fill(0);\n    } else {\n      this.inverseCovarianceInput = new Array(this.inputDimension).fill(0);\n    }\n  },\n\n  /**\n   * Estimate the likelihood of an observation for the input modality only.\n   * Called by `likelihood` when relevant.\n   * @param  {Array} inputObservation observation (input modality only)\n   * @return {number}\n   * @private\n   */\n  inputLikelihood(inputObservation) {\n    if (this.covarianceDeterminantInput === 0) {\n      throw new Error('Covariance Matrix of input modality is not invertible');\n    }\n\n    let euclideanDistance = 0;\n    if (this.covarianceMode === 'full') {\n      for (let l = 0; l < this.inputDimension; l += 1) {\n        let tmp = 0;\n        for (let k = 0; k < this.inputDimension; k += 1) {\n          tmp += this.inverseCovarianceInput[(l * this.inputDimension) + k] *\n            (inputObservation[k] - this.mean[k]);\n        }\n        euclideanDistance += (inputObservation[l] - this.mean[l]) * tmp;\n      }\n    } else {\n      for (let l = 0; l < this.inputDimension; l += 1) {\n        euclideanDistance += this.inverseCovariance[l] *\n          (inputObservation[l] - this.mean[l]) *\n          (inputObservation[l] - this.mean[l]);\n      }\n    }\n\n    let p = Math.exp(-0.5 * euclideanDistance) /\n               Math.sqrt(this.covarianceDeterminantInput *\n                    ((2 * Math.PI) ** this.inputDimension));\n\n    if (p < 1e-180 || Number.isNaN(p) || Math.abs(p) === +Infinity) p = 1e-180;\n\n    return p;\n  },\n\n  /**\n   * Estimate the output values associated with an input observation by\n   * regression, given the distribution parameters.\n   *\n   * @todo Clarify the maths here.\n   *\n   * @param  {Array} inputObservation observation (input modality only)\n   * @return {Array} Output values\n   */\n  regression(inputObservation) {\n    const outputDimension = this.dimension - this.inputDimension;\n    const prediction = Array(outputDimension).fill(0);\n\n    if (this.covarianceMode === 'full') {\n      for (let d = 0; d < outputDimension; d += 1) {\n        prediction[d] = this.mean[this.inputDimension + d];\n        for (let e = 0; e < this.inputDimension; e += 1) {\n          let tmp = 0;\n          for (let f = 0; f < this.inputDimension; f += 1) {\n            tmp += this.inverseCovarianceInput[(e * this.inputDimension) + f] *\n              (inputObservation[f] - this.mean[f]);\n          }\n          prediction[d] += tmp *\n            this.covariance[((d + this.inputDimension) * this.dimension) + e];\n        }\n      }\n    } else {\n      for (let d = 0; d < outputDimension; d += 1) {\n        prediction[d] = this.mean[this.inputDimension + d];\n      }\n    }\n    return prediction;\n  },\n\n  /**\n   * Update the inverse covariance\n   * @private\n   */\n  updateInverseCovarianceBimodal() {\n    if (this.covarianceMode === 'full') {\n      const covMatrixInput = Matrix(this.inputDimension, this.inputDimension);\n      for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n        for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n          covMatrixInput.data[(d1 * this.inputDimension) + d2] =\n            this.covariance[(d1 * this.dimension) + d2];\n        }\n      }\n      const invInput = covMatrixInput.pinv();\n      this.covarianceDeterminantInput = invInput.determinant;\n      this.inverseCovarianceInput = invInput.matrix.data;\n    } else { // DIAGONAL COVARIANCE\n      this.covarianceDeterminantInput = 1;\n      for (let d = 0; d < this.inputDimension; d += 1) {\n        if (this.covariance[d] <= 0) {\n          throw new Error('Non-invertible matrix');\n        }\n        this.inverseCovarianceInput[d] = 1 / this.covariance[d];\n        this.covarianceDeterminantInput *= this.covariance[d];\n      }\n    }\n    this.updateOutputCovariance();\n  },\n\n  /**\n   * Update the output covariance\n   * @private\n   */\n  updateOutputCovariance() {\n    if (this.covarianceMode === 'diagonal') {\n      this.outputCovariance = this.covariance.slice(0, this.inputDimension);\n      return;\n    }\n\n    // CASE: FULL COVARIANCE\n    const covMatrixInput = Matrix(this.inputDimension, this.inputDimension);\n    for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n        covMatrixInput.data[(d1 * this.inputDimension) + d2] =\n          this.covariance[(d1 * this.dimension) + d2];\n      }\n    }\n    const inv = covMatrixInput.pinv();\n    const covarianceGS = Matrix(this.inputDimension, this.outputDimension);\n    for (let d1 = 0; d1 < this.inputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n        covarianceGS.data[(d1 * this.outputDimension) + d2] =\n          this.covariance[(d1 * this.dimension) + this.inputDimension + d2];\n      }\n    }\n    const covarianceSG = Matrix(this.outputDimension, this.inputDimension);\n    for (let d1 = 0; d1 < this.outputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.inputDimension; d2 += 1) {\n        covarianceSG.data[(d1 * this.inputDimension) + d2] =\n          this.covariance[((this.inputDimension + d1) * this.dimension) + d2];\n      }\n    }\n    const tmptmptmp = inv.matrix.product(covarianceGS);\n    const covarianceMod = covarianceSG.product(tmptmptmp);\n    this.outputCovariance = Array(this.outputDimension ** 2).fill(0);\n    for (let d1 = 0; d1 < this.outputDimension; d1 += 1) {\n      for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n        this.outputCovariance[(d1 * this.outputDimension) + d2] =\n          this.covariance[((this.inputDimension + d1) * this.dimension) +\n            this.inputDimension + d2] -\n            covarianceMod.data[(d1 * this.outputDimension) + d2];\n      }\n    }\n  },\n};\n\n/**\n * Multivariate Gaussian Distribution factory function.\n * Full covariance, optionally multimodal with support for regression.\n *\n * @function\n * @param {Number} [inputDimension=1]      Dimension of the input modality\n * @param {Number} [outputDimension=0]     Dimension of the output\n * modality (positive for regression, otherwise 0 for recognition).\n * @param {String} [covarianceMode='full'] covariance mode (full vs\n * diagonal)\n * @return {baseGaussianPrototype|bimodalGaussianPrototype}\n *\n * @property {boolean} bimodal           Specifies if the distribution is\n * bimodal (for regression use)\n * @property {number}  inputDimension    input dimension\n * @property {number}  outputDimension   output dimension\n * @property {number}  dimension         Total dimension\n * @property {Array}   mean              Distribution mean\n * @property {Array}   covariance        Distribution covariance\n * @property {Array}   inverseCovariance Inverse covariance\n */\nexport default function GaussianDistribution(\n  inputDimension = 1,\n  outputDimension = 0,\n  covarianceMode = 'full',\n) {\n  const bimodal = outputDimension > 0;\n  const dimension = inputDimension + outputDimension;\n  const proto = bimodal ?\n    Object.assign({}, baseGaussianPrototype, bimodalGaussianPrototype) :\n    baseGaussianPrototype;\n  const data = Object.assign(\n    {\n      bimodal,\n      dimension,\n      inputDimension,\n      outputDimension,\n      covarianceMode,\n      covarianceDeterminant: 0,\n    },\n    bimodal ? { covarianceDeterminantInput: 0 } : {},\n  );\n  const dist = Object.assign(\n    Object.create(proto),\n    data,\n  );\n  dist.allocate();\n  return dist;\n}\n","const trainerPrototype = /** @lends withEMTraining */ {\n  /**\n   * Train the model from the given training set, using the\n   * Expectation-Maximisation algorithm.\n   *\n   * @param  {TrainingSet} trainingSet Training Set\n   * @return {Object} Parameters of the trained model\n   */\n  train(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) {\n      throw new Error('The training set is empty');\n    }\n\n    this.initTraining(trainingSet);\n\n    let logLikelihood = -Infinity;\n    let iterations = 0;\n    let previousLogLikelihood = logLikelihood;\n\n    while (!this.converged(iterations, logLikelihood, previousLogLikelihood)) {\n      previousLogLikelihood = logLikelihood;\n      logLikelihood = this.updateTraining(trainingSet);\n\n      const pctChg =\n        100 * Math.abs((logLikelihood - previousLogLikelihood) / previousLogLikelihood);\n      if (Number.isNaN(pctChg) && iterations > 1) {\n        throw new Error('An error occured during training');\n      }\n\n      iterations += 1;\n    }\n\n    this.terminateTraining();\n    return this.params;\n  },\n\n  /**\n   * Return `true` if the training has converged according to the criteria\n   * specified at the creation\n   *\n   * @param  {number} iteration       Current iteration\n   * @param  {number} logProb         Current log-likelihood of the training set\n   * @param  {number} previousLogProb Previous log-likelihood of the training\n   * set\n   * @return {boolean}\n   *\n   * @private\n   */\n  converged(iteration, logProb, previousLogProb) {\n    if (iteration >= this.convergenceCriteria.maxIterations) return true;\n    if (this.convergenceCriteria.maxIterations >= this.convergenceCriteria.minIterations) {\n      return iteration >= this.convergenceCriteria.maxIterations;\n    }\n    if (iteration < this.convergenceCriteria.minIterations) return false;\n    const percentChange = 100 * Math.abs((logProb - previousLogProb) / logProb);\n    return percentChange <= this.convergenceCriteria.percentChange;\n  },\n};\n\n/**\n * Add ABSTRACT training capabilities to a model for which the training process\n * use the Expectation-Maximisation (EM) algorithm. This is used in particular\n * for training GMMs and HMMs.\n *\n * The final instance needs to implement `initTraining`, `updateTraining` and\n * `terminateTraining` methods. `updateTraining` will be called until the\n * convergence criteria are met. Convergence depends on\n * - A minimum number of iterations\n * - A maximum number of iterations\n * - A threshold on the relative change of the log-likelihood of the training\n * data between successive iterations.\n *\n * @todo details\n *\n * @param  {Object} [o]                   Source object\n * @param  {Object} [convergenceCriteria] Set of convergence criteria\n * @param  {number} [convergenceCriteria.percentChange=1e-3] Threshold in % of\n * the relative change of the log-likelihood, under which the training stops.\n * @param  {number} [convergenceCriteria.minIterations=5]    minimum number of iterations\n * @param  {number} [convergenceCriteria.maxIterations=100]  maximum number of iterations\n * @return {Object}\n */\nexport default function withEMTraining(\n  o,\n  convergenceCriteria = {\n    percentChange: 1e-3,\n    minIterations: 5,\n    maxIterations: 100,\n  },\n) {\n  return Object.assign(o, trainerPrototype, { convergenceCriteria });\n}\n","import { isBaseModel } from '../core/model_base_mixin';\nimport GaussianDistribution from '../common/gaussian_distribution';\n\n/**\n * GMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst gmmBasePrototype = /** @lends withGMMBase */ {\n  /**\n   * Allocate the training variables\n   * @private\n   */\n  allocate() {\n    this.params.components = Array.from(\n      Array(this.params.gaussians),\n      () => new GaussianDistribution(\n        this.params.inputDimension,\n        this.params.outputDimension,\n        this.params.covarianceMode,\n      ),\n    );\n    this.params.mixtureCoeffs = Array(this.params.gaussians).fill(0);\n    this.beta = new Array(this.params.gaussians).fill(0);\n  },\n\n  /**\n   * Compute the likelihood of an observation given the GMM's parameters\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}\n   */\n  likelihood(observation) {\n    let likelihood = 0;\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.beta[c] = this.componentLikelihood(observation, c);\n      likelihood += this.beta[c];\n    }\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.beta[c] /= likelihood;\n    }\n\n    return likelihood;\n  },\n\n  /**\n   * Compute the likelihood of an observation for a single component\n   * @param  {Array<Number>} observation Observation vector\n   * @param  {Number} mixtureComponent Component index\n   * @return {Number}\n   * @private\n   */\n  componentLikelihood(observation, mixtureComponent) {\n    if (mixtureComponent >= this.params.gaussians) {\n      throw new Error('The index of the Gaussian Mixture Component is out of bounds');\n    }\n    return this.params.mixtureCoeffs[mixtureComponent] *\n        this.params.components[mixtureComponent].likelihood(observation);\n  },\n\n  /**\n   * Update the inverse covariance of each Gaussian component\n   * @private\n   */\n  updateInverseCovariances() {\n    this.params.components.forEach((c) => {\n      c.updateInverseCovariance();\n    });\n    try {\n      this.params.components.forEach((c) => {\n        c.updateInverseCovariance();\n      });\n    } catch (e) {\n      throw new Error('Matrix inversion error: varianceoffset must be too small');\n    }\n  },\n\n  /**\n   * Normalize the mixing coefficients of the Gaussian mixture\n   * @private\n   */\n  normalizeMixtureCoeffs() {\n    let normConst = 0;\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      normConst += this.params.mixtureCoeffs[c];\n    }\n    if (normConst > 0) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.mixtureCoeffs[c] /= normConst;\n      }\n    } else {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      }\n    }\n  },\n\n  /**\n   * Regularize the covariances\n   * @private\n   */\n  regularize() {\n    this.params.components.forEach((c) => {\n      c.regularize(this.currentRegularization);\n    });\n  },\n};\n\n/**\n * Bimodal (regression) GMM Prototype\n * @type {Object}\n * @ignore\n */\nconst gmmBimodalPrototype = /** @lends withGMMBase */ {\n  /**\n   * Estimate the output values corresponding to the input observation, by\n   * regression given the GMM's parameters. This method is called Gaussian\n   * Mixture Regression (GMR).\n   *\n   * @param  {Array<Number>} inputObservation Observation on the input modality\n   * @return {Array<Number>} Output values (length = outputDimension)\n   */\n  regression(inputObservation) {\n    this.results.outputValues = Array(this.params.outputDimension).fill(0);\n    this.results.outputCovariance = Array(this.params.covarianceMode === 'full' ? this.params.outputDimension ** 2 : this.params.outputDimension).fill(0);\n    let tmpOutputValues;\n\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      tmpOutputValues = this.params.components[c].regression(inputObservation);\n      for (let d = 0; d < this.params.outputDimension; d += 1) {\n        this.results.outputValues[d] += this.beta[c] * tmpOutputValues[d];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n            this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n              (this.beta[c] ** 2) *\n              this.params.components[c].outputCovariance[(d * this.params.outputDimension) + d2];\n          }\n        } else {\n          this.results.outputCovariance[d] +=\n            (this.beta[c] ** 2) * this.params.components[c].outputCovariance[d];\n        }\n      }\n    }\n    return this.results.outputValues;\n  },\n};\n\n/**\n * Add basic GMM capabilities to a single-class model. This enables the\n * computation of the likelihoods and regression operations common to\n * training and prediction\n *\n * @see withGMMTraining\n * @see withGMMPrediction\n *\n * @param  {ModelBase} o Source Model\n * @return {GMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withGMMBase(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    gmmBasePrototype,\n    o.params.bimodal ? gmmBimodalPrototype : {},\n  );\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withKMeansTraining from '../kmeans/kmeans_training_mixin';\n\n/**\n * GMM Training Prototype\n * @type {Object}\n * @ignore\n */\nconst gmmTrainerPrototype = /** @lends withGMMTraining */ {\n  /**\n   * Initialize the EM Training process\n   * @param  {TrainingSet} trainingSet Training set\n   */\n  initTraining(trainingSet) {\n    this.allocate();\n    this.initParametersToDefault(trainingSet.standardDeviation());\n    this.initMeansWithKMeans(trainingSet);\n    this.initCovariances(trainingSet);\n    this.regularize();\n    this.updateInverseCovariances();\n  },\n\n  /**\n   * Initialize the model parameters to their default values\n   * @param  {Array<Number>} dataStddev Standard deviation of the training data\n   * @private\n   */\n  initParametersToDefault(dataStddev) {\n    let normCoeffs = 0;\n    this.currentRegularization = dataStddev.map(std => Math.max(\n      this.params.regularization.absolute,\n      this.params.regularization.relative * std,\n    ));\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      if (this.params.covarianceMode === 'full') {\n        this.params.components[c].covariance = Array(this.params.dimension ** 2)\n          .fill(this.params.regularization.absolute / 2);\n      } else {\n        this.params.components[c].covariance = Array(this.params.dimension).fill(0);\n      }\n      this.params.components[c].regularize(this.currentRegularization);\n      this.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      normCoeffs += this.params.mixtureCoeffs[c];\n    }\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.mixtureCoeffs[c] /= normCoeffs;\n    }\n  },\n\n  /**\n   * Initialize the means of the model using a K-Means algorithm\n   *\n   * @see withKMeansTraining\n   *\n   * @param  {TrainingSet} trainingSet training set\n   * @private\n   */\n  initMeansWithKMeans(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n    const kmeans = withKMeansTraining(\n      ModelBase({\n        inputDimension: this.params.inputDimension,\n        outputDimension: this.params.outputDimension,\n      }),\n      this.params.gaussians,\n      { initialization: 'data' },\n    );\n    const kmeansParams = kmeans.train(trainingSet);\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.components[c].mean = kmeansParams.centers[c];\n    }\n  },\n\n  /**\n   * Initialize the covariances of the model from the training set\n   *\n   * @param  {TrainingSet} trainingSet training set\n   * @private\n   */\n  initCovariances(trainingSet) {\n    // TODO: simplify with covariance symmetricity\n    // TODO: If Kmeans, covariances from cluster members\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      this.params.components[n].covariance = Array((this.params.covarianceMode === 'full') ? this.params.dimension ** 2 : this.params.dimension).fill(0);\n    }\n\n    const gmeans = Array(this.params.gaussians * this.params.dimension).fill(0);\n    const factor = Array(this.params.gaussians).fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.gaussians);\n      let offset = 0;\n      for (let n = 0; n < this.params.gaussians; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            gmeans[(n * this.params.dimension) + d1] += phrase.get(offset + t, d1);\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n                this.params.components[n]\n                  .covariance[(d1 * this.params.dimension) + d2] +=\n                  phrase.get(offset + t, d1) * phrase.get(offset + t, d2);\n              }\n            } else {\n              this.params.components[n].covariance[d1] +=\n                phrase.get(offset + t, d1) ** 2;\n            }\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        gmeans[(n * this.params.dimension) + d1] /= factor[n];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[n].covariance[(d1 * this.params.dimension) + d2] /= factor[n];\n          }\n        } else {\n          this.params.components[n].covariance[d1] /= factor[n];\n        }\n      }\n    }\n\n    for (let n = 0; n < this.params.gaussians; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[n].covariance[(d1 * this.params.dimension) + d2] -=\n              gmeans[(n * this.params.dimension) + d1] *\n              gmeans[(n * this.params.dimension) + d2];\n          }\n        } else {\n          this.params.components[n].covariance[d1] -=\n            gmeans[(n * this.params.dimension) + d1] ** 2;\n        }\n      }\n    }\n  },\n\n  /**\n   * Update the EM Training process (1 EM iteration).\n   * @param  TrainingSet trainingSet training set\n   */\n  updateTraining(trainingSet) {\n    let logProb = 0;\n    let totalLength = 0;\n    trainingSet.forEach((phrase) => {\n      totalLength += phrase.length;\n    });\n    const phraseIndices = Object.keys(trainingSet.phrases);\n\n    const p = Array.from(\n      Array(this.params.gaussians),\n      () => new Array(totalLength).fill(0),\n    );\n    const E = Array(this.params.gaussians).fill(0);\n    let tbase = 0;\n\n    trainingSet.forEach((phrase) => {\n      for (let t = 0; t < phrase.length; t += 1) {\n        let normConst = 0;\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          p[c][tbase + t] = this.componentLikelihood(phrase.getFrame(t), c);\n\n          if (p[c][tbase + t] === 0 ||\n            Number.isNaN(p[c][tbase + t]) ||\n            p[c][tbase + t] === +Infinity) {\n            p[c][tbase + t] = 1e-100;\n          }\n          normConst += p[c][tbase + t];\n        }\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          p[c][tbase + t] /= normConst;\n          E[c] += p[c][tbase + t];\n        }\n        logProb += Math.log(normConst);\n      }\n      tbase += phrase.length;\n    });\n\n    // Estimate Mixture coefficients\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      this.params.mixtureCoeffs[c] = E[c] / totalLength;\n    }\n\n    // Estimate means\n    for (let c = 0; c < this.params.gaussians; c += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.components[c].mean[d] = 0;\n        tbase = 0;\n        for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n          const phrase = trainingSet.phrases[phraseIndices[pix]];\n          for (let t = 0; t < phrase.length; t += 1) {\n            this.params.components[c].mean[d] +=\n              p[c][tbase + t] * phrase.get(t, d);\n          }\n          tbase += phrase.length;\n        }\n        this.params.components[c].mean[d] /= E[c];\n      }\n    }\n\n    // estimate covariances\n    if (this.params.covarianceMode === 'full') {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n          for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n            this.params.components[c].covariance[(d1 * this.params.dimension) + d2] = 0;\n            tbase = 0;\n            for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n              const phrase = trainingSet.phrases[phraseIndices[pix]];\n              for (let t = 0; t < phrase.length; t += 1) {\n                this.params.components[c].covariance[(d1 * this.params.dimension) + d2] +=\n                  p[c][tbase + t] *\n                  (phrase.get(t, d1) - this.params.components[c].mean[d1]) *\n                  (phrase.get(t, d2) - this.params.components[c].mean[d2]);\n              }\n              tbase += phrase.length;\n            }\n            this.params.components[c].covariance[(d1 * this.params.dimension) + d2] /= E[c];\n            if (d1 !== d2) {\n              this.params.components[c].covariance[(d2 * this.params.dimension) + d1] =\n                this.params.components[c].covariance[(d1 * this.params.dimension) + d2];\n            }\n          }\n        }\n      }\n    } else {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n          this.params.components[c].covariance[d1] = 0;\n          tbase = 0;\n          for (let pix = 0; pix < phraseIndices.length; pix += 1) {\n            const phrase = trainingSet.phrases[phraseIndices[pix]];\n            for (let t = 0; t < phrase.length; t += 1) {\n              const value = (phrase.get(t, d1) - this.params.components[c].mean[d1]);\n              this.params.components[c].covariance[d1] +=\n                    p[c][tbase + t] * value * value;\n            }\n            tbase += phrase.length;\n          }\n          this.params.components[c].covariance[d1] /= E[c];\n        }\n      }\n    }\n\n    this.regularize();\n    this.updateInverseCovariances();\n\n    return logProb;\n  },\n\n  /**\n   * Terminate the EM Training process\n   */\n  terminateTraining() {},\n};\n\n/**\n * Add GMM Training capabilities to a GMM Model\n * @param  {GMMBase} o               Source GMM Model\n * @param  {Number} [gaussians=1]    Number of Gaussian components\n * @param  {Object} [regularization] Regularization parameters\n * @param  {Number} [regularization.absolute=1e-3] Absolute regularization\n * @param  {Number} [regularization.relative=1e-2] Relative Regularization\n (relative to the training set's variance along each dimension)\n * @param  {String} [covarianceMode='full'] Covariance mode ('full' or diagonal)\n * @return {BMMBase}\n */\nexport default function withGMMTraining(\n  o,\n  gaussians = 1,\n  regularization = { absolute: 1e-3, relative: 1e-2 },\n  covarianceMode = 'full',\n) {\n  if (!Object.keys(o).includes('params')) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    gmmTrainerPrototype,\n    {\n      params: {\n        ...o.params,\n        gaussians,\n        regularization,\n        covarianceMode,\n      },\n    },\n  );\n}\n","import ModelBase from './model_base_mixin';\n\n/**\n * Multiclass Models Mixin\n * @type {Object}\n * @ignore\n */\nconst MulticlassBasePrototype = /** @lends MulticlassModelBase */{\n  /**\n   * Get the number of classes in the model\n   * @return {number} number of classes\n   */\n  size() {\n    return Object.keys(this.models).length;\n  },\n\n  /**\n   * Check if a class with the given label exists\n   * @param  {string} label Class label\n   * @return {boolean}\n   */\n  includes(label) {\n    return Object.keys(this.models).includes(label);\n  },\n\n  /**\n   * Remove a class by label\n   * @param  {string} label Class label\n   */\n  remove(label) {\n    if (this.includes(label)) {\n      delete this.models[label];\n    }\n  },\n};\n\n/**\n * Create an abstract Multiclass Model\n * @param       {number]} inputDimension  input dimension\n * @param       {number]} outputDimension output dimension\n * @param       {Object} parameters       additional parameters to copy\n * @function\n */\nexport default function MulticlassModelBase({\n  inputDimension,\n  outputDimension,\n  ...parameters\n}) {\n  return Object.assign(\n    ModelBase({ inputDimension, outputDimension, ...parameters }),\n    MulticlassBasePrototype,\n  );\n}\n","/**\n * Add multiclass training capabilities to a model. It takes as argument\n * the training function called to train each class of the training set.\n *\n * @param  {MulticlassModelBase} o Source model\n * @param  {Function}  trainingFunction Training function for a single class\n * @return {MulticlassModelBase}\n */\nexport default function withMulticlassTraining(\n  o,\n  trainingFunction,\n) {\n  return Object.assign(\n    o,\n    /** @lends withMulticlassTraining */ {\n      /**\n       * Train the model, optionally specifying a set of classes to train\n       *\n       * @param  {TrainingSet} trainingSet   Training data set\n       * @param  {undefined|Array<String>} [labels=undefined] Labels\n       * corresponding to the classes to be trained (all if unspecified)\n       * @return {Object} the parameters of the trained model\n       *\n       * @throws {Error} if the training set is empty\n       * @throws {Error} if one of the specified class does not exist\n       */\n      train(trainingSet, labels = undefined) {\n        if (!trainingSet || trainingSet.empty()) {\n          throw new Error('The training set is empty');\n        }\n        if (labels) {\n          labels.forEach((l) => {\n            if (!this.includes(l)) {\n              throw new Error(`Class labeled ${l} does not exist`);\n            }\n          });\n        }\n\n        this.params.classes = {};\n        const labs = labels || trainingSet.labels();\n        labs.forEach((label) => {\n          const ts = trainingSet.getPhrasesOfClass(label);\n          // console.log(ts);\n          this.params.classes[label] = trainingFunction(ts);\n        });\n        return this.params;\n      },\n    },\n  );\n}\n","/**\n * Circular Buffer prototype\n *\n * @property {number}  capacity Buffer capacity\n * @property {number}  length Current buffer length\n * @property {boolean} full Specifies if the buffer is full\n *\n * @ignore\n */\nconst circularBufferPrototype = /** @lends CircularBuffer */ {\n  /**\n   * Clear the buffer contents\n   */\n  clear() {\n    this.length = 0;\n    this.index = 0;\n    this.full = false;\n    this.buffer = [];\n  },\n\n  /**\n   * Push a value to the buffer\n   * @param  {*} value data value (any type)\n   */\n  push(value) {\n    if (this.full) {\n      this.buffer[this.index] = value;\n      this.index = (this.index + 1) % this.capacity;\n    } else {\n      this.buffer.push(value);\n      this.length += 1;\n      this.full = (this.length === this.capacity);\n    }\n  },\n\n  /**\n   * Get the value at a given index\n   * @param  {number} idx data index\n   * @return {anything}   value at index\n   */\n  get(idx) {\n    return this.buffer[(idx + this.index) % this.capacity];\n  },\n\n  /**\n   * Fill the buffer with a constant value\n   * @param  {*} value data value (any type)\n   */\n  fill(value) {\n    this.length = this.capacity;\n    this.index = 0;\n    this.full = true;\n    this.buffer = Array(this.capacity).fill(value);\n  },\n\n  /**\n   * Iterate over the buffer's data\n   * @param  {Function} callback Callback function\n   * (@see Array.prototype.forEach).\n   */\n  forEach(callback) {\n    for (let i = 0; i < this.length; i += 1) {\n      callback(this.buffer[(i + this.index) % this.capacity], i);\n    }\n  },\n\n  /**\n   * Get an array of the buffer current values (ordered)\n   * @return {Array} Buffer contents\n   */\n  values() {\n    return this.buffer.slice(this.index)\n      .concat(this.buffer.slice(0, this.index));\n  },\n};\n\n/**\n * Circular Buffer Data Structure (any data type)\n * @param  {number} capacity Buffer capacity\n * @return {circularBufferPrototype}\n * @function\n *\n * @property {number}  capacity Buffer capacity\n * @property {number}  length Current buffer length\n * @property {boolean} full Specifies if the buffer is full\n */\nexport default function CircularBuffer(capacity) {\n  const buffer = Object.create(circularBufferPrototype);\n  buffer.capacity = capacity;\n  buffer.clear();\n  return buffer;\n}\n","import { isBaseModel } from './model_base_mixin';\nimport CircularBuffer from '../common/circular_buffer';\n\n/**\n * Prototype for models with prediction capabilities\n * @param  {Boolean} bimodal Specifies whether the model is bimodal\n * @return {Object}\n * @ignore\n */\nconst predictionBasePrototype = bimodal => (/** @lends withAbtractPrediction */{\n  /**\n   * Likelihood Buffer\n   * @type {CircularBuffer}\n   * @private\n   */\n  likelihoodBuffer: CircularBuffer(1),\n\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @param {Number} [lw] Size (in frames) of the likelihood smoothing window\n   */\n  setLikelihoodWindow(lw) {\n    this.likelihoodWindow = lw;\n    this.likelihoodBuffer = CircularBuffer(lw);\n  },\n\n  /**\n   * Reset the prediction process\n   * @return {Modelbase} the model\n   */\n  reset() {\n    this.likelihoodBuffer.clear();\n    return this;\n  },\n\n  /**\n   * Update the predictions with a new observation\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Object} Prediction results\n   *\n   * @todo document results data structure\n   */\n  predict(observation) {\n    const likelihood = this.likelihood(observation);\n    if (bimodal) {\n      this.regression(observation);\n    }\n    this.updateResults(likelihood);\n    return this.results;\n  },\n\n  /**\n   * Update the prediction results\n   * @param  {Number} instantLikelihood Instantaneous likelihood\n   * @private\n   */\n  updateResults(instantLikelihood) {\n    this.results.instantLikelihood = instantLikelihood;\n    this.likelihoodBuffer.push(Math.log(instantLikelihood));\n    this.results.logLikelihood = 0;\n    const bufSize = this.likelihoodBuffer.length;\n    for (let i = 0; i < bufSize; i += 1) {\n      this.results.logLikelihood += this.likelihoodBuffer.get(i);\n    }\n    this.results.logLikelihood /= bufSize;\n  },\n});\n\n/**\n * Add ABSTRACT prediction capabilities to an existing model\n * @param  {Modelbase} o                 Source model\n * @param  {Number} [likelihoodWindow=1] Size of the likelihood smoothing window\n * @return {Modelbase}\n */\nexport default function withAbtractPrediction(o, likelihoodWindow = 1) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const results = Object.assign(\n    { instantLikelihood: 0, logLikelihood: 0 },\n    o.params.bimodal ? { outputValues: [], outputCovariance: [] } : {},\n  );\n  return Object.assign(\n    o,\n    predictionBasePrototype(o.params.bimodal),\n    { results, likelihoodBuffer: CircularBuffer(likelihoodWindow) },\n  );\n}\n","/**\n * Check if the specification is respected for a given parameter and value,\n * and clip if relevant.\n *\n * @ignore\n *\n * @param  {String}        model      Stream Operator Name (for logging)\n * @param  {String}        parameter     Attribute name\n * @param  {Specification} specification Attribute specification\n * @param  {*}             value         Attribute value\n * @return {*}                           Type-checked parameter value\n */\nfunction checkSpec(model, parameter, specification, value) {\n  if (!specification) return;\n  if (specification.constructor === Array && !specification.includes(value)) {\n    throw new Error(`Attribute '${parameter}' (value: '${value}') is not allowed for model '${model}' (options: [${specification}]).`);\n  } else if (specification.constructor === Object) {\n    if (Object.keys(specification).includes('min') && value < specification.min) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is inferior to the minimum required value of ${specification.min} for model '${model}'.`);\n    }\n    if (Object.keys(specification).includes('max') && value > specification.max) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is superior to the maximum required value of ${specification.min} for model '${model}'.`);\n    }\n  } else if (typeof specification === 'function') {\n    if (!specification(value)) {\n      throw new Error(`Attribute '${parameter}' (value: ${value}) is incompatible with model '${model}'.`);\n    }\n  }\n}\n\n/**\n * Check the parameters of a model and return the parameters of the\n * output stream.\n *\n * The specification should be a structure of the form:\n * ```\n * const streamSpecification = {\n *   <parameter name>: {\n *     required: <boolean>,\n *     check: <null || Array || { min: <minimum value>, max: <maximum value>} || Function >,\n *     transform: Function,\n *   },\n * };\n * ```\n *\n * @param  {String} model      Name of the model for logging\n * @param  {Object} specification I/O Stream Specification\n * @param  {Object} values        Attributes of the input stream\n * @return {Object}               Attributes of the output stream\n *\n * @example\n * import setupStreamAttributes from 'stream';\n *\n * const specification = {\n *   type: {\n *     required: false,\n *     check: null,\n *     transform: x => x || null,\n *   },\n *   format: {\n *     required: true,\n *     check: ['scalar', 'vector'],\n *     transform: x => x,\n *   },\n *   size: {\n *     required: true,\n *     check: { min: 1 },\n *     transform: x => 2 * x,\n *   },\n *   stuff: {\n *     required: true,\n *     check: x => Math.log2(x) === Math.floor(Math.log2(x)),\n *     transform: x => Math.log2(x),\n *   },\n * };\n *\n * const values = {\n *   type: 'anything',\n *   format: 'vector',\n *   size: 3,\n *   stuff: 8,\n *   another: 'one',\n * };\n *\n * setupStreamAttributes('module name', specification, values);\n * // Returns:\n * // {\n * //   type: 'anything',\n * //   format: 'vector',\n * //   size: 6,\n * //   stuff: 3,\n * //   another: 'one',\n * // }\n */\nexport default function validateParameters(model, specification, values) {\n  const parameters = Object.assign({}, values);\n  Object.keys(specification).forEach((attr) => {\n    const spec = specification[attr];\n\n    // Check for required parameters\n    if (spec.required && !Object.keys(values).includes(attr)) {\n      throw new Error(`Stream parameter '${attr}' is required for model '${model}'.`);\n    }\n\n    // Check the validity of the input parameters\n    checkSpec(model, attr, spec.check, values[attr]);\n\n    parameters[attr] = spec.transform ?\n      spec.transform(values[attr]) :\n      values[attr];\n  });\n  return parameters;\n}\n","import validateParameters from '../common/validation';\nimport { isBaseModel } from '../core/model_base_mixin';\n\nconst gmmParameterSpec = gaussians => ({\n  gaussians: {\n    required: true,\n    check: { min: 1 },\n  },\n  regularization: {\n    required: true,\n    check: ({ absolute, relative }) =>\n      (absolute && relative && absolute > 0 && relative > 0),\n  },\n  covarianceMode: {\n    required: true,\n    check: ['full', 'diagonal'],\n  },\n  mixtureCoeffs: {\n    required: true,\n    check: m => m.length === gaussians,\n  },\n  components: {\n    required: true,\n    check: c => c.length === gaussians,\n  },\n});\n\n/**\n * Add GMM prediction capabilities to a single-class model. Mostly, this checks\n * the validity of the model parameters\n *\n * @todo validate gaussian components\n *\n * @param  {GMMBaseModel} o Source Model\n * @return {GMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withGMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  validateParameters('GMM', gmmParameterSpec(o.params.gaussians), o.params);\n  return Object.assign(\n    o,\n    { beta: new Array(o.params.gaussians).fill(0) },\n  );\n}\n","import { isBaseModel } from './model_base_mixin';\n\n/**\n * Multiclass prediction mixin\n * @type {Object}\n * @ignore\n */\nconst MulticlassPredictionBasePrototype = /** @lends withMulticlassPrediction */ {\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @return {Number}\n   */\n  getLikelihoodWindow() {\n    return this.likelihoodWindow;\n  },\n\n  /**\n   * Likelihood Window (used to smooth the log-likelihoods over several frames)\n   * @param {Number} [lw] Size (in frames) of the likelihood smoothing window\n   */\n  setLikelihoodWindow(lw) {\n    this.likelihoodWindow = lw;\n    Object.keys(this.models).forEach((label) => {\n      this.models[label].setLikelihoodWindow(lw);\n    });\n  },\n\n  /**\n   * Reset the prediction process. This is particularly important for temporal\n   * models such as HMMs, that depends on previous observations.\n   */\n  reset() {\n    Object.values(this.models).forEach(m => m.reset());\n    this.results = {\n      labels: [],\n      instantLikelihoods: [],\n      smoothedLikelihoods: [],\n      smoothedLogLikelihoods: [],\n      smoothedNormalizedLikelihoods: [],\n      likeliest: null,\n      classes: {},\n    };\n    if (this.params.bimodal) {\n      this.resetBimodal();\n    }\n  },\n\n  /**\n   * Make a prediction from a new observation (updates the results member)\n   * @param  {Array<Number>} observation Observation vector\n   */\n  predict(observation) {\n    Object.values(this.models).forEach(m => m.predict(observation));\n    this.updateResults();\n  },\n\n  updateResults() {\n    const labs = Object.keys(this.models).sort();\n    this.results.labels = labs;\n    let normInstant = 0;\n    let normSmoothed = 0;\n    let maxLogLikelihood = -Infinity;\n    this.results.classes = labs\n      .map((lab, i) => {\n        this.results.instantLikelihoods[i] =\n          this.models[lab].results.instantLikelihood;\n        this.results.smoothedLogLikelihoods[i] =\n          this.models[lab].results.logLikelihood;\n        this.results.smoothedLikelihoods[i] =\n          Math.exp(this.results.smoothedLogLikelihoods[i]);\n        normInstant += this.results.instantLikelihoods[i];\n        normSmoothed += this.results.smoothedLikelihoods[i];\n        if (this.results.smoothedLogLikelihoods[i] > maxLogLikelihood) {\n          maxLogLikelihood = this.results.smoothedLogLikelihoods[i];\n          this.results.likeliest = lab;\n        }\n        return { [lab]: this.models[lab].results };\n      })\n      .reduce((o, x) => ({ ...o, ...x }), {});\n    this.results.smoothedNormalizedLikelihoods =\n      this.results.smoothedLikelihoods.map(x => x / normSmoothed);\n    this.results.instantNormalizedLikelihoods =\n      this.results.instantLikelihoods.map(x => x / normInstant);\n    if (this.params.bimodal) {\n      this.updateRegressionResults();\n    }\n  },\n};\n\nconst MulticlassPredictionBimodalPrototype = {\n  resetBimodal() {\n    this.results.outputValues = [];\n    this.results.outputCovariance = [];\n  },\n\n  updateRegressionResults() {\n    if (this.params.multiClassRegressionEstimator === 'likeliest') {\n      this.results.outputValues =\n        this.models[this.results.likeliest].results.outputValues;\n      this.results.outputCovariance =\n        this.models[this.results.likeliest].results.outputCovariance;\n    } else if (this.params.multiClassRegressionEstimator === 'mixture') {\n      this.results.outputValues = Array(this.outputDimension).fill(0);\n      this.results.outputCovariance = Array(this.outputDimension ** (this.configuration.covarianceMode === 'full' ? 2 : 1)).fill(0);\n      this.results.labels.forEach((lab) => {\n        this.results.outputValues.map((x, i) => x + (\n          this.results.smoothedNormalizedLikelihoods[i] *\n          this.models[lab].results.outputValues[i]\n        ));\n        this.results.outputCovariance.map((x, i) => x + (\n          this.results.smoothedNormalizedLikelihoods[i] *\n          this.models[lab].results.outputCovariance[i]\n        ));\n      });\n    } else {\n      throw new Error('Unknown regression estimator, use `likeliest` or `mixture`');\n    }\n  },\n};\n\n/**\n * Add multiclass prediction capabilities to a multiclass model\n * @param  {MulticlassModelBase} o Source model\n * @param  {String} [multiClassRegressionEstimator='likeliest'] Type of\n * regression estimator:\n * - `likeliest` selects the output values from the likeliest class\n * - `mixture` computes the output values as the weighted sum of the\n * contributions of each class, weighed by their normalized likelihood\n * @return {MulticlassPredictionBasePrototype}\n * @function\n */\nexport default function withMulticlassPrediction(o, multiClassRegressionEstimator = 'likeliest') {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  const m = Object.assign(\n    o,\n    MulticlassPredictionBasePrototype,\n    o.params.bimodal ? MulticlassPredictionBimodalPrototype : {},\n  );\n  m.params.multiClassRegressionEstimator = multiClassRegressionEstimator;\n  return m;\n}\n","import GaussianDistribution from '../common/gaussian_distribution';\nimport ModelBase from '../core/model_base_mixin';\nimport withEMTraining from '../core/em_training_mixin';\nimport withGMMBase from './gmm_base_mixin';\nimport withGMMTraining from './gmm_training_mixin';\nimport MulticlassModelBase from '../core/multiclass_mixin';\nimport withMulticlassTraining from '../core/multiclass_training_mixin';\nimport withAbtractPrediction from '../core/prediction_mixin';\nimport withGMMPrediction from './gmm_prediction_mixin';\nimport withMulticlassPrediction from '../core/multiclass_prediction_mixin';\n\n/**\n * @typedef {Object} GMMParameters\n * @property {Boolean} bimodal Specifies if the model is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} gaussians Number of gaussian components in the mixture\n * @property {String} covarianceMode Covariance mode ('full' or 'diagonal')\n * @property {Array<Number>} mixtureCoeffs mixture coefficients ('weight' of\n * each gaussian component)\n * @property {Array<GaussianDistribution>} components Gaussian components\n */\n\n/**\n * Train a single-class GMM Model.\n *\n * @todo GMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {GMMParameters} Parameters of the trained GMM\n */\nexport function trainGMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const { gaussians, regularization, covarianceMode } = configuration;\n  const model = withGMMTraining(\n    withEMTraining(\n      withGMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        ...configuration,\n      })),\n      convergenceCriteria,\n    ),\n    gaussians,\n    regularization,\n    covarianceMode,\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Train a multi-class GMM Model.\n *\n * @todo GMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {Object} Parameters of the trained GMM\n */\nexport function trainMulticlassGMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withMulticlassTraining(\n    MulticlassModelBase({ inputDimension, outputDimension, ...configuration }),\n    ts => trainGMM(ts, configuration, convergenceCriteria),\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Create a GMM Predictor from a full set of parameters (generated by trainGMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function GMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withGMMPrediction(withAbtractPrediction(\n    withGMMBase(ModelBase(params)),\n    likelihoodWindow,\n  ));\n  params.components.forEach((c, i) => {\n    model.params.components[i] = Object.assign(GaussianDistribution(\n      params.inputDimension,\n      params.outputDimension,\n      params.covarianceMode,\n    ), c);\n  });\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass GMM Predictor from a full set of parameters\n * (generated by trainMulticlassGMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function MulticlassGMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withMulticlassPrediction(MulticlassModelBase(params));\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = GMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model.reset();\n  return model;\n}\n","import { isBaseModel } from '../core/model_base_mixin';\n\n//\n// TODO: hierarchical + exit probabilities methods.\n//\n\n/**\n * HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hmmBasePrototype = /** @lends withHMMBase */ {\n  /**\n   * Specifies if the forward algorithm has been initialized\n   * @type {Boolean}\n   * @private\n   */\n  forwardInitialized: false,\n\n  /**\n   * Specifies if the containing multiclass model is isHierarchical\n   * @todo check that\n   * @type {Boolean}\n   * @private\n   */\n  isHierarchical: false,\n\n  /**\n   * Initialize the forward algorithm (See rabiner, 1989)\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}                    `ct` (inverse likelihood)\n   */\n  initializeForwardAlgorithm(observation) {\n    let normConst = 0;\n    if (this.params.transitionMode === 'ergodic') {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.alpha[i] = this.params.prior[i] *\n          this.params.xStates[i].likelihood(observation);\n        normConst += this.alpha[i];\n      }\n    } else {\n      this.alpha = new Array(this.params.states).fill(0);\n      this.alpha[0] = this.params.xStates[0].likelihood(observation);\n      normConst += this.alpha[0];\n    }\n    this.forwardInitialized = true;\n    if (normConst > 0) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.alpha[i] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 1 / this.params.states;\n    }\n    return 1;\n  },\n\n  /**\n   * Update the forward algorithm (See rabiner, 1989)\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}                    `ct` (inverse likelihood)\n   */\n  updateForwardAlgorithm(observation) {\n    let normConst = 0;\n    this.previousAlpha = this.alpha.slice();\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.alpha[j] += this.previousAlpha[i] *\n            this.params.transition[i][j];\n        }\n      } else {\n        this.alpha[j] += this.previousAlpha[j] * this.params.transition[j * 2];\n        if (j > 0) {\n          this.alpha[j] += this.previousAlpha[j - 1] *\n            this.params.transition[((j - 1) * 2) + 1];\n        } else {\n          this.alpha[0] += this.previousAlpha[this.params.states - 1] *\n            this.params.transition[(this.params.states * 2) - 1];\n        }\n      }\n      this.alpha[j] *= this.params.xStates[j].likelihood(observation);\n      normConst += this.alpha[j];\n    }\n    if (normConst > 1e-300) {\n      for (let j = 0; j < this.params.states; j += 1) {\n        this.alpha[j] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    return 0;\n  },\n};\n\n/**\n * Add basic HMM capabilities to a single-class model. This enables the\n * computation of the likelihoods and regression operations common to\n * training and prediction\n *\n * @see withHMMTraining\n * @see withHMMPrediction\n *\n * @param  {ModelBase} o Source Model\n * @return {HMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHMMBase(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(o, hmmBasePrototype);\n}\n","import TrainingSet from '../training_set';\nimport ModelBase from '../core/model_base_mixin';\nimport withGMMBase from '../gmm/gmm_base_mixin';\nimport { trainGMM } from '../gmm';\n\nconst TRANSITION_REGULARIZATION = 1e-5;\n\n/**\n * HMM Training Prototype\n * @type {Object}\n * @ignore\n */\nconst hmmTrainerPrototype = /** @lends withHMMTraining */ {\n  /**\n   * Initialize the EM Training process\n   * @param  {TrainingSet} trainingSet Training set\n   */\n  initTraining(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    this.allocate(trainingSet);\n    this.initParametersToDefault(trainingSet.standardDeviation());\n    if (this.params.gaussians > 1) {\n      this.initMeansCovariancesWithGMMEM(trainingSet);\n    } else {\n      this.initMeansWithAllPhrases(trainingSet);\n      this.initCovariancesFullyObserved(trainingSet);\n    }\n  },\n\n  /**\n   * Allocate the model's parameters and training variables\n   * @param  {TrainingSet} trainingSet The training set\n   * @private\n   */\n  allocate(trainingSet) {\n    const {\n      inputDimension,\n      outputDimension,\n      gaussians,\n      regularization,\n      covarianceMode,\n    } = this.params;\n    this.params.xStates = Array.from(\n      new Array(this.params.states),\n      () => withGMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        gaussians,\n        regularization,\n        covarianceMode,\n      })),\n    );\n    this.params.xStates.forEach(s => s.allocate());\n    this.alpha = new Array(this.params.states).fill(0);\n    this.previousAlpha = new Array(this.params.states).fill(0);\n    this.beta = new Array(this.params.states).fill(0);\n    this.previousBeta = new Array(this.params.states).fill(0);\n\n    // Initialize Algorithm variables\n    // ---------------------------------------\n    const nbPhrases = trainingSet.size();\n    this.gammaSequence = new Array(nbPhrases).fill(null);\n    this.epsilonSequence = new Array(nbPhrases).fill(null);\n    this.gammaSequenceperMixture = new Array(nbPhrases).fill(null);\n    let maxT = 0;\n    let i = 0;\n    trainingSet.forEach((phrase) => {\n      const T = phrase.length;\n      this.gammaSequence[i] = Array.from(\n        new Array(T),\n        () => new Array(this.params.states).fill(0),\n      );\n      if (this.params.transitionMode === 'ergodic') {\n        this.epsilonSequence[i] = Array.from(\n          new Array(T),\n          () => Array.from(\n            new Array(this.params.states),\n            () => new Array(this.params.states).fill(0),\n          ),\n        );\n      } else {\n        this.epsilonSequence[i] = Array.from(\n          new Array(T),\n          () => new Array(this.params.states * 2).fill(0),\n        );\n      }\n      this.gammaSequenceperMixture[i] =\n        new Array(this.params.gaussians).fill(0);\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.gammaSequenceperMixture[i][c] =\n          Array.from(\n            new Array(T),\n            () => new Array(this.params.states).fill(0),\n          );\n      }\n      if (T > maxT) {\n        maxT = T;\n      }\n      i += 1;\n    });\n\n    this.gammaSum = new Array(this.params.states).fill(0);\n    this.gammaSumPerMixture = new Array(this.params.states * this.params.gaussians).fill(0);\n  },\n\n  /**\n   * Update the EM Training process (1 EM iteration).\n   * @param  TrainingSet trainingSet training set\n   */\n  updateTraining(trainingSet) {\n    let logProb = 0;\n\n    // Forward-backward for each phrase\n    // =================================================\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      if (phrase.length > 0) {\n        logProb += this.baumWelchForwardBackward(phrase, phraseIndex);\n      }\n      phraseIndex += 1;\n    });\n    this.baumWelchGammaSum(trainingSet);\n\n    // Re-estimate model parameters\n    // =================================================\n\n    // set covariance and mixture coefficients to zero for each state\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.xStates[i].params.mixtureCoeffs[c] = 0;\n        if (this.params.covarianceMode === 'full') {\n          this.params.xStates[i].params.components[c].covariance =\n            new Array(this.params.dimension ** 2).fill(0);\n        } else {\n          this.params.xStates[i].params.components[c].covariance =\n            new Array(this.params.dimension).fill(0);\n        }\n      }\n    }\n\n    this.baumWelchEstimateMixtureCoefficients(trainingSet);\n    this.baumWelchEstimateMeans(trainingSet);\n    this.baumWelchEstimateCovariances(trainingSet);\n    if (this.params.transitionMode === 'ergodic') {\n      this.baumWelchEstimatePrior(trainingSet);\n    }\n    this.baumWelchEstimateTransitions(trainingSet);\n    return logProb;\n  },\n\n  /**\n   * terminate the EM Training process\n   * @param  TrainingSet trainingSet training set\n   */\n  terminateTraining() {\n    this.normalizeTransitions();\n    this.gammaSequence = null;\n    this.epsilonSequence = null;\n    this.gammaSequenceperMixture = null;\n    this.alphaSeq = null;\n    this.betaSeq = null;\n    this.gammaSum = null;\n    this.gammaSumPerMixture = null;\n    this.params.xStates = this.params.xStates.map(s => s.params);\n  },\n\n  /**\n   * Initialize the model parameters to their default values\n   * @param  {Array<Number>} dataStddev Standard deviation of the training data\n   * @private\n   */\n  initParametersToDefault(dataStddev) {\n    if (this.params.transitionMode === 'ergodic') {\n      this.setErgodic();\n    } else {\n      this.setLeftRight();\n    }\n    const currentRegularization = dataStddev.map(std => Math.max(\n      this.params.regularization.absolute,\n      this.params.regularization.relative * std,\n    ));\n    const initCovariance = (this.params.covarianceMode === 'full') ?\n      () => new Array(this.params.dimension ** 2)\n        .fill(this.params.regularization.absolute / 2) :\n      () => new Array(this.params.dimension)\n        .fill(0);\n    for (let i = 0; i < this.params.states; i += 1) {\n      // this.params.xStates[i].initParametersToDefault(dataStddev);\n      const s = this.params.xStates[i];\n      s.currentRegularization = currentRegularization;\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        s.params.components[c].covariance = initCovariance();\n        s.params.components[c].regularize(currentRegularization);\n        s.params.mixtureCoeffs[c] = 1 / this.params.gaussians;\n      }\n    }\n  },\n\n  /**\n   * Initialize the means of each state using all available phrases in the\n   * training set\n   * @param  {TrainingSet} trainingSet Training set\n   * @private\n   */\n  initMeansWithAllPhrases(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.xStates[n].params.components[0].mean[d] = 0.0;\n      }\n    }\n\n    const factor = new Array(this.params.states).fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.states);\n      let offset = 0;\n      for (let n = 0; n < this.params.states; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d = 0; d < this.params.dimension; d += 1) {\n            this.params.xStates[n].params.components[0].mean[d] +=\n              phrase.get(offset + t, d);\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d = 0; d < this.params.dimension; d += 1) {\n        this.params.xStates[n].params.components[0].mean[d] /= factor[n];\n      }\n    }\n  },\n\n  /**\n   * Initialize the covariance by direct (fully-observed) estimation from the\n   * training data.\n   * @param  {[type]} trainingSet [description]\n   * @private\n   */\n  initCovariancesFullyObserved(trainingSet) {\n    if (!trainingSet || trainingSet.empty()) return;\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      this.params.xStates[n].params.components[0].covariance =\n        new Array(this.params.dimension ** (this.params.covarianceMode === 'full' ? 2 : 1)).fill(0);\n    }\n\n    const factor = new Array(this.params.states).fill(0);\n    const othermeans = new Array(this.params.states * this.params.dimension)\n      .fill(0);\n    trainingSet.forEach((phrase) => {\n      const step = Math.floor(phrase.length / this.params.states);\n      let offset = 0;\n      for (let n = 0; n < this.params.states; n += 1) {\n        for (let t = 0; t < step; t += 1) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            othermeans[((n * this.params.dimension)) + d1] +=\n                phrase.get(offset + t, d1);\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n                this.params.xStates[n].params.components[0]\n                  .covariance[(d1 * this.params.dimension) + d2] +=\n                    phrase.get(offset + t, d1) *\n                    phrase.get(offset + t, d2);\n              }\n            } else {\n              this.params.xStates[n].params.components[0].covariance[d1] +=\n                phrase.get(offset + t, d1) ** 2;\n            }\n          }\n        }\n        offset += step;\n        factor[n] += step;\n      }\n    });\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        othermeans[(n * this.params.dimension) + d1] /= factor[n];\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.xStates[n].params.components[0]\n              .covariance[(d1 * this.params.dimension) + d2] /=\n                factor[n];\n          }\n        } else {\n          this.params.xStates[n].params.components[0].covariance[d1] /= factor[n];\n        }\n      }\n    }\n\n    for (let n = 0; n < this.params.states; n += 1) {\n      for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n        if (this.params.covarianceMode === 'full') {\n          for (let d2 = 0; d2 < this.params.dimension; d2 += 1) {\n            this.params.xStates[n].params.components[0]\n              .covariance[(d1 * this.params.dimension) + d2] -=\n                othermeans[(n * this.params.dimension) + d1] *\n                othermeans[(n * this.params.dimension) + d2];\n          }\n        } else {\n          this.params.xStates[n].params.components[0].covariance[d1] -=\n            othermeans[(n * this.params.dimension) + d1] *\n            othermeans[(n * this.params.dimension) + d1];\n        }\n      }\n      this.params.xStates[n].regularize();\n      this.params.xStates[n].updateInverseCovariances();\n    }\n  },\n\n  /**\n   * Initialize the means and covariance of each state's observation probability\n   * distribution using the Expectation-Maximization algorithm for GMMs\n   * @param  {[type]} trainingSet [description]\n   * @private\n   */\n  initMeansCovariancesWithGMMEM(trainingSet) {\n    for (let n = 0; n < this.params.states; n += 1) {\n      const ts = TrainingSet(this.params);\n      // eslint-disable-next-line no-loop-func\n      trainingSet.forEach((phrase, phraseIndex) => {\n        const step = Math.floor(phrase.length / this.params.states);\n        if (step > 0) {\n          ts.push(phraseIndex, phrase.label);\n          for (let t = n * step; t < (n + 1) * step; t += 1) {\n            ts.getPhrase(phraseIndex).push(phrase.getFrame(t));\n          }\n        }\n      });\n      if (!ts.empty()) {\n        const gmmParams = trainGMM(ts, this.params);\n        for (let c = 0; c < this.params.gaussians; c += 1) {\n          this.params.xStates[n].params.components[c].mean =\n            gmmParams.components[c].mean;\n          this.params.xStates[n].params.components[c].covariance =\n            gmmParams.components[c].covariance;\n          this.params.xStates[n].updateInverseCovariances();\n        }\n      }\n    }\n  },\n\n  /**\n   * Initialize the transition matrix to an ergodic transition matrix\n   * @private\n   */\n  setErgodic() {\n    const p = 1 / this.params.states;\n    this.params.prior = new Array(this.params.states).fill(p);\n    this.params.transition = Array.from(\n      new Array(this.params.states),\n      () => new Array(this.params.states).fill(p),\n    );\n  },\n\n  /**\n   * Initialize the transition matrix to a left-right transition matrix\n   * @private\n   */\n  setLeftRight() {\n    this.params.prior = new Array(this.params.states).fill(0);\n    this.params.prior[0] = 1;\n    this.params.transition = new Array(this.params.states * 2).fill(0.5);\n    this.params.transition[(this.params.states - 1) * 2] = 1;\n    this.params.transition[((this.params.states - 1) * 2) + 1] = 0;\n  },\n\n  /**\n   * Normalize the hidden state transition parameters\n   * (prior + transition matrix)\n   * @private\n   */\n  normalizeTransitions() {\n    if (this.params.transitionMode === 'ergodic') {\n      const normPrior = this.params.prior.reduce((a, b) => a + b, 0);\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] /= normPrior;\n        let transitionNorm = 0;\n        for (let j = 0; j < this.params.states; j += 1) {\n          transitionNorm += this.params.transition[i][j];\n        }\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.params.transition[i][j] /= transitionNorm;\n        }\n      }\n    } else {\n      for (let i = 0; i < this.params.states; i += 1) {\n        const transitionNorm = this.params.transition[i * 2] + this.params.transition[(i * 2) + 1];\n        this.params.transition[i * 2] /= transitionNorm;\n        this.params.transition[(i * 2) + 1] /= transitionNorm;\n      }\n    }\n  },\n\n  /**\n   * Initialize the backward algorithm (see rabiner, 1989)\n   * @param  {Number} ct Inverse probability at time T - 1 (last observation of\n   * the sequence)\n   * @private\n   */\n  initializeBackwardAlgorithm(ct) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = ct;\n    }\n  },\n\n  /**\n   * Initialize the backward algorithm (see rabiner, 1989)\n   * @param  {Number} ct Inverse probability at time t\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  updateBackwardAlgorithm(ct, observation) {\n    this.previousBeta = this.beta.slice();\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.beta[i] += this.params.transition[i][j] *\n            this.previousBeta[j] *\n            this.params.xStates[j].likelihood(observation);\n        }\n      } else {\n        this.beta[i] += this.params.transition[i * 2] *\n          this.previousBeta[i] *\n          this.params.xStates[i].likelihood(observation);\n        if (i < this.params.states - 1) {\n          this.beta[i] += this.params.transition[(i * 2) + 1] *\n            this.previousBeta[i + 1] *\n            this.params.xStates[i + 1].likelihood(observation);\n        }\n      }\n      this.beta[i] *= ct;\n      if (Number.isNaN(this.beta[i]) || Math.abs(this.beta[i]) === +Infinity) {\n        this.beta[i] = 1e100;\n      }\n    }\n  },\n\n  /**\n   * Forward algorithm update step for the Baum-Welch algorithms. It is similar\n   * to `updateForwardAlgorithm` except it takes precomputed observation\n   * likelihoods as argument.\n   * @param  {Array<Number>} observationLikelihoods observation likelihoods\n   * @private\n   */\n  baumWelchForwardUpdate(observationLikelihoods) {\n    let normConst = 0;\n    this.previousAlpha = this.alpha.slice();\n    for (let j = 0; j < this.params.states; j += 1) {\n      this.alpha[j] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.alpha[j] += this.previousAlpha[i] *\n            this.params.transition[i][j];\n        }\n      } else {\n        this.alpha[j] += this.previousAlpha[j] * this.params.transition[j * 2];\n        if (j > 0) {\n          this.alpha[j] += this.previousAlpha[j - 1] *\n            this.params.transition[((j - 1) * 2) + 1];\n        } else {\n          this.alpha[0] += this.previousAlpha[this.params.states - 1] *\n            this.params.transition[(this.params.states * 2) - 1];\n        }\n      }\n      this.alpha[j] *= observationLikelihoods[j];\n      normConst += this.alpha[j];\n    }\n    if (Number.isNaN(normConst)) {\n      throw new Error('Holy molly');\n    }\n    if (normConst > 1e-300) {\n      for (let j = 0; j < this.params.states; j += 1) {\n        this.alpha[j] /= normConst;\n      }\n      return 1 / normConst;\n    }\n    return 0;\n  },\n\n  /**\n   * Backward algorithm update step for the Baum-Welch algorithms. It is similar\n   * to `updatebackwardAlgorithm` except it takes precomputed observation\n   * likelihoods as argument.\n   * @param  {Number} ct Inverse probability at time t\n   * @param  {Array<Number>} observationLikelihoods observation likelihoods\n   * @private\n   */\n  baumWelchBackwardUpdate(ct, observationLikelihoods) {\n    this.previousBeta = this.beta.slice();\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.beta[i] = 0;\n      if (this.params.transitionMode === 'ergodic') {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.beta[i] +=\n            this.params.transition[i][j] *\n            this.previousBeta[j] *\n            observationLikelihoods[j];\n        }\n      } else {\n        this.beta[i] += this.params.transition[i * 2] *\n          this.previousBeta[i] *\n          observationLikelihoods[i];\n        if (i < this.params.states - 1) {\n          this.beta[i] += this.params.transition[(i * 2) + 1] *\n            this.previousBeta[i + 1] *\n            observationLikelihoods[i + 1];\n        }\n      }\n      this.beta[i] *= ct;\n      if (Number.isNaN(this.beta[i]) || Math.abs(this.beta[i]) === +Infinity) {\n        this.beta[i] = 1e100;\n      }\n    }\n  },\n\n  /**\n   * Forward-Backward algorithm for the Baum-Welch training algorithm\n   * @param  {Phrase} currentPhrase Current data phrase\n   * @param  {Number} phraseIndex   Current phrase index\n   * @return {Number} Log-likelihood\n   * @private\n   */\n  baumWelchForwardBackward(currentPhrase, phraseIndex) {\n    const T = currentPhrase.length;\n\n    const ct = new Array(T).fill(0);\n    let logProb;\n    this.alphaSeq = [];\n    this.betaSeq = [];\n\n    const observationProbabilities = Array.from(\n      new Array(T),\n      () => new Array(this.params.states).fill(0),\n    );\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        observationProbabilities[t][i] =\n          this.params.xStates[i].likelihood(currentPhrase.getFrame(t));\n      }\n    }\n\n    // Forward algorithm\n    ct[0] = this.initializeForwardAlgorithm(currentPhrase.getFrame(0));\n    logProb = -Math.log(ct[0]);\n    this.alphaSeq.push(this.alpha.slice());\n\n    for (let t = 1; t < T; t += 1) {\n      ct[t] = this.baumWelchForwardUpdate(observationProbabilities[t]);\n      logProb -= Math.log(ct[t]);\n      this.alphaSeq.push(this.alpha.slice());\n    }\n\n    // Backward algorithm\n    this.initializeBackwardAlgorithm(ct[T - 1]);\n    this.betaSeq.push(this.beta.slice());\n\n    for (let t = T - 2; t >= 0; t -= 1) {\n      this.baumWelchBackwardUpdate(ct[t], observationProbabilities[t + 1]);\n      this.betaSeq.push(this.beta.slice());\n    }\n    this.betaSeq.reverse();\n\n    // Compute Gamma Variable\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.gammaSequence[phraseIndex][t][i] =\n          (this.alphaSeq[t][i] * this.betaSeq[t][i]) / ct[t];\n      }\n    }\n\n    // Compute Gamma variable for each mixture component\n    let normConst;\n\n    for (let t = 0; t < T; t += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        normConst = 0;\n        if (this.params.gaussians === 1) {\n          const oo = observationProbabilities[t][i];\n          this.gammaSequenceperMixture[phraseIndex][0][t][i] =\n            this.gammaSequence[phraseIndex][t][i] * oo;\n          normConst += oo;\n        } else {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            const oo = this.params.xStates[i]\n              .componentLikelihood(currentPhrase.getFrame(t), c);\n            this.gammaSequenceperMixture[phraseIndex][c][t][i] =\n              this.gammaSequence[phraseIndex][t][i] *\n              oo;\n            normConst += oo;\n          }\n        }\n        if (normConst > 0) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.gammaSequenceperMixture[phraseIndex][c][t][i] /= normConst;\n          }\n        }\n      }\n    }\n\n    // Compute Epsilon Variable\n    if (this.params.transitionMode === 'ergodic') {\n      for (let t = 0; t < T - 1; t += 1) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          for (let j = 0; j < this.params.states; j += 1) {\n            this.epsilonSequence[phraseIndex][t][i][j] =\n              this.alphaSeq[t][i] *\n              this.params.transition[i][j] *\n              this.betaSeq[t + 1][j];\n            this.epsilonSequence[phraseIndex][t][i][j] *=\n              observationProbabilities[t + 1][j];\n          }\n        }\n      }\n    } else {\n      for (let t = 0; t < T - 1; t += 1) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          this.epsilonSequence[phraseIndex][t][i * 2] =\n            this.alphaSeq[t][i] *\n            this.params.transition[i * 2] *\n            this.betaSeq[t + 1][i];\n          this.epsilonSequence[phraseIndex][t][i * 2] *=\n            observationProbabilities[t + 1][i];\n          if (i < this.params.states - 1) {\n            this.epsilonSequence[phraseIndex][t][(i * 2) + 1] =\n              this.alphaSeq[t][i] *\n              this.params.transition[(i * 2) + 1] *\n              this.betaSeq[t + 1][i + 1];\n            this.epsilonSequence[phraseIndex][t][(i * 2) + 1] *=\n              observationProbabilities[t + 1][i + 1];\n          }\n        }\n      }\n    }\n\n    return logProb;\n  },\n\n  /**\n   * Sums the Gamma variables used for parameter estimation during training\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchGammaSum(trainingSet) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.gammaSum[i] = 0;\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.gammaSumPerMixture[(i * this.params.gaussians) + c] = 0;\n      }\n    }\n\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          this.gammaSum[i] +=\n            this.gammaSequence[phraseIndex][t][i];\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.gammaSumPerMixture[(i * this.params.gaussians) + c] +=\n              this.gammaSequenceperMixture[phraseIndex][c][t][i];\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n  },\n\n  /**\n   * Estimate the mixture coefficients of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateMixtureCoefficients(trainingSet) {\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            this.params.xStates[i].params.mixtureCoeffs[c] +=\n              this.gammaSequenceperMixture[phraseIndex][c][t][i];\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale mixture coefficients\n    for (let i = 0; i < this.params.states; i += 1) {\n      this.params.xStates[i].normalizeMixtureCoeffs();\n    }\n  },\n\n  /**\n   * Estimate the means of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateMeans(trainingSet) {\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        this.params.xStates[i].params.components[c].mean.fill(0);\n      }\n    }\n\n    // Re-estimate Mean\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            for (let d = 0; d < this.params.dimension; d += 1) {\n              this.params.xStates[i].params.components[c].mean[d] +=\n                this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                phrase.get(t, d);\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Normalize mean\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        for (let d = 0; d < this.params.dimension; d += 1) {\n          if (this.gammaSumPerMixture[(i * this.params.gaussians) + c] > 0) {\n            this.params.xStates[i].params.components[c].mean[d] /=\n              this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n          }\n          if (Number.isNaN(this.params.xStates[i].params.components[c].mean[d])) {\n            throw new Error('Convergence Error');\n          }\n        }\n      }\n    }\n  },\n\n  /**\n   * Estimate the covariances of the GMM observation probability\n   * distribution at each state.\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateCovariances(trainingSet) {\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let t = 0; t < phrase.length; t += 1) {\n          for (let c = 0; c < this.params.gaussians; c += 1) {\n            for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n              if (this.params.covarianceMode === 'full') {\n                for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n                  this.params.xStates[i].params.components[c]\n                    .covariance[(d1 * this.params.dimension) + d2] +=\n                    this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                    (phrase.get(t, d1) -\n                      this.params.xStates[i].params.components[c].mean[d1]) *\n                    (phrase.get(t, d2) -\n                      this.params.xStates[i].params.components[c].mean[d2]);\n                }\n              } else {\n                const value = phrase.get(t, d1) -\n                  this.params.xStates[i].params.components[c].mean[d1];\n                this.params.xStates[i].params.components[c].covariance[d1] +=\n                  this.gammaSequenceperMixture[phraseIndex][c][t][i] *\n                  (value ** 2);\n              }\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale covariance\n    for (let i = 0; i < this.params.states; i += 1) {\n      for (let c = 0; c < this.params.gaussians; c += 1) {\n        if (this.gammaSumPerMixture[(i * this.params.gaussians) + c] > 0) {\n          for (let d1 = 0; d1 < this.params.dimension; d1 += 1) {\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = d1; d2 < this.params.dimension; d2 += 1) {\n                this.params.xStates[i].params.components[c]\n                  .covariance[(d1 * this.params.dimension) + d2] /=\n                  this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n                if (d1 !== d2) {\n                  this.params.xStates[i].params.components[c]\n                    .covariance[(d2 * this.params.dimension) + d1] =\n                    this.params.xStates[i].params.components[c]\n                      .covariance[(d1 * this.params.dimension) + d2];\n                }\n              }\n            } else {\n              this.params.xStates[i].params.components[c].covariance[d1] /=\n                this.gammaSumPerMixture[(i * this.params.gaussians) + c];\n            }\n          }\n        }\n      }\n      this.params.xStates[i].regularize();\n      this.params.xStates[i].updateInverseCovariances();\n    }\n  },\n\n  /**\n   * Estimate the prior probabilities of the model\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimatePrior(trainingSet) {\n    this.params.prior.fill(0);\n\n    // Re-estimate Prior probabilities\n    let sumprior = 0;\n    for (let phraseIndex = 0;\n      phraseIndex < trainingSet.size();\n      phraseIndex += 1) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] += this.gammaSequence[phraseIndex][0][i];\n        sumprior += this.params.prior[i];\n      }\n    }\n\n    // Scale Prior vector\n    if (sumprior > 0) {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.prior[i] /= sumprior;\n      }\n    } else {\n      throw new Error('The Prior is all ZERO.....');\n    }\n  },\n\n  /**\n   * Estimate the transition probabilities of the model\n   * @param  {TrainingSet} trainingSet Training Set\n   * @private\n   */\n  baumWelchEstimateTransitions(trainingSet) {\n    // Set transition matrix to 0\n    this.params.transition = this.params.transitionMode === 'ergodic' ?\n      Array.from(\n        new Array(this.params.states),\n        () => new Array(this.params.states).fill(0),\n      ) :\n      new Array(this.params.states * 2).fill(0);\n\n    // Re-estimate Transition probabilities\n    let phraseIndex = 0;\n    trainingSet.forEach((phrase) => {\n      if (phrase.length > 0) {\n        for (let i = 0; i < this.params.states; i += 1) {\n          // Experimental: A bit of regularization (sometimes avoids\n          // numerical errors)\n          if (this.params.transitionMode === 'leftright') {\n            this.params.transition[i * 2] += TRANSITION_REGULARIZATION;\n            if (i < this.params.states - 1) {\n              this.params.transition[(i * 2) + 1] += TRANSITION_REGULARIZATION;\n            } else {\n              this.params.transition[i * 2] += TRANSITION_REGULARIZATION;\n            }\n          }\n          // End Regularization\n          if (this.params.transitionMode === 'ergodic') {\n            for (let j = 0; j < this.params.states; j += 1) {\n              for (let t = 0; t < phrase.length - 1; t += 1) {\n                this.params.transition[i][j] +=\n                  this.epsilonSequence[phraseIndex][t][i][j];\n              }\n            }\n          } else {\n            for (let t = 0; t < phrase.length - 1; t += 1) {\n              this.params.transition[i * 2] +=\n                this.epsilonSequence[phraseIndex][t][i * 2];\n            }\n            if (i < this.params.states - 1) {\n              for (let t = 0; t < phrase.length - 1; t += 1) {\n                this.params.transition[(i * 2) + 1] +=\n                  this.epsilonSequence[phraseIndex][t][(i * 2) + 1];\n              }\n            }\n          }\n        }\n      }\n      phraseIndex += 1;\n    });\n\n    // Scale transition matrix\n    if (this.params.transitionMode === 'ergodic') {\n      for (let i = 0; i < this.params.states; i += 1) {\n        for (let j = 0; j < this.params.states; j += 1) {\n          this.params.transition[i][j] /=\n            (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n          if (Number.isNaN(this.params.transition[i][j])) {\n            throw new Error('Convergence Error. Check your training data or increase the variance offset');\n          }\n        }\n      }\n    } else {\n      for (let i = 0; i < this.params.states; i += 1) {\n        this.params.transition[i * 2] /=\n          (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n        if (Number.isNaN(this.params.transition[i * 2])) {\n          throw new Error('Convergence Error. Check your training data or increase the variance offset');\n        }\n        if (i < this.params.states - 1) {\n          this.params.transition[(i * 2) + 1] /=\n            (this.gammaSum[i] + (2 * TRANSITION_REGULARIZATION));\n          if (Number.isNaN(this.params.transition[(i * 2) + 1])) {\n            throw new Error('Convergence Error. Check your training data or increase the variance offset');\n          }\n        }\n      }\n    }\n  },\n};\n\n/**\n * Add HMM Training capabilities to a HMM Model\n * @param  {HMMBase} o               Source HMM Model\n * @param  {Number} [states=1]       Number of hidden states\n * @param  {Number} [gaussians=1]    Number of Gaussian components\n * @param  {Object} [regularization] Regularization parameters\n * @param  {Number} [regularization.absolute=1e-3] Absolute regularization\n * @param  {Number} [regularization.relative=1e-2] Relative Regularization\n (relative to the training set's variance along each dimension)\n * @param  {String} [transitionMode='ergodic'] Structure of the transition\n * matrix ('ergodic' or 'left-right').\n * @param  {String} [covarianceMode='full'] Covariance mode ('full' or diagonal)\n * @return {BMMBase}\n */\nexport default function withHMMTraining(\n  o,\n  states = 1,\n  gaussians = 1,\n  regularization = { absolute: 1e-3, relative: 1e-2 },\n  transitionMode = 'leftright',\n  covarianceMode = 'full',\n) {\n  if (!Object.keys(o).includes('params')) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  return Object.assign(\n    o,\n    hmmTrainerPrototype,\n    {\n      params: {\n        ...o.params,\n        states,\n        gaussians,\n        regularization,\n        transitionMode,\n        covarianceMode,\n      },\n    },\n  );\n}\n","import validateParameters from '../common/validation';\nimport { isBaseModel } from '../core/model_base_mixin';\nimport { GMMPredictor } from '../gmm';\n\nconst hmmParameterSpec = (states, transitionMode) => ({\n  states: {\n    required: true,\n    check: { min: 1 },\n  },\n  gaussians: {\n    required: true,\n    check: { min: 1 },\n  },\n  regularization: {\n    required: true,\n    check: ({ absolute, relative }) =>\n      (absolute && relative && absolute > 0 && relative > 0),\n  },\n  transitionMode: {\n    required: true,\n    check: ['ergodic', 'leftright'],\n  },\n  covarianceMode: {\n    required: true,\n    check: ['full', 'diagonal'],\n  },\n  prior: {\n    required: true,\n    check: m => transitionMode === 'leftright' || m.length === states,\n  },\n  transition: {\n    required: true,\n    check: m => (transitionMode === 'leftright' ?\n      m.length === 2 * states :\n      m.length === states),\n  },\n  xStates: {\n    required: true,\n    check: m => m.length === states,\n  },\n});\n\n\n/**\n * HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hmmPredictionPrototype = /** @lends withHMMPrediction */ {\n  forwardInitialized: false,\n  isHierarchical: false,\n\n  /**\n   * Setup the Model by allocating GMM predictors to each of the hidden states\n   * @return {HMMBaseModel} the model\n   * @private\n   */\n  setup() {\n    this.params.xStates = this.params.xStates.map(s => GMMPredictor(s).reset());\n    return this;\n  },\n\n  /**\n   * Reset the prediction process\n   * @return {HMMBaseModel} the model\n   */\n  reset() {\n    this.likelihoodBuffer.clear();\n    this.params.xStates.forEach((s) => { s.reset(); });\n    return this;\n  },\n\n  /**\n   * Compute the likelihood of an observation given the HMM's parameters\n   * @param  {Array<Number>} observation Observation vector\n   * @return {Number}\n   */\n  likelihood(observation) {\n    const ct = (this.forwardInitialized) ?\n      this.updateForwardAlgorithm(observation) :\n      this.initializeForwardAlgorithm(observation);\n    this.updateAlphaWindow();\n    this.updateProgress();\n    return 1 / ct;\n  },\n\n  updateProgress() {\n    this.results.progress = 0.0;\n    for (let i = this.windowMinindex; i < this.windowMaxindex; i += 1) {\n      if (this.isHierarchical) {\n        this.results.progress += (this.alpha[i] + this.alpha1[i] + this.alpha2[i]) *\n          (i / this.windowNormalizationConstant);\n      } else {\n        this.results.progress += (this.alpha[i] * i) /\n          this.windowNormalizationConstant;\n      }\n    }\n    this.results.progress /= this.params.states - 1;\n  },\n\n  /**\n   * Update the state probabilities filtering window (for multiclass\n   * hierarchical HMM I think...)\n   * @private\n   */\n  updateAlphaWindow() {\n    this.results.likeliestState = 0;\n    // Get likeliest State\n    let bestAlpha = this.isHierarchical ?\n      (this.alpha[0] + this.alpha1[0]) :\n      this.alpha[0];\n    for (let i = 1; i < this.params.states; i += 1) {\n      if (this.isHierarchical) {\n        if ((this.alpha[i] + this.alpha1[i]) > bestAlpha) {\n          bestAlpha = this.alpha[i] + this.alpha1[i];\n          this.results.likeliestState = i;\n        }\n      } else if (this.alpha[i] > bestAlpha) {\n        bestAlpha = this.alpha[i];\n        this.results.likeliestState = i;\n      }\n    }\n\n    // Compute Window\n    this.windowMinindex = this.results.likeliestState - Math.floor(this.params.states / 2);\n    this.windowMaxindex = this.results.likeliestState + Math.floor(this.params.states / 2);\n    this.windowMinindex = (this.windowMinindex >= 0) ? this.windowMinindex : 0;\n    this.windowMaxindex = (this.windowMaxindex <= this.params.states) ?\n      this.windowMaxindex : this.params.states;\n    this.windowNormalizationConstant = 0.0;\n    for (let i = this.windowMinindex; i < this.windowMaxindex; i += 1) {\n      this.windowNormalizationConstant += this.isHierarchical ?\n        (this.alpha[i] + this.alpha1[i]) :\n        this.alpha[i];\n    }\n  },\n};\n\n/**\n * Bimodal (regression) HMM Prototype\n * @type {Object}\n * @ignore\n */\nconst hmmBimodalPredictionPrototype = /** @lends withHMMPrediction */ {\n  /**\n   * Estimate the output values corresponding to the input observation, by\n   * regression given the HMM's parameters. This method is called Hidden\n   * Mixture Regression (GMR).\n   *\n   * @param  {Array<Number>} inputObservation Observation on the input modality\n   * @return {Array<Number>} Output values (length = outputDimension)\n   */\n  regression(inputObservation) {\n    this.results.outputValues = Array(this.params.outputDimension).fill(0);\n    this.results.outputCovariance = Array(this.params.covarianceMode === 'full' ? this.params.outputDimension ** 2 : this.params.outputDimension).fill(0);\n\n    if (this.params.regressionEstimator === 'likeliest') {\n      this.params.xStates[this.results.likeliestState].predict(inputObservation);\n      this.results.outputValues =\n        this.params.xStates[this.results.likeliestState].results.outputValues;\n      return this.results.outputValues;\n    }\n\n    const clipMinState = (this.params.regressionEstimator === 'full') ?\n      0 : this.windowMinindex;\n    const clipMaxState = (this.params.regressionEstimator === 'full') ?\n      this.params.states : this.windowMaxindex;\n    let normalizationConstant = (this.params.regressionEstimator === 'full') ?\n      1 : this.windowNormalizationConstant;\n\n    if (normalizationConstant <= 0.0) normalizationConstant = 1;\n\n    // Compute Regression\n    for (let i = clipMinState; i < clipMaxState; i += 1) {\n      this.params.xStates[i].likelihood(inputObservation);\n      this.params.xStates[i].regression(inputObservation);\n      const tmpPredictedOutput = this.params.xStates[i].results.outputValues;\n      for (let d = 0; d < this.params.outputDimension; d += 1) {\n        if (this.isHierarchical) {\n          this.results.outputValues[d] +=\n            (this.alpha[i] + this.alpha1[i]) *\n            (tmpPredictedOutput[d] / normalizationConstant);\n          if (this.params.covarianceMode === 'full') {\n            for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n              this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n                (this.alpha[i] + this.alpha1[i]) *\n                (this.alpha[i] + this.alpha1[i]) *\n                (this.params.xStates[i].results\n                  .outputCovariance[(d * this.params.outputDimension) + d2] /\n                normalizationConstant);\n            }\n          } else {\n            this.results.outputCovariance[d] +=\n              (this.alpha[i] + this.alpha1[i]) *\n              (this.alpha[i] + this.alpha1[i]) *\n              (this.params.xStates[i].results.outputCovariance[d] /\n              normalizationConstant);\n          }\n        } else {\n          this.results.outputValues[d] += this.alpha[i] *\n            (tmpPredictedOutput[d] / normalizationConstant);\n          if (this.params.covarianceMode === 'full') {\n            for (let d2 = 0; d2 < this.params.outputDimension; d2 += 1) {\n              this.results.outputCovariance[(d * this.params.outputDimension) + d2] +=\n                (this.alpha[i] ** 2) *\n                (this.params.xStates[i].results\n                  .outputCovariance[(d * this.params.outputDimension) + d2] /\n                normalizationConstant);\n            }\n          } else {\n            this.results.outputCovariance[d] +=\n              ((this.alpha[i] ** 2) *\n              this.params.xStates[i].results.outputCovariance[d]) /\n              normalizationConstant;\n          }\n        }\n      }\n    }\n    return this.results.outputValues;\n  },\n};\n\n/**\n * Add HMM prediction capabilities to a single-class model. Mostly, this checks\n * the validity of the model parameters\n *\n * @todo validate gaussian components\n *\n * @param  {HMMBaseModel} o Source Model\n * @return {HMMBaseModel}\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  validateParameters('HMM', hmmParameterSpec(o.params.states, o.params.transitionMode), o.params);\n  return Object.assign(\n    o,\n    hmmPredictionPrototype,\n    o.params.bimodal ? hmmBimodalPredictionPrototype : {},\n    {\n      alpha: new Array(o.params.states).fill(0),\n      previous_alpha_: new Array(o.params.states).fill(0),\n    },\n  ).setup();\n}\n","import { isBaseModel } from '../core/model_base_mixin';\n\nconst DEFAULT_EXITPROBABILITY_LAST_STATE = 0.1;\n\n/**\n * Hierarchical HMM Base prototype\n * @type {Object}\n * @ignore\n */\nconst hierarchicalHmmPredictionPrototype =\n/** @lends withHierarchicalHMMPrediction */\n{\n  /**\n   * Specificies if the forward algorithm has been initialized\n   * @type {Boolean}\n   * @private\n   */\n  forwardInitialized: false,\n\n  /**\n   * Setup the model (allocate transition parameters)\n   * @return {HierarchicalHMM} [description]\n   * @private\n   */\n  setup() {\n    const numClasses = this.size();\n    this.params.prior = new Array(numClasses).fill(1 / numClasses);\n    this.params.transition = Array.from(\n      new Array(numClasses),\n      () => new Array(numClasses).fill(1 / numClasses),\n    );\n    this.params.exitTransition = new Array(numClasses).fill(0.1);\n    Object.values(this.models).forEach((model) => {\n      const m = model;\n      m.isHierarchical = true;\n    });\n    this.updateExitProbabilities();\n    return this;\n  },\n\n  /**\n   * Update the exit probabilities of each sub-Markov model\n   * @param  {Array<Number>|undefined} [exitProbabilities=undefined] Vector of\n   * exit probabilities (optional)\n   * @private\n   */\n  updateExitProbabilities(exitProbabilities = undefined) {\n    const exitProb = (exitProbabilities !== undefined) ?\n      exitProbabilities :\n      new Array(this.params.states - 1).fill(0)\n        .concat([DEFAULT_EXITPROBABILITY_LAST_STATE]);\n    Object.keys(this.models).forEach((label) => {\n      this.models[label].params.exitProbabilities = exitProb.slice();\n    });\n  },\n\n  /**\n   * Reset the prediction process. This is particularly important for temporal\n   * models such as HMMs, that depends on previous observations.\n   */\n  reset() {\n    Object.values(this.models).forEach(m => m.reset());\n    this.results = {\n      labels: [],\n      instantLikelihoods: [],\n      smoothedLikelihoods: [],\n      smoothedLogLikelihoods: [],\n      smoothedNormalizedLikelihoods: [],\n      exitLikelihood: [],\n      likeliest: null,\n      classes: {},\n    };\n    if (this.params.bimodal) {\n      this.resetBimodal();\n    }\n    this.forwardInitialized = false;\n  },\n\n  /**\n   * Make a prediction from a new observation (updates the results member)\n   * @param  {Array<Number>} observation Observation vector\n   */\n  predict(observation) {\n    if (this.forwardInitialized) {\n      this.updateForwardAlgorithm(observation);\n    } else {\n      this.initializeForwardAlgorithm(observation);\n    }\n    Object.keys(this.models).sort().forEach((label) => {\n      const model = this.models[label];\n      model.updateAlphaWindow();\n      model.updateProgress();\n      model.updateResults(model.results.instantLikelihood);\n    });\n    this.updateResults();\n\n    if (this.params.bimodal) {\n      Object.values(this.models).forEach(m => m.regression(observation));\n\n      if (this.params.multiClassRegressionEstimator === 'likeliest') {\n        this.results.outputValues =\n          this.models[this.results.likeliest].results.outputValues;\n        this.results.outputCovariance =\n          this.models[this.results.likeliest].results.outputCovariance;\n      } else {\n        this.results.outputValues = new Array(this.outputDimension).fill(0);\n        this.results.outputCovariance =\n          new Array(this.params.covarianceMode === 'full' ?\n            this.outputDimension ** 2 :\n            this.outputDimension).fill(0);\n\n        let modelIndex = 0;\n        Object.values(this.models).forEach((model) => {\n          for (let d = 0; d < this.outputDimension; d += 1) {\n            this.results.outputValues[d] +=\n              this.results.smoothedNormalizedLikelihoods[modelIndex] *\n              model.second.results.outputValues[d];\n\n            if (this.params.covarianceMode === 'full') {\n              for (let d2 = 0; d2 < this.outputDimension; d2 += 1) {\n                this.results.outputCovariance[(d * this.outputDimension) + d2] +=\n                  this.results.smoothedNormalizedLikelihoods[modelIndex] *\n                  model.results.outputCovariance[(d * this.outputDimension) + d2];\n              }\n            } else {\n              this.results.outputCovariance[d] +=\n                this.results.smoothedNormalizedLikelihoods[modelIndex] *\n                model.second.results.outputCovariance[d];\n            }\n          }\n          modelIndex += 1;\n        });\n      }\n    }\n  },\n\n  /**\n   * Initialize the forward algorithm of the hierarchical HMM\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  initializeForwardAlgorithm(observation) {\n    let normConst = 0;\n    let modelIndex = 0;\n    const classes = Object.keys(this.models).sort();\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      model.alpha1 = new Array(N).fill(0);\n      model.alpha2 = new Array(N).fill(0);\n\n      // Compute Emission probability and initialize on the first state of\n      // the primitive\n      if (model.params.transitionMode === 'ergodic') {\n        model.results.instantLikelihood = 0;\n        for (let i = 0; i < N; i += 1) {\n          model.alpha[i] = this.params.prior[modelIndex] *\n            model.params.prior[i] *\n            model.params.xStates[i].likelihood(observation);\n          model.results.instantLikelihood += model.alpha[i];\n        }\n      } else {\n        model.alpha[0] = this.params.prior[modelIndex] *\n          model.params.xStates[0].likelihood(observation);\n        [model.results.instantLikelihood] = model.alpha;\n      }\n      normConst += model.results.instantLikelihood;\n      modelIndex += 1;\n    });\n\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      for (let i = 0; i < N; i += 1) {\n        model.alpha[i] /= normConst;\n      }\n    });\n\n\n    this.frontierV1 = new Array(this.size).fill(0);\n    this.frontierV2 = new Array(this.size).fill(0);\n    this.forwardInitialized = true;\n  },\n\n  /**\n   * Update the forward algorithm of the hierarchical HMM\n   * @param  {Array<Number>} observation Observation vector\n   * @private\n   */\n  updateForwardAlgorithm(observation) {\n    let normConst = 0;\n\n    // Frontier Algorithm: variables\n    let tmp = 0;\n\n    // Intermediate variables: compute the sum of probabilities of making a\n    // transition to a new primitive\n    this.frontierV1 = this.likelihoodAlpha(1);\n    this.frontierV2 = this.likelihoodAlpha(2);\n\n    // FORWARD UPDATE\n    // --------------------------------------\n    let dstModelIndex = 0;\n    const classes = Object.keys(this.models).sort();\n    classes.forEach((label) => {\n      const dstModel = this.models[label];\n      const N = dstModel.params.states;\n\n      // 1) COMPUTE FRONTIER VARIABLE\n      //    --------------------------------------\n      // frontier variable : intermediate computation variable\n      const front = new Array(N).fill(0);\n\n      if (dstModel.params.transitionMode === 'ergodic') {\n        for (let k = 0; k < N; k += 1) {\n          for (let j = 0; j < N; j += 1) {\n            front[k] += (dstModel.params.transition[j][k] /\n              (1 - dstModel.params.exitProbabilities[j]))\n              * dstModel.alpha[j];\n          }\n\n          for (\n            let srcModelIndex = 0;\n            srcModelIndex < this.size();\n            srcModelIndex += 1\n          ) {\n            front[k] += dstModel.params.prior[k] * (\n              (this.frontierV1[srcModelIndex] *\n              this.params.transition[srcModelIndex][dstModelIndex]) +\n              (this.params.prior[dstModelIndex] *\n              this.frontierV2[srcModelIndex])\n            );\n          }\n        }\n      } else {\n        // k=0: first state of the primitive\n        front[0] = dstModel.params.transition[0] * dstModel.alpha[0];\n\n        for (\n          let srcModelIndex = 0;\n          srcModelIndex < this.size();\n          srcModelIndex += 1\n        ) {\n          front[0] += (this.frontierV1[srcModelIndex] *\n            this.params.transition[srcModelIndex][dstModelIndex]) +\n            (this.params.prior[dstModelIndex] *\n              this.frontierV2[srcModelIndex]);\n        }\n\n        // k>0: rest of the primitive\n        for (let k = 1; k < N; k += 1) {\n          front[k] += (dstModel.params.transition[k * 2] /\n            (1 - dstModel.params.exitProbabilities[k])) *\n            dstModel.alpha[k];\n          front[k] += (dstModel.params.transition[((k - 1) * 2) + 1] /\n            (1 - dstModel.params.exitProbabilities[k - 1])) *\n            dstModel.alpha[k - 1];\n        }\n\n        for (let k = 0; k < N; k += 1) {\n          dstModel.alpha[k] = 0;\n          dstModel.alpha1[k] = 0;\n          dstModel.alpha2[k] = 0;\n        }\n      }\n\n      // 2) UPDATE FORWARD VARIABLE\n      //    --------------------------------------\n      dstModel.results.exitLikelihood = 0.0;\n      dstModel.results.instantLikelihood = 0.0;\n\n      // end of the primitive: handle exit states\n      for (let k = 0; k < N; k += 1) {\n        tmp = dstModel.params.xStates[k].likelihood(observation) * front[k];\n        dstModel.alpha2[k] = this.params.exitTransition[dstModelIndex] *\n          dstModel.params.exitProbabilities[k] * tmp;\n        dstModel.alpha1[k] = (1 - this.params.exitTransition[dstModelIndex]) *\n          dstModel.params.exitProbabilities[k] * tmp;\n        dstModel.alpha[k] = (1 - dstModel.params.exitProbabilities[k]) * tmp;\n\n        dstModel.results.exitLikelihood += dstModel.alpha1[k] + dstModel.alpha2[k];\n        dstModel.results.instantLikelihood += dstModel.alpha[k] +\n          dstModel.alpha1[k] + dstModel.alpha2[k];\n        normConst += tmp;\n      }\n\n      dstModel.results.exitRatio = dstModel.results.exitLikelihood /\n        dstModel.results.instantLikelihood;\n\n      dstModelIndex += 1;\n    });\n\n    classes.forEach((label) => {\n      const model = this.models[label];\n      const N = model.params.states;\n      for (let k = 0; k < N; k += 1) {\n        model.alpha[k] /= normConst;\n        model.alpha1[k] /= normConst;\n        model.alpha2[k] /= normConst;\n      }\n    });\n  },\n\n  /**\n   * Compute the likelihood of a given probability.\n   * @param  {Number} exitNum Exit level number\n   * @return {Array<Number>}\n   */\n  likelihoodAlpha(exitNum) {\n    const likelihoodVector = new Array(this.size()).fill(0);\n    if (exitNum < 0) {\n      // Likelihood over all exit states\n      let modelIndex = 0;\n      Object.keys(this.models).sort().forEach((label) => {\n        const model = this.models[label];\n        likelihoodVector[modelIndex] = 0.0;\n        for (let k = 0; k < model.params.states; k += 1) {\n          likelihoodVector[modelIndex] += model.second.alpha[k] +\n            model.second.alpha1[k] +\n            model.second.alpha2[k];\n        }\n        modelIndex += 1;\n      });\n    } else {\n      // Likelihood for exit state \"exitNum\"\n      let modelIndex = 0;\n      Object.keys(this.models).sort().forEach((label) => {\n        const model = this.models[label];\n        likelihoodVector[modelIndex] = 0;\n        let { alpha } = model;\n        if (exitNum === 1) {\n          alpha = model.alpha1;\n        }\n        if (exitNum === 2) {\n          alpha = model.alpha2;\n        }\n        for (let k = 0; k < model.params.states; k += 1) {\n          likelihoodVector[modelIndex] += alpha[k];\n        }\n        modelIndex += 1;\n      });\n    }\n    return likelihoodVector;\n  },\n};\n\n/**\n * Add Hierarchical HMM prediction capabilities to a multi-class model.\n *\n * @todo algorithmic details\n * @todo validate parameters\n * @todo validate gaussian components\n *\n * @param  {MulticlassBaseModel} o Source Model\n * @return {HierarchicalHMM}\n *\n * @extends withMulticlassPrediction\n *\n * @throws {Error} is o is not a ModelBase\n */\nexport default function withHierarchicalHMMPrediction(o) {\n  if (!isBaseModel(o)) {\n    throw new Error('The base object must include a standard set of parameters (`params` key), @see `ModelBase`.');\n  }\n  // validateParameters(\n  //   'Hierarchical HMM',\n  //   hierarchicalHmmParameterSpec(o.params.states, o.params.transitionMode),\n  //   o.params,\n  // );\n  return Object.assign(\n    o,\n    hierarchicalHmmPredictionPrototype,\n    {\n      // alpha: new Array(o.params.states).fill(0),\n      // previous_alpha_: new Array(o.params.states).fill(0),\n    },\n  ).setup();\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withEMTraining from '../core/em_training_mixin';\nimport withHMMBase from './hmm_base_mixin';\nimport withHMMTraining from './hmm_training_mixin';\nimport MulticlassModelBase from '../core/multiclass_mixin';\nimport withMulticlassTraining from '../core/multiclass_training_mixin';\nimport withAbtractPrediction from '../core/prediction_mixin';\nimport withHMMPrediction from './hmm_prediction_mixin';\nimport withMulticlassPrediction from '../core/multiclass_prediction_mixin';\nimport withHierarchicalHMMPrediction from './hierarchical_hmm_prediction_mixin';\n\n/**\n * @typedef {Object} HMMParameters\n * @property {Boolean} bimodal Specifies if the model is bimodal\n * @property {Number} inputDimension Dimension of the input modality\n * @property {Number} outputDimension Dimension of the output modality\n * @property {Number} dimension Total dimension\n * @property {Number} states Number of hidden states in the Markov model\n * @property {Number} gaussians Number of components in the Gaussian mixture\n * observation distribution of each state\n * @property {String} transitionMode Transition matrix mode ('ergodic' or 'leftright')\n * @property {String} covarianceMode Covariance mode ('full' or 'diagonal')\n * @property {Array<Number>} mixtureCoeffs mixture coefficients ('weight' of\n * each gaussian component)\n * @property {Array<GaussianDistribution>} components Gaussian components\n */\n\n/**\n * Train a single-class HMM Model.\n *\n * @todo HMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {HMMParameters} Parameters of the trained HMM\n */\nexport function trainHMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const {\n    states,\n    gaussians,\n    regularization,\n    transitionMode,\n    covarianceMode,\n  } = configuration;\n  const model = withHMMTraining(\n    withEMTraining(\n      withHMMBase(ModelBase({\n        inputDimension,\n        outputDimension,\n        ...configuration,\n      })),\n      convergenceCriteria,\n    ),\n    states,\n    gaussians,\n    regularization,\n    transitionMode,\n    covarianceMode,\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Train a multi-class HMM Model.\n *\n * @todo HMM details\n *\n * @param  {TrainingSet} trainingSet                training set\n * @param  {Object} configuration                   Training configuration\n * @param  {Object} [convergenceCriteria=undefined] Convergence criteria of the\n * EM algorithm\n * @return {Object} Parameters of the trained HMM\n */\nexport function trainMulticlassHMM(\n  trainingSet,\n  configuration,\n  convergenceCriteria = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withMulticlassTraining(\n    MulticlassModelBase({ inputDimension, outputDimension, ...configuration }),\n    ts => trainHMM(ts, configuration, convergenceCriteria),\n  );\n  return model.train(trainingSet);\n}\n\n/**\n * Create a HMM Predictor from a full set of parameters (generated by trainHMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function HMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withHMMPrediction(withAbtractPrediction(\n    withHMMBase(ModelBase(params)),\n    likelihoodWindow,\n  ));\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass HMM Predictor from a full set of parameters\n * (generated by trainMulticlassHMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function MulticlassHMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  const model = withMulticlassPrediction(MulticlassModelBase(params));\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = HMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model.reset();\n  return model;\n}\n\n/**\n * Create a Multiclass HMM Predictor from a full set of parameters\n * (generated by trainMulticlassHMM).\n * @param       {Object} params                       Model parameters\n * @param       {number} [likelihoodWindow=undefined] Likelihoow window size\n * @function\n */\nexport function HierarchicalHMMPredictor(\n  params,\n  likelihoodWindow = undefined,\n) {\n  let model = MulticlassModelBase(params);\n  model.models = {};\n  Object.keys(params.classes).forEach((label) => {\n    model.models[label] = HMMPredictor(params.classes[label], likelihoodWindow);\n  });\n  model = withHierarchicalHMMPrediction(withMulticlassPrediction(model));\n  model.reset();\n  return model;\n}\n","import ModelBase from '../core/model_base_mixin';\nimport withKMeansTraining from './kmeans_training_mixin';\n\n/**\n * Train a K-Means model.\n *\n * @todo K-Means details\n *\n * @param  {TrainingSet} trainingSet           training set\n * @param  {number} clusters                   Number of clusters\n * @param  {Object} [trainingConfig=undefined] Training configuration\n * @return {Object}                            K-Means parameters\n */\nexport default function trainKmeans(\n  trainingSet,\n  clusters,\n  trainingConfig = undefined,\n) {\n  const { inputDimension, outputDimension } = trainingSet;\n  const model = withKMeansTraining(\n    ModelBase({\n      inputDimension,\n      outputDimension,\n    }),\n    clusters,\n    trainingConfig,\n  );\n  return model.train(trainingSet);\n}\n"],"names":["phrasePrototype","index","dim","Math","floor","Error","this","dimension","bimodal","inputDimension","inputData","length","outputData","concat","observation","push","slice","trim","outputDimension","mean","Array","fill","d","t","get","stddev","sqrt","minmax","from","min","Infinity","max","trainingSetPrototype","Object","keys","phrases","phraseIndex","includes","toString","callback","forEach","label","phrase","p","undefined","columnNames","assign","create","Phrase","filter","i","map","reduce","x","ts","TrainingSet","ll","sum","totalLength","ModelBase","isBaseModel","o","key","params","a","b","euclidean","v1","v2","x1","kMeansTrainingPrototype","trainingSet","empty","centers","clusters","trainingConfig","initialization","initializeClustersRandom","initializeClustersForgy","initClustersWithFirstPhrase","trainingNbIterations","maxIterations","previousCenters","updateCenters","meanClusterDistance","maxRelativeCenterVariation","k","l","relativeDistanceThreshold","getPhrase","indices","step","offset","c","random","pointsPerCluster","ppc","clustIdx","_","getFrame","numFramesPerCluster","frame","minDistance","clusterMembership","distance","withKMeansTraining","trainingConfiguration","model","matrixPrototype","data","out","Matrix","ncols","nrows","j","mat","gaussJordanInverse","transp","transpose","prod","product","determinant","matrix","dst","newMat","n","abs","swapLines","ii","tmp","nc","baseGaussianPrototype","covarianceMode","covariance","inverseCovariance","allocateBimodal","covarianceDeterminant","inputLikelihood","euclideanDistance","exp","PI","Number","isNaN","regularization","covMatrix","inv","pinv","updateInverseCovarianceBimodal","dimension1","dimension2","gaussianEllipse","y","trace","eigenVal1","eigenVal2","width","height","angle","atan","tantheta","tan","updateInverseCovariance","bimodalGaussianPrototype","inverseCovarianceInput","inputObservation","covarianceDeterminantInput","prediction","e","f","covMatrixInput","d1","d2","invInput","updateOutputCovariance","outputCovariance","covarianceGS","covarianceSG","tmptmptmp","covarianceMod","GaussianDistribution","proto","dist","allocate","trainerPrototype","initTraining","logLikelihood","iterations","previousLogLikelihood","converged","updateTraining","pctChg","terminateTraining","iteration","logProb","previousLogProb","convergenceCriteria","minIterations","percentChange","withEMTraining","gmmBasePrototype","components","gaussians","mixtureCoeffs","beta","likelihood","componentLikelihood","mixtureComponent","normConst","regularize","currentRegularization","gmmBimodalPrototype","tmpOutputValues","results","outputValues","regression","withGMMBase","gmmTrainerPrototype","initParametersToDefault","standardDeviation","initMeansWithKMeans","initCovariances","updateInverseCovariances","dataStddev","normCoeffs","std","absolute","relative","kmeansParams","train","gmeans","factor","phraseIndices","E","tbase","log","pix","value","MulticlassBasePrototype","models","MulticlassModelBase","parameters","withMulticlassTraining","trainingFunction","labels","classes","getPhrasesOfClass","circularBufferPrototype","full","buffer","capacity","idx","CircularBuffer","clear","predictionBasePrototype","lw","likelihoodWindow","likelihoodBuffer","updateResults","instantLikelihood","bufSize","withAbtractPrediction","validateParameters","specification","values","attr","spec","required","parameter","constructor","check","transform","gmmParameterSpec","m","MulticlassPredictionBasePrototype","setLikelihoodWindow","reset","resetBimodal","predict","labs","sort","normInstant","normSmoothed","maxLogLikelihood","lab","instantLikelihoods","smoothedLogLikelihoods","smoothedLikelihoods","likeliest","[object Object]","smoothedNormalizedLikelihoods","instantNormalizedLikelihoods","updateRegressionResults","MulticlassPredictionBimodalPrototype","multiClassRegressionEstimator","configuration","withMulticlassPrediction","trainGMM","withGMMTraining","GMMPredictor","withGMMPrediction","hmmBasePrototype","transitionMode","states","alpha","prior","xStates","forwardInitialized","previousAlpha","transition","withHMMBase","hmmTrainerPrototype","initMeansCovariancesWithGMMEM","initMeansWithAllPhrases","initCovariancesFullyObserved","s","previousBeta","nbPhrases","size","gammaSequence","epsilonSequence","gammaSequenceperMixture","T","gammaSum","gammaSumPerMixture","baumWelchForwardBackward","baumWelchGammaSum","baumWelchEstimateMixtureCoefficients","baumWelchEstimateMeans","baumWelchEstimateCovariances","baumWelchEstimatePrior","baumWelchEstimateTransitions","normalizeTransitions","alphaSeq","betaSeq","setErgodic","setLeftRight","initCovariance","othermeans","gmmParams","normPrior","transitionNorm","ct","observationLikelihoods","currentPhrase","observationProbabilities","initializeForwardAlgorithm","baumWelchForwardUpdate","initializeBackwardAlgorithm","baumWelchBackwardUpdate","reverse","oo","normalizeMixtureCoeffs","sumprior","hmmParameterSpec","hmmPredictionPrototype","updateForwardAlgorithm","updateAlphaWindow","updateProgress","progress","windowMinindex","windowMaxindex","isHierarchical","alpha1","alpha2","windowNormalizationConstant","likeliestState","bestAlpha","hmmBimodalPredictionPrototype","regressionEstimator","clipMinState","clipMaxState","normalizationConstant","tmpPredictedOutput","hierarchicalHmmPredictionPrototype","numClasses","exitTransition","updateExitProbabilities","exitProbabilities","exitProb","modelIndex","second","N","frontierV1","frontierV2","likelihoodAlpha","dstModelIndex","dstModel","front","srcModelIndex","exitLikelihood","exitRatio","exitNum","likelihoodVector","trainHMM","withHMMTraining","HMMPredictor","setup","withHMMPrediction","withHierarchicalHMMPrediction"],"mappings":"sLAIA,MAAMA,OAOAC,EAAOC,MACY,iBAAVD,GAAsBE,KAAKC,MAAMH,KAAWA,QAC/C,IAAII,MAAM,mCAEdH,GAAOI,KAAKC,gBACR,IAAIF,MAAM,sCAEdC,KAAKE,QAAS,IACZN,EAAMI,KAAKG,eAAgB,IACzBR,GAASK,KAAKI,UAAUC,aACpB,IAAIN,MAAM,sCAEXC,KAAKI,UAAUT,GAAOC,MAE3BD,GAASK,KAAKM,WAAWD,aACrB,IAAIN,MAAM,sCAEXC,KAAKM,WAAWX,GAAOC,EAAMI,KAAKG,mBAEvCR,GAASK,KAAKK,aACV,IAAIN,MAAM,mCAEbC,KAAKI,UAAUT,SACZ,IAAII,MAAM,eAEXC,KAAKI,UAAUT,GAAOC,aAStBD,MACHA,GAASK,KAAKK,aACV,IAAIN,MAAM,sCAEdC,KAAKE,QACAF,KAAKI,UAAUT,GAAOY,OAAOP,KAAKM,WAAWX,IAE/CK,KAAKI,UAAUT,SASnBa,MAECA,EAAYH,SAAWL,KAAKC,gBACxB,IAAIF,MAAM,mCAGdC,KAAKE,cACFE,UAAUK,KAAKD,EAAYE,MAAM,EAAGV,KAAKG,sBACzCG,WAAWG,KAAKD,EAAYE,MAAMV,KAAKG,eAAgBH,KAAKC,kBAE5DG,UAAUK,KAAKD,QAGjBH,QAAU,aAUPG,OACHR,KAAKE,cACF,IAAIH,MAAM,0CAEdS,EAAYH,SAAWL,KAAKG,qBACxB,IAAIJ,MAAM,wCAGbK,UAAUK,KAAKD,QACfG,mBAUIH,OACJR,KAAKE,cACF,IAAIH,MAAM,0CAEdS,EAAYH,SAAWL,KAAKY,sBACxB,IAAIb,MAAM,wCAGbO,WAAWG,KAAKD,QAChBG,qBAOAN,OAAS,OACTD,kBACAE,iCAOAF,kBACAO,2BAOAL,mBACAK,qBASCE,EAAOC,MAAMd,KAAKC,WAAWc,KAAK,OACnC,IAAIC,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,KACrC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC/BD,IAAMhB,KAAKkB,IAAID,EAAGD,KAEpBA,IAAMhB,KAAKK,cAEXQ,6BASDM,EAASL,MAAMd,KAAKC,WAAWc,KAAK,GACpCF,EAAOb,KAAKa,WACb,IAAIG,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,KACrC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC7BD,KAAOhB,KAAKkB,IAAID,EAAGD,GAAKH,EAAKG,KAAOhB,KAAKkB,IAAID,EAAGD,GAAKH,EAAKG,MAE5DA,IAAMhB,KAAKK,SACXW,GAAKnB,KAAKuB,KAAKD,EAAOH,WAExBG,kBASDE,EAASP,MAAMQ,KACnBR,MAAMd,KAAKC,WACX,MAASsB,IAAMC,EAAAA,EAAUC,KAAMD,EAAAA,SAE5B,IAAIR,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAKK,OAAQY,GAAK,IAC7BD,GAAGO,IAAM1B,KAAK0B,IAAIvB,KAAKkB,IAAID,EAAGD,GAAIK,EAAOL,GAAGO,OAC5CP,GAAGS,IAAM5B,KAAK4B,IAAIzB,KAAKkB,IAAID,EAAGD,GAAIK,EAAOL,GAAGS,YAGhDJ,UAQHrB,KAAKE,eACFG,OAASR,KAAK0B,IAAIvB,KAAKI,UAAUC,OAAQL,KAAKM,WAAWD,6SCjMpE,MAAMqB,iBAMKC,OAAOC,KAAK5B,KAAK6B,SAASxB,uBAQV,IAAhBL,KAAKK,kBAQJyB,UACJH,OAAOC,KAAK5B,KAAK6B,SAASE,SAASD,EAAYE,YAC1ChC,KAAK6B,QAAQC,EAAYE,YAE3B,cAUDC,UACCL,KAAK5B,KAAK6B,SAASK,QAASJ,MACxB9B,KAAK6B,QAAQC,GAAcA,EAAa9B,KAAK6B,iBAYrDC,EAAaK,EAAmBC,SAC7BC,OAAgBC,IAAXF,EAAwBA,EDyKxB,UAAgBjC,iBACZ,EADYS,kBAEX,EAFW2B,cAGf,KAHeJ,QAIrB,cAEFlC,EAAYE,EAAiBS,SAC5Be,OAAOa,OACZb,OAAOc,OAAO/C,YAEHkB,EAAkB,wDAInB,iDAIK2B,GAAezB,MAAMb,GAAWc,KAAK,MC3LR2B,iBAC1B1C,KAAKG,+BACJH,KAAKY,4BACTZ,KAAKuC,uBACAD,IAAVH,EAAuBA,EAAQL,EAAYE,yBAEhDH,QAAQC,GAAeO,EACrBA,UAOFP,UACE9B,KAAK6B,QAAQC,gBAOVK,QACLN,QAAUF,OAAOC,KAAK5B,KAAK6B,SAC7Bc,OAAOC,GAAK5C,KAAK6B,QAAQe,GAAGT,QAAUA,GACtCU,IAAID,KAAQA,EAAG5C,KAAK6B,QAAQe,MAC5BE,OAAO,CAACC,EAAGV,SAAYU,EAAMV,qBAO3BR,8BAQWM,SACVa,EAAKC,EAAYjD,eACpB6B,QAAUF,OAAOC,KAAK5B,KAAK6B,SAC3Bc,OAAOC,GAAK5C,KAAK6B,QAAQe,GAAGT,QAAUA,GACtCU,IAAID,KAAQA,EAAG5C,KAAK6B,QAAQe,MAC5BE,OAAO,CAACC,EAAGV,SAAYU,EAAMV,OACzBW,mBAQArB,OAAOC,KAAK5B,KAAK6B,SACrBgB,IAAID,GAAK5C,KAAK6B,QAAQe,GAAGT,OACzBW,OAAO,CAACI,EAAIH,IAAOG,EAAGnB,SAASgB,GAAKG,EAAKA,EAAG3C,QAAQwC,0BAQhDpB,OAAOC,KAAK5B,KAAK6B,uBAQlBsB,EAAMrC,MAAMd,KAAKC,WAAWc,KAAK,OACnCqC,EAAc,gBACXxB,KAAK5B,KAAK6B,SAASK,QAASU,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAK6B,QAAQe,GAAGvC,OAAQY,GAAK,IAC3CD,IAAMhB,KAAK6B,QAAQe,GAAG1B,IAAID,EAAGD,MAGtBhB,KAAK6B,QAAQe,GAAGvC,SAG1B8C,EAAIN,IAAIE,GAAKA,EAAIK,8BAQlBjC,EAASL,MAAMd,KAAKC,WAAWc,KAAK,GACpCF,EAAOb,KAAKa,WACduC,EAAc,gBACXxB,KAAK5B,KAAK6B,SAASK,QAASU,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAK6B,QAAQe,GAAGvC,OAAQY,GAAK,IACxCD,KAAOhB,KAAK6B,QAAQe,GAAG1B,IAAID,EAAGD,GAAKH,EAAKG,KAAO,KAG3ChB,KAAK6B,QAAQe,GAAGvC,SAG1Bc,EAAO0B,IAAIE,GAAKlD,KAAKuB,KAAK2B,EAAIK,oBAQ/B/B,EAASP,MAAMQ,KACnBR,MAAMd,KAAKC,WACX,MAASsB,IAAMC,EAAAA,EAAUC,KAAMD,EAAAA,mBAE1BI,KAAK5B,KAAK6B,SAASK,QAASU,QAC5B,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,MAClC,IAAIC,EAAI,EAAGA,EAAIjB,KAAK6B,QAAQe,GAAGvC,OAAQY,GAAK,IACxCD,GAAGO,KAAO1B,KAAK0B,IAAIF,EAAOL,GAAGO,IAAKvB,KAAK6B,QAAQe,GAAG1B,IAAID,EAAGD,MACzDA,GAAGS,KAAO5B,KAAK4B,IAAIJ,EAAOL,GAAGS,IAAKzB,KAAK6B,QAAQe,GAAG1B,IAAID,EAAGD,MAI/DK,IAqBI,SAAS4B,GAAY9C,iBACjB,EADiBS,kBAEhB,EAFgB2B,cAGpB,gBAERtC,EAAYE,EAAiBS,SAC5Be,OAAOa,OACZb,OAAOc,OAAOf,YAEHd,EAAkB,6DAId2B,GAAezB,MAAMb,GAAWc,KAAK,iBC9MzC,SAASsC,SAAUlD,iBAAAS,2BAK1ByB,0DACCA,EAAEnC,eACFmC,EAAElC,sBACFkC,EAAEzB,uBACFyB,EAAEpC,uBAGFoC,wBAEMzB,EAAkB,+BAGlBT,gCAGAS,0BAGAT,EAAiBS,MAWzB,SAAS0C,EAAYC,OACrB5B,OAAOC,KAAK2B,GAAGxB,SAAS,UAAW,OAAO,SACjC,UAAW,iBAAkB,kBAAmB,aAClDc,IAAIW,GAAO7B,OAAOC,KAAK2B,EAAEE,QAAQ1B,SAASyB,IACnDV,OAAO,CAACY,EAAGC,IAAMD,GAAKC,GAAG,GCzCf,SAASC,EAAUC,EAAIC,UAC7BjE,KAAKuB,KAAKyC,EACdhB,IAAI,CAACkB,EAAInB,KAAOmB,EAAKD,EAAGlB,KAAO,GAC/BE,OAAO,CAACY,EAAGX,IAAOW,EAAIX,EAAI,UCNzBiB,SACEC,OACCA,GAAeA,EAAYC,cACxB,IAAInE,MAAM,qCAGb0D,OAAOU,QAAUrD,MAAMQ,KAC1BR,MAAMd,KAAKyD,OAAOW,UAClB,IAAM,IAAItD,MAAMd,KAAKyD,OAAOxD,WAAWc,KAAK,IAMH,WAAvCf,KAAKqE,eAAeC,oBACjBC,yBAAyBN,QACzB,GAA2C,UAAvCjE,KAAKqE,eAAeC,oBACxBE,wBAAwBP,OACxB,CAAA,GAA2C,SAAvCjE,KAAKqE,eAAeC,qBAGvB,IAAIvE,MAAM,4EAFX0E,4BAA4BR,OAMjC,IAAIS,EAAuB,EAC3BA,EAAuB1E,KAAKqE,eAAeM,cAC3CD,GAAwB,EACxB,OACME,EAAkB5E,KAAKyD,OAAOU,aAE/BU,cAAcD,EAAiBX,OAEhCa,EAAsB,EACtBC,EAA6B,MAC5B,IAAIC,EAAI,EAAGA,EAAIhF,KAAKyD,OAAOW,SAAUY,GAAK,EAAG,KAC3C,IAAIC,EAAI,EAAGA,EAAIjF,KAAKyD,OAAOW,SAAUa,GAAK,EACzCD,IAAMC,OACerB,EACrB5D,KAAKyD,OAAOU,QAAQa,GACpBhF,KAAKyD,OAAOU,QAAQc,OAIGpF,KAAK4B,IAChCmC,EACEgB,EAAgBI,GAChBhF,KAAKyD,OAAOU,QAAQa,IAEtBD,SAGmB/E,KAAKyD,OAAOW,UAAYpE,KAAKyD,OAAOW,SAAW,MACxCpE,KAAKyD,OAAOW,aACZU,GACG9E,KAAKqE,eAAea,0BAA2B,aAE3ElF,KAAKyD,oCAGcQ,SACpB7B,EAAS6B,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDC,EAAOxF,KAAKC,MAAMsC,EAAO/B,OAASL,KAAKyD,OAAOW,cAEhDkB,EAAS,MACR,IAAIC,EAAI,EAAGA,EAAIvF,KAAKyD,OAAOW,SAAUmB,GAAK,EAAG,MAC3C9B,OAAOU,QAAQoB,GAAK,IAAIzE,MAAMd,KAAKyD,OAAOxD,WAAWc,KAAK,OAC1D,IAAIE,EAAI,EAAGA,EAAIoE,EAAMpE,GAAK,MACxB,IAAID,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOU,QAAQoB,GAAGvE,IAAMoB,EAAOlB,IAAIoE,EAASrE,EAAGD,GAAKqE,KAGnDA,6BAIWpB,SACjB7B,EAAS6B,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDA,EAAUtE,MAAMQ,KACpBR,MAAMsB,EAAO/B,QACb,IAAMR,KAAKC,MAAMD,KAAK2F,SAAWxF,KAAKyD,OAAOW,WAEzCqB,EAAmBL,EAAQtC,OAC/B,CAAC4C,EAAK9C,WACEP,EAAIqD,WACR9C,IAAM,EACDP,GAETvB,MAAMd,KAAKyD,OAAOW,UAAUrD,KAAK,QAE9B,IAAI6B,EAAI,EAAGA,EAAIwC,EAAQ/E,OAAQuC,GAAK,EAAG,OACpC+C,EAAWP,EAAQxC,OACpB,IAAI5B,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOU,QAAQwB,GAAU3E,IAAMoB,EAAOlB,IAAI0B,EAAG5B,QAGjDyC,OAAOU,QAAQjC,QAAQ,CAAC0D,EAAGL,UACzB9B,OAAOU,QAAQoB,GAAKvF,KAAKyD,OAAOU,QAAQoB,GAC1C1C,IAAIE,GAAKA,EAAI0C,EAAiBF,+BAIbtB,SAChB7B,EAAS6B,EAAYkB,UAAUlB,EAAYmB,UAAU,IACrDA,EAAUtE,MAAMQ,KACpBR,MAAMd,KAAKyD,OAAOW,UAClB,IAAMvE,KAAKC,MAAMD,KAAK2F,SAAWpD,EAAO/B,cAErCoD,OAAOU,QAAUiB,EAAQvC,IAAID,GAAKR,EAAOyD,SAASjD,mBAG3CgC,EAAiBX,QACxBR,OAAOU,QAAUrD,MAAMQ,KAAKR,MAAMd,KAAKyD,OAAOW,UAAW,IAC5D,IAAItD,MAAMd,KAAKyD,OAAOxD,WAAWc,KAAK,UAClC+E,EAAsBhF,MAAMd,KAAKyD,OAAOW,UAAUrD,KAAK,KACjDmB,QAASE,QACd,IAAInB,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,EAAG,OACnC8E,EAAQ3D,EAAOyD,SAAS5E,OAC1B+E,EAAcpC,EAAUmC,EAAOnB,EAAgB,IAC/CqB,EAAoB,MACnB,IAAIjB,EAAI,EAAGA,EAAIhF,KAAKyD,OAAOW,SAAUY,GAAK,EAAG,OAC1CkB,EAAWtC,EACfmC,EACAnB,EAAgBI,GAChBhF,KAAKyD,OAAOxD,WAEViG,EAAWF,MACOhB,IACNkB,KAGED,IAAsB,MACrC,IAAIjF,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOU,QAAQ8B,GAAmBjF,IAAMoB,EAAOlB,IAAID,EAAGD,UAI5D,IAAIgE,EAAI,EAAGA,EAAIhF,KAAKyD,OAAOW,SAAUY,GAAK,KACzCc,EAAoBd,GAAK,MACtB,IAAIhE,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOU,QAAQa,GAAGhE,IAAM8E,EAAoBd,KAO5C,SAASmB,EACtB5C,EACAa,EACAgC,UAEK9C,EAAYC,SACT,IAAIxD,MAAM,qGAEZsE,EAAiB1C,OAAOa,uBACZ,mCACW,mBACZ,gBACA,KACd4D,GACGC,EAAQ1E,OAAOa,OAAOe,EAAGS,+BAGzBP,OAAOW,SAAWA,EACjBiC,ECvKT,MAWMC,gBAMKtG,KAAKuG,KAAKzD,OAAO,CAACY,EAAGC,IAAMD,EAAIC,EAAG,sBAQnC6C,EAAMC,EAAOzG,KAAK0G,MAAO1G,KAAK2G,WAC/B,IAAI/D,EAAI,EAAGA,EAAI5C,KAAK0G,MAAO9D,GAAK,MAC9B,IAAIgE,EAAI,EAAGA,EAAI5G,KAAK2G,MAAOC,GAAK,IAC/BL,KAAM3D,EAAI5C,KAAK2G,MAASC,GAAK5G,KAAKuG,KAAMK,EAAI5G,KAAK0G,MAAS9D,UAG3D4D,WAQDK,MACF7G,KAAK0G,QAAUG,EAAIF,YACf,IAAI5G,MAAM,6CAEZyG,EAAMC,EAAOzG,KAAK2G,MAAOE,EAAIH,WAC9B,IAAI9D,EAAI,EAAGA,EAAI5C,KAAK2G,MAAO/D,GAAK,MAC9B,IAAIgE,EAAI,EAAGA,EAAIC,EAAIH,MAAOE,GAAK,EAAG,GACjCL,KAAM3D,EAAIiE,EAAIH,MAASE,GAAK,MAC3B,IAAI5B,EAAI,EAAGA,EAAIhF,KAAK0G,MAAO1B,GAAK,IAC/BuB,KAAM3D,EAAIiE,EAAIH,MAASE,IACzB5G,KAAKuG,KAAM3D,EAAI5C,KAAK0G,MAAS1B,GAAK6B,EAAIN,KAAMvB,EAAI6B,EAAIH,MAASE,UAI9DJ,aASHxG,KAAK2G,QAAU3G,KAAK0G,aACf1G,KAAK8G,2BAGRC,EAAS/G,KAAKgH,eAChBhH,KAAK2G,OAAS3G,KAAK0G,MAAO,OACtBO,EAAOF,EAAOG,QAAQlH,OACtBmH,YAAEA,EAAaC,OAAQC,GAAQJ,EAAKH,4BACjCK,YAAAA,EAAaC,OAAQC,EAAIH,QAAQH,UAEtCE,EAAOjH,KAAKkH,QAAQH,IACpBI,YAAEA,EAAaC,OAAQC,GAAQJ,EAAKH,4BACjCK,YAAAA,EAAaC,OAAQL,EAAOG,QAAQG,6BASzCrH,KAAK2G,QAAU3G,KAAK0G,YAChB,IAAI3G,MAAM,+DAEdoH,EAAc,QACZN,EAAMJ,EAAOzG,KAAK2G,MAAoB,EAAb3G,KAAK0G,OAC9BY,EAASb,EAAOzG,KAAK2G,MAAoB,EAAb3G,KAAK0G,OACjCa,EAAIvH,KAAK2G,UAGV,IAAI/D,EAAI,EAAGA,EAAI2E,EAAG3E,GAAK,EAAG,KACxB,IAAIgE,EAAI,EAAGA,EAAIW,EAAGX,GAAK,IACtBL,KAAU,EAAJ3D,EAAQ2E,EAAKX,GAAK5G,KAAKuG,KAAM3D,EAAI2E,EAAKX,KAE9CL,KAAU,EAAJ3D,EAAQ2E,EAAKA,EAAI3E,GAAK,MAG7B,IAAIoC,EAAI,EAAGA,EAAIuC,EAAGvC,GAAK,EAAG,KACzBpC,EAAIoC,OACDnF,KAAK2H,IAAIX,EAAIN,KAAU,EAAJ3D,EAAQ2E,EAAKvC,IArGf,aAsGjB,KACKuC,QACF,IAAIxH,MAAM,4BAGL8G,EAAIN,KAAU,EAAJ3D,EAAQ2E,EAAKvC,GAGlCpC,IAAMoC,KACJyC,UAAU7E,EAAGoC,KAGZuB,KAAOM,EAAIN,KAAK7F,YAElB,IAAIkG,EAAI,EAAGA,EAAI,EAAIW,EAAGX,GAAK,IACvBL,KAAU,EAAJvB,EAAQuC,EAAKX,IAAMC,EAAIN,KAAU,EAAJvB,EAAQuC,EAAKvC,OAEpD,IAAI0C,EAAK,EAAGA,EAAKH,EAAGG,GAAM,KACzBA,IAAO1C,MACJ,IAAI4B,EAAI,EAAGA,EAAI,EAAIW,EAAGX,GAAK,IACvBL,KAAW,EAALmB,EAASH,EAAKX,IACvBC,EAAIN,KAAW,EAALmB,EAASH,EAAKvC,GACxBsC,EAAOf,KAAU,EAAJvB,EAAQuC,EAAKX,KAIhCL,KAAOe,EAAOf,KAAK7F,cAGnB2G,EAAMZ,EAAOzG,KAAK2G,MAAO3G,KAAK0G,WAC/B,IAAI9D,EAAI,EAAGA,EAAI2E,EAAG3E,GAAK,MACrB,IAAIgE,EAAI,EAAGA,EAAIW,EAAGX,GAAK,IACtBL,KAAM3D,EAAI2E,EAAKX,GAAKC,EAAIN,KAAU,EAAJ3D,EAAQ2E,EAAKA,EAAIX,UAG9CO,YAAAA,EAAaC,OAAQC,cAStBzE,EAAGgE,OACN,IAAI5B,EAAI,EAAGA,EAAIhF,KAAK0G,MAAO1B,GAAK,EAAG,OAChC2C,EAAM3H,KAAKuG,KAAM3D,EAAI5C,KAAK0G,MAAS1B,QACpCuB,KAAM3D,EAAI5C,KAAK0G,MAAS1B,GAAKhF,KAAKuG,KAAMK,EAAI5G,KAAK0G,MAAS1B,QAC1DuB,KAAMK,EAAI5G,KAAK0G,MAAS1B,GAAK2C,gBAU1B/E,EAAGgE,OACR,IAAI5B,EAAI,EAAGA,EAAIhF,KAAK2G,MAAO3B,GAAK,EAAG,OAChC2C,EAAM3H,KAAKuG,KAAMvB,EAAIhF,KAAK0G,MAAS9D,QACpC2D,KAAMvB,EAAIhF,KAAK0G,MAAS9D,GAAK5C,KAAKuG,KAAMvB,EAAIhF,KAAK0G,MAASE,QAC1DL,KAAMvB,EAAIhF,KAAK0G,MAASE,GAAKe,KAiBzB,SAASlB,EAAOE,EAAQ,EAAGD,GAAQ,SAC1CkB,EAAKlB,EAAQ,EAAIC,EAAQD,SACxB/E,OAAOa,OACZb,OAAOc,OAAO6D,kBAGLsB,OACD9G,MAAM6F,EAAQiB,GAAI7G,KAAK,KC5KnC,MAAM8G,mBAMGhH,KAAO,IAAIC,MAAMd,KAAKC,WAAWc,KAAK,GACf,SAAxBf,KAAK8H,qBACFC,WAAa,IAAIjH,MAAMd,KAAKC,WAAa,GAAGc,KAAK,QACjDiH,kBAAoB,IAAIlH,MAAMd,KAAKC,WAAa,GAAGc,KAAK,UAExDgH,WAAa,IAAIjH,MAAMd,KAAKC,WAAWc,KAAK,QAC5CiH,kBAAoB,IAAIlH,MAAMd,KAAKC,WAAWc,KAAK,IAEtDf,KAAKE,cACF+H,8BAcEzH,MAC0B,IAA/BR,KAAKkI,4BACD,IAAInI,MAAM,0CAEdC,KAAKE,SAAWM,EAAYH,SAAWL,KAAKG,sBACvCH,KAAKmI,gBAAgB3H,MAE1BA,EAAYH,SAAWL,KAAKC,gBACxB,IAAIF,2EAA2EC,KAAKC,sBAAsBO,EAAYH,gBAG1H+H,EAAoB,KACI,SAAxBpI,KAAK8H,mBACF,IAAI7C,EAAI,EAAGA,EAAIjF,KAAKC,UAAWgF,GAAK,EAAG,KACtC0C,EAAM,MACL,IAAI3C,EAAI,EAAGA,EAAIhF,KAAKC,UAAW+E,GAAK,KAChChF,KAAKgI,kBAAmB/C,EAAIjF,KAAKC,UAAa+E,IAClDxE,EAAYwE,GAAKhF,KAAKa,KAAKmE,QAEVxE,EAAYyE,GAAKjF,KAAKa,KAAKoE,IAAM0C,WAGpD,IAAI1C,EAAI,EAAGA,EAAIjF,KAAKC,UAAWgF,GAAK,KAClBjF,KAAKgI,kBAAkB/C,IACzCzE,EAAYyE,GAAKjF,KAAKa,KAAKoE,KAC3BzE,EAAYyE,GAAKjF,KAAKa,KAAKoE,QAI9B5C,EAAIxC,KAAKwI,KAAK,GAAMD,GACtBvI,KAAKuB,KAAKpB,KAAKkI,uBAA0B,EAAIrI,KAAKyI,KAAOtI,KAAKC,kBAE5DoC,EAAI,QAAUkG,OAAOC,MAAMnG,IAAMxC,KAAK2H,IAAInF,KAAQb,EAAAA,OAChD,QAGCa,cAUEoG,MACmB,SAAxBzI,KAAK8H,mBACF,IAAI9G,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,OAClC+G,WAAY/G,EAAIhB,KAAKC,UAAae,IAAMyH,EAAezH,YAGzD,IAAIA,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,OAClC+G,WAAW/G,IAAMyH,EAAezH,iCAUb,SAAxBhB,KAAK8H,eAA2B,OAC5BY,EAAYjC,EAAOzG,KAAKC,UAAWD,KAAKC,aAEpCsG,KAAOvG,KAAK+H,WAAWrH,cAC3BiI,EAAMD,EAAUE,YACjBV,sBAAwBS,EAAIxB,iBAC5Ba,kBAAoBW,EAAIvB,OAAOb,SAC/B,MACA2B,sBAAwB,MACxB,IAAIlH,EAAI,EAAGA,EAAIhB,KAAKC,UAAWe,GAAK,EAAG,IACtChB,KAAK+H,WAAW/G,IAAM,QAClB,IAAIjB,MAAM,8BAEbiI,kBAAkBhH,GAAK,EAAIhB,KAAK+H,WAAW/G,QAC3CkH,uBAAyBlI,KAAK+H,WAAW/G,IAG9ChB,KAAKE,cACF2I,4CAWCC,EAAYC,MAChBD,GAAc9I,KAAKC,WAAa8I,GAAc/I,KAAKC,gBAC/C,IAAIF,MAAM,iCAGZiJ,KACD,IACA,QACI,SACC,QACD,OAQLtF,EACAC,EACA4B,IARYxC,EAAI/C,KAAKa,KAAKiI,KACdG,EAAIjJ,KAAKa,KAAKkI,GAQF,SAAxB/I,KAAK8H,kBACH9H,KAAK+H,WAAYe,EAAa9I,KAAKC,UAAa6I,KAChD9I,KAAK+H,WAAYe,EAAa9I,KAAKC,UAAa8I,KAChD/I,KAAK+H,WAAYgB,EAAa/I,KAAKC,UAAa8I,OAEhD/I,KAAK+H,WAAWe,KAChB,IACA9I,KAAK+H,WAAWgB,UAIhBG,EAAQxF,EAAI6B,EACZ4B,EAAezD,EAAI6B,EAAM5B,EAAIA,EAC7BwF,EAAY,IAAOD,EAAQrJ,KAAKuB,KAAM8H,GAAS,EAAM,EAAI/B,IACzDiC,EAAY,IAAOF,EAAQrJ,KAAKuB,KAAM8H,GAAS,EAAM,EAAI/B,aAC/CkC,MAAQxJ,KAAKuB,KAAK,MAAQ+H,KAC1BG,OAASzJ,KAAKuB,KAAK,MAAQgI,KAC3BG,MAAQ1J,KAAK2J,KAAK7F,GAAKwF,EAAY5D,IAC/CgD,OAAOC,MAAMQ,EAAgBO,WACfA,MAAQ1J,KAAKyI,GAAK,GAG7BU,eAYGA,EAAiBF,EAAYC,MACnCD,GAAc9I,KAAKC,WAAa8I,GAAc/I,KAAKC,gBAC/C,IAAIF,MAAM,gCAGbc,KAAKiI,GAAcE,EAAgBjG,OACnClC,KAAKkI,GAAcC,EAAgBC,QAElCE,EAAaH,EAAgBK,MAAQL,EAAgBK,MAAS,MAC9DD,EAAaJ,EAAgBM,OAASN,EAAgBM,OAAU,MAChEG,EAAW5J,KAAK6J,IAAIV,EAAgBO,OACpC5F,GAAMwF,EAAYC,GAAaK,GAAcA,GAAY,EAAK,GAC9DlE,EAAI4D,EAAaxF,EAAI8F,EACrB/F,EAAI0F,EAAazF,EAAI8F,EAEC,SAAxBzJ,KAAK8H,qBACFC,WAAYe,EAAa9I,KAAKC,UAAa6I,GAAcpF,OACzDqE,WAAYe,EAAa9I,KAAKC,UAAa8I,GAAcpF,OACzDoE,WAAYgB,EAAa/I,KAAKC,UAAa6I,GAAcnF,OACzDoE,WAAYgB,EAAa/I,KAAKC,UAAa8I,GAAcxD,SAEzDwC,WAAWe,GAAcpF,OACzBqE,WAAWgB,GAAcxD,QAE3BoE,4BAqBHC,qBAM0B,SAAxB5J,KAAK8H,oBACF+B,uBAAyB,IAAI/I,MAAMd,KAAKG,gBAAkB,GAAGY,KAAK,QAElE8I,uBAAyB,IAAI/I,MAAMd,KAAKG,gBAAgBY,KAAK,oBAWtD+I,MAC0B,IAApC9J,KAAK+J,iCACD,IAAIhK,MAAM,6DAGdqI,EAAoB,KACI,SAAxBpI,KAAK8H,mBACF,IAAI7C,EAAI,EAAGA,EAAIjF,KAAKG,eAAgB8E,GAAK,EAAG,KAC3C0C,EAAM,MACL,IAAI3C,EAAI,EAAGA,EAAIhF,KAAKG,eAAgB6E,GAAK,KACrChF,KAAK6J,uBAAwB5E,EAAIjF,KAAKG,eAAkB6E,IAC5D8E,EAAiB9E,GAAKhF,KAAKa,KAAKmE,QAEf8E,EAAiB7E,GAAKjF,KAAKa,KAAKoE,IAAM0C,WAGzD,IAAI1C,EAAI,EAAGA,EAAIjF,KAAKG,eAAgB8E,GAAK,KACvBjF,KAAKgI,kBAAkB/C,IACzC6E,EAAiB7E,GAAKjF,KAAKa,KAAKoE,KAChC6E,EAAiB7E,GAAKjF,KAAKa,KAAKoE,QAInC5C,EAAIxC,KAAKwI,KAAK,GAAMD,GACbvI,KAAKuB,KAAKpB,KAAK+J,4BACR,EAAIlK,KAAKyI,KAAOtI,KAAKG,uBAEnCkC,EAAI,QAAUkG,OAAOC,MAAMnG,IAAMxC,KAAK2H,IAAInF,KAAQb,EAAAA,KAAUa,EAAI,QAE7DA,cAYEyH,SACHlJ,EAAkBZ,KAAKC,UAAYD,KAAKG,eACxC6J,EAAalJ,MAAMF,GAAiBG,KAAK,MAEnB,SAAxBf,KAAK8H,mBACF,IAAI9G,EAAI,EAAGA,EAAIJ,EAAiBI,GAAK,EAAG,GAChCA,GAAKhB,KAAKa,KAAKb,KAAKG,eAAiBa,OAC3C,IAAIiJ,EAAI,EAAGA,EAAIjK,KAAKG,eAAgB8J,GAAK,EAAG,KAC3CtC,EAAM,MACL,IAAIuC,EAAI,EAAGA,EAAIlK,KAAKG,eAAgB+J,GAAK,KACrClK,KAAK6J,uBAAwBI,EAAIjK,KAAKG,eAAkB+J,IAC5DJ,EAAiBI,GAAKlK,KAAKa,KAAKqJ,MAE1BlJ,IAAM2G,EACf3H,KAAK+H,YAAa/G,EAAIhB,KAAKG,gBAAkBH,KAAKC,UAAagK,aAIhE,IAAIjJ,EAAI,EAAGA,EAAIJ,EAAiBI,GAAK,IAC7BA,GAAKhB,KAAKa,KAAKb,KAAKG,eAAiBa,UAG7CgJ,uCAQqB,SAAxBhK,KAAK8H,eAA2B,OAC5BqC,EAAiB1D,EAAOzG,KAAKG,eAAgBH,KAAKG,oBACnD,IAAIiK,EAAK,EAAGA,EAAKpK,KAAKG,eAAgBiK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKrK,KAAKG,eAAgBkK,GAAM,IAChC9D,KAAM6D,EAAKpK,KAAKG,eAAkBkK,GAC/CrK,KAAK+H,WAAYqC,EAAKpK,KAAKC,UAAaoK,SAGxCC,EAAWH,EAAevB,YAC3BmB,2BAA6BO,EAASnD,iBACtC0C,uBAAyBS,EAASlD,OAAOb,SACzC,MACAwD,2BAA6B,MAC7B,IAAI/I,EAAI,EAAGA,EAAIhB,KAAKG,eAAgBa,GAAK,EAAG,IAC3ChB,KAAK+H,WAAW/G,IAAM,QAClB,IAAIjB,MAAM,8BAEb8J,uBAAuB7I,GAAK,EAAIhB,KAAK+H,WAAW/G,QAChD+I,4BAA8B/J,KAAK+H,WAAW/G,SAGlDuJ,sDAQuB,aAAxBvK,KAAK8H,gCACF0C,iBAAmBxK,KAAK+H,WAAWrH,MAAM,EAAGV,KAAKG,uBAKlDgK,EAAiB1D,EAAOzG,KAAKG,eAAgBH,KAAKG,oBACnD,IAAIiK,EAAK,EAAGA,EAAKpK,KAAKG,eAAgBiK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKrK,KAAKG,eAAgBkK,GAAM,IAChC9D,KAAM6D,EAAKpK,KAAKG,eAAkBkK,GAC/CrK,KAAK+H,WAAYqC,EAAKpK,KAAKC,UAAaoK,SAGxC1B,EAAMwB,EAAevB,OACrB6B,EAAehE,EAAOzG,KAAKG,eAAgBH,KAAKY,qBACjD,IAAIwJ,EAAK,EAAGA,EAAKpK,KAAKG,eAAgBiK,GAAM,MAC1C,IAAIC,EAAK,EAAGA,EAAKrK,KAAKY,gBAAiByJ,GAAM,IACnC9D,KAAM6D,EAAKpK,KAAKY,gBAAmByJ,GAC9CrK,KAAK+H,WAAYqC,EAAKpK,KAAKC,UAAaD,KAAKG,eAAiBkK,SAG9DK,EAAejE,EAAOzG,KAAKY,gBAAiBZ,KAAKG,oBAClD,IAAIiK,EAAK,EAAGA,EAAKpK,KAAKY,gBAAiBwJ,GAAM,MAC3C,IAAIC,EAAK,EAAGA,EAAKrK,KAAKG,eAAgBkK,GAAM,IAClC9D,KAAM6D,EAAKpK,KAAKG,eAAkBkK,GAC7CrK,KAAK+H,YAAa/H,KAAKG,eAAiBiK,GAAMpK,KAAKC,UAAaoK,SAGhEM,EAAYhC,EAAIvB,OAAOF,QAAQuD,GAC/BG,EAAgBF,EAAaxD,QAAQyD,QACtCH,iBAAmB1J,MAAMd,KAAKY,iBAAmB,GAAGG,KAAK,OACzD,IAAIqJ,EAAK,EAAGA,EAAKpK,KAAKY,gBAAiBwJ,GAAM,MAC3C,IAAIC,EAAK,EAAGA,EAAKrK,KAAKY,gBAAiByJ,GAAM,OAC3CG,iBAAkBJ,EAAKpK,KAAKY,gBAAmByJ,GAClDrK,KAAK+H,YAAa/H,KAAKG,eAAiBiK,GAAMpK,KAAKC,UACjDD,KAAKG,eAAiBkK,GACtBO,EAAcrE,KAAM6D,EAAKpK,KAAKY,gBAAmByJ,KA2B9C,SAASQ,EACtB1K,EAAiB,EACjBS,EAAkB,EAClBkH,EAAiB,cAEX5H,EAAUU,EAAkB,EAC5BX,EAAYE,EAAiBS,EAC7BkK,EAAQ5K,EACZyB,OAAOa,UAAWqF,EAAuB+B,GACzC/B,EACItB,EAAO5E,OAAOa,wGAOO,GAEzBtC,GAAY6J,2BAA4B,OAEpCgB,EAAOpJ,OAAOa,OAClBb,OAAOc,OAAOqI,GACdvE,YAEGyE,WACED,EC/bT,MAAME,SAQEhH,OACCA,GAAeA,EAAYC,cACxB,IAAInE,MAAM,kCAGbmL,aAAajH,OAEdkH,GAAiB3J,EAAAA,EACjB4J,EAAa,EACbC,EAAwBF,QAEpBnL,KAAKsL,UAAUF,EAAYD,EAAeE,IAAwB,GAChDF,IACRnL,KAAKuL,eAAetH,SAE9BuH,EACJ,IAAM3L,KAAK2H,KAAK2D,EAAgBE,GAAyBA,MACvD9C,OAAOC,MAAMgD,IAAWJ,EAAa,QACjC,IAAIrL,MAAM,uCAGJ,cAGX0L,oBACEzL,KAAKyD,kBAeJiI,EAAWC,EAASC,MACxBF,GAAa1L,KAAK6L,oBAAoBlH,cAAe,OAAO,KAC5D3E,KAAK6L,oBAAoBlH,eAAiB3E,KAAK6L,oBAAoBC,qBAC9DJ,GAAa1L,KAAK6L,oBAAoBlH,iBAE3C+G,EAAY1L,KAAK6L,oBAAoBC,cAAe,OAAO,SACzC,IAAMjM,KAAK2H,KAAKmE,EAAUC,GAAmBD,IAC3C3L,KAAK6L,oBAAoBE,gBA2BtC,SAASC,EACtBzI,EACAsI,iBACiB,mBACA,gBACA,aAGVlK,OAAOa,OAAOe,EAAG0H,GAAoBY,oBAAAA,IClF9C,MAAMI,mBAMGxI,OAAOyI,WAAapL,MAAMQ,KAC7BR,MAAMd,KAAKyD,OAAO0I,WAClB,IAAM,IAAItB,EACR7K,KAAKyD,OAAOtD,eACZH,KAAKyD,OAAO7C,gBACZZ,KAAKyD,OAAOqE,sBAGXrE,OAAO2I,cAAgBtL,MAAMd,KAAKyD,OAAO0I,WAAWpL,KAAK,QACzDsL,KAAO,IAAIvL,MAAMd,KAAKyD,OAAO0I,WAAWpL,KAAK,eAQzCP,OACL8L,EAAa,MACZ,IAAI/G,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzC8G,KAAK9G,GAAKvF,KAAKuM,oBAAoB/L,EAAa+E,MACvCvF,KAAKqM,KAAK9G,OAErB,IAAIA,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzC8G,KAAK9G,IAAM+G,SAGXA,uBAUW9L,EAAagM,MAC3BA,GAAoBxM,KAAKyD,OAAO0I,gBAC5B,IAAIpM,MAAM,uEAEXC,KAAKyD,OAAO2I,cAAcI,GAC7BxM,KAAKyD,OAAOyI,WAAWM,GAAkBF,WAAW9L,oCAQnDiD,OAAOyI,WAAWhK,QAASqD,MAC5BoE,qCAGGlG,OAAOyI,WAAWhK,QAASqD,MAC5BoE,4BAEJ,MAAOM,SACD,IAAIlK,MAAM,2FASd0M,EAAY,MACX,IAAIlH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,KACjCvF,KAAKyD,OAAO2I,cAAc7G,MAErCkH,EAAY,MACT,IAAIlH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAO2I,cAAc7G,IAAMkH,WAG7B,IAAIlH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAO2I,cAAc7G,GAAK,EAAIvF,KAAKyD,OAAO0I,6BAU9C1I,OAAOyI,WAAWhK,QAASqD,MAC5BmH,WAAW1M,KAAK2M,2BAUlBC,cASO9C,OAGL+C,OAFCC,QAAQC,aAAejM,MAAMd,KAAKyD,OAAO7C,iBAAiBG,KAAK,QAC/D+L,QAAQtC,iBAAmB1J,MAAqC,SAA/Bd,KAAKyD,OAAOqE,eAA4B9H,KAAKyD,OAAO7C,iBAAmB,EAAIZ,KAAKyD,OAAO7C,iBAAiBG,KAAK,OAG9I,IAAIwE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,EAAG,GAC/BvF,KAAKyD,OAAOyI,WAAW3G,GAAGyH,WAAWlD,OAClD,IAAI9I,EAAI,EAAGA,EAAIhB,KAAKyD,OAAO7C,gBAAiBI,GAAK,UAC/C8L,QAAQC,aAAa/L,IAAMhB,KAAKqM,KAAK9G,GAAKsH,EAAgB7L,GAC5B,SAA/BhB,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKrK,KAAKyD,OAAO7C,gBAAiByJ,GAAM,OAClDyC,QAAQtC,iBAAkBxJ,EAAIhB,KAAKyD,OAAO7C,gBAAmByJ,IAC/DrK,KAAKqM,KAAK9G,IAAM,EACjBvF,KAAKyD,OAAOyI,WAAW3G,GAAGiF,iBAAkBxJ,EAAIhB,KAAKyD,OAAO7C,gBAAmByJ,aAG9EyC,QAAQtC,iBAAiBxJ,IAC3BhB,KAAKqM,KAAK9G,IAAM,EAAKvF,KAAKyD,OAAOyI,WAAW3G,GAAGiF,iBAAiBxJ,UAIlEhB,KAAK8M,QAAQC,eAiBT,SAASE,EAAY1J,OAC7BD,EAAYC,SACT,IAAIxD,MAAM,sGAEX4B,OAAOa,OACZe,EACA0I,EACA1I,EAAEE,OAAOvD,QAAU0M,MC9JvB,MAAMM,gBAKSjJ,QACN+G,gBACAmC,wBAAwBlJ,EAAYmJ,0BACpCC,oBAAoBpJ,QACpBqJ,gBAAgBrJ,QAChByI,kBACAa,oDAQiBC,OAClBC,EAAa,OACZd,sBAAwBa,EAAW3K,IAAI6K,GAAO7N,KAAK4B,IACtDzB,KAAKyD,OAAOgF,eAAekF,SAC3B3N,KAAKyD,OAAOgF,eAAemF,SAAWF,QAEnC,IAAInI,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,EACX,SAA/BvF,KAAKyD,OAAOqE,oBACTrE,OAAOyI,WAAW3G,GAAGwC,WAAajH,MAAMd,KAAKyD,OAAOxD,WAAa,GACnEc,KAAKf,KAAKyD,OAAOgF,eAAekF,SAAW,QAEzClK,OAAOyI,WAAW3G,GAAGwC,WAAajH,MAAMd,KAAKyD,OAAOxD,WAAWc,KAAK,QAEtE0C,OAAOyI,WAAW3G,GAAGmH,WAAW1M,KAAK2M,4BACrClJ,OAAO2I,cAAc7G,GAAK,EAAIvF,KAAKyD,OAAO0I,aACjCnM,KAAKyD,OAAO2I,cAAc7G,OAErC,IAAIA,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAO2I,cAAc7G,IAAMkI,uBAYhBxJ,OACbA,GAAeA,EAAYC,QAAS,aASnC2J,EARS1H,EACb9C,kBACkBrD,KAAKyD,OAAOtD,+BACXH,KAAKyD,OAAO7C,kBAE/BZ,KAAKyD,OAAO0I,WACV7H,eAAgB,SAEQwJ,MAAM7J,OAC7B,IAAIsB,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAOyI,WAAW3G,GAAG1E,KAAOgN,EAAa1J,QAAQoB,oBAU1CtB,OAGTA,GAAeA,EAAYC,QAAS,WAEpC,IAAIqD,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO0I,UAAW5E,GAAK,OACzC9D,OAAOyI,WAAW3E,GAAGQ,WAAajH,MAAsC,SAA/Bd,KAAKyD,OAAOqE,eAA6B9H,KAAKyD,OAAOxD,WAAa,EAAID,KAAKyD,OAAOxD,WAAWc,KAAK,SAG5IgN,EAASjN,MAAMd,KAAKyD,OAAO0I,UAAYnM,KAAKyD,OAAOxD,WAAWc,KAAK,GACnEiN,EAASlN,MAAMd,KAAKyD,OAAO0I,WAAWpL,KAAK,KACrCmB,QAASE,UACbiD,EAAOxF,KAAKC,MAAMsC,EAAO/B,OAASL,KAAKyD,OAAO0I,eAChD7G,EAAS,MACR,IAAIiC,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO0I,UAAW5E,GAAK,EAAG,KAC5C,IAAItG,EAAI,EAAGA,EAAIoE,EAAMpE,GAAK,MACxB,IAAImJ,EAAK,EAAGA,EAAKpK,KAAKyD,OAAOxD,UAAWmK,GAAM,OACzC7C,EAAIvH,KAAKyD,OAAOxD,UAAamK,IAAOhI,EAAOlB,IAAIoE,EAASrE,EAAGmJ,GAChC,SAA/BpK,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKrK,KAAKyD,OAAOxD,UAAWoK,GAAM,OAC5C5G,OAAOyI,WAAW3E,GACpBQ,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,IAC3CjI,EAAOlB,IAAIoE,EAASrE,EAAGmJ,GAAMhI,EAAOlB,IAAIoE,EAASrE,EAAGoJ,aAGnD5G,OAAOyI,WAAW3E,GAAGQ,WAAWqC,IACnChI,EAAOlB,IAAIoE,EAASrE,EAAGmJ,IAAO,KAI5B/E,IACHkC,IAAMlC,SAIZ,IAAIkC,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO0I,UAAW5E,GAAK,MACzC,IAAI6C,EAAK,EAAGA,EAAKpK,KAAKyD,OAAOxD,UAAWmK,GAAM,OACzC7C,EAAIvH,KAAKyD,OAAOxD,UAAamK,IAAO4D,EAAOzG,GAChB,SAA/BvH,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKrK,KAAKyD,OAAOxD,UAAWoK,GAAM,OAC5C5G,OAAOyI,WAAW3E,GAAGQ,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,IAAO2D,EAAOzG,aAG/E9D,OAAOyI,WAAW3E,GAAGQ,WAAWqC,IAAO4D,EAAOzG,OAKpD,IAAIA,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO0I,UAAW5E,GAAK,MACzC,IAAI6C,EAAK,EAAGA,EAAKpK,KAAKyD,OAAOxD,UAAWmK,GAAM,KACd,SAA/BpK,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKrK,KAAKyD,OAAOxD,UAAWoK,GAAM,OAC5C5G,OAAOyI,WAAW3E,GAAGQ,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,IAClE0D,EAAQxG,EAAIvH,KAAKyD,OAAOxD,UAAamK,GACrC2D,EAAQxG,EAAIvH,KAAKyD,OAAOxD,UAAaoK,aAGpC5G,OAAOyI,WAAW3E,GAAGQ,WAAWqC,IACnC2D,EAAQxG,EAAIvH,KAAKyD,OAAOxD,UAAamK,IAAO,kBAUvCnG,OACT0H,EAAU,EACVvI,EAAc,IACNlB,QAASE,OACJA,EAAO/B,eAElB4N,EAAgBtM,OAAOC,KAAKqC,EAAYpC,SAExCQ,EAAIvB,MAAMQ,KACdR,MAAMd,KAAKyD,OAAO0I,WAClB,IAAM,IAAIrL,MAAMsC,GAAarC,KAAK,IAE9BmN,EAAIpN,MAAMd,KAAKyD,OAAO0I,WAAWpL,KAAK,OACxCoN,EAAQ,IAEAjM,QAASE,QACd,IAAInB,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,EAAG,KACrCwL,EAAY,MACX,IAAIlH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,IAC5CA,GAAG4I,EAAQlN,GAAKjB,KAAKuM,oBAAoBnK,EAAOyD,SAAS5E,GAAIsE,IAEvC,IAApBlD,EAAEkD,GAAG4I,EAAQlN,IACfsH,OAAOC,MAAMnG,EAAEkD,GAAG4I,EAAQlN,KAC1BoB,EAAEkD,GAAG4I,EAAQlN,KAAQO,EAAAA,OACnB+D,GAAG4I,EAAQlN,GAAK,WAEPoB,EAAEkD,GAAG4I,EAAQlN,OAEvB,IAAIsE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,IAC5CA,GAAG4I,EAAQlN,IAAMwL,IACjBlH,IAAMlD,EAAEkD,GAAG4I,EAAQlN,MAEZpB,KAAKuO,IAAI3B,MAEbrK,EAAO/B,aAIb,IAAIkF,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAO2I,cAAc7G,GAAK2I,EAAE3I,GAAKnC,MAInC,IAAImC,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,MACzC,IAAIvE,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,EAAG,MAC5CyC,OAAOyI,WAAW3G,GAAG1E,KAAKG,GAAK,IAC5B,MACH,IAAIqN,EAAM,EAAGA,EAAMJ,EAAc5N,OAAQgO,GAAO,EAAG,OAChDjM,EAAS6B,EAAYpC,QAAQoM,EAAcI,QAC5C,IAAIpN,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,OACjCwC,OAAOyI,WAAW3G,GAAG1E,KAAKG,IAC7BqB,EAAEkD,GAAG4I,EAAQlN,GAAKmB,EAAOlB,IAAID,EAAGD,MAE3BoB,EAAO/B,YAEboD,OAAOyI,WAAW3G,GAAG1E,KAAKG,IAAMkN,EAAE3I,MAKR,SAA/BvF,KAAKyD,OAAOqE,mBACT,IAAIvC,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,MACzC,IAAI6E,EAAK,EAAGA,EAAKpK,KAAKyD,OAAOxD,UAAWmK,GAAM,MAC5C,IAAIC,EAAKD,EAAIC,EAAKrK,KAAKyD,OAAOxD,UAAWoK,GAAM,EAAG,MAChD5G,OAAOyI,WAAW3G,GAAGwC,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,GAAM,IAClE,MACH,IAAIgE,EAAM,EAAGA,EAAMJ,EAAc5N,OAAQgO,GAAO,EAAG,OAChDjM,EAAS6B,EAAYpC,QAAQoM,EAAcI,QAC5C,IAAIpN,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,OACjCwC,OAAOyI,WAAW3G,GAAGwC,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,IAClEhI,EAAEkD,GAAG4I,EAAQlN,IACZmB,EAAOlB,IAAID,EAAGmJ,GAAMpK,KAAKyD,OAAOyI,WAAW3G,GAAG1E,KAAKuJ,KACnDhI,EAAOlB,IAAID,EAAGoJ,GAAMrK,KAAKyD,OAAOyI,WAAW3G,GAAG1E,KAAKwJ,OAE/CjI,EAAO/B,YAEboD,OAAOyI,WAAW3G,GAAGwC,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,IAAO6D,EAAE3I,GACzE6E,IAAOC,SACJ5G,OAAOyI,WAAW3G,GAAGwC,WAAYsC,EAAKrK,KAAKyD,OAAOxD,UAAamK,GAClEpK,KAAKyD,OAAOyI,WAAW3G,GAAGwC,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,aAMzE,IAAI9E,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,MACzC,IAAI6E,EAAK,EAAGA,EAAKpK,KAAKyD,OAAOxD,UAAWmK,GAAM,EAAG,MAC/C3G,OAAOyI,WAAW3G,GAAGwC,WAAWqC,GAAM,IACnC,MACH,IAAIiE,EAAM,EAAGA,EAAMJ,EAAc5N,OAAQgO,GAAO,EAAG,OAChDjM,EAAS6B,EAAYpC,QAAQoM,EAAcI,QAC5C,IAAIpN,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,EAAG,OACnCqN,EAASlM,EAAOlB,IAAID,EAAGmJ,GAAMpK,KAAKyD,OAAOyI,WAAW3G,GAAG1E,KAAKuJ,QAC7D3G,OAAOyI,WAAW3G,GAAGwC,WAAWqC,IAC/B/H,EAAEkD,GAAG4I,EAAQlN,GAAKqN,EAAQA,KAEzBlM,EAAO/B,YAEboD,OAAOyI,WAAW3G,GAAGwC,WAAWqC,IAAO8D,EAAE3I,eAK/CmH,kBACAa,2BAEE5B,0BCtPX,MAAM4C,iBAMK5M,OAAOC,KAAK5B,KAAKwO,QAAQnO,iBAQzB8B,UACAR,OAAOC,KAAK5B,KAAKwO,QAAQzM,SAASI,WAOpCA,GACDnC,KAAK+B,SAASI,WACTnC,KAAKwO,OAAOrM,KAYV,SAASsM,SAAoBtO,iBAAAS,qBAGvC8N,mDAEI/M,OAAOa,OACZa,KAAYlD,eAAAA,EAAgBS,gBAAAA,GAAoB8N,IAChDH,GC1CW,SAASI,EACtBpL,EACAqL,UAEOjN,OAAOa,OACZe,SAaQU,EAAa4K,OACZ5K,GAAeA,EAAYC,cACxB,IAAInE,MAAM,oCAEd8O,KACK3M,QAAS+C,QACTjF,KAAK+B,SAASkD,SACX,IAAIlF,uBAAuBkF,2BAKlCxB,OAAOqL,YACCD,GAAU5K,EAAY4K,UAC9B3M,QAASC,UACNa,EAAKiB,EAAY8K,kBAAkB5M,QAEpCsB,OAAOqL,QAAQ3M,GAASyM,EAAiB5L,KAEzChD,KAAKyD,UCpCpB,MAAMuL,gBAKG3O,OAAS,OACTV,MAAQ,OACRsP,MAAO,OACPC,gBAOFZ,GACCtO,KAAKiP,WACFC,OAAOlP,KAAKL,OAAS2O,OACrB3O,OAASK,KAAKL,MAAQ,GAAKK,KAAKmP,gBAEhCD,OAAOzO,KAAK6N,QACZjO,QAAU,OACV4O,KAAQjP,KAAKK,SAAWL,KAAKmP,eASlCC,UACKpP,KAAKkP,QAAQE,EAAMpP,KAAKL,OAASK,KAAKmP,gBAO1Cb,QACEjO,OAASL,KAAKmP,cACdxP,MAAQ,OACRsP,MAAO,OACPC,OAASpO,MAAMd,KAAKmP,UAAUpO,KAAKuN,YAQlCrM,OACD,IAAIW,EAAI,EAAGA,EAAI5C,KAAKK,OAAQuC,GAAK,IAC3B5C,KAAKkP,QAAQtM,EAAI5C,KAAKL,OAASK,KAAKmP,UAAWvM,oBASnD5C,KAAKkP,OAAOxO,MAAMV,KAAKL,OAC3BY,OAAOP,KAAKkP,OAAOxO,MAAM,EAAGV,KAAKL,UAczB,SAAS0P,EAAeF,SAC/BD,EAASvN,OAAOc,OAAOuM,YACtBG,SAAWA,IACXG,QACAJ,ECjFT,MAAMK,EAA0BrP,sBAMZmP,EAAe,uBAMbG,QACbC,iBAAmBD,OACnBE,iBAAmBL,EAAeG,wBAQlCE,iBAAiBJ,QACftP,cAUDQ,SACA8L,EAAatM,KAAKsM,WAAW9L,UAC/BN,QACG8M,WAAWxM,QAEbmP,cAAcrD,GACZtM,KAAK8M,uBAQA8C,QACP9C,QAAQ8C,kBAAoBA,OAC5BF,iBAAiBjP,KAAKZ,KAAKuO,IAAIwB,SAC/B9C,QAAQ3B,cAAgB,QACvB0E,EAAU7P,KAAK0P,iBAAiBrP,WACjC,IAAIuC,EAAI,EAAGA,EAAIiN,EAASjN,GAAK,OAC3BkK,QAAQ3B,eAAiBnL,KAAK0P,iBAAiBxO,IAAI0B,QAErDkK,QAAQ3B,eAAiB0E,KAUnB,SAASC,EAAsBvM,EAAGkM,EAAmB,OAC7DnM,EAAYC,SACT,IAAIxD,MAAM,qGAEZ+M,EAAUnL,OAAOa,QACnBoN,kBAAmB,EAAGzE,cAAe,GACvC5H,EAAEE,OAAOvD,SAAY6M,gBAAkBvC,gCAElC7I,OAAOa,OACZe,EACAgM,EAAwBhM,EAAEE,OAAOvD,UAC/B4M,QAAAA,EAAS4C,iBAAkBL,EAAeI,KCSjC,SAASM,EAAmB1J,EAAO2J,EAAeC,SACzDvB,EAAa/M,OAAOa,UAAWyN,iBAC9BrO,KAAKoO,GAAe9N,QAASgO,UAC5BC,EAAOH,EAAcE,MAGvBC,EAAKC,WAAazO,OAAOC,KAAKqO,GAAQlO,SAASmO,SAC3C,IAAInQ,2BAA2BmQ,6BAAgC7J,QAzF3E,SAAmBA,EAAOgK,EAAWL,EAAe1B,MAC7C0B,MACDA,EAAcM,cAAgBxP,QAAUkP,EAAcjO,SAASuM,SAC3D,IAAIvO,oBAAoBsQ,eAAuB/B,iCAAqCjI,iBAAqB2J,QAC1G,GAAIA,EAAcM,cAAgB3O,OAAQ,IAC3CA,OAAOC,KAAKoO,GAAejO,SAAS,QAAUuM,EAAQ0B,EAAczO,UAChE,IAAIxB,oBAAoBsQ,cAAsB/B,mDAAuD0B,EAAczO,kBAAkB8E,UAEzI1E,OAAOC,KAAKoO,GAAejO,SAAS,QAAUuM,EAAQ0B,EAAcvO,UAChE,IAAI1B,oBAAoBsQ,cAAsB/B,mDAAuD0B,EAAczO,kBAAkB8E,YAExI,GAA6B,mBAAlB2J,IACXA,EAAc1B,SACX,IAAIvO,oBAAoBsQ,cAAsB/B,kCAAsCjI,SAgFlFA,EAAO6J,EAAMC,EAAKI,MAAON,EAAOC,MAE/BA,GAAQC,EAAKK,UACtBL,EAAKK,UAAUP,EAAOC,IACtBD,EAAOC,KAEJxB,EC5GT,MAAM+B,EAAmBtE,0BAEX,SACD5K,IAAK,8BAGJ,QACH,EAAGoM,SAAAA,EAAUC,SAAAA,KACjBD,GAAYC,GAAYD,EAAW,GAAKC,EAAW,6BAG5C,SACF,OAAQ,sCAGN,QACH8C,GAAKA,EAAErQ,SAAW8L,yBAGf,QACH5G,GAAKA,EAAElF,SAAW8L,KChB7B,MAAMwE,gCAMK3Q,KAAKyP,sCAOMD,QACbC,iBAAmBD,SACjB5N,KAAK5B,KAAKwO,QAAQtM,QAASC,SAC3BqM,OAAOrM,GAAOyO,oBAAoBpB,qBASlCS,OAAOjQ,KAAKwO,QAAQtM,QAAQwO,GAAKA,EAAEG,cACrC/D,qIAMQ,iBAGT9M,KAAKyD,OAAOvD,cACT4Q,wBAQDtQ,UACCyP,OAAOjQ,KAAKwO,QAAQtM,QAAQwO,GAAKA,EAAEK,QAAQvQ,SAC7CmP,uCAICqB,EAAOrP,OAAOC,KAAK5B,KAAKwO,QAAQyC,YACjCnE,QAAQ+B,OAASmC,MAClBE,EAAc,EACdC,EAAe,EACfC,GAAoB5P,EAAAA,OACnBsL,QAAQgC,QAAUkC,EACpBnO,IAAI,CAACwO,EAAKzO,UACJkK,QAAQwE,mBAAmB1O,GAC9B5C,KAAKwO,OAAO6C,GAAKvE,QAAQ8C,uBACtB9C,QAAQyE,uBAAuB3O,GAClC5C,KAAKwO,OAAO6C,GAAKvE,QAAQ3B,mBACtB2B,QAAQ0E,oBAAoB5O,GAC/B/C,KAAKwI,IAAIrI,KAAK8M,QAAQyE,uBAAuB3O,OAChC5C,KAAK8M,QAAQwE,mBAAmB1O,MAC/B5C,KAAK8M,QAAQ0E,oBAAoB5O,GAC7C5C,KAAK8M,QAAQyE,uBAAuB3O,GAAKwO,MACxBpR,KAAK8M,QAAQyE,uBAAuB3O,QAClDkK,QAAQ2E,UAAYJ,IAElBK,CAACL,GAAMrR,KAAKwO,OAAO6C,GAAKvE,WAElChK,OAAO,CAACS,EAAGR,SAAYQ,EAAMR,YAC3B+J,QAAQ6E,8BACX3R,KAAK8M,QAAQ0E,oBAAoB3O,IAAIE,GAAKA,EAAIoO,QAC3CrE,QAAQ8E,6BACX5R,KAAK8M,QAAQwE,mBAAmBzO,IAAIE,GAAKA,EAAImO,GAC3ClR,KAAKyD,OAAOvD,cACT2R,4BAKLC,uBAEGhF,QAAQC,qBACRD,QAAQtC,kDAIqC,cAA9CxK,KAAKyD,OAAOsO,mCACTjF,QAAQC,aACX/M,KAAKwO,OAAOxO,KAAK8M,QAAQ2E,WAAW3E,QAAQC,kBACzCD,QAAQtC,iBACXxK,KAAKwO,OAAOxO,KAAK8M,QAAQ2E,WAAW3E,QAAQtC,qBACzC,CAAA,GAAkD,YAA9CxK,KAAKyD,OAAOsO,oCAcf,IAAIhS,MAAM,mEAbX+M,QAAQC,aAAejM,MAAMd,KAAKY,iBAAiBG,KAAK,QACxD+L,QAAQtC,iBAAmB1J,MAAMd,KAAKY,kBAA0D,SAAtCZ,KAAKgS,cAAclK,eAA4B,EAAI,IAAI/G,KAAK,QACtH+L,QAAQ+B,OAAO3M,QAASmP,SACtBvE,QAAQC,aAAalK,IAAI,CAACE,EAAGH,IAAMG,EACtC/C,KAAK8M,QAAQ6E,8BAA8B/O,GAC3C5C,KAAKwO,OAAO6C,GAAKvE,QAAQC,aAAanK,SAEnCkK,QAAQtC,iBAAiB3H,IAAI,CAACE,EAAGH,IAAMG,EAC1C/C,KAAK8M,QAAQ6E,8BAA8B/O,GAC3C5C,KAAKwO,OAAO6C,GAAKvE,QAAQtC,iBAAiB5H,SAoBrC,SAASqP,EAAyB1O,EAAGwO,EAAgC,iBAC7EzO,EAAYC,SACT,IAAIxD,MAAM,qGAEZ2Q,EAAI/O,OAAOa,OACfe,EACAoN,EACApN,EAAEE,OAAOvD,QAAU4R,eAEnBrO,OAAOsO,8BAAgCA,EAClCrB,EC1GF,SAASwB,EACdjO,EACA+N,EACAnG,SAEM1L,eAAEA,EAAFS,gBAAkBA,GAAoBqD,GACtCkI,UAAEA,EAAF1D,eAAaA,EAAbX,eAA6BA,GAAmBkK,SRwOzC,SACbzO,EACA4I,EAAY,EACZ1D,GAAmBkF,SAAU,KAAMC,SAAU,KAC7C9F,EAAiB,YAEZnG,OAAOC,KAAK2B,GAAGxB,SAAS,gBACrB,IAAIhC,MAAM,sGAEX4B,OAAOa,OACZe,EACA2J,eAGO3J,EAAEE,0DQrPG0O,CACZnG,EACEiB,EAAY5J,yCAGP2O,KAELnG,GAEFM,EACA1D,EACAX,GAEWgG,MAAM7J,GAiCd,SAASmO,EACd3O,EACAgM,SAEMpJ,EFtDO,SAA2B9C,OACnCD,EAAYC,SACT,IAAIxD,MAAM,wGAEC,MAAO0Q,EAAiBlN,EAAEE,OAAO0I,WAAY5I,EAAEE,QAC3D9B,OAAOa,OACZe,GACE8I,KAAM,IAAIvL,MAAMyC,EAAEE,OAAO0I,WAAWpL,KAAK,KE+C/BsR,CAAkBvC,EAC9B7C,EAAY5J,EAAUI,IACtBgM,aAEKvD,WAAWhK,QAAQ,CAACqD,EAAG3C,OACtBa,OAAOyI,WAAWtJ,GAAKjB,OAAOa,OAAOqI,EACzCpH,EAAOtD,eACPsD,EAAO7C,gBACP6C,EAAOqE,gBACNvC,OAECsL,QACCxK,EC7FT,MAAMiM,uBAMgB,kBAQJ,6BAOW9R,OACrBiM,EAAY,KACmB,YAA/BzM,KAAKyD,OAAO8O,mBACT,IAAI3P,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,OACtC6P,MAAM7P,GAAK5C,KAAKyD,OAAOiP,MAAM9P,GAChC5C,KAAKyD,OAAOkP,QAAQ/P,GAAG0J,WAAW9L,MACvBR,KAAKyS,MAAM7P,aAGrB6P,MAAQ,IAAI3R,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,QAC3C0R,MAAM,GAAKzS,KAAKyD,OAAOkP,QAAQ,GAAGrG,WAAW9L,MACrCR,KAAKyS,MAAM,WAErBG,oBAAqB,EACtBnG,EAAY,EAAG,KACZ,IAAI7J,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,OACtC6P,MAAM7P,IAAM6J,SAEZ,EAAIA,MAER,IAAI7F,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,OACtC6L,MAAM7L,GAAK,EAAI5G,KAAKyD,OAAO+O,cAE3B,0BAQchS,OACjBiM,EAAY,OACXoG,cAAgB7S,KAAKyS,MAAM/R,YAC3B,IAAIkG,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,EAAG,SACzC6L,MAAM7L,GAAK,EACmB,YAA/B5G,KAAKyD,OAAO8O,mBACT,IAAI3P,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,OACtC6P,MAAM7L,IAAM5G,KAAK6S,cAAcjQ,GAClC5C,KAAKyD,OAAOqP,WAAWlQ,GAAGgE,aAGzB6L,MAAM7L,IAAM5G,KAAK6S,cAAcjM,GAAK5G,KAAKyD,OAAOqP,WAAe,EAAJlM,GAC5DA,EAAI,OACD6L,MAAM7L,IAAM5G,KAAK6S,cAAcjM,EAAI,GACtC5G,KAAKyD,OAAOqP,WAAsB,GAATlM,EAAI,GAAU,QAEpC6L,MAAM,IAAMzS,KAAK6S,cAAc7S,KAAKyD,OAAO+O,OAAS,GACvDxS,KAAKyD,OAAOqP,WAAiC,EAArB9S,KAAKyD,OAAO+O,OAAc,QAGnDC,MAAM7L,IAAM5G,KAAKyD,OAAOkP,QAAQ/L,GAAG0F,WAAW9L,MACtCR,KAAKyS,MAAM7L,MAEtB6F,EAAY,OAAQ,KACjB,IAAI7F,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,OACtC6L,MAAM7L,IAAM6F,SAEZ,EAAIA,SAEN,IAiBI,SAASsG,EAAYxP,OAC7BD,EAAYC,SACT,IAAIxD,MAAM,sGAEX4B,OAAOa,OAAOe,EAAG+O,GC5G1B,MAOMU,gBAKS/O,GACNA,IAAeA,EAAYC,eAE3B8G,SAAS/G,QACTkJ,wBAAwBlJ,EAAYmJ,qBACrCpN,KAAKyD,OAAO0I,UAAY,OACrB8G,8BAA8BhP,SAE9BiP,wBAAwBjP,QACxBkP,6BAA6BlP,eAS7BA,SACD9D,iBAAAS,kBAAAuL,YAAA1D,iBAAAX,kBAMF9H,KAAKyD,YACJA,OAAOkP,QAAU7R,MAAMQ,KAC1B,IAAIR,MAAMd,KAAKyD,OAAO+O,QACtB,IAAMvF,EAAY5J,6FAQfI,OAAOkP,QAAQzQ,QAAQkR,GAAKA,EAAEpI,iBAC9ByH,MAAQ,IAAI3R,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,QAC3C8R,cAAgB,IAAI/R,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,QACnDsL,KAAO,IAAIvL,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,QAC1CsS,aAAe,IAAIvS,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,SAIjDuS,EAAYrP,EAAYsP,YACzBC,cAAgB,IAAI1S,MAAMwS,GAAWvS,KAAK,WAC1C0S,gBAAkB,IAAI3S,MAAMwS,GAAWvS,KAAK,WAC5C2S,wBAA0B,IAAI5S,MAAMwS,GAAWvS,KAAK,UAErD6B,EAAI,IACIV,QAASE,UACbuR,EAAIvR,EAAO/B,YACZmT,cAAc5Q,GAAK9B,MAAMQ,KAC5B,IAAIR,MAAM6S,GACV,IAAM,IAAI7S,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,IAER,YAA/Bf,KAAKyD,OAAO8O,oBACTkB,gBAAgB7Q,GAAK9B,MAAMQ,KAC9B,IAAIR,MAAM6S,GACV,IAAM7S,MAAMQ,KACV,IAAIR,MAAMd,KAAKyD,OAAO+O,QACtB,IAAM,IAAI1R,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,UAIxC0S,gBAAgB7Q,GAAK9B,MAAMQ,KAC9B,IAAIR,MAAM6S,GACV,IAAM,IAAI7S,MAA2B,EAArBd,KAAKyD,OAAO+O,QAAYzR,KAAK,SAG5C2S,wBAAwB9Q,GAC3B,IAAI9B,MAAMd,KAAKyD,OAAO0I,WAAWpL,KAAK,OACnC,IAAIwE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzCmO,wBAAwB9Q,GAAG2C,GAC9BzE,MAAMQ,KACJ,IAAIR,MAAM6S,GACV,IAAM,IAAI7S,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,OAM1C,SAGF6S,SAAW,IAAI9S,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,QAC9C8S,mBAAqB,IAAI/S,MAAMd,KAAKyD,OAAO+O,OAASxS,KAAKyD,OAAO0I,WAAWpL,KAAK,mBAOxEkD,OACT0H,EAAU,EAIV7J,EAAc,IACNI,QAASE,IACfA,EAAO/B,OAAS,OACPL,KAAK8T,yBAAyB1R,EAAQN,OAEpC,SAEZiS,kBAAkB9P,OAMlB,IAAIrB,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,MACtC,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAOkP,QAAQ/P,GAAGa,OAAO2I,cAAc7G,GAAK,EACd,SAA/BvF,KAAKyD,OAAOqE,oBACTrE,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GAAGwC,WAC1C,IAAIjH,MAAMd,KAAKyD,OAAOxD,WAAa,GAAGc,KAAK,QAExC0C,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GAAGwC,WAC1C,IAAIjH,MAAMd,KAAKyD,OAAOxD,WAAWc,KAAK,eAKzCiT,qCAAqC/P,QACrCgQ,uBAAuBhQ,QACvBiQ,6BAA6BjQ,GACC,YAA/BjE,KAAKyD,OAAO8O,qBACT4B,uBAAuBlQ,QAEzBmQ,6BAA6BnQ,GAC3B0H,4BAQF0I,4BACAb,cAAgB,UAChBC,gBAAkB,UAClBC,wBAA0B,UAC1BY,SAAW,UACXC,QAAU,UACVX,SAAW,UACXC,mBAAqB,UACrBpQ,OAAOkP,QAAU3S,KAAKyD,OAAOkP,QAAQ9P,IAAIuQ,GAAKA,EAAE3P,iCAQ/B+J,GACa,YAA/BxN,KAAKyD,OAAO8O,oBACTiC,kBAEAC,qBAED9H,EAAwBa,EAAW3K,IAAI6K,GAAO7N,KAAK4B,IACvDzB,KAAKyD,OAAOgF,eAAekF,SAC3B3N,KAAKyD,OAAOgF,eAAemF,SAAWF,IAElCgH,EAAiD,SAA/B1U,KAAKyD,OAAOqE,eAClC,IAAM,IAAIhH,MAAMd,KAAKyD,OAAOxD,WAAa,GACtCc,KAAKf,KAAKyD,OAAOgF,eAAekF,SAAW,GAC9C,IAAM,IAAI7M,MAAMd,KAAKyD,OAAOxD,WACzBc,KAAK,OACL,IAAI6B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,EAAG,OAExCwQ,EAAIpT,KAAKyD,OAAOkP,QAAQ/P,KAC5B+J,sBAAwBA,MACrB,IAAIpH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,IAC5C9B,OAAOyI,WAAW3G,GAAGwC,WAAa2M,MAClCjR,OAAOyI,WAAW3G,GAAGmH,WAAWC,KAChClJ,OAAO2I,cAAc7G,GAAK,EAAIvF,KAAKyD,OAAO0I,oCAW1BlI,OACjBA,GAAeA,EAAYC,QAAS,WAEpC,IAAIqD,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO+O,OAAQjL,GAAK,MACtC,IAAIvG,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW,GAAGrL,KAAKG,GAAK,QAIpDgN,EAAS,IAAIlN,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,KACtCmB,QAASE,UACbiD,EAAOxF,KAAKC,MAAMsC,EAAO/B,OAASL,KAAKyD,OAAO+O,YAChDlN,EAAS,MACR,IAAIiC,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO+O,OAAQjL,GAAK,EAAG,KACzC,IAAItG,EAAI,EAAGA,EAAIoE,EAAMpE,GAAK,MACxB,IAAID,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW,GAAGrL,KAAKG,IAC/CoB,EAAOlB,IAAIoE,EAASrE,EAAGD,MAGnBqE,IACHkC,IAAMlC,SAGZ,IAAIkC,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO+O,OAAQjL,GAAK,MACtC,IAAIvG,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW,GAAGrL,KAAKG,IAAMgN,EAAOzG,iCAWvCtD,OACtBA,GAAeA,EAAYC,QAAS,WAEpC,IAAIqD,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO+O,OAAQjL,GAAK,OACtC9D,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW,GAAGnE,WAC1C,IAAIjH,MAAMd,KAAKyD,OAAOxD,YAA6C,SAA/BD,KAAKyD,OAAOqE,eAA4B,EAAI,IAAI/G,KAAK,SAGvFiN,EAAS,IAAIlN,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,GAC5C4T,EAAa,IAAI7T,MAAMd,KAAKyD,OAAO+O,OAASxS,KAAKyD,OAAOxD,WAC3Dc,KAAK,KACImB,QAASE,UACbiD,EAAOxF,KAAKC,MAAMsC,EAAO/B,OAASL,KAAKyD,OAAO+O,YAChDlN,EAAS,MACR,IAAIiC,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO+O,OAAQjL,GAAK,EAAG,KACzC,IAAItG,EAAI,EAAGA,EAAIoE,EAAMpE,GAAK,MACxB,IAAImJ,EAAK,EAAGA,EAAKpK,KAAKyD,OAAOxD,UAAWmK,GAAM,OACpC7C,EAAIvH,KAAKyD,OAAOxD,UAAcmK,IACvChI,EAAOlB,IAAIoE,EAASrE,EAAGmJ,GACQ,SAA/BpK,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKrK,KAAKyD,OAAOxD,UAAWoK,GAAM,OAC5C5G,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW,GACtCnE,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,IACzCjI,EAAOlB,IAAIoE,EAASrE,EAAGmJ,GACvBhI,EAAOlB,IAAIoE,EAASrE,EAAGoJ,aAGxB5G,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW,GAAGnE,WAAWqC,IACrDhI,EAAOlB,IAAIoE,EAASrE,EAAGmJ,IAAO,KAI5B/E,IACHkC,IAAMlC,SAIZ,IAAIkC,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO+O,OAAQjL,GAAK,MACtC,IAAI6C,EAAK,EAAGA,EAAKpK,KAAKyD,OAAOxD,UAAWmK,GAAM,OACrC7C,EAAIvH,KAAKyD,OAAOxD,UAAamK,IAAO4D,EAAOzG,GACpB,SAA/BvH,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKrK,KAAKyD,OAAOxD,UAAWoK,GAAM,OAC5C5G,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW,GACtCnE,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,IACzC2D,EAAOzG,aAGR9D,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW,GAAGnE,WAAWqC,IAAO4D,EAAOzG,OAKtE,IAAIA,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO+O,OAAQjL,GAAK,EAAG,KACzC,IAAI6C,EAAK,EAAGA,EAAKpK,KAAKyD,OAAOxD,UAAWmK,GAAM,KACd,SAA/BpK,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKrK,KAAKyD,OAAOxD,UAAWoK,GAAM,OAC5C5G,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW,GACtCnE,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,IACzCsK,EAAYpN,EAAIvH,KAAKyD,OAAOxD,UAAamK,GACzCuK,EAAYpN,EAAIvH,KAAKyD,OAAOxD,UAAaoK,aAG1C5G,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW,GAAGnE,WAAWqC,IACrDuK,EAAYpN,EAAIvH,KAAKyD,OAAOxD,UAAamK,GACzCuK,EAAYpN,EAAIvH,KAAKyD,OAAOxD,UAAamK,QAG1C3G,OAAOkP,QAAQpL,GAAGmF,kBAClBjJ,OAAOkP,QAAQpL,GAAGgG,2DAUGtJ,OACvB,IAAIsD,EAAI,EAAGA,EAAIvH,KAAKyD,OAAO+O,OAAQjL,GAAK,EAAG,OACxCvE,EAAKC,EAAYjD,KAAKyD,aAEhBvB,QAAQ,CAACE,EAAQN,WACrBuD,EAAOxF,KAAKC,MAAMsC,EAAO/B,OAASL,KAAKyD,OAAO+O,WAChDnN,EAAO,EAAG,GACT5E,KAAKqB,EAAaM,EAAOD,WACvB,IAAIlB,EAAIsG,EAAIlC,EAAMpE,GAAKsG,EAAI,GAAKlC,EAAMpE,GAAK,IAC3CkE,UAAUrD,GAAarB,KAAK2B,EAAOyD,SAAS5E,QAIhD+B,EAAGkB,QAAS,OACT0Q,EAAY1C,EAASlP,EAAIhD,KAAKyD,YAC/B,IAAI8B,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW3G,GAAG1E,KAC1C+T,EAAU1I,WAAW3G,GAAG1E,UACrB4C,OAAOkP,QAAQpL,GAAG9D,OAAOyI,WAAW3G,GAAGwC,WAC1C6M,EAAU1I,WAAW3G,GAAGwC,gBACrBtE,OAAOkP,QAAQpL,GAAGgG,iDAWvBlL,EAAI,EAAIrC,KAAKyD,OAAO+O,YACrB/O,OAAOiP,MAAQ,IAAI5R,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAKsB,QAClDoB,OAAOqP,WAAahS,MAAMQ,KAC7B,IAAIR,MAAMd,KAAKyD,OAAO+O,QACtB,IAAM,IAAI1R,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAKsB,yBAStCoB,OAAOiP,MAAQ,IAAI5R,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,QAClD0C,OAAOiP,MAAM,GAAK,OAClBjP,OAAOqP,WAAa,IAAIhS,MAA2B,EAArBd,KAAKyD,OAAO+O,QAAYzR,KAAK,SAC3D0C,OAAOqP,WAAsC,GAA1B9S,KAAKyD,OAAO+O,OAAS,IAAU,OAClD/O,OAAOqP,WAAuC,GAA1B9S,KAAKyD,OAAO+O,OAAS,GAAU,GAAK,6BAS1B,YAA/BxS,KAAKyD,OAAO8O,eAA8B,OACtCsC,EAAY7U,KAAKyD,OAAOiP,MAAM5P,OAAO,CAACY,EAAGC,IAAMD,EAAIC,EAAG,OACvD,IAAIf,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,EAAG,MACzCa,OAAOiP,MAAM9P,IAAMiS,MACpBC,EAAiB,MAChB,IAAIlO,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,KACzB5G,KAAKyD,OAAOqP,WAAWlQ,GAAGgE,OAEzC,IAAIA,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,OACtCnD,OAAOqP,WAAWlQ,GAAGgE,IAAMkO,YAI/B,IAAIlS,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,EAAG,OACxCkS,EAAiB9U,KAAKyD,OAAOqP,WAAe,EAAJlQ,GAAS5C,KAAKyD,OAAOqP,WAAgB,EAAJlQ,EAAS,QACnFa,OAAOqP,WAAe,EAAJlQ,IAAUkS,OAC5BrR,OAAOqP,WAAgB,EAAJlQ,EAAS,IAAMkS,gCAWjBC,OACrB,IAAInS,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,OACtCyJ,KAAKzJ,GAAKmS,2BAUKA,EAAIvU,QACrB6S,aAAerT,KAAKqM,KAAK3L,YACzB,IAAIkC,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,EAAG,SACzCyJ,KAAKzJ,GAAK,EACoB,YAA/B5C,KAAKyD,OAAO8O,mBACT,IAAI3L,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,OACtCyF,KAAKzJ,IAAM5C,KAAKyD,OAAOqP,WAAWlQ,GAAGgE,GACxC5G,KAAKqT,aAAazM,GAClB5G,KAAKyD,OAAOkP,QAAQ/L,GAAG0F,WAAW9L,aAGjC6L,KAAKzJ,IAAM5C,KAAKyD,OAAOqP,WAAe,EAAJlQ,GACrC5C,KAAKqT,aAAazQ,GAClB5C,KAAKyD,OAAOkP,QAAQ/P,GAAG0J,WAAW9L,GAChCoC,EAAI5C,KAAKyD,OAAO+O,OAAS,SACtBnG,KAAKzJ,IAAM5C,KAAKyD,OAAOqP,WAAgB,EAAJlQ,EAAS,GAC/C5C,KAAKqT,aAAazQ,EAAI,GACtB5C,KAAKyD,OAAOkP,QAAQ/P,EAAI,GAAG0J,WAAW9L,SAGvC6L,KAAKzJ,IAAMmS,GACZxM,OAAOC,MAAMxI,KAAKqM,KAAKzJ,KAAO/C,KAAK2H,IAAIxH,KAAKqM,KAAKzJ,MAASpB,EAAAA,UACvD6K,KAAKzJ,GAAK,gCAYEoS,OACjBvI,EAAY,OACXoG,cAAgB7S,KAAKyS,MAAM/R,YAC3B,IAAIkG,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,EAAG,SACzC6L,MAAM7L,GAAK,EACmB,YAA/B5G,KAAKyD,OAAO8O,mBACT,IAAI3P,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,OACtC6P,MAAM7L,IAAM5G,KAAK6S,cAAcjQ,GAClC5C,KAAKyD,OAAOqP,WAAWlQ,GAAGgE,aAGzB6L,MAAM7L,IAAM5G,KAAK6S,cAAcjM,GAAK5G,KAAKyD,OAAOqP,WAAe,EAAJlM,GAC5DA,EAAI,OACD6L,MAAM7L,IAAM5G,KAAK6S,cAAcjM,EAAI,GACtC5G,KAAKyD,OAAOqP,WAAsB,GAATlM,EAAI,GAAU,QAEpC6L,MAAM,IAAMzS,KAAK6S,cAAc7S,KAAKyD,OAAO+O,OAAS,GACvDxS,KAAKyD,OAAOqP,WAAiC,EAArB9S,KAAKyD,OAAO+O,OAAc,QAGnDC,MAAM7L,IAAMoO,EAAuBpO,MAC3B5G,KAAKyS,MAAM7L,MAEtB2B,OAAOC,MAAMiE,SACT,IAAI1M,MAAM,iBAEd0M,EAAY,OAAQ,KACjB,IAAI7F,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,OACtC6L,MAAM7L,IAAM6F,SAEZ,EAAIA,SAEN,2BAWesI,EAAIC,QACrB3B,aAAerT,KAAKqM,KAAK3L,YACzB,IAAIkC,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,EAAG,SACzCyJ,KAAKzJ,GAAK,EACoB,YAA/B5C,KAAKyD,OAAO8O,mBACT,IAAI3L,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,OACtCyF,KAAKzJ,IACR5C,KAAKyD,OAAOqP,WAAWlQ,GAAGgE,GAC1B5G,KAAKqT,aAAazM,GAClBoO,EAAuBpO,aAGtByF,KAAKzJ,IAAM5C,KAAKyD,OAAOqP,WAAe,EAAJlQ,GACrC5C,KAAKqT,aAAazQ,GAClBoS,EAAuBpS,GACrBA,EAAI5C,KAAKyD,OAAO+O,OAAS,SACtBnG,KAAKzJ,IAAM5C,KAAKyD,OAAOqP,WAAgB,EAAJlQ,EAAS,GAC/C5C,KAAKqT,aAAazQ,EAAI,GACtBoS,EAAuBpS,EAAI,SAG5ByJ,KAAKzJ,IAAMmS,GACZxM,OAAOC,MAAMxI,KAAKqM,KAAKzJ,KAAO/C,KAAK2H,IAAIxH,KAAKqM,KAAKzJ,MAASpB,EAAAA,UACvD6K,KAAKzJ,GAAK,kCAYIqS,EAAenT,SAChC6R,EAAIsB,EAAc5U,OAElB0U,EAAK,IAAIjU,MAAM6S,GAAG5S,KAAK,OACzB4K,OACC2I,iBACAC,iBAECW,EAA2BpU,MAAMQ,KACrC,IAAIR,MAAM6S,GACV,IAAM,IAAI7S,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,QAEtC,IAAIE,EAAI,EAAGA,EAAI0S,EAAG1S,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,IAClB3B,GAAG2B,GAC1B5C,KAAKyD,OAAOkP,QAAQ/P,GAAG0J,WAAW2I,EAAcpP,SAAS5E,MAK5D,GAAKjB,KAAKmV,2BAA2BF,EAAcpP,SAAS,OACpDhG,KAAKuO,IAAI2G,EAAG,SAClBT,SAAS7T,KAAKT,KAAKyS,MAAM/R,aAEzB,IAAIO,EAAI,EAAGA,EAAI0S,EAAG1S,GAAK,IACvBA,GAAKjB,KAAKoV,uBAAuBF,EAAyBjU,OAClDpB,KAAKuO,IAAI2G,EAAG9T,SAClBqT,SAAS7T,KAAKT,KAAKyS,MAAM/R,cAI3B2U,4BAA4BN,EAAGpB,EAAI,SACnCY,QAAQ9T,KAAKT,KAAKqM,KAAK3L,aAEvB,IAAIO,EAAI0S,EAAI,EAAG1S,GAAK,EAAGA,GAAK,OAC1BqU,wBAAwBP,EAAG9T,GAAIiU,EAAyBjU,EAAI,SAC5DsT,QAAQ9T,KAAKT,KAAKqM,KAAK3L,cAEzB6T,QAAQgB,cAGR,IAAItU,EAAI,EAAGA,EAAI0S,EAAG1S,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,OACtC4Q,cAAc1R,GAAab,GAAG2B,GAChC5C,KAAKsU,SAASrT,GAAG2B,GAAK5C,KAAKuU,QAAQtT,GAAG2B,GAAMmS,EAAG9T,OAKlDwL,MAEC,IAAIxL,EAAI,EAAGA,EAAI0S,EAAG1S,GAAK,MACrB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,EAAG,MAClC,EACkB,IAA1B5C,KAAKyD,OAAO0I,UAAiB,OACzBqJ,EAAKN,EAAyBjU,GAAG2B,QAClC8Q,wBAAwB5R,GAAa,GAAGb,GAAG2B,GAC9C5C,KAAKwT,cAAc1R,GAAab,GAAG2B,GAAK4S,KAC7BA,WAER,IAAIjQ,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,EAAG,OAC3CiQ,EAAKxV,KAAKyD,OAAOkP,QAAQ/P,GAC5B2J,oBAAoB0I,EAAcpP,SAAS5E,GAAIsE,QAC7CmO,wBAAwB5R,GAAayD,GAAGtE,GAAG2B,GAC9C5C,KAAKwT,cAAc1R,GAAab,GAAG2B,GACnC4S,KACWA,KAGb/I,EAAY,MACT,IAAIlH,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzCmO,wBAAwB5R,GAAayD,GAAGtE,GAAG2B,IAAM6J,KAO3B,YAA/BzM,KAAKyD,OAAO8O,mBACT,IAAItR,EAAI,EAAGA,EAAI0S,EAAI,EAAG1S,GAAK,MACzB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,MACtC,IAAIgE,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,OACtC6M,gBAAgB3R,GAAab,GAAG2B,GAAGgE,GACtC5G,KAAKsU,SAASrT,GAAG2B,GACjB5C,KAAKyD,OAAOqP,WAAWlQ,GAAGgE,GAC1B5G,KAAKuU,QAAQtT,EAAI,GAAG2F,QACjB6M,gBAAgB3R,GAAab,GAAG2B,GAAGgE,IACtCsO,EAAyBjU,EAAI,GAAG2F,YAKnC,IAAI3F,EAAI,EAAGA,EAAI0S,EAAI,EAAG1S,GAAK,MACzB,IAAI2B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,OACtC6Q,gBAAgB3R,GAAab,GAAO,EAAJ2B,GACnC5C,KAAKsU,SAASrT,GAAG2B,GACjB5C,KAAKyD,OAAOqP,WAAe,EAAJlQ,GACvB5C,KAAKuU,QAAQtT,EAAI,GAAG2B,QACjB6Q,gBAAgB3R,GAAab,GAAO,EAAJ2B,IACnCsS,EAAyBjU,EAAI,GAAG2B,GAC9BA,EAAI5C,KAAKyD,OAAO+O,OAAS,SACtBiB,gBAAgB3R,GAAab,GAAQ,EAAJ2B,EAAS,GAC7C5C,KAAKsU,SAASrT,GAAG2B,GACjB5C,KAAKyD,OAAOqP,WAAgB,EAAJlQ,EAAS,GACjC5C,KAAKuU,QAAQtT,EAAI,GAAG2B,EAAI,QACrB6Q,gBAAgB3R,GAAab,GAAQ,EAAJ2B,EAAS,IAC7CsS,EAAyBjU,EAAI,GAAG2B,EAAI,WAMvC+I,qBAQS1H,OACX,IAAIrB,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,EAAG,MACzCgR,SAAShR,GAAK,MACd,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzCsO,mBAAoBjR,EAAI5C,KAAKyD,OAAO0I,UAAa5G,GAAK,MAI3DzD,EAAc,IACNI,QAASE,QACd,IAAIQ,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,EAAG,MACpC2S,SAAShR,IACZ5C,KAAKwT,cAAc1R,GAAab,GAAG2B,OAChC,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzCsO,mBAAoBjR,EAAI5C,KAAKyD,OAAO0I,UAAa5G,IACpDvF,KAAK0T,wBAAwB5R,GAAayD,GAAGtE,GAAG2B,MAIzC,0CAUkBqB,OAC/BnC,EAAc,IACNI,QAASE,QACd,IAAIQ,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,MACjC,IAAIsE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAOkP,QAAQ/P,GAAGa,OAAO2I,cAAc7G,IAC1CvF,KAAK0T,wBAAwB5R,GAAayD,GAAGtE,GAAG2B,MAIzC,QAIZ,IAAIA,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,OACtCa,OAAOkP,QAAQ/P,GAAG6S,iDAUJxR,OAChB,IAAIrB,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,MACtC,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,OACzC9B,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GAAG1E,KAAKE,KAAK,OAKtDe,EAAc,IACNI,QAASE,QACd,IAAIQ,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,MACjC,IAAIsE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,MACzC,IAAIvE,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,OACzCyC,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GAAG1E,KAAKG,IAC/ChB,KAAK0T,wBAAwB5R,GAAayD,GAAGtE,GAAG2B,GAChDR,EAAOlB,IAAID,EAAGD,MAKT,QAIZ,IAAI4B,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,MACtC,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,MACzC,IAAIvE,EAAI,EAAGA,EAAIhB,KAAKyD,OAAOxD,UAAWe,GAAK,KAC1ChB,KAAK6T,mBAAoBjR,EAAI5C,KAAKyD,OAAO0I,UAAa5G,GAAK,SACxD9B,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GAAG1E,KAAKG,IAC/ChB,KAAK6T,mBAAoBjR,EAAI5C,KAAKyD,OAAO0I,UAAa5G,IAEtDgD,OAAOC,MAAMxI,KAAKyD,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GAAG1E,KAAKG,UAC1D,IAAIjB,MAAM,mDAaGkE,OACvBnC,EAAc,IACNI,QAASE,QACd,IAAIQ,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,MACtC,IAAI3B,EAAI,EAAGA,EAAImB,EAAO/B,OAAQY,GAAK,MACjC,IAAIsE,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,MACzC,IAAI6E,EAAK,EAAGA,EAAKpK,KAAKyD,OAAOxD,UAAWmK,GAAM,KACd,SAA/BpK,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAKD,EAAIC,EAAKrK,KAAKyD,OAAOxD,UAAWoK,GAAM,OAC7C5G,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GACtCwC,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,IAC3CrK,KAAK0T,wBAAwB5R,GAAayD,GAAGtE,GAAG2B,IAC/CR,EAAOlB,IAAID,EAAGmJ,GACbpK,KAAKyD,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GAAG1E,KAAKuJ,KAClDhI,EAAOlB,IAAID,EAAGoJ,GACbrK,KAAKyD,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GAAG1E,KAAKwJ,QAElD,OACCiE,EAAQlM,EAAOlB,IAAID,EAAGmJ,GAC1BpK,KAAKyD,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GAAG1E,KAAKuJ,QAC9C3G,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GAAGwC,WAAWqC,IACrDpK,KAAK0T,wBAAwB5R,GAAayD,GAAGtE,GAAG2B,GAC/C0L,GAAS,KAMP,QAIZ,IAAI1L,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,EAAG,KACzC,IAAI2C,EAAI,EAAGA,EAAIvF,KAAKyD,OAAO0I,UAAW5G,GAAK,KAC1CvF,KAAK6T,mBAAoBjR,EAAI5C,KAAKyD,OAAO0I,UAAa5G,GAAK,MACxD,IAAI6E,EAAK,EAAGA,EAAKpK,KAAKyD,OAAOxD,UAAWmK,GAAM,KACd,SAA/BpK,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAKD,EAAIC,EAAKrK,KAAKyD,OAAOxD,UAAWoK,GAAM,OAC7C5G,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GACtCwC,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,IAC3CrK,KAAK6T,mBAAoBjR,EAAI5C,KAAKyD,OAAO0I,UAAa5G,GACpD6E,IAAOC,SACJ5G,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GACtCwC,WAAYsC,EAAKrK,KAAKyD,OAAOxD,UAAamK,GAC3CpK,KAAKyD,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GACtCwC,WAAYqC,EAAKpK,KAAKyD,OAAOxD,UAAaoK,cAI9C5G,OAAOkP,QAAQ/P,GAAGa,OAAOyI,WAAW3G,GAAGwC,WAAWqC,IACrDpK,KAAK6T,mBAAoBjR,EAAI5C,KAAKyD,OAAO0I,UAAa5G,QAK3D9B,OAAOkP,QAAQ/P,GAAG8J,kBAClBjJ,OAAOkP,QAAQ/P,GAAG2K,oDASJtJ,QAChBR,OAAOiP,MAAM3R,KAAK,OAGnB2U,EAAW,MACV,IAAI5T,EAAc,EACrBA,EAAcmC,EAAYsP,OAC1BzR,GAAe,MACV,IAAIc,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,OACtCa,OAAOiP,MAAM9P,IAAM5C,KAAKwT,cAAc1R,GAAa,GAAGc,MAC/C5C,KAAKyD,OAAOiP,MAAM9P,QAK9B8S,EAAW,SAKP,IAAI3V,MAAM,kCAJX,IAAI6C,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,OACtCa,OAAOiP,MAAM9P,IAAM8S,gCAYDzR,QAEtBR,OAAOqP,WAA4C,YAA/B9S,KAAKyD,OAAO8O,eACnCzR,MAAMQ,KACJ,IAAIR,MAAMd,KAAKyD,OAAO+O,QACtB,IAAM,IAAI1R,MAAMd,KAAKyD,OAAO+O,QAAQzR,KAAK,IAE3C,IAAID,MAA2B,EAArBd,KAAKyD,OAAO+O,QAAYzR,KAAK,OAGrCe,EAAc,OACNI,QAASE,OACfA,EAAO/B,OAAS,MACb,IAAIuC,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,KAGR,cAA/B5C,KAAKyD,OAAO8O,sBACT9O,OAAOqP,WAAe,EAAJlQ,IAx1BD,KAy1BlBA,EAAI5C,KAAKyD,OAAO+O,OAAS,OACtB/O,OAAOqP,WAAgB,EAAJlQ,EAAS,IA11Bb,UA41Bfa,OAAOqP,WAAe,EAAJlQ,IA51BH,MAg2BW,YAA/B5C,KAAKyD,OAAO8O,mBACT,IAAI3L,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,MACtC,IAAI3F,EAAI,EAAGA,EAAImB,EAAO/B,OAAS,EAAGY,GAAK,OACrCwC,OAAOqP,WAAWlQ,GAAGgE,IACxB5G,KAAKyT,gBAAgB3R,GAAab,GAAG2B,GAAGgE,OAGzC,KACA,IAAI3F,EAAI,EAAGA,EAAImB,EAAO/B,OAAS,EAAGY,GAAK,OACrCwC,OAAOqP,WAAe,EAAJlQ,IACrB5C,KAAKyT,gBAAgB3R,GAAab,GAAO,EAAJ2B,MAErCA,EAAI5C,KAAKyD,OAAO+O,OAAS,MACtB,IAAIvR,EAAI,EAAGA,EAAImB,EAAO/B,OAAS,EAAGY,GAAK,OACrCwC,OAAOqP,WAAgB,EAAJlQ,EAAS,IAC/B5C,KAAKyT,gBAAgB3R,GAAab,GAAQ,EAAJ2B,EAAS,MAM5C,IAIkB,YAA/B5C,KAAKyD,OAAO8O,oBACT,IAAI3P,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,MACtC,IAAIgE,EAAI,EAAGA,EAAI5G,KAAKyD,OAAO+O,OAAQ5L,GAAK,UACtCnD,OAAOqP,WAAWlQ,GAAGgE,IACvB5G,KAAK4T,SAAShR,GAAM,KACnB2F,OAAOC,MAAMxI,KAAKyD,OAAOqP,WAAWlQ,GAAGgE,UACnC,IAAI7G,MAAM,wFAKjB,IAAI6C,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,EAAG,SACzCa,OAAOqP,WAAe,EAAJlQ,IACpB5C,KAAK4T,SAAShR,GAAM,KACnB2F,OAAOC,MAAMxI,KAAKyD,OAAOqP,WAAe,EAAJlQ,UAChC,IAAI7C,MAAM,kFAEd6C,EAAI5C,KAAKyD,OAAO+O,OAAS,SACtB/O,OAAOqP,WAAgB,EAAJlQ,EAAS,IAC9B5C,KAAK4T,SAAShR,GAAM,KACnB2F,OAAOC,MAAMxI,KAAKyD,OAAOqP,WAAgB,EAAJlQ,EAAS,WAC1C,IAAI7C,MAAM,kFC/4B5B,MAAM4V,EAAmB,CAACnD,EAAQD,wBAEpB,SACDhR,IAAK,yBAGJ,SACDA,IAAK,8BAGJ,QACH,EAAGoM,SAAAA,EAAUC,SAAAA,KACjBD,GAAYC,GAAYD,EAAW,GAAKC,EAAW,6BAG5C,SACF,UAAW,wCAGT,SACF,OAAQ,8BAGN,QACH8C,GAAwB,cAAnB6B,GAAkC7B,EAAErQ,SAAWmS,yBAGjD,QACH9B,GAAyB,cAAnB6B,EACX7B,EAAErQ,SAAW,EAAImS,EACjB9B,EAAErQ,SAAWmS,sBAGL,QACH9B,GAAKA,EAAErQ,SAAWmS,KAUvBoD,uBACgB,kBACJ,sBAQTnS,OAAOkP,QAAU3S,KAAKyD,OAAOkP,QAAQ9P,IAAIuQ,GAAKhB,EAAagB,GAAGvC,SAC5D7Q,0BAQF0P,iBAAiBJ,aACjB7L,OAAOkP,QAAQzQ,QAASkR,MAAUvC,UAChC7Q,iBAQEQ,SACHuU,EAAM/U,KAAK4S,mBACf5S,KAAK6V,uBAAuBrV,GAC5BR,KAAKmV,2BAA2B3U,eAC7BsV,yBACAC,iBACE,EAAIhB,yBAINjI,QAAQkJ,SAAW,MACnB,IAAIpT,EAAI5C,KAAKiW,eAAgBrT,EAAI5C,KAAKkW,eAAgBtT,GAAK,EAC1D5C,KAAKmW,oBACFrJ,QAAQkJ,WAAahW,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,GAAK5C,KAAKqW,OAAOzT,KACpEA,EAAI5C,KAAKsW,kCAEPxJ,QAAQkJ,UAAahW,KAAKyS,MAAM7P,GAAKA,EACxC5C,KAAKsW,iCAGNxJ,QAAQkJ,UAAYhW,KAAKyD,OAAO+O,OAAS,4BASzC1F,QAAQyJ,eAAiB,MAE1BC,EAAYxW,KAAKmW,eAClBnW,KAAKyS,MAAM,GAAKzS,KAAKoW,OAAO,GAC7BpW,KAAKyS,MAAM,OACR,IAAI7P,EAAI,EAAGA,EAAI5C,KAAKyD,OAAO+O,OAAQ5P,GAAK,EACvC5C,KAAKmW,eACFnW,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,GAAM4T,MACzBxW,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,QACnCkK,QAAQyJ,eAAiB3T,GAEvB5C,KAAKyS,MAAM7P,GAAK4T,MACbxW,KAAKyS,MAAM7P,QAClBkK,QAAQyJ,eAAiB3T,QAK7BqT,eAAiBjW,KAAK8M,QAAQyJ,eAAiB1W,KAAKC,MAAME,KAAKyD,OAAO+O,OAAS,QAC/E0D,eAAiBlW,KAAK8M,QAAQyJ,eAAiB1W,KAAKC,MAAME,KAAKyD,OAAO+O,OAAS,QAC/EyD,eAAkBjW,KAAKiW,gBAAkB,EAAKjW,KAAKiW,eAAiB,OACpEC,eAAkBlW,KAAKkW,gBAAkBlW,KAAKyD,OAAO+O,OACxDxS,KAAKkW,eAAiBlW,KAAKyD,OAAO+O,YAC/B8D,4BAA8B,MAC9B,IAAI1T,EAAI5C,KAAKiW,eAAgBrT,EAAI5C,KAAKkW,eAAgBtT,GAAK,OACzD0T,6BAA+BtW,KAAKmW,eACtCnW,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,GAC7B5C,KAAKyS,MAAM7P,KAUb6T,cASO3M,WACJgD,QAAQC,aAAejM,MAAMd,KAAKyD,OAAO7C,iBAAiBG,KAAK,QAC/D+L,QAAQtC,iBAAmB1J,MAAqC,SAA/Bd,KAAKyD,OAAOqE,eAA4B9H,KAAKyD,OAAO7C,iBAAmB,EAAIZ,KAAKyD,OAAO7C,iBAAiBG,KAAK,GAE3G,cAApCf,KAAKyD,OAAOiT,gCACTjT,OAAOkP,QAAQ3S,KAAK8M,QAAQyJ,gBAAgBxF,QAAQjH,QACpDgD,QAAQC,aACX/M,KAAKyD,OAAOkP,QAAQ3S,KAAK8M,QAAQyJ,gBAAgBzJ,QAAQC,aACpD/M,KAAK8M,QAAQC,mBAGhB4J,EAAoD,SAApC3W,KAAKyD,OAAOiT,oBAChC,EAAI1W,KAAKiW,eACLW,EAAoD,SAApC5W,KAAKyD,OAAOiT,oBAChC1W,KAAKyD,OAAO+O,OAASxS,KAAKkW,mBACxBW,EAA6D,SAApC7W,KAAKyD,OAAOiT,oBACvC,EAAI1W,KAAKsW,4BAEPO,GAAyB,IAAKA,EAAwB,OAGrD,IAAIjU,EAAI+T,EAAc/T,EAAIgU,EAAchU,GAAK,EAAG,MAC9Ca,OAAOkP,QAAQ/P,GAAG0J,WAAWxC,QAC7BrG,OAAOkP,QAAQ/P,GAAGoK,WAAWlD,SAC5BgN,EAAqB9W,KAAKyD,OAAOkP,QAAQ/P,GAAGkK,QAAQC,iBACrD,IAAI/L,EAAI,EAAGA,EAAIhB,KAAKyD,OAAO7C,gBAAiBI,GAAK,KAChDhB,KAAKmW,uBACFrJ,QAAQC,aAAa/L,KACvBhB,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,KAC5BkU,EAAmB9V,GAAK6V,GACQ,SAA/B7W,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKrK,KAAKyD,OAAO7C,gBAAiByJ,GAAM,OAClDyC,QAAQtC,iBAAkBxJ,EAAIhB,KAAKyD,OAAO7C,gBAAmByJ,KAC/DrK,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,KAC5B5C,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,KAC5B5C,KAAKyD,OAAOkP,QAAQ/P,GAAGkK,QACrBtC,iBAAkBxJ,EAAIhB,KAAKyD,OAAO7C,gBAAmByJ,GACxDwM,aAGC/J,QAAQtC,iBAAiBxJ,KAC3BhB,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,KAC5B5C,KAAKyS,MAAM7P,GAAK5C,KAAKoW,OAAOxT,KAC5B5C,KAAKyD,OAAOkP,QAAQ/P,GAAGkK,QAAQtC,iBAAiBxJ,GACjD6V,gBAGC/J,QAAQC,aAAa/L,IAAMhB,KAAKyS,MAAM7P,IACxCkU,EAAmB9V,GAAK6V,GACQ,SAA/B7W,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKrK,KAAKyD,OAAO7C,gBAAiByJ,GAAM,OAClDyC,QAAQtC,iBAAkBxJ,EAAIhB,KAAKyD,OAAO7C,gBAAmByJ,IAC/DrK,KAAKyS,MAAM7P,IAAM,GACjB5C,KAAKyD,OAAOkP,QAAQ/P,GAAGkK,QACrBtC,iBAAkBxJ,EAAIhB,KAAKyD,OAAO7C,gBAAmByJ,GACxDwM,aAGC/J,QAAQtC,iBAAiBxJ,IAC1BhB,KAAKyS,MAAM7P,IAAM,EACnB5C,KAAKyD,OAAOkP,QAAQ/P,GAAGkK,QAAQtC,iBAAiBxJ,GAChD6V,SAKH7W,KAAK8M,QAAQC,eCxNxB,MAOMgK,uBAQgB,gBAQZC,EAAahX,KAAKuT,mBACnB9P,OAAOiP,MAAQ,IAAI5R,MAAMkW,GAAYjW,KAAK,EAAIiW,QAC9CvT,OAAOqP,WAAahS,MAAMQ,KAC7B,IAAIR,MAAMkW,GACV,IAAM,IAAIlW,MAAMkW,GAAYjW,KAAK,EAAIiW,SAElCvT,OAAOwT,eAAiB,IAAInW,MAAMkW,GAAYjW,KAAK,WACjDkP,OAAOjQ,KAAKwO,QAAQtM,QAASmE,IACxBA,EACR8P,gBAAiB,SAEhBe,0BACElX,8BASemX,SAChBC,OAAkC9U,IAAtB6U,EAChBA,EACA,IAAIrW,MAAMd,KAAKyD,OAAO+O,OAAS,GAAGzR,KAAK,GACpCR,QAhDkC,YAiDhCqB,KAAK5B,KAAKwO,QAAQtM,QAASC,SAC3BqM,OAAOrM,GAAOsB,OAAO0T,kBAAoBC,EAAS1W,0BASlDuP,OAAOjQ,KAAKwO,QAAQtM,QAAQwO,GAAKA,EAAEG,cACrC/D,uJAOQ,iBAGT9M,KAAKyD,OAAOvD,cACT4Q,oBAEF8B,oBAAqB,WAOpBpS,MACFR,KAAK4S,wBACFiD,uBAAuBrV,QAEvB2U,2BAA2B3U,UAE3BoB,KAAK5B,KAAKwO,QAAQyC,OAAO/O,QAASC,UACjCkE,EAAQrG,KAAKwO,OAAOrM,KACpB2T,sBACAC,mBACApG,cAActJ,EAAMyG,QAAQ8C,0BAE/BD,gBAED3P,KAAKyD,OAAOvD,kBACP+P,OAAOjQ,KAAKwO,QAAQtM,QAAQwO,GAAKA,EAAE1D,WAAWxM,IAEH,cAA9CR,KAAKyD,OAAOsO,mCACTjF,QAAQC,aACX/M,KAAKwO,OAAOxO,KAAK8M,QAAQ2E,WAAW3E,QAAQC,kBACzCD,QAAQtC,iBACXxK,KAAKwO,OAAOxO,KAAK8M,QAAQ2E,WAAW3E,QAAQtC,qBACzC,MACAsC,QAAQC,aAAe,IAAIjM,MAAMd,KAAKY,iBAAiBG,KAAK,QAC5D+L,QAAQtC,iBACX,IAAI1J,MAAqC,SAA/Bd,KAAKyD,OAAOqE,eACpB9H,KAAKY,iBAAmB,EACxBZ,KAAKY,iBAAiBG,KAAK,OAE3BsW,EAAa,SACVpH,OAAOjQ,KAAKwO,QAAQtM,QAASmE,QAC7B,IAAIrF,EAAI,EAAGA,EAAIhB,KAAKY,gBAAiBI,GAAK,UACxC8L,QAAQC,aAAa/L,IACxBhB,KAAK8M,QAAQ6E,8BAA8B0F,GAC3ChR,EAAMiR,OAAOxK,QAAQC,aAAa/L,GAED,SAA/BhB,KAAKyD,OAAOqE,mBACT,IAAIuC,EAAK,EAAGA,EAAKrK,KAAKY,gBAAiByJ,GAAM,OAC3CyC,QAAQtC,iBAAkBxJ,EAAIhB,KAAKY,gBAAmByJ,IACzDrK,KAAK8M,QAAQ6E,8BAA8B0F,GAC3ChR,EAAMyG,QAAQtC,iBAAkBxJ,EAAIhB,KAAKY,gBAAmByJ,aAG3DyC,QAAQtC,iBAAiBxJ,IAC5BhB,KAAK8M,QAAQ6E,8BAA8B0F,GAC3ChR,EAAMiR,OAAOxK,QAAQtC,iBAAiBxJ,MAG9B,iCAWKR,OACrBiM,EAAY,EACZ4K,EAAa,QACXvI,EAAUnN,OAAOC,KAAK5B,KAAKwO,QAAQyC,SACjC/O,QAASC,UACTkE,EAAQrG,KAAKwO,OAAOrM,GACpBoV,EAAIlR,EAAM5C,OAAO+O,YACjB4D,OAAS,IAAItV,MAAMyW,GAAGxW,KAAK,KAC3BsV,OAAS,IAAIvV,MAAMyW,GAAGxW,KAAK,GAIG,YAAhCsF,EAAM5C,OAAO8O,eAA8B,GACvCzF,QAAQ8C,kBAAoB,MAC7B,IAAIhN,EAAI,EAAGA,EAAI2U,EAAG3U,GAAK,IACpB6P,MAAM7P,GAAK5C,KAAKyD,OAAOiP,MAAM2E,GACjChR,EAAM5C,OAAOiP,MAAM9P,GACnByD,EAAM5C,OAAOkP,QAAQ/P,GAAG0J,WAAW9L,KAC/BsM,QAAQ8C,mBAAqBvJ,EAAMoM,MAAM7P,UAG3C6P,MAAM,GAAKzS,KAAKyD,OAAOiP,MAAM2E,GACjChR,EAAM5C,OAAOkP,QAAQ,GAAGrG,WAAW9L,IACpC6F,EAAMyG,QAAQ8C,mBAAqBvJ,EAAMoM,SAE/BpM,EAAMyG,QAAQ8C,qBACb,MAGR1N,QAASC,UACTkE,EAAQrG,KAAKwO,OAAOrM,GACpBoV,EAAIlR,EAAM5C,OAAO+O,WAClB,IAAI5P,EAAI,EAAGA,EAAI2U,EAAG3U,GAAK,IACpB6P,MAAM7P,IAAM6J,SAKjB+K,WAAa,IAAI1W,MAAMd,KAAKuT,MAAMxS,KAAK,QACvC0W,WAAa,IAAI3W,MAAMd,KAAKuT,MAAMxS,KAAK,QACvC6R,oBAAqB,0BAQLpS,OACjBiM,EAAY,EAGZ9E,EAAM,OAIL6P,WAAaxX,KAAK0X,gBAAgB,QAClCD,WAAazX,KAAK0X,gBAAgB,OAInCC,EAAgB,QACd7I,EAAUnN,OAAOC,KAAK5B,KAAKwO,QAAQyC,SACjC/O,QAASC,UACTyV,EAAW5X,KAAKwO,OAAOrM,GACvBoV,EAAIK,EAASnU,OAAO+O,OAKpBqF,EAAQ,IAAI/W,MAAMyW,GAAGxW,KAAK,MAEO,YAAnC6W,EAASnU,OAAO8O,mBACb,IAAIvN,EAAI,EAAGA,EAAIuS,EAAGvS,GAAK,EAAG,KACxB,IAAI4B,EAAI,EAAGA,EAAI2Q,EAAG3Q,GAAK,IACpB5B,IAAO4S,EAASnU,OAAOqP,WAAWlM,GAAG5B,IACxC,EAAI4S,EAASnU,OAAO0T,kBAAkBvQ,IACrCgR,EAASnF,MAAM7L,OAInB,IAAIkR,EAAgB,EACpBA,EAAgB9X,KAAKuT,OACrBuE,GAAiB,IAEX9S,IAAM4S,EAASnU,OAAOiP,MAAM1N,IAC/BhF,KAAKwX,WAAWM,GACjB9X,KAAKyD,OAAOqP,WAAWgF,GAAeH,GACrC3X,KAAKyD,OAAOiP,MAAMiF,GACnB3X,KAAKyX,WAAWK,QAIjB,GAEC,GAAKF,EAASnU,OAAOqP,WAAW,GAAK8E,EAASnF,MAAM,OAGxD,IAAIqF,EAAgB,EACpBA,EAAgB9X,KAAKuT,OACrBuE,GAAiB,IAEX,IAAO9X,KAAKwX,WAAWM,GAC3B9X,KAAKyD,OAAOqP,WAAWgF,GAAeH,GACrC3X,KAAKyD,OAAOiP,MAAMiF,GACjB3X,KAAKyX,WAAWK,OAIjB,IAAI9S,EAAI,EAAGA,EAAIuS,EAAGvS,GAAK,IACpBA,IAAO4S,EAASnU,OAAOqP,WAAe,EAAJ9N,IACrC,EAAI4S,EAASnU,OAAO0T,kBAAkBnS,IACvC4S,EAASnF,MAAMzN,KACXA,IAAO4S,EAASnU,OAAOqP,WAAsB,GAAT9N,EAAI,GAAU,IACrD,EAAI4S,EAASnU,OAAO0T,kBAAkBnS,EAAI,IAC3C4S,EAASnF,MAAMzN,EAAI,OAGlB,IAAIA,EAAI,EAAGA,EAAIuS,EAAGvS,GAAK,IACjByN,MAAMzN,GAAK,IACXoR,OAAOpR,GAAK,IACZqR,OAAOrR,GAAK,IAMhB8H,QAAQiL,eAAiB,IACzBjL,QAAQ8C,kBAAoB,MAGhC,IAAI5K,EAAI,EAAGA,EAAIuS,EAAGvS,GAAK,IACpB4S,EAASnU,OAAOkP,QAAQ3N,GAAGsH,WAAW9L,GAAeqX,EAAM7S,KACxDqR,OAAOrR,GAAKhF,KAAKyD,OAAOwT,eAAeU,GAC9CC,EAASnU,OAAO0T,kBAAkBnS,GAAK2C,IAChCyO,OAAOpR,IAAM,EAAIhF,KAAKyD,OAAOwT,eAAeU,IACnDC,EAASnU,OAAO0T,kBAAkBnS,GAAK2C,IAChC8K,MAAMzN,IAAM,EAAI4S,EAASnU,OAAO0T,kBAAkBnS,IAAM2C,IAExDmF,QAAQiL,gBAAkBH,EAASxB,OAAOpR,GAAK4S,EAASvB,OAAOrR,KAC/D8H,QAAQ8C,mBAAqBgI,EAASnF,MAAMzN,GACnD4S,EAASxB,OAAOpR,GAAK4S,EAASvB,OAAOrR,MAC1B2C,IAGNmF,QAAQkL,UAAYJ,EAAS9K,QAAQiL,eAC5CH,EAAS9K,QAAQ8C,qBAEF,MAGX1N,QAASC,UACTkE,EAAQrG,KAAKwO,OAAOrM,GACpBoV,EAAIlR,EAAM5C,OAAO+O,WAClB,IAAIxN,EAAI,EAAGA,EAAIuS,EAAGvS,GAAK,IACpByN,MAAMzN,IAAMyH,IACZ2J,OAAOpR,IAAMyH,IACb4J,OAAOrR,IAAMyH,qBAUTwL,SACRC,EAAmB,IAAIpX,MAAMd,KAAKuT,QAAQxS,KAAK,MACjDkX,EAAU,EAAG,KAEXZ,EAAa,SACVzV,KAAK5B,KAAKwO,QAAQyC,OAAO/O,QAASC,UACjCkE,EAAQrG,KAAKwO,OAAOrM,KACTkV,GAAc,MAC1B,IAAIrS,EAAI,EAAGA,EAAIqB,EAAM5C,OAAO+O,OAAQxN,GAAK,IAC3BqS,IAAehR,EAAMiR,OAAO7E,MAAMzN,GACjDqB,EAAMiR,OAAOlB,OAAOpR,GACpBqB,EAAMiR,OAAOjB,OAAOrR,MAEV,QAEX,KAEDqS,EAAa,SACVzV,KAAK5B,KAAKwO,QAAQyC,OAAO/O,QAASC,UACjCkE,EAAQrG,KAAKwO,OAAOrM,KACTkV,GAAc,MAC3B5E,MAAEA,GAAUpM,EACA,IAAZ4R,MACM5R,EAAM+P,QAEA,IAAZ6B,MACM5R,EAAMgQ,YAEX,IAAIrR,EAAI,EAAGA,EAAIqB,EAAM5C,OAAO+O,OAAQxN,GAAK,IAC3BqS,IAAe5E,EAAMzN,MAE1B,WAGXkT,IChTJ,SAASC,EACdlU,EACA+N,EACAnG,SAEM1L,eAAEA,EAAFS,gBAAkBA,GAAoBqD,GACtCuO,SAAArG,YAAA1D,iBAAA8J,iBAAAzK,kBAMFkK,SHu3BS,SACbzO,EACAiP,EAAS,EACTrG,EAAY,EACZ1D,GAAmBkF,SAAU,KAAMC,SAAU,KAC7C2E,EAAiB,YACjBzK,EAAiB,YAEZnG,OAAOC,KAAK2B,GAAGxB,SAAS,gBACrB,IAAIhC,MAAM,sGAEX4B,OAAOa,OACZe,EACAyP,eAGOzP,EAAEE,oFGt4BG2U,CACZpM,EACE+G,EAAY1P,yCAGP2O,KAELnG,GAEF2G,EACArG,EACA1D,EACA8J,EACAzK,GAEWgG,MAAM7J,GAiCd,SAASoU,EACd5U,EACAgM,SAEMpJ,EFkIO,SAA2B9C,OACnCD,EAAYC,SACT,IAAIxD,MAAM,wGAEC,MAAO4V,EAAiBpS,EAAEE,OAAO+O,OAAQjP,EAAEE,OAAO8O,gBAAiBhP,EAAEE,QACjF9B,OAAOa,OACZe,EACAqS,EACArS,EAAEE,OAAOvD,QAAUuW,YAEV,IAAI3V,MAAMyC,EAAEE,OAAO+O,QAAQzR,KAAK,mBACtB,IAAID,MAAMyC,EAAEE,OAAO+O,QAAQzR,KAAK,KAEnDuX,QE/IYC,CAAkBzI,EAC9BiD,EAAY1P,EAAUI,IACtBgM,aAEIoB,QACCxK,gCC/FM,SACbpC,EACAG,EACAC,SAEMlE,eAAEA,EAAFS,gBAAkBA,GAAoBqD,SAC9BkC,EACZ9C,wCAIAe,EACAC,GAEWyJ,MAAM7J,sCN0Cd,SACLA,EACA+N,EACAnG,SAEM1L,eAAEA,EAAFS,gBAAkBA,GAAoBqD,SAC9B0K,EACZF,KAAsBtO,eAAAA,EAAgBS,gBAAAA,GAAoBoR,IAC1DhP,GAAMkP,EAASlP,EAAIgP,EAAenG,IAEvBiC,MAAM7J,8CAmCd,SACLR,EACAgM,SAEMpJ,EAAQ4L,EAAyBxD,EAAoBhL,aACrD+K,iBACC5M,KAAK6B,EAAOqL,SAAS5M,QAASC,MAC7BqM,OAAOrM,GAASiQ,EAAa3O,EAAOqL,QAAQ3M,GAAQsN,OAEtDoB,QACCxK,qCK5CF,SACLpC,EACA+N,EACAnG,SAEM1L,eAAEA,EAAFS,gBAAkBA,GAAoBqD,SAC9B0K,EACZF,KAAsBtO,eAAAA,EAAgBS,gBAAAA,GAAoBoR,IAC1DhP,GAAMmV,EAASnV,EAAIgP,EAAenG,IAEvBiC,MAAM7J,8CA4Bd,SACLR,EACAgM,SAEMpJ,EAAQ4L,EAAyBxD,EAAoBhL,aACrD+K,iBACC5M,KAAK6B,EAAOqL,SAAS5M,QAASC,MAC7BqM,OAAOrM,GAASkW,EAAa5U,EAAOqL,QAAQ3M,GAAQsN,OAEtDoB,QACCxK,8BAUF,SACL5C,EACAgM,OAEIpJ,EAAQoI,EAAoBhL,YAC1B+K,iBACC5M,KAAK6B,EAAOqL,SAAS5M,QAASC,MAC7BqM,OAAOrM,GAASkW,EAAa5U,EAAOqL,QAAQ3M,GAAQsN,QDuN/C,SAAuClM,OAC/CD,EAAYC,SACT,IAAIxD,MAAM,sGAOX4B,OAAOa,OACZe,EACAwT,MAKAuB,QCrOME,CAA8BvG,EAAyB5L,KACzDwK,QACCxK"}